<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>PlanetTogether Knowledge Base</title>
  <style>
    @page {
      size: A4;
      margin: 20mm 15mm 25mm 15mm;
    }
    
    * {
      box-sizing: border-box;
    }
    
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      font-size: 11pt;
      line-height: 1.5;
      color: #1a1a1a;
      max-width: 100%;
      margin: 0;
      padding: 20px;
    }
    
    h1 {
      color: #0a3d62;
      font-size: 28pt;
      text-align: center;
      margin-bottom: 10px;
      page-break-after: avoid;
    }
    
    .subtitle {
      text-align: center;
      color: #666;
      font-size: 12pt;
      margin-bottom: 30px;
    }
    
    .toc {
      background: #f8f9fa;
      border: 1px solid #dee2e6;
      border-radius: 8px;
      padding: 20px 30px;
      margin-bottom: 40px;
      page-break-after: always;
    }
    
    .toc h2 {
      color: #0a3d62;
      margin-top: 0;
      font-size: 18pt;
      border-bottom: 2px solid #0a3d62;
      padding-bottom: 10px;
    }
    
    .toc ul {
      list-style: none;
      padding-left: 0;
      margin: 0;
    }
    
    .toc-category {
      margin: 15px 0 5px 0;
    }
    
    .toc-category > a {
      font-weight: bold;
      color: #0a3d62;
      font-size: 12pt;
      text-decoration: none;
    }
    
    .toc-category > a:hover {
      text-decoration: underline;
    }
    
    .toc-category > ul {
      padding-left: 20px;
      margin-top: 5px;
    }
    
    .toc-article {
      margin: 3px 0;
    }
    
    .toc-article a {
      color: #495057;
      text-decoration: none;
      font-size: 10pt;
    }
    
    .toc-article a:hover {
      color: #0a3d62;
      text-decoration: underline;
    }
    
    .category-header {
      color: #0a3d62;
      font-size: 20pt;
      border-bottom: 3px solid #0a3d62;
      padding-bottom: 8px;
      margin-top: 40px;
      page-break-after: avoid;
    }
    
    .article {
      margin-bottom: 30px;
      padding: 15px 0;
      border-bottom: 1px solid #e9ecef;
      page-break-inside: avoid;
    }
    
    .article-title {
      color: #2c3e50;
      font-size: 14pt;
      margin-bottom: 8px;
      page-break-after: avoid;
    }
    
    .source-url {
      font-size: 9pt;
      color: #6c757d;
      margin-bottom: 10px;
    }
    
    .source-url a {
      color: #0a3d62;
    }
    
    .article-content {
      font-size: 10.5pt;
      line-height: 1.6;
    }
    
    .article-content h1,
    .article-content h2,
    .article-content h3,
    .article-content h4 {
      color: #2c3e50;
      margin-top: 15px;
      margin-bottom: 8px;
      page-break-after: avoid;
    }
    
    .article-content h1 { font-size: 14pt; }
    .article-content h2 { font-size: 13pt; }
    .article-content h3 { font-size: 12pt; }
    .article-content h4 { font-size: 11pt; }
    
    .article-content p {
      margin: 8px 0;
    }
    
    .article-content ul,
    .article-content ol {
      margin: 10px 0;
      padding-left: 25px;
    }
    
    .article-content li {
      margin: 4px 0;
    }
    
    .article-content a {
      color: #0a3d62;
      text-decoration: underline;
    }
    
    .article-content code {
      background: #f4f4f4;
      padding: 2px 6px;
      border-radius: 3px;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 9.5pt;
    }
    
    .article-content pre {
      background: #f4f4f4;
      padding: 12px;
      border-radius: 5px;
      overflow-x: auto;
      font-size: 9pt;
      line-height: 1.4;
    }
    
    .article-content table {
      border-collapse: collapse;
      width: 100%;
      margin: 15px 0;
      font-size: 10pt;
    }
    
    .article-content th,
    .article-content td {
      border: 1px solid #dee2e6;
      padding: 8px 10px;
      text-align: left;
    }
    
    .article-content th {
      background: #f8f9fa;
      font-weight: bold;
    }
    
    .article-content img {
      max-width: 100%;
      height: auto;
    }
    
    .article-content blockquote {
      border-left: 4px solid #0a3d62;
      margin: 15px 0;
      padding: 10px 15px;
      background: #f8f9fa;
      font-style: italic;
    }
    
    .footer {
      text-align: center;
      font-size: 9pt;
      color: #6c757d;
      margin-top: 40px;
      padding-top: 20px;
      border-top: 1px solid #dee2e6;
    }
  </style>
</head>
<body>
  <h1>PlanetTogether Knowledge Base</h1>
  <p class="subtitle">Complete Reference Guide - Generated December 12, 2025</p>
  <p class="subtitle">184 Articles across 45 Categories</p>
  
  <nav class="toc">
    <h2>Table of Contents</h2>
    <ul>
      <li class="toc-category"><a href="#cat-ai-chatbots">AI Chatbots</a><ul><li class="toc-article"><a href="#article-262-planettogether-bot-library">PlanetTogether Bot Library</a></li><li class="toc-article"><a href="#article-343-planettogether-knowledge-base-v12">PlanetTogether Knowledge Base V12</a></li></ul></li><li class="toc-category"><a href="#cat-boards">Boards</a><ul><li class="toc-article"><a href="#article-273-activities-board">Activities Board</a></li><li class="toc-article"><a href="#article-289-buffer-management-board">Buffer Management Board</a></li><li class="toc-article"><a href="#article-245-capacity-planning-board">Capacity Planning Board</a></li><li class="toc-article"><a href="#article-196-customers-board">Customers Board</a></li><li class="toc-article"><a href="#article-284-database-manager-board">Database Manager Board</a></li><li class="toc-article"><a href="#article-247-gantt-board">Gantt Board</a></li><li class="toc-article"><a href="#article-242-grid-edit-mode">Grid Edit Mode</a></li><li class="toc-article"><a href="#article-288-import-mappings-board">Import Mappings Board</a></li><li class="toc-article"><a href="#article-304-inventory-plan-board">Inventory Plan Board</a></li><li class="toc-article"><a href="#article-212-jobs-board">Jobs Board</a></li><li class="toc-article"><a href="#article-329-kpis-board">KPIs Board</a></li><li class="toc-article"><a href="#article-182-materials-board">Materials Board</a></li><li class="toc-article"><a href="#article-267-metrics-board">Metrics Board</a></li><li class="toc-article"><a href="#article-317-object-bulk-edit-tiles">Object Bulk Edit Tiles</a></li><li class="toc-article"><a href="#article-183-purchase-orders-board">Purchase Orders Board</a></li><li class="toc-article"><a href="#article-265-routing-templates-board">Routing Templates Board</a></li><li class="toc-article"><a href="#article-286-sales-orders-board">Sales Orders Board</a></li><li class="toc-article"><a href="#article-297-scenario-data-board">Scenario Data Board</a></li><li class="toc-article"><a href="#article-248-sequence-planning-board">Sequence Planning Board</a></li><li class="toc-article"><a href="#article-311-storage-areas-board">Storage Areas Board</a></li></ul></li><li class="toc-category"><a href="#cat-boards-grid-properties">Boards &gt; Grid Properties</a><ul><li class="toc-article"><a href="#article-205-capacity-planning-board-grid-properties">Capacity Planning Board Grid Properties</a></li><li class="toc-article"><a href="#article-285-customers-board-grid-properties">Customers Board Grid Properties</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-analytics">Concepts &gt; Analytics</a><ul><li class="toc-article"><a href="#article-306-analytics-with-power-bi">Analytics with Power BI</a></li><li class="toc-article"><a href="#article-180-predictive-kpi-tiles">Predictive KPI Tiles</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-constraints">Concepts &gt; Constraints</a><ul><li class="toc-article"><a href="#article-300-allowed-helpers">Allowed Helpers</a></li><li class="toc-article"><a href="#article-346-compatibility-codes">Compatibility Codes</a></li><li class="toc-article"><a href="#article-315-item-compatibility">Item Compatibility</a></li><li class="toc-article"><a href="#article-171-resource-connectors">Resource Connectors</a></li><li class="toc-article"><a href="#article-243-storage-area-connectors">Storage Area Connectors</a></li><li class="toc-article"><a href="#article-179-successor-manufacturing-orders">Successor Manufacturing Orders</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-custom-object-properties">Concepts &gt; Custom Object Properties</a><ul><li class="toc-article"><a href="#article-264-attributes">Attributes</a></li><li class="toc-article"><a href="#article-211-user-defined-fields-udfs">User Defined Fields (UDFs)</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-jobs">Concepts &gt; Jobs</a><ul><li class="toc-article"><a href="#article-189-alternate-paths">Alternate Paths</a></li><li class="toc-article"><a href="#article-260-job-details-dialog">Job Details Dialog</a></li><li class="toc-article"><a href="#article-299-job-structure">Job Structure</a></li><li class="toc-article"><a href="#article-230-stock-materials-bill-of-materials">Stock Materials (Bill of Materials)</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-manual-scheduling">Concepts &gt; Manual Scheduling</a><ul><li class="toc-article"><a href="#article-345-compress-the-schedule">Compress the Schedule</a></li><li class="toc-article"><a href="#article-294-locking-and-anchoring">Locking and Anchoring</a></li><li class="toc-article"><a href="#article-279-splitting-and-joining-jobs-manufacturing-orders-an">Splitting and Joining Jobs, Manufacturing Orders, and Operations</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-modeling-techniques">Concepts &gt; Modeling Techniques</a><ul><li class="toc-article"><a href="#article-348-multi-plant-data-model">Multi-Plant Data Model</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-planning">Concepts &gt; Planning</a><ul><li class="toc-article"><a href="#article-250-mps-mrp-optimize-plan-settings">MPS/MRP Optimize Plan Settings</a></li><li class="toc-article"><a href="#article-302-mps-mrp-planning">MPS/MRP Planning</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-publishing">Concepts &gt; Publishing</a><ul><li class="toc-article"><a href="#article-323-export-and-publish-overview">Export and Publish Overview</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-reporting">Concepts &gt; Reporting</a><ul><li class="toc-article"><a href="#article-206-automatic-activity-reporting-and-finishing">Automatic Activity Reporting and Finishing</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-resources-departments-plants">Concepts &gt; Resources, Departments, &amp; Plants</a><ul><li class="toc-article"><a href="#article-238-capabilities">Capabilities</a></li><li class="toc-article"><a href="#article-268-helper-resources">Helper Resources</a></li><li class="toc-article"><a href="#article-281-multi-tasking-resources">Multi-Tasking Resources</a></li><li class="toc-article"><a href="#article-181-plant-stability">Plant Stability</a></li><li class="toc-article"><a href="#article-193-plants-departments-and-resources">Plants, Departments, and Resources</a></li><li class="toc-article"><a href="#article-234-resource-capacity">Resource Capacity</a></li><li class="toc-article"><a href="#article-251-tank-resources">Tank Resources</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-scenarios">Concepts &gt; Scenarios</a><ul><li class="toc-article"><a href="#article-274-scenario-management">Scenario Management</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-sequencing">Concepts &gt; Sequencing</a><ul><li class="toc-article"><a href="#article-227-auto-split-operations">Auto-Split Operations</a></li><li class="toc-article"><a href="#article-216-cleans">Cleans</a></li><li class="toc-article"><a href="#article-249-manufacturing-order-production-overlap">Manufacturing Order Production Overlap</a></li><li class="toc-article"><a href="#article-219-operation-batching">Operation Batching</a></li><li class="toc-article"><a href="#article-333-optimization">Optimization</a></li><li class="toc-article"><a href="#article-339-optimize-settings">Optimize Settings</a></li><li class="toc-article"><a href="#article-198-product-rules">Product Rules</a></li><li class="toc-article"><a href="#article-175-schedule-clock-planning-horizon">Schedule Clock &amp; Planning Horizon</a></li><li class="toc-article"><a href="#article-272-setup-time">Setup Time</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-warehouses-items-inventory">Concepts &gt; Warehouses, Items &amp; Inventory</a><ul><li class="toc-article"><a href="#article-187-items-inventories-warehouses-storage-areas">Items, Inventories, Warehouses, &amp; Storage Areas</a></li><li class="toc-article"><a href="#article-200-lot-controlled-planning">Lot Controlled Planning</a></li></ul></li><li class="toc-category"><a href="#cat-concepts-workspaces">Concepts &gt; Workspaces</a><ul><li class="toc-article"><a href="#article-296-board-tile-settings">Board Tile Settings</a></li><li class="toc-article"><a href="#article-280-download-scenario">Download Scenario</a></li><li class="toc-article"><a href="#article-269-grid-personalization">Grid Personalization</a></li><li class="toc-article"><a href="#article-342-layouts-metrics-and-targets">Layouts, Metrics, and Targets</a></li><li class="toc-article"><a href="#article-244-system-settings">System Settings</a></li><li class="toc-article"><a href="#article-188-user-management">User Management</a></li><li class="toc-article"><a href="#article-340-user-settings">User Settings</a></li><li class="toc-article"><a href="#article-321-workspace-profiles-dashboard">Workspace Profiles Dashboard</a></li></ul></li><li class="toc-category"><a href="#cat-feedback-support">Feedback &amp; Support</a><ul><li class="toc-article"><a href="#article-176-planettogether-support-holidays">PlanetTogether Support Holidays</a></li></ul></li><li class="toc-category"><a href="#cat-feedback-support-product-feedback">Feedback &amp; Support &gt; Product Feedback</a><ul><li class="toc-article"><a href="#article-217-product-feedback">Product Feedback</a></li></ul></li><li class="toc-category"><a href="#cat-feedback-support-product-support">Feedback &amp; Support &gt; Product Support</a><ul><li class="toc-article"><a href="#article-220-request-support">Request Support</a></li></ul></li><li class="toc-category"><a href="#cat-getting-started-for-network-administrators-it-prof">Getting Started &gt; For Network Administrators &amp; IT Professionals</a><ul><li class="toc-article"><a href="#article-210-server-administration">Server Administration</a></li></ul></li><li class="toc-category"><a href="#cat-getting-started-for-schedulers-standard-users">Getting Started &gt; For Schedulers &amp; Standard Users</a><ul><li class="toc-article"><a href="#article-263-client-sign-in-manager-application">Client Sign-In Manager Application</a></li><li class="toc-article"><a href="#article-334-desktop-client-installation-guide">Desktop Client Installation Guide</a></li><li class="toc-article"><a href="#article-191-keyboard-shortcuts">Keyboard Shortcuts</a></li><li class="toc-article"><a href="#article-255-main-toolbar">Main Toolbar</a></li><li class="toc-article"><a href="#article-229-modern-user-interface">Modern User Interface</a></li></ul></li><li class="toc-category"><a href="#cat-integrations">Integrations</a><ul><li class="toc-article"><a href="#article-347-importing-data-overview">Importing Data: Overview</a></li><li class="toc-article"><a href="#article-278-integrations-overview">Integrations: Overview</a></li></ul></li><li class="toc-category"><a href="#cat-integrations-aveva-mes">Integrations &gt; Aveva MES</a><ul><li class="toc-article"><a href="#article-261-aveva-mes-integration-data">AVEVA MES Integration Data</a></li><li class="toc-article"><a href="#article-173-aveva-mes-integration-overview">AVEVA MES Integration Overview</a></li><li class="toc-article"><a href="#article-236-aveva-mes-integration-setup">AVEVA MES Integration Setup</a></li></ul></li><li class="toc-category"><a href="#cat-integrations-microsoft-excel">Integrations &gt; Microsoft Excel</a><ul><li class="toc-article"><a href="#article-232-full-excel-integration-package">Full Excel Integration Package</a></li><li class="toc-article"><a href="#article-307-microsoft-excel-integration">Microsoft Excel Integration</a></li><li class="toc-article"><a href="#article-335-simple-excel-integration-package">Simple Excel Integration Package</a></li><li class="toc-article"><a href="#article-322-surestart-integration-methodology">SureStart Integration Methodology</a></li></ul></li><li class="toc-category"><a href="#cat-integrations-standard-planettogether-integration">Integrations &gt; Standard PlanetTogether Integration</a><ul><li class="toc-article"><a href="#article-215-standard-import-database">Standard Import Database</a></li><li class="toc-article"><a href="#article-276-standard-integration-api">Standard Integration API</a></li><li class="toc-article"><a href="#article-308-standard-publish-database">Standard Publish Database</a></li></ul></li><li class="toc-category"><a href="#cat-object-import-mappings-inventory-objects-mappings">Object Import Mappings &gt; Inventory Objects Mappings</a><ul><li class="toc-article"><a href="#article-350-forecast-mappings">Forecast Mappings</a></li><li class="toc-article"><a href="#article-292-inventory-mappings">Inventory Mappings</a></li><li class="toc-article"><a href="#article-303-item-mappings">Item Mappings</a></li><li class="toc-article"><a href="#article-327-item-storage-lots-mappings">Item Storage Lots Mappings</a></li><li class="toc-article"><a href="#article-235-item-storage-mappings">Item Storage Mappings</a></li><li class="toc-article"><a href="#article-341-lots-mappings">Lots Mappings</a></li><li class="toc-article"><a href="#article-241-plant-warehouse-mappings">Plant Warehouse Mappings</a></li><li class="toc-article"><a href="#article-310-purchases-to-stock-mappings">Purchases To Stock Mappings</a></li><li class="toc-article"><a href="#article-275-resource-storage-area-connector-in-mappings">Resource Storage Area Connector In Mappings</a></li><li class="toc-article"><a href="#article-252-resource-storage-area-connector-out-mappings">Resource Storage Area Connector Out Mappings</a></li><li class="toc-article"><a href="#article-324-sales-order-mappings">Sales Order Mappings</a></li><li class="toc-article"><a href="#article-192-storage-area-connector-in-mappings">Storage Area Connector In Mappings</a></li><li class="toc-article"><a href="#article-293-storage-area-connector-mappings">Storage Area Connector Mappings</a></li><li class="toc-article"><a href="#article-312-storage-area-connector-out-mappings">Storage Area Connector Out Mappings</a></li><li class="toc-article"><a href="#article-309-storage-area-mappings">Storage Area Mappings</a></li><li class="toc-article"><a href="#article-328-transfer-order-mappings">Transfer Order Mappings</a></li><li class="toc-article"><a href="#article-170-warehouse-mappings">Warehouse Mappings</a></li></ul></li><li class="toc-category"><a href="#cat-object-import-mappings-job-objects-mappings">Object Import Mappings &gt; Job Objects Mappings</a><ul><li class="toc-article"><a href="#article-214-alternate-path-node-mappings">Alternate Path &amp; Node Mappings</a></li><li class="toc-article"><a href="#article-337-customer-mappings">Customer Mappings</a></li><li class="toc-article"><a href="#article-319-internal-activity-mappings">Internal Activity Mappings</a></li><li class="toc-article"><a href="#article-194-job-mappings">Job Mappings</a></li><li class="toc-article"><a href="#article-298-manufacturing-order-mappings">Manufacturing Order Mappings</a></li><li class="toc-article"><a href="#article-202-material-mappings">Material Mappings</a></li><li class="toc-article"><a href="#article-246-operation-attribute-mappings">Operation Attribute Mappings</a></li><li class="toc-article"><a href="#article-291-product-mappings">Product Mappings</a></li><li class="toc-article"><a href="#article-233-required-capabilities-mappings">Required Capabilities Mappings</a></li><li class="toc-article"><a href="#article-190-resource-operation-mappings">Resource Operation Mappings</a></li><li class="toc-article"><a href="#article-222-resource-requirement-mappings">Resource Requirement Mappings</a></li><li class="toc-article"><a href="#article-257-successor-manufacturing-order-mappings">Successor Manufacturing Order Mappings</a></li><li class="toc-article"><a href="#article-271-user-field-mappings">User Field Mappings</a></li></ul></li><li class="toc-category"><a href="#cat-object-import-mappings-resource-objects-mappings">Object Import Mappings &gt; Resource Objects Mappings</a><ul><li class="toc-article"><a href="#article-259-allowed-helper-resource-mappings">Allowed Helper Resource Mappings</a></li><li class="toc-article"><a href="#article-320-attribute-code-table-mappings">Attribute Code Table Mappings</a></li><li class="toc-article"><a href="#article-270-attribute-mappings">Attribute Mappings</a></li><li class="toc-article"><a href="#article-239-attribute-range-table-mappings">Attribute Range Table Mappings</a></li><li class="toc-article"><a href="#article-240-capability-assignment-mappings">Capability Assignment Mappings</a></li><li class="toc-article"><a href="#article-221-capability-mappings">Capability Mappings</a></li><li class="toc-article"><a href="#article-224-capacity-interval-mappings">Capacity Interval Mappings</a></li><li class="toc-article"><a href="#article-283-capacity-interval-resource-mappings">Capacity Interval Resource Mappings</a></li><li class="toc-article"><a href="#article-287-cell-mappings">Cell Mappings</a></li><li class="toc-article"><a href="#article-314-cleanout-trigger-table-mappings">Cleanout Trigger Table Mappings</a></li><li class="toc-article"><a href="#article-203-compatibility-code-table-mappings">Compatibility Code Table Mappings</a></li><li class="toc-article"><a href="#article-209-department-mappings">Department Mappings</a></li><li class="toc-article"><a href="#article-301-plant-mappings">Plant Mappings</a></li><li class="toc-article"><a href="#article-223-product-rules-mappings">Product Rules Mappings</a></li><li class="toc-article"><a href="#article-172-recurring-capacity-interval-mappings">Recurring Capacity Interval Mappings</a></li><li class="toc-article"><a href="#article-256-resource-attribute-mappings">Resource Attribute Mappings</a></li><li class="toc-article"><a href="#article-213-resource-connector-mappings">Resource Connector Mappings</a></li><li class="toc-article"><a href="#article-199-resource-mappings">Resource Mappings</a></li><li class="toc-article"><a href="#article-258-setup-code-table-mappings">Setup Code Table Mappings</a></li><li class="toc-article"><a href="#article-184-user-mappings">User Mappings</a></li></ul></li><li class="toc-category"><a href="#cat-packages-extensions-custom-package-development">Packages &amp; Extensions &gt; Custom Package Development</a><ul><li class="toc-article"><a href="#article-237-create-a-custom-software-package">Create a Custom Software Package</a></li><li class="toc-article"><a href="#article-313-planettogether-sdk-getting-started">PlanetTogether SDK: Getting Started</a></li></ul></li><li class="toc-category"><a href="#cat-partner-resources-sales-enablement">Partner Resources &gt; Sales Enablement</a><ul><li class="toc-article"><a href="#article-331-partners-resource-hub">Partners Resource Hub</a></li><li class="toc-article"><a href="#article-186-sample-data-models">Sample Data Models</a></li><li class="toc-article"><a href="#article-332-version-12-availability-adoption">Version 12 Availability &amp; Adoption</a></li></ul></li><li class="toc-category"><a href="#cat-partner-resources-software-licensing">Partner Resources &gt; Software Licensing</a><ul><li class="toc-article"><a href="#article-277-license-request-form">License Request Form</a></li></ul></li><li class="toc-category"><a href="#cat-planettogether-employee-resources-software-license">PlanetTogether Employee Resources &gt; Software Licenses</a><ul><li class="toc-article"><a href="#article-305-software-licensing-overview">Software Licensing Overview</a></li></ul></li><li class="toc-category"><a href="#cat-server-administration-installation-and-updates">Server Administration &gt; Installation and Updates</a><ul><li class="toc-article"><a href="#article-316-deploy-integration-files-to-server">Deploy Integration Files to Server</a></li><li class="toc-article"><a href="#article-174-installer-downloads">Installer Downloads</a></li><li class="toc-article"><a href="#article-207-offline-software-installation-and-manual-deploymen">Offline Software Installation and Manual Deployment</a></li><li class="toc-article"><a href="#article-253-server-installation-guide">Server Installation Guide</a></li><li class="toc-article"><a href="#article-336-single-sign-on-sso-integration">Single Sign On (SSO) Integration</a></li><li class="toc-article"><a href="#article-228-software-package-management">Software Package Management</a></li><li class="toc-article"><a href="#article-204-uninstall-planettogether">Uninstall PlanetTogether</a></li></ul></li><li class="toc-category"><a href="#cat-server-administration-licensing">Server Administration &gt; Licensing</a><ul><li class="toc-article"><a href="#article-266-manually-install-license-key-files">Manually Install License Key Files</a></li></ul></li><li class="toc-category"><a href="#cat-server-administration-system-network-requirements">Server Administration &gt; System &amp; Network Requirements</a><ul><li class="toc-article"><a href="#article-201-it-reference-guide">IT Reference Guide</a></li><li class="toc-article"><a href="#article-282-ssl-certificate-management">SSL Certificate Management</a></li><li class="toc-article"><a href="#article-195-system-performance">System Performance</a></li></ul></li><li class="toc-category"><a href="#cat-server-administration-workspace-instance-managemen">Server Administration &gt; Workspace Instance Management</a><ul><li class="toc-article"><a href="#article-226-audit-log">Audit Log</a></li><li class="toc-article"><a href="#article-326-instance-manager">Instance Manager</a></li><li class="toc-article"><a href="#article-344-migrating-from-version-11">Migrating from Version 11</a></li><li class="toc-article"><a href="#article-185-restore-a-scenario-from-a-recording-backup">Restore a Scenario from a Recording Backup</a></li></ul></li><li class="toc-category"><a href="#cat-software-releases-roadmap-product-roadmap">Software Releases &amp; Roadmap &gt; Product Roadmap</a><ul><li class="toc-article"><a href="#article-231-early-access-program">Early Access Program</a></li><li class="toc-article"><a href="#article-338-product-roadmap">Product Roadmap</a></li><li class="toc-article"><a href="#article-351-software-release-announcements-opt-in-out">Software Release Announcements Opt-In/Out</a></li></ul></li><li class="toc-category"><a href="#cat-software-releases-roadmap-release-notes">Software Releases &amp; Roadmap &gt; Release Notes</a><ul><li class="toc-article"><a href="#article-295-release-notes-12-1-3">Release Notes: 12.1.3</a></li><li class="toc-article"><a href="#article-177-release-notes-12-1-4">Release Notes: 12.1.4</a></li><li class="toc-article"><a href="#article-178-release-notes-12-2-0">Release Notes: 12.2.0</a></li><li class="toc-article"><a href="#article-325-release-notes-12-2-1">Release Notes: 12.2.1</a></li><li class="toc-article"><a href="#article-169-release-notes-12-3-0">Release Notes: 12.3.0</a></li></ul></li><li class="toc-category"><a href="#cat-software-releases-roadmap-software-installation">Software Releases &amp; Roadmap &gt; Software Installation</a><ul><li class="toc-article"><a href="#article-225-software-installation-and-upgrades">Software Installation and Upgrades</a></li></ul></li><li class="toc-category"><a href="#cat-software-releases-roadmap-upgrade-guides">Software Releases &amp; Roadmap &gt; Upgrade Guides</a><ul><li class="toc-article"><a href="#article-197-upgrading-from-12-1-x-or-12-2-x-to-12-3-x">Upgrading from 12.1.x or 12.2.x to 12.3.x</a></li></ul></li><li class="toc-category"><a href="#cat-software-releases-roadmap-version-12-introduction">Software Releases &amp; Roadmap &gt; Version 12 Introduction</a><ul><li class="toc-article"><a href="#article-290-new-functions-features">New Functions &amp; Features</a></li></ul></li><li class="toc-category"><a href="#cat-troubleshooting">Troubleshooting</a><ul><li class="toc-article"><a href="#article-208-delivering-files-to-planettogether-support">Delivering Files to PlanetTogether Support</a></li><li class="toc-article"><a href="#article-330-software-assembly-version-detector">Software Assembly Version Detector</a></li></ul></li><li class="toc-category"><a href="#cat-troubleshooting-common-issues">Troubleshooting &gt; Common Issues</a><ul><li class="toc-article"><a href="#article-318-troubleshoot-client-sign-in-manager-application">Troubleshoot: Client Sign-In Manager Application</a></li><li class="toc-article"><a href="#article-349-troubleshoot-desktop-client-user-interface-display">Troubleshoot: Desktop Client User Interface Display</a></li><li class="toc-article"><a href="#article-218-troubleshoot-instance-manager">Troubleshoot: Instance Manager</a></li><li class="toc-article"><a href="#article-254-troubleshoot-instance-starting-in-read-only-mode">Troubleshoot: Instance Starting in Read-Only Mode</a></li></ul></li><li class="toc-category"><a href="#cat-troubleshooting-error-codes">Troubleshooting &gt; Error Codes</a><ul><li class="toc-article"><a href="#article-352-error-codes">Error Codes</a></li></ul></li>
    </ul>
  </nav>
  
  <main>
    <h2 id="cat-ai-chatbots" class="category-header">AI Chatbots</h2>
        <section class="article" id="article-262-planettogether-bot-library">
          <h3 class="article-title">PlanetTogether Bot Library</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/ai-chatbot-v2" target="_blank">Source</a></p>
          <div class="article-content">PT Knowledge Base
Get answers about PT app based on existing KB articles 

AI Factory Builder - Starter Edition
Create a spreadsheet that includes a simple scenario with simulated data for a specific company or a segment of manufacturing for import into PT Starter Web App.

AI Factory Builder
Create a spreadsheet that includes a standard scenario with simulated data for a specific company or a segment of manufacturing for import into PT. 
The required xml file and a brief instruction video can be obtained in LMS Course

AI Factory Builder V2
Upload customer source documents to create an import spreadsheet that combines customer data with simulated data for a specific company. Compatible with the Simple Excel Integration Package.

Feature Assistant
Assists consultant or customer by suggesting PT features to address specific pain points.

APS Translator
Translate manufacturing documents or simple text between English and other languages and obtain downloadable files. Use DeepL Translate for translating documents while maintaining their original formatting.

Blog Writer
Generate educational blogs that include PT expert insights.

Company Insights
Provides a comprehensive overview of any company

Test Plan from Audio Transcript
Generates detailed test plan based on a transcript of test steps

Excel to SQL Database
Create a SQL database from an Excel spreadsheet

PT Website
General knowledge about PlanetTogether

Partner Lead Generator
Gathers information about potential partners and provides info on the partnering program</div>
        </section>
      
        <section class="article" id="article-343-planettogether-knowledge-base-v12">
          <h3 class="article-title">PlanetTogether Knowledge Base V12</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/ai-chatbot-12" target="_blank">Source</a></p>
          <div class="article-content"></div>
        </section>
      <h2 id="cat-boards" class="category-header">Boards</h2>
        <section class="article" id="article-273-activities-board">
          <h3 class="article-title">Activities Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/activities-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Activities Board is used to analyze scheduled job activities, fine-tune the schedule via manual modifications as necessary, and/or report progress on running activities. This board offers users many options to manually move or reschedule activities one at a time or in bulk, or even edit activities and operations from within the board. 

Jump to section:

Activity Scheduling Tiles (Primary and Secondary)

Activity Actions Tile

Unscheduled Jobs Tile

Activity Move Tile

Activity Comments Tile

Activity Status Tile

Required Capabilities Tile

Operation Details Tile

Activity Scheduling Grid Tiles (Primary and Secondary)

The Activity Scheduling tiles can be used to visualize statistics of scheduled resources, track Metrics related to those statistics, or for drag/drop manual rescheduling. 

A user preference labelled Synchronize Activity Grid layouts is available which when enabled will synchronize the grid layouts between the Primary and the Secondary scheduling tile grids.

Show Resource Filter

Quickly filter the visible activities in the grid using the Resource Filter to view activities scheduled on one or more specific resources. Use the Multi Select option to allow for multiple selections from the list of available departments and resources.

Select Objects Selected in Gantt

When this option is enabled, the Activity Scheduling tile grid will automatically filter to only show activities of the operations that are selected in the Gantt board. It might be helpful to dock the Gantt board and Activities board or unpin one of the boards so that both can be viewed at the same time.

Drag/Drop Scheduling

One or more Activity grid rows can be selected (for multiple row selection, use Shift on the keyboard while clicking on rows to select multiple consecutive rows or Ctrl+click to select multiple non-consecutive rows) and then dragged and dropped within one of the grids or from one grid to another to effectively move or reschedule the selected activity(ies).

The result of the move will be indicated by a color code in the Move Result grid column and a reason for the color code in the Move Result Reason column. All reason and color combinations:

"Exact Move" (#FF05806F) - Move was successful

"Activity not eligible on resource <Resource>" (#FFFFF0F0) - The Activity is not eligible on the target resource

"Activity locked on resource <Resource>" (#FFB56FF2) - The Activity is locked on the target resource

"Moving from resource <Resource> is not allowed" (#FFFFF0F0) - Moving from this resource is not allowed

"Path is not eligible" (#FFF2E205) - Alternate Path must exist, have 1 lead activity, and differ from the current path

"Activity is in production" (#FFF08000) - The Activity is in production

"Material Constraint" (#FFFF00FF) - The Operation has a material constraint

"Predecessor Constraint" (#FFF0CC3E) - The Operation is constrained by a predecessor

"Operation On Hold until <Time>" (#FFFFFF00) - The Operation is on hold

"MO On Hold until <Time>" (#FFFFFF00) - The Manufacturing Order is on hold

"Job On Hold until <Time>" (#FFFFFF00) - The Job is on hold

"Moved without constraint" (#FF0B6B5E) - The Activity is constrained by the clock

"Moved without constraint" (#FF24E36A) - The Activity was moved with no constraints

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Activity Actions Tile

The Activity Actions tile allows users to perform various actions on one or more Activities. Select one or more Activities from either the Primary or the Secondary Activity Scheduling tile grids, then click the desired Action button to perform the action on the selected activity(ies). If grid row selections are made to both the Primary and Secondary Activity Scheduling tile grids then the chosen action will be executed on the Activity objects from the grid that was most recently selected from (the actions cannot/will not be executed on selections from both grids).

Note that all of the same actions may be performed via the right-click menu of any grid row.

Available Actions

Management:

Open: Open the Job Details dialog associated with the selected grid Activity row. Only one grid row selection is supported. If more than one row is selected, only one Job Details dialog will open (the one associated with the Activity with the lowest numbered grid row). 

Hide Other Jobs: Hide all other jobs from the Gantt temporarily. Click anywhere in the Gantt chart to restore visibility of the hidden jobs.

Set Job Color: Select a color from the color picker to overwrite the existing Job color

Show Job Flow: Focus attention on the Activities of the Job(s) of the selected Activity(ies) by auto-generating a temporary Gantt View configuration. Delete the Gantt View or select another Gantt View from the dropdown to switch back to the previous view.

Show Connected Jobs Flow: Focus attention on the Activities of the Job of the selected Activity and all of the connected jobs, such as jobs with hard pegged materials, by auto-generating a temporary Gantt View configuration. Delete the Gantt View or select another Gantt View from the dropdown to switch back to the previous view.

Delete Jobs: Delete the job(s) associated with the selected Activity(ies)

Job Properties: Open the Job Properties tile with the properties of the Job associated with the selected Activity in focus.

Reports:

Show Job Traveler Report: Open the standard Job Traveler report for the job(s) associated with the selected Activity(ies).

Reporting:

Materials: A shortcut to open the Materials board with a filter applied to focus on the materials required for the selected Activity. Only one grid row selection is supported.

Find In Gantt: Opens the Gantt board with the selected activity in focus. Only one grid row selection is supported.

Activity Status: Open the Activity Status tile to report progress against the selected activity.

Scheduling:

Set Sub-Job Need Date and JIT Date: Recalculates the the Need Dates JIT start dates of the sub-jobs of the selected job(s) (those that are feeding it material or which are pegged via lot codes). This option only becomes available when Set Sub-Job Need Dates is enabled in System Settings ➡️ Scheduling Options or User Settings ➡️ Optimize Settings.

Reset Job JIT Date: Recalculates the the JIT start date(s) of the selected job(s).

Optimize Selected Jobs and Supplying Jobs: Performs an optimizes for the selected job(s) and any job(s) that are supplying materials for the selected job(s).

Optimize Selected Jobs: Performs an optimize for only the job(s) selected. This optimize does not include any of the jobs supplying materials for the selected jobs.

Compress: Reschedule all Activities of each Job(s) associated with the selected Activity(ies) to schedule as early as possible without displacing other scheduled activities based on the most constrained operation of each job. 

WIP Compress: Reschedule all Activities of each Job(s) associated with the selected Activity(ies) to schedule as close to their JIT date without displacing other scheduled activities.

Move Activities: Open the Activity Move tile from the Activities board to perform a manual move of the selected Activity(ies) to a specific time and resource (where eligible).

Unschedule Job: Unschedule the job(s) associated with the selected Activity(ies).

Ignore Constraints: Change all stock material requirements on the selected Activity(ies) from Constrained by Available Date to Ignored-Constraint, and from Constrained by Earlier of Lead Time and Available Date to Ignored-LeadTimeConstraint so that subsequent scheduling actions will not enforce material constraints.

Restore Constraints: Change all stock material requirements on the selected Activity(ies) back from Ignored-Constraint to Constrained by Available Date, and from Ignored-LeadTimeConstraint to Constrained by Earlier of Lead Time and Available Date so that subsequent scheduling actions will once again enforce material constraints.

Expedite:

Do ASAP: Reschedule all Activities of the selected Job(s) to begin as early as possible, as early as the start of the schedule (constraints allowed). Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Preserve the Frozen Span: Reschedule all Activities of the selected Job(s) to begin as early as possible without entering the Frozen Span area. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Preserve the Stable Span: Reschedule all Activities of the selected Job(s) to begin as early as possible without entering the Stable Span area. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

To DateTime: Reschedule all Activities of the selected Job(s) to begin as close as possible to the specified date. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Add Cycles To:

Fill capacity before the start of the next Cleanout Interval: Increase the production output of the selected Activity in order to completely consume the capacity on the scheduled resource up to the next scheduled Cleanout capacity interval on the resource.

Fill capacity before the start of the next Offline Interval: Increase the production output of the selected Activity in order to completely consume the capacity on the scheduled resource up to the next scheduled Offline capacity interval on the resource.

End near the end of first Capacity Interval used: Increase or decrease the production output of the selected Activity in order to have it finish at the end of the Capacity interval that it's currently scheduled to start on.

End near the end of last Capacity Interval used: Increase or decrease the production output of the selected Activity in order to have it finish at the end of the Capacity interval that it's currently scheduled to finish on.

End near the start of next Activity: Increase the production output of the selected Activity in order to have it finish at the start of the next Activity that's scheduled on the same resource.

End near the start of next Cleanout Interval: Increase the production output of the selected Activity in order to have it finish at the start of next scheduled Cleanout capacity interval on the resource.

End near the start of next Offline Interval: Increase the production output of the selected Activity in order to have it finish at the start of next scheduled Offline capacity interval on the resource.

Gantts:

Connected Jobs: Opens the Connected Jobs Gantt tile from the Jobs board with all of the jobs associated with all selected Activity rows loaded into the Gantt chart.

Job Watch: Opens the Job Watch Gantt tile from the Jobs board with all of the jobs associated with all selected Activity rows loaded into the Gantt chart.

Lock to current Resource:

Job: Lock all activities of the job(s) associated with the selected Activity(ies) to their currently scheduled resource.

Manufacturing Order: Lock all activities of the manufacturing order(s) associated with the selected Activity(ies) to their currently scheduled resource.

Operation: Lock all activities of the operation(s) associated with the selected Activity(ies) to their currently scheduled resource.

Unlock from current Resource:

Job: Unlock all activities of the job(s) associated with the selected Activity(ies) from their currently scheduled resource.

Manufacturing Order: Unlock all activities of the manufacturing order(s) associated with the selected Activity(ies) from their currently scheduled resource.

Operation: Unlock all activities of the operation(s) associated with the selected Activity(ies) from their currently scheduled resource.

Anchor in Time:

Activity: Anchor the selected activity(ies) at their currently scheduled point in time.

Job and supplying Manufacturing Orders: Anchor all activities of the job(s) and supplying manufacturing order(s) of the selected activity(ies) at their currently scheduled point in time.

Manufacturing Orders: Anchor all activities of the manufacturing order(s) of the selected activity(ies) at their currently scheduled point in time.

Operation: Anchor all activities of the operation(s) of the selected activity(ies) at their currently scheduled point in time.

Unanchor in Time:

Activity: Unanchor the selected activity(ies) from their currently anchored point in time.

Job and supplying Manufacturing Orders: Unanchor all activities of the job(s) and supplying manufacturing order(s) of the selected activity(ies) from their currently anchored point in time.

Manufacturing Orders: Unanchor all activities of the manufacturing order(s) of the selected activity(ies) from their currently anchored point in time.

Operation: Unanchor all activities of the operation(s) of the selected activity(ies) from their currently anchored point in time.

Hold:

Job: Pops up a dialog to enter a "Hold Until" date and time and a reason for the hold. Once confirmed, the job(s) associated with the selected activity(ies) will be placed on hold until the specified date and time.

Manufacturing Order: Pops up a dialog to enter a "Hold Until" date and time and a reason for the hold. Once confirmed, the manufacturing order(s) associated with the selected activity(ies) will be placed on hold until the specified date and time.

Operation: Pops up a dialog to enter a "Hold Until" date and time and a reason for the hold. Once confirmed, the operation(s) associated with the selected activity(ies) will be placed on hold until the specified date and time.

Un-Hold:

Job: Removes the "On Hold" status of the job(s) associated with the selected activity(ies).

Manufacturing Order: Removes the "On Hold" status of the manufacturing order(s) associated with the selected activity(ies).

Operation: Removes the "On Hold" status of the operation(s) associated with the selected activity(ies).

Lock to Current Path:

Manufacturing Order: Lock the manufacturing order(s) associated with the selected activity(ies) to their currently scheduled Path.

Unlock from Current Path:

Manufacturing Order: Unlock the manufacturing order(s) associated with the selected activity(ies) from their currently locked Path.

Unscheduled Jobs Tile

This tile shows a grid view of all unscheduled jobs and offers quick actions to put those jobs on the schedule. Select one or more grid rows and click one of the toolbar actions, or drag and drop the job(s) onto the Activity Scheduling grid where they're eligible to schedule to manually insert them into the schedule.

ASAP: Schedule the selected job(s) as close to the start of the clock as possible (similar to a "Shift+Expedite").

Preserve Frozen Span: Schedule the selected job(s) as close to the end of the frozen span as possible (similar to a standard "Expedite").

JIT: Schedule the selected job(s) as close to their JIT date as possible.

Activity Move Tile

The Activity Move tile allows users to manually reschedule one or more activities to a specific resource and a specific date and time or relative to a significant point (e.g. the end of the planning horizon) or relative to another currently scheduled activity.

Step 1: Select Activity(ies) to Move

Select one or more activities from either the Primary or Secondary Activity Scheduling tile grid, then the Activity Move tile will update in real time with available options based on the selections.

Step 2: Select an Eligible Target Resource

Eligible resources are visualized by rows with white backgrounds in the leftmost Resource grid of the Activity Move tile, while ineligible resources are visualized by rows with a pink background. The currently selected resource row will have a light blue background.

Step 3: Select a Time to Start

Once the Activity(ies) and Resource are selected, choose when to schedule the activity(ies) by selecting a radio option and providing supplemental information from the "Select Time to Start" area. Choose one of:

Significant Point: Choose the desired Significant Point from the dropdown of options

Specific time: Specify the desired date and time

Just Before/After: Choose Just Before or Just After, then select a scheduled activity from the grid directly beneath these options.

Once ready, click the Move to resource and time button near the title bar of the Activity Move tile to complete the move.

Activity Comments Tile

Use the Activity Comments tile to view or enter Job, Operation, or Manufacturing Order notes or Activity comments. This can be helpful for communication between the shop floor operators and schedulers or for anyone to include extra details about the various tasks.

Activity Status Tile

The Activity Status tile is used to visualize and/or report progress on an activity, or to quickly change the activity's Quantity per Cycle, Setup Time, Cycle Hours, Post-Processing Time, Cleanout Time, or Cleanout Grade. 

Production Status: Update the status of the activity. Note that an Activity cannot be reset back to Waiting or Ready status once it's in production ("Started", "Setting Up, "Running", etc.) and cannot be Paused unless its status is either "Setting Up" or "Running".

Quantity:

Expected Finish Qty: The amount expected to be produced by the activity. Defined by the job settings; cannot be edited here.

Expected Scrap Qty: The amount expected to be scrapped by the activity. Defined by the job settings; cannot be edited here.

Reported Finish Qty: The quantity of the activity that has been completed to date. Editable input.

Reported Scrap Qty: The quantity of the activity that has been scrapped to date. Editable input.

Expected Quantity per Cycle: The Quantity per Cycle that is currently configured on the Activity.

Manual Override Quantity per Cycle: Enter a new value here to override the configured expected value.

Allocate material from on-hand inventory: When enabled, a proportional amount of all required materials to perform the activity will be allocated to the activity from on-hand inventory based on the Reported vs. Expected finish quantities, effectively consuming or removing the material from inventory. 

Release product to warehouse: When enabled, the reported finish quantity will be added to on-hand inventory.

Reported Start Date: Specifies a date and time that the activity started.

Reported Finish Date: Specifies a date and time that the activity finished.

Set to Scheduled Dates: Quickly set the reported start and finish times to those of the currently scheduled times.

Time:

Expected Setup: The duration of Setup time expected to be incurred by the activity.

Expected Cycle: The cycle time for this activity. 

Expected Run: The duration of Run/Cycle/Production time expected to be incurred by the activity. Calculated by the system according to Cycle Hours, Quantity per Cycle, and number of cycles that the Activity will perform.

Expected Post-Processing: The duration of Post-Processing time expected to be incurred by the activity. Defined by the job settings; cannot be edited here.

Expected Clean: The duration of Clean time expected to be incurred by the activity. Defined by the job settings; cannot be edited here.

Reported Setup: The duration of Setup time that has been incurred by the activity to date. Editable input.

Reported Post-Processing: The duration of Post-Processing time that has been incurred by the activity to date. Editable input.

Reported Clean: The duration of Clean time that has been incurred by the activity to date. Editable input.

Reported Run: The duration of Run/Cycle/Production time that has been incurred by the activity to date. Editable input.

Manual Override Setup: Override the activity's Expected Setup duration. Editable input.

Manual Override Cycle: Override the activity's Cycle Hours. Editable input.

Manual Override Post-Processing: Override the activity's Expected Post-Processing duration. Editable input.

Manual Override Clean: Override the activity's Expected Clean duration. Editable input.

Cleanout Grade: The Grade value of the activity's Clean. This is used by the system when determining when to reset sequence-dependent clean calculations. Editable input.

People: Define the People Usage for the activity

Use All Available People: Consume the capacity of all available people from the capacity interval that the scheduled activity falls on.

Use the number specified below: Consume or require a specific number of people to perform the activity. This is not a scheduling constraint. If a capacity interval with fewer than this number of people has available capacity then the activity will be considered eligible to schedule there. If scheduled on such an interval then the activity will take longer to complete by a factor of the missing number of people (e.g. if an activity is set to require "2" people but an available capacity interval only has "1" person assigned to it then the activity will take 2x as long to complete).

Use the text input provided to specify the number of people required.

Uses an even multiple of the number specified, up to the Capacity Interval limit: Consume or require a multiple of a specific number of people to perform the activity, up to the available number of people on the Capacity Interval. This is a scheduling constraint. If a capacity interval has fewer than this number of people available then the activity will not be considered eligible to schedule there. The actual number of people used will scale up in intervals of the specified number until as many available people on the capacity interval are utilized.

Use the text input provided to specify the minimum and multiple of number of people required.

Comments: Include additional comments for informational purposes, if desired.

Finish at Expected Values: Click this button to automatically finish the activity at the specified Expected Finish and Scrap Quantities. There is no need to enter any Reported Quantities when using this button.

Finish at Reported Values: Click this button to finish the activity at the currently specified Reported Finish and Scrap Quantities.

Required Capabilities Tile

This tile offers a quick interface to view or even adjust the required capabilities for the selected Operation. Note that any changes made to the capability requirements will cause the entire job associated with the operation to unschedule since this type of change impacts the schedulability of the operation.

Select Resource Requirement

If there are more than one resource requirement configured on the operation then first select the resource requirement to view or edit from the dropdown of options. Once one is selected, the table below which shows the required capabilities will become editable.

Add or Remove a Required Capability

Adding or removing a required capability is as simple as checking or unchecking any of the Capability Requirements from the "Selected" column of the grid, then clicking the "Save Changes" button.

Note that any changes made to the capability requirements will cause the entire job associated with the operation to unschedule.

Operation Details Tile

This tile offers a quick access interface to view or modify properties of the selected Operation.

For details of each property and setting and their function, see: Operation Dialog</div>
        </section>
      
        <section class="article" id="article-289-buffer-management-board">
          <h3 class="article-title">Buffer Management Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/buffer-management-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Buffers are used in scheduling to reduce the risk of delays due to variability. They are set on different objects based on their type, but they generally add a span of time before an item is due. Buffer penetration is calculated as a percentage based on the time the predecessor operation moves into the buffer span, which will set the warning level. 

The Buffer Management Board is the primary tool used to monitor risky buffer penetration. Monitoring time buffers allows planners to focus on jobs at risk of critical delays that can affect on-time delivery and possibly starve drum resources.

The Buffer Management Board is used for three main purposes:

Identify which manufacturing orders and purchase orders are at risk concerning their various DBR buffers so that they can be expedited.

Determine the level of urgency after clarifying the risk level in terms of throughput and revenue.

Compare plant performance in terms of buffer penetration.

Options

This top section can control what is shown in the graphical chart and the bottom grids. This section allows the user to focus on the information of interest. After changing the values found in this section, click on Apply to update the chart and grids based on the current options.

Plants: This section displays a list of all plants in the data model. Check one or more plants to filter data for those specific plants.

Chart Controls: These values only affect the chart, not the grids. 

Primary/Secondary Group: These settings work together to determine how the data is displayed in the chart. 

Primary and Secondary Values can be grouped by Plant, Buffer Type, or Warning Level.

If the Secondary Group option is set to “None,” then a simple graph is shown using the options specified for the Primary Group.

If the Secondary Group option is set to another value, those values are shown grouped within the Primary Group.

Note: If warning levels are shown as the primary group, and the second group is set to “None,” then the chart is colored in Green/Yellow/Orange/Red according to the warning level.

Values: This control determines what type of data is plotted along the Y-axis of the chart.

Throughput: The sum of the throughputs of the manufacturing order jobs. Note that if the same job appears more than once on the list, it is only counted once.

Revenue: The sum of the revenues for the manufacturing order jobs. Note that if the same job appears more than once on the list, it is only counted once.

Count: The total number of purchase orders and manufacturing orders included in the grids.

Item Quantity: The sum of the quantities of the manufacturing orders. Note that if the same manufacturing order appears more than once on the lists, it is counted only once.

Drum Work Hours: The sum of the work hours scheduled on the drums for all drum buffer manufacturing orders in the grid.

Buffer Types: Buffers are used to minimize delays by accounting for possible variability in the schedule. In the buffer management view, the information shown in the bar graph can be filtered to show only the relevant types of buffers. The buffer types available are Material, Drum, Shipping, and Stock. 

Material: Material buffers pertain to purchase orders.

Drum: Drum buffers pertain to manufacturing orders.

Shipping: Shipping buffers pertain to manufacturing orders.

Stock: Stock buffers pertain to purchase orders. 

Warning Levels: There are four warning levels related to the amount of buffer penetration occurring. If only one warning level is checked, the chart is colored according to the selected warning level. The higher the buffer penetration, the closer the operation is to being late. 

Late (Red): More than 100% buffer penetration. 

Critical (Orange): More than 66% buffer penetration.

Warning (Yellow): Between 33% and 66% buffer penetration.

OK (Green): Less than 33% buffer penetration.

Note: The warning level filter works in conjunction with the M.O. Penetration Type described below for manufacturing orders. The warning level is based on the level of the penetration type specified.

M.O. Penetration Type 

Current: This is based on the current date and time and the manufacturing order’s current status.

Projected: This is based on where the manufacturing order is currently scheduled.

Note: Purchase orders only have current penetration since they are not scheduled.

Chart

The chart provides an easy way to compare various buffer-related measures specified in the top Options section.

Grids

The grids section is used to view the amount of buffer penetration for each purchase order or manufacturing order to easily identify which orders are at risk of being late or causing a delay. The grids are divided into four tabs according to buffers: Material, Drum, Shipping, and Stock. Users can see current and projected penetration percentages, the warning level associated with the amount of penetration, and any additional information about the purchase order or manufacturing order. 

The Drum Buffers and Shipping Buffers tabs allow users to drill down into the Job/Manufacturing Order by clicking the "Open Job" button or double-clicking the row selector. 

Drum Buffers are a time span added before constrained resources (called "Drums") to avoid starving those resources and prevent reducing throughput.

Shipping Buffers are added from the manufacturing order's need date to set the shipping need date. Therefore, manufacturing orders should be done before the shipping need date to avoid Shipping Buffer Penetration.</div>
        </section>
      
        <section class="article" id="article-245-capacity-planning-board">
          <h3 class="article-title">Capacity Planning Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capacity-planning-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Capacity Planning is one of the main functions of PlanetTogether. Finite capacity planning is of great concern to manufacturers as there are a limited number of hours in a day and a limited amount of production that can be accomplished in those hours.

The Capacity Planning board allows users to manage resources and visualize capacity in use and available capacity over a specified period of time. The tools available should help to reveal possible bottlenecks in the schedule before they occur on the shop floor. 

Jump to section:

Resources Grid

Resource Actions Tile

Assigned Capability Chooser Tile

Resource Bulk Edit Tile

Resource Performance Report

Resource Production Report

Resource Capacity Utilization Report

Resource Schedule Report

Resource Production Availability Chart

Unutilized Capacity Chart

Resource Capacity Chart

Resource Units Chart

Resource Utilization Chart

Resource Utilization by Number of People Chart Tile

Resources Grid

Use the Resources grid to view information about each Resource in the data model. Apply filters to the grid to help to narrow down the data presented in each of the Report and Chart tiles.

Use the Find in Gantt button in the toolbar to bring the selected resource into focus in the Gantt board.

Use Grid Edit Mode to edit resource settings. For Department and Plant settings, refer to the respective tiles in the Scenario Data Board.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Capacity Planning Board Grid Properties

Resource Actions Tile

The Resource Actions tile allows users to perform various actions on one or more Resources. Select one or more Resources from the Resources grid, then click the desired Action button to perform the action on the selected resource(s).

Note that all of the same actions may be performed via the right-click menu of any grid row.

Available Actions

Management:

Duplicate Resource: Create a duplicate of the selected resource.

Select All: Select all grid rows.

New Resource: Create a new resource. When clicked, the user will be prompted to select with department and plant the resource should be created in.

Delete Resource(s): Delete the selected resource.

Reporting:

Show Resource Schedule Report: A shortcut to open the Resource Schedule Report tile with the selected resource data in focus.

Show Resource Production Report: A shortcut to open the Resource Production Report tile with the selected resource data in focus.

Show Activity List for Selected Resource: A shortcut to open the Activities board with a filter applied to only show scheduled activities for the selected resource.

Find in Gantt: Bring the selected resource into focus in the Gantt board

Scheduling:

Activate: A quick way to Activate a previously Deactivated resource.

Deactivate: A quick way to Deactivate a previously Activated resource. All activities scheduled on the resource must be unscheduled or rescheduled first.

Compress Resource: Compress all scheduled activities on the resource according to the Compress Settings.

Assigned Capability Chooser Tile

This tile is used to manage capability assignments per resource. Select a row from the Resources grid of a resource whose capabilities need updated, then proceed to check the box next to each of the capability names that should be assigned to the selected resource. Finally, be sure to Save the edits.

The tile is only able to edit the assigned capabilities of a single resource. If multiple grid rows are selected at the time of editing then only the first one which was selected will be editable.

Resource Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more resources. Select one or more rows from the Resources grid, then choose properties and values that should be applied to each selected resource. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

Resource Performance Report

The Resource Performance Report provides insight into the number of setups, cycles (runs), and post-processes that have occurred to generate a performance score. This is done by comparing the expected run hours and quantities to the reported ones of finished activities, where the standard is 100%. Thus, resources performing slower than standard will have performance scores above 100%, while resources performing faster than standard will have performance scores below 100%. 

Select one or more rows from the Resources grid and statistics for all selected Resources will be plotted in the report.

Resource Production Report

The Resource Production Report plots scheduled production quantities of each product made on the selected Resource over a period of time grouped in time buckets. Data for only 1 Resource can be plotted at a time. 

Time Bucket

Select the time bucket in the dropdown in the top left corner of the report (Hour, Day, Week, Month, Custom, etc.). The time bucket duration determines the amount of time to include production statistics for in each plotted point (cell) in the report table.

Start Time

Choose a start time for the report using the date and time pickers.

Time Horizon

Choose either "Short-Term" or "Planning Horizon" to determine how far ahead to view scheduled production statistics for the selected resource.

Export

Use the Export icon button to export the report to the desired format (XLSX, PDF, HTML, or CSV).

Resource Capacity Utilization Report

The Resource Capacity Utilization Report is a chart and report combination that compares the total capacity of a resource to the utilized capacity. The gray section on the chart shows the total capacity and the blue section is the utilized capacity. The duration, start and end dates, and production type can be change along the top of the chart.

The bottom section shows a grid stating the total vs utilized capacity based on the specified time bucket.

Users can hold the Shift key and select multiple resources. The cart will show the totals of both resources, and the grid will have it broken out by resource.

Resource Schedule Report

The Resource Schedule Report offers details of each Activity scheduled on the selected Resource over a specified period of time. Data for only 1 Resource can be plotted at a time.

Refresh

Use the Refresh button to refresh the data in the Report after making scheduling changes. Useful for when the Refresh Automatically option is disabled.

Duration

Define the duration from the Report Start date that scheduled Activity information should be plotted for the selected Resource.

Report Start

Select the start date of the report using the date and time pickers.

Show Material Requirements

When enabled, Material Requirements will be listed for each plotted Activity

Refresh Automatically

When enabled, the report table will refresh automatically as the schedule changes.

Export

Use the Export icon button to export the report to the desired format (XLSX, PDF, HTML, or CSV).

Resource Production Availability Chart

The Resource Production Availability Chart plots the scheduled availability of each selected Resource over a period of time grouped in time buckets. This represents the amount of Online capacity on a resource which is not being utilized.

For example, if the Time Bucket is "1 week" and the Unit of Measure is "Available %" then the plotted data reflects the average availability per selected resource across all shifts in 1 week buckets of time between the defined Start and End dates.

Unit of Measure

Choose to view the availability in terms of number of hours, percentage of total hours, or a decimal value between 0 (no availability) and 1 (completely available, no online capacity is used).

Time Bucket

Select the time bucket in the dropdown next to the Unit of Measure dropdown selection. The time bucket duration determines the amount of time to include resource availability statistics for in each plotted point.

Start Date

Choose a start date for the chart using the date picker.

End Date

Choose an end date for the chart using the date picker.

Job Commitments

Choose from the list of single or multiple Job Commitment levels in order to view resource availability based strictly on the scheduled jobs that have the selected Job Commitment level(s).

Chart Style

Choose from a Line Chart, Bar Chart, Area Chart, etc. in order to visualize the data in different formats.

Toggle Legend

Toggle visibility of the Resource Selection Legend on/off.

Legend

Use the Resource Selection Legend to select which resources to plot in the chart.

Unutilized Capacity Chart

The Unutilized Capacity chart is a specialized chart that plots the number of hours that a resource remains idle where it could have been otherwise performing some work if its available online capacity intervals were configured differently. Capacity will be reported as Unutilized when, for example, an operation is allowed to start on one capacity interval of a resource, but then the next online interval doesn't allow it to continue (perhaps it's configured to not be [ ] Used for Run but the started operation is still running); then the capacity is consumed because the scheduled operation spans that time period, but no work is done since the interval is not capable of performing the work.

Resource Capacity Chart

The Resource Capacity Chart plots the total capacity of each selected Resource over a period of time grouped in time buckets. This represents the amount of Online capacity on a resource.

Unit of Measure

Choose to view the total capacity in terms of number of hours or a relative decimal value between 0 (no online capacity) and 1 (online 24/7).

Time Bucket

Select the time bucket in the dropdown next to the Unit of Measure dropdown selection. The time bucket duration determines the amount of time to include resource capacity statistics for in each plotted point.

Start Date

Choose a start date for the chart using the date picker.

End Date

Choose an end date for the chart using the date picker.

Chart Style

Choose from a Line Chart, Bar Chart, Area Chart, etc. in order to visualize the data in different formats.

Toggle Legend

Toggle visibility of the Resource Selection Legend on/off.

Legend

Use the Resource Selection Legend to select which resources to plot in the chart.

Resource Units Chart

The Resource Units chart displays the total number of units (product quantity) each resource is scheduled to produce within each time bucket. This gives clear view of the planned output for each machine or work center.

Resource Utilization Chart

The Resource Utilization Chart shows how much of a resource's available capacity is being used. This helps to identify which resources are heavily loaded and which are underutilized.

Resource Utilization by Number of People Chart

The Resource Utilization by Number of People Chart shows how much of a resource's available capacity is being used while factoring in the number of people being utilized.

For example, if a shift is configured with its Number of People set to "3" and an operation is scheduled at that time to use all 3 people for 8 hours, then the utilized hours will total 8 * 3 = 24 hours. This helps to identify which resources are heavily loaded and which are underutilized. 

See Also

Plants, Departments, and Resources

Gantt Board

Scenario Data Board

Resource Mappings

Department Mappings

Plant Mappings</div>
        </section>
      
        <section class="article" id="article-196-customers-board">
          <h3 class="article-title">Customers Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/customers-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Customers Board is still very much a work in progress. Currently the only thing that can be done within the Customers Board is to manage information and properties associated with each customer.

The long-term vision for this board is to have tools available to generate reports based on customer data (think: revenue generated per customer, on-time vs. late deliveries per customer, order types and volume over time per customer, etc.) which should help to predict customer behavior, visualize customer trends, and gauge customer loyalty and satisfaction based on those trends. With this knowledge, organizations can choose to prioritize certain customer's orders or find ways to engage with their customers so that they may better understand the data and improve relationships and customer retention.

Jump to section:

Customers Grid

Customer Actions Tile

Customer Bulk Edit Tile

Customer Sales Orders Charts Tile

Customer Jobs Charts Tile

Customer Job Watch Gantt

Customers Grid

Use the Customers grid to create or delete customer objects or export customer data.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Customers Board Grid Properties

Customer Actions Tile

The Customer Actions tile allows users to perform various actions on one or more Customer objects. Select one or more rows from the Customers grid, then click the desired Action button to perform the action on the selected customer(s).

New

Create a new customer object with default values.

Copy

Create a new customer object as a copy of the existing selected customer object.

Select All

Select all grid rows. Alternatively, use the Ctrl+A keyboard shortcut.

Delete

Delete the selected customer object.

Customer Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more customers. Select one or more rows from the Customers grid, then choose properties and values that should be applied to each selected customer. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

Customer Sales Orders Charts Tile

The Customer Sales Orders Charts tile offers some graphical insights into each customer's associated sales orders. Users may view On-Time vs. Late orders and may choose to view the number of units or pieces ordered, or total revenue.

Select one or more customers from the grid to see each customer's data plotted in the chart. Hover over the plotted data to see specific statistics.

Customer Jobs Charts Tile

The Customer Jobs Charts tile offers some graphical insights into each customer's associated jobs. Users may view On-Time vs. Late jobs and may choose to view the number of units or pieces ordered, or total revenue.

Select one or more customers from the grid to see each customer's data plotted in the chart. Hover over the plotted data to see specific statistics.

Customer Job Watch Gantt Tile

Select one or more customers from the grid to see each customer's associated scheduled jobs isolated in the Job Watch Gantt.

Each Activity Block on the Gantt chart can be interacted with in the same manner as the Gantt Board charts.

Tooltips are enabled and cannot be disabled.

Show All Eligible Resources: When enabled, all resources which are eligible to schedule any of the activities of any of the watched jobs will appear in the Gantt, even if none of the activities of the watched jobs are scheduled there.

See Also

Customer Mappings

Job Mappings

Sales Order Mappings</div>
        </section>
      
        <section class="article" id="article-284-database-manager-board">
          <h3 class="article-title">Database Manager Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/database-manager-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Database Manager Board allows users to connect to and edit data from any SQL database. Generally, PlanetTogether instances are connected to SQL databases to import the data used for scheduling and to publish the schedule data out. The Database Manager Board allows users to connect to a database so that they can easily view and customize the data as needed.

This tool is handy for schedulers to modify configuration tables that can alter the import (for example, by adding a Resource or an Attribute) directly in PlanetTogether without going into SQL Server or their ERP system where the data often originates. 

Jump to section:

Connect to a server

Connect to a database

Browse a database

Edit a database

Connect to a server

To connect to a SQL server, click the Connect to a server button at the top of the board.

Enter an appropriate Server Name, choose to use Windows Credentials or enter a SQL user name and password, then click Connect.

Connect to a database

Upon establishing a successful connection to the server in the aforementioned Connect to a server step, the dialog will update to show a dropdown list of all databases that the user has access to. Select one from the list and click Confirm.

It's possible to quickly select a different database after establishing a connection to another by using the Select Database dropdown selection from the top menu then simply clicking the name of the desired database from the list.

Browse a database

Once a connection is established to the server and a database is selected, its Tables and Views will appear in the left side of the board. Expand either the Tables or Views menus and click once on any of the tables or views to select them and load all of their data in the grid view on the right side of the board.

Use column filters to search for specific text within any grid column.

Edit a database

In order for a database table or view to be editable in the Database Manager Board view, the table or view must have a primary key column defined. If users try to save edits to any table or view that does not have a primary key column defined then they will receive an error:

Update was not successful because the specified table does not have a primary key column

For information about how to create a primary key column or to assign one, see this article from Microsoft: Create Primary Keys.

Once a primary key column exists, users can make required edits directly in the grid in the Database Manager board, then click the Save Table Changes button in the top navigation to save the edits.</div>
        </section>
      
        <section class="article" id="article-247-gantt-board">
          <h3 class="article-title">Gantt Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/gantt-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether offers a Gantt chart to display scheduled activities of jobs ordered along a timeline broken out per shop floor resource to help schedulers and shop-floor personnel to visualize the schedule in an easy-to-read display. Each activity is rendered as a horizontal block with customizable overlaid text and various customizable color indicators for things like activity statuses, constraints, delivery timing, and bottlenecks. Each block can easily be dragged and dropped along the Gantt to another point in time and/or onto another resource or alternate path where it's eligible to schedule to simplify fine-tuning of the schedule.

Jump to section:

Gantt Chart

Toolbar Options

Resources Grid

Activity Blocks: Segments & Labels

Tooltips

Product Campaigns

Drag and Drop Scheduling

Activity Block Right-Click Actions

Job Watch Gantt Tile

Activity Status Tile

Job Properties Tile

Capacity Tools Tile

Resource Utilization by Number of People Tile

Resource Utilization Chart Tile

Resource Units Chart Tile

Resource Production Availability Chart Tile

Unutilized Capacity Chart Tile

Resource Capacity Chart Tile

Gantt Chart

The Gantt view consists of a Toolbar across the top with many options and features, a Resources grid on the left side with various information related to each Resource, and the Gantt chart itself where scheduled activities are visualized by rectangular activity blocks in the center of each resource swimlane, resource scheduling capacity is visualized by capacity interval blocks rendered at the bottom of each resource swimlane, and product campaigns can be visualized by campaign blocks at the top of each resource swimlane.

Plant View Gantt layout configurations can be customized and selected from a dropdown to display all resources in all plants, all resources in a specific plant, only resources found within a department, or a mix and match of any specific resources from any department that the user wants to view in one chart. The benefit of using a Gantt chart is to facilitate the visibility of the schedule and make it easier to see potential problems like bottlenecks and late deliveries. 

Toolbar Options

The toolbar options are found at the top of the Gantt chart. These options allow users to zoom in and out of the chart, find jobs and resources, and customize the information displayed on the activity blocks. 

Resize to fit rows: Adjust the height of the Gantt swimlane rows so that the visible resource swimlanes are displayed to fit the screen. A minimum height is enforced if there are many visible resource swimlanes which may result in the need to scroll up/down in the resource grid to view all swimlanes.

Zoom in: Zoom in by a small increment.

Zoom out: Zoom out by a small increment.

Zoom Gantt: Zoom to various intervals from a list of options. Below is a list of keyboard shortcuts to achieve the same zoom levels:

Ctrl + N = Now

Ctrl + T = Today

Ctrl + W = Week

Ctrl + Shift + T = Two weeks

Ctrl + M = Month

Ctrl + Y = Year

Ctrl + F = Frozen span

Ctrl + S = Stable Span

Ctrl + Shift + H = Planning Horizon

Variable Zoom: Show a magnified window on the Gantt for a multi-zoom level view. When enabled, a portion of the left side of the Gantt chart will be highlighted in blue and will show a zoomed-in perspective of the leftmost scheduled activities.

Zoom factor: Used in conjunction with Variable Zoom, sets the zoom level seen in the magnified window. Higher numbers reflect a more "zoomed in" view.

Job Lookup: Find a Job by its Name or External Id. If found, the Gantt chart will zoom to focus on the job and the job will be displayed with a blue flashing overlay. 

Resource Lookup: Find a Resource by its Name. If found, the Gantt chart will scroll to focus on the resource swimlane and the resource grid row will be given a blue background for emphasis. 

Print Gantt: Print or export to PDF any of the user's custom Gantt layouts

The dialog gives users the option to select one custom Gantt layout to print, or offers a Print All button to print or export two or more select Gantt layouts (or all layouts, if desired).

Select Layout: Use the dropdown in the top right corner to select the Gantt layout to be printed or exported.

Page Setup: Adjust paper size, page orientation, and margin settings.

Print: Print the selected layout. An additional prompt will appear to allow users to select the destination printer, or choose to save as a PDF.

Export Directory: Choose where to store the exported files.

Export: Export the files according to the current configured settings.

Print All: Opens a dialog to allow the user to select one or more custom Gantt Layouts for printing or exporting. Upon clicking Accept, the Export process will automatically begin and the selected layouts will be exported according to the current configured settings.

Duration: Select the number of hours/days/weeks of the chosen layout(s) which should be exported.

Time Per Page: Define how much time should be displayed per each printed or exported page.

Tooltips: When enabled, a tooltip window will appear as users scroll their mouse over Activity Blocks. The window contains information about scheduled activities and capacity intervals. The contents of the tooltip window can be customized per user. For more information, see: User Settings.

Fade: This feature is used in conjunction with the drop-down menu found immediately to its right. When enabled, all activity blocks apart from the one selected will fade to a transparent color. The drop-down menu allows users to opt to fade in additional activity blocks related to the selected one.

Job: Fade in all activities of the Job that is associated with the selected Activity.

Manufacturing Order: Fade in all activities of the Manufacturing Order that is associated with the selected Activity.

Operation: Fade in all activities of the Operation that is associated with the selected Activity.

Activity: Fade in only the selected Activity.

Inventory: Fade in all activities which have a common inventory association with the selected Activity.

All Relations: Fade in all activities of the Job that is associated with the selected Activity, as well as any activities which have a common inventory association.

Options: 

Anchor Activities in time after drag-and-drop or Expedite: When enabled, any activity that is dragged and dropped or expedited will automatically be anchored in time. For more information, see: Locking and Anchoring.

Lock Activities to Resources after drag-and-drop or Expedite: When enabled, any activity that is dragged and dropped or expedited will automatically be locked to the scheduled resource. For more information, see: Locking and Anchoring.

Move to Exactly the place specified: When enabled, dragging and dropping an activity to schedule on top of another scheduled activity will force the existing scheduled activity to move to a later point in time to make room for the newly placed one. When disabled, existing scheduled activities have priority and the dragged and dropped one will schedule immediately after the existing scheduled activity if placed on top of the existing block.

Expedite Successors after an Activity is moved: When enabled, any successor operation(s) to a drag-and-drop-moved activity will automatically be expedited to schedule as close to the newly scheduled activity as possible. Existing scheduled activities may be rescheduled later as a result.

Show Scheduling Hints: When enabled, scheduling hints will appear as vertical lines with labels in the Gantt chart whenever an activity is selected. Select an activity by clicking once on the activity block. Hints include: constraint release times (material availability, predecessor operation or MO end date, head start release date, etc.), JIT start date, and job need date, job finish date, among others.

Show Highlighting: When enabled, all activity block segments are replaced by Job Color highlighting so that all activity blocks in the Gantt are a solid color which reflects their associated job's configured Job Color.

Show Activity Links: When enabled, lines are drawn on the Gantt when an activity is selected to show linkages between the selected activity and other activities. Select an activity by clicking once on the activity block. Linkages shown include: predecessor and successor operations, operations that supply material, operations that consume material, helper resource activities, among others. Information about each activity link can be displayed by clicking on the line as its drawn in the Gantt.

View as Daily Activities: This view provides an easier-to-read view of the work to be done each day by resource. Each activity block spans the entire day's width, making it easier to read the text for each order. This view is useful for floor shop personnel who wish to see what will be worked on each day. 

If multiple operations are scheduled on the same day, they will appear stacked on top of each other with gray areas on each side so that each block spans the entire day. 

Note: if the scheduled activity starts on one day and ends the day after, the width of the activity block will span the entire two days.

Display Settings: A shortcut to the User Settings screen where the activity blocks, segments, and labels can be customized. For more information about customizing activity blocks, see: User Settings.

Plant View Gantt Layout Configuration: Select from a dropdown of all default or custom Plant View Gantt layout configurations. Each configuration may display a filtered set of resources in various sort orders according to the user's Plant View Configuration settings. For more information about creating and customizing Plant View Configurations, see: User Settings.

Resources Grid

The Resources grid can be expanded to show various resource data. Each column can be dragged and dropped to be rearranged in the order of the user's preference. The order of the columns will be stored as part of the user's Workspace Profile.

Helpful shortcuts:

Double-click any resource grid row to be taken to the Capacity Planning board with the selected resource in focus to view or edit its properties.

Right-click any resource grid row to perform various actions or view various reports

Activity Blocks: Segments & Labels

Each user may customize the Activity Blocks in the Gantt according to their preferences to show them the most useful data and information to them. Their settings are all stored as part of their Workspace Profile which can be shared with other users, if desired (see: Workspace Profiles Dashboard).

Click the Display Settings button from the Gantt Toolbar or navigate to User Settings from the Users menu dropdown in the main toolbar. Find the Gantt Activity Block and Segments settings under the Gantt section of the User Settings Board.

Each Activity Block consists of two parts: Segments and Labels. 

Segments

Segments are represented by colored horizontal bars in each Activity Block. Each Segment represents some unique piece of data or information related to the operation to give schedulers quick visual cues or indicators related to the Job, Operation, or Activity's production status, timing, progress, bottlenecks, and/or any custom piece of data or information users might want to incorporate into the Segments. 

The color of the segment will change to reflect the status or value of the property being displayed. Each of the colors represented at each possible status or value of the property related to the segment can be customized by clicking on the color block from the User Settings screen and choosing the desired color.

There are many different Segments and users have the option to display all of them or they can pick and choose which one or ones they prefer to see. From User Settings ➡️ Segments, toggle each segment on/off as desired.

Segment types include:

Commitment: Display the Job's Commitment level based on the property of the same name. 

Estimate: This is often an automatically generated job used to forecast demand or work without a firm job or demand behind it.

Planned: Similar to estimate, there is more certainty to a planned job, but it is still an order that may not have a firm job behind it.

Firm: This is a job that has been created by customer demand via a sales order for a work order.

Released: This is a job that has been created by customer demand and has been released to the shop floor for production. 

Material Status: Display information related to the Source(s) (or lack thereof) of all Materials required by the Activity. At least one of the "Item Types" checkboxes must also be checked for this segment to appear and provide any useful information.

Material Sources Planned: One or more Materials are not available but are covered by existing Jobs or Purchases

Material Sources Available: One or more Materials are available and are covered by existing Jobs or Purchases

Material Sources Unknown: One or more Materials are not available and are not covered by existing Jobs or Purchases

Material Sources Firm: One or more Materials are not available but are covered by existing Jobs or Purchases which are Firm.

Buffers: Display the level of buffer penetration for either material, drum, shipping, or stock buffers.

OK: Less than 33% buffer penetration.

Warning: Between 34% and 66% buffer penetration.

Critical: More than 66% buffer penetration.

Late: This activity is late. 

DBR Penetration Type: There are two types of buffer penetration types for manufacturing orders

Current: This is based on the current PC time and the manufacturing order's current status.

Projected: This is based on where the manufacturing order is currently scheduled on the Gantt. 

Priority: Display a color associated with the priority number assigned to the job. Define the Low and Medium range, then the High range is assumed to be anything higher than the highest Medium range setting. Use the "Preview value" input to visualize in the Settings screen what color a particular Priority value will look like based on the defined parameters.

Status: Display the current Scheduled Status of the Activity

On-Hold: The Activity is On Hold

Paused: The Activity is Paused.

Waiting: The Activity is waiting for some constraint before it can be eligible to start - a material, a predecessor operation, or a predecessor manufacturing order.

Ready: The Activity has all of its constraints satisfied (material, predecessor operations, MO release date) and is ready to start. 

Started: The Activity has had time or quantity reported or worked on so is considered "Started".

Setting-Up: The Activity is currently in the "Setup" phase of production (pre-production). 

Running: The Activity is currently in the "Run/Cycle" phase of production.

Post-Processing: The Activity is currently in the "Post-Processing" phase of production (post-production).

Transferring: The Activity's production phases are finished and the product(s) that it produces are being transferred to inventory or to the next resource.

Progress: Display the production progress of the Activity as a completion percentage in terms of the Reported Good Quantity compared to its Required Finish Quantity.

Process: Display the various phases of the Activity's production -- Setup, Cycle/Run, Post-Processing, and Storage. Each status is displayed as a vertical bar within the segment whose width is determined by the length of time to complete the process step, and each can have its own custom label text.

Use Setup Code Colors: When enabled, the Setup Color defined on the Operation will override the Setup segment color selection when drawn in the Gantt.

Setup: A label or color indicator for the Setup phase of the Activity.

Run: A label or color indicator for the Run/Cycle phase of the Activity.

Post-Process: A label or color indicator for the Post-Processing phase of the Activity.

Storage: A label or color indicator for the Storage phase of the Activity.

Clean: A label or color indicator for the Clean phase of an Activity.

Max Delay: Display indicators when an operation is in violation of its Max Delay Hours settings between it and its predecessor or successor operation. 

Ends Early: The operation is scheduled to end too early compared to where the successor operation is currently scheduled. The time between its Scheduled End Date and the successor's Scheduled Start Date is greater than Max Delay Hours.

Starts Late: The operation is scheduled to start too late compared to where its predecessor operation is currently scheduled. The time between its Scheduled Start Date and its predecessor's Scheduled End Date is greater than Max Delay Hours.

Both: The operation has both a predecessor and successor operation in violation of its Max Delay Hours setting.

Timing: Display the timing of the Job associated with the Activity as a comparison of its Scheduled Start and Finish dates against its Need Date.

Too Early: The activity is scheduled to end earlier than its Need Date minus the job's defined MaxEarlyDeliveryDays. The default value is "0" (zero) which effectively disables the feature/flag. Any job with a value of "0" in the MaxEarlyDeliveryDays field will never be considered to be scheduled "Too Early". 

On-Time: The activity is scheduled to finish no earlier than its Need Date minus the job's Max Early Delivery Days, nor any later than its Need Date minus the job's Almost Late Days. If either Max Early Delivery Days or Almost Late Days is set to "0" (zero) then those conditions do not apply. If neither of the conditions apply then an activity is considered "On Time" if it is scheduled to finish before its Need Date.

Almost Late: The activity is scheduled to finish before its Need Date but later than its Need Date minus the job's Almost Late Days. The default value for Almost Late Days is "0" (zero) which effectively disables the feature/flag. Any job with a value of "0" in the Almost Late Days field will never be considered "Almost Late".

Late: The activity is scheduled to finish after its Need Date. A constraining predecessor job or operation is forcing this activity to schedule later than its Need Date.

Capacity Bottleneck: The activity is scheduled to finish after its Need Date and is causing downstream operations to be late as a result.

Material Bottleneck: The activity is scheduled to finish after its Need Date due to its required materials not being available. It's causing downstream activities to also be late as a result. 

Release Bottleneck: The activity is bottlenecked by a set release date on the Manufacturing Order.

Attribute: Display color-coded information based on user-defined Attributes on the Operation, Job, and/or Product. Choose which data gets displayed by toggling the various switches. Each of the available switches may enable a new segment within the Attribute Segment which presents the data. Each attribute whose Show In Gantt flag is True will be displayed in a new segment within the Attribute Segment. Its color will equal that of the Attribute Color property value assigned to the associated Attribute.

Show Attribute Name: Display the Name of any Operation Attribute whose Show In Gantt flag is True.

Show Attribute Number: Display the Number property value of any Operation Attribute whose Show In Gantt flag is True.

Show Attribute Code: Display the Code property value of any Operation Attribute whose Show In Gantt flag is True.

Job Color: Display a segment with the Job Name with a background color equal to the Color of the Job associated with the activity block. 

Product Color: Display a segment with the MO Product Name with a background color equal to the ProductColor of the Product that is produced by the Manufacturing Order of the associated activity block. 

Advanced Sorting

If a user enables the user preference to Show advanced user settings, then they will see advanced options to define a Segment Priority, Minimum Height, and Proportional Height Weight to each segment.

Segment Priority: The segment priority determines the sort order in which the segment appears in the Gantt. Lower numbered priority values will be sorted before higher valued segments.

Minimum Height: Define the minimum segment height in pixels.

Proportional Height Weight: A percentage value weight which determines the segment height proportional to other enabled/visible segments.

Labels

Activity Block Labels refer to the visible text displayed in the Gantt block. Labels can be configured separately for each individual Segment that is enabled to be displayed,</div>
        </section>
      
        <section class="article" id="article-242-grid-edit-mode">
          <h3 class="article-title">Grid Edit Mode</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/grid-edit-mode" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Each of the boards which utilize a grid to present object property values and data is equipped with a Grid Edit mode which allows users to quickly add notes or update editable object property values.

Jump to section:

Standard Functionality

Grid Editor Workspace Profile

Standard Functionality

When Grid Edit mode is enabled, the grid layout cannot be modified so start by selecting or creating a grid layout which displays the desired editable properties, then click the Edit Mode icon at the top of the board grid to enable Edit Mode.

Once enabled, editable property values have a white background in the grid while non-editable properties display with a gray background. As users make modifications to any property value, their changes are not immediately saved. They can see their changes via a yellow background in the grid cell whose value was updated.

Any number of changes can be made, then when the user is done they can opt to save or revert the changes before disabling Grid Edit mode to go back to browsing.

Grid Editor Workspace Profile

A Workspace Profile is available to download and import for users who may frequently be modifying many property values and want a quick way to select preconfigured layouts with the most commonly edited and editable properties organized in a manner that groups like-properties and like-objects together.

Download the Workspace Profile here: [ INSERT LINK HERE ]

Follow the steps in the Workspace Profile Dashboard article's Import section to import the profile from the downloaded file so that it can be easily selected from the User dropdown in the main toolbar.

See Also

Activities Board

Capacity Planning Board

Customers Board

Inventory Plan Board

Jobs Board

Materials Board

Purchase Orders Board

Routing Templates Board

Sales Orders Board</div>
        </section>
      
        <section class="article" id="article-288-import-mappings-board">
          <h3 class="article-title">Import Mappings Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/import-mappings-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Import Mappings Board is the gateway to the Interface Setup Wizard. The wizard guides users through the process of creating and testing an interface to a backend system database. Users have flexibility to import some or all object types available, then configure database field-to-PlanetTogether property mappings. SQL queries can be used to filter the incoming data from the selected database table/view, and/or in any of the property mapping inputs for conditional values or any number of use cases.

Jump to section:

Welcome

Resource Objects

Inventory Objects

Job Objects

Mappings Pages Interface

Welcome

Users will be presented with a Welcome screen the first time they visit the Import Mappings board. Give it a quick once-over then it probably makes sense to check the box to [x] Skip this welcome screen next time.

The Welcome screen presents the option of using a Custom Interface instead of importing from a database, but this is not typically used. This option requires creating a custom program file named CustomInterface.dll placed in the ProgramFiles folder. 

Click the Next button in the lower right corner to proceed to select which Resource Objects should be imported.

Resource Objects

Resource Objects deal primarily with the physical setup of the manufacturing facility and will consist of how machines and capital are organized into a tiered structure. Additionally, Resource Objects are meant to reflect the manufacturer’s capacity to do work and the type of work that can be done.

Select which objects to include during the Refresh operation using the toggles next to each line item.

Use these links to navigate to the specific object mappings articles:

User Mappings

Plant Mappings

Department Mappings

Capability Mappings

Cell Mappings

Resource Mappings

Capability Assignment Mappings

Resource Connector Mappings

Allowed Helper Resource Mappings

Resource Attribute Mappings

Capacity Interval Mappings

Recurring Capacity Interval Mappings

Product Rule Mappings

Attribute Setup Table Mappings

Attribute Code Table Mappings

Setup Code Table Mappings

Click the Next button in the lower right corner to proceed to select which Inventory Objects should be imported.

Inventory Objects

Inventory Objects pertain to the materials and products that the manufacturer purchases and produces and stores in inventory. Thus, Item and Inventory Objects will deal with raw and intermediate materials and SKUs and the warehouses that stock them. Objects range from physical inventory and warehouses, to planned purchase orders to stock, sales order demands, and forecasted demands.

Select which objects to include during the Refresh operation using the toggles next to each line item.

Use these links to navigate to the specific object mappings articles:

Item Mappings

Warehouse Mappings

Warehouse Plant Mappings

Inventory Mappings

Lot Mappings

Sales Order Mappings

Forecast Mappings

Purchase To Stock Mappings

Transfer Order Mappings

Click the Next button in the lower right corner to proceed to select which Job Objects should be imported.

Job Objects

Job Objects refer to work order or production order information. Job Objects include the routing information for the products that need to be created, as well as other business information like customer information, order quantities, and due dates. Where Resource Objects define what can be produced, Job Objects define how the items are produced and will ultimately inform the Resource Objects of what should be produced on a given day.

For more information about how PlanetTogether breaks down Jobs into individual components, see: Job Structure.

Select which objects to include during the Refresh operation using the toggles next to each line item.

Use these links to navigate to the specific object mappings articles:

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Internal Activity Mappings

Resource Requirement Mappings

Required Capability Mappings

Material Mappings (BOM)

Product Mappings

Operation Attribute Mappings

Successor Manufacturing Order Mappings

Alternate Path & Node Mappings

Customer Mappings

Mappings Pages Interface

The User Interface on each of the mappings pages makes the SQL field-to-PlanetTogether property mapping task intuitive and very flexible to accommodate the multitude of ways customers may have their SQL data sources configured.

Select From

Use the Select From text input to start building a SQL SELECT statement to fetch data from one or more SQL tables or views that contain the data related to the object mappings page currently in focus. Certain portions of the SELECT statement are built into PlanetTogether already so this is just an area to input a table or view name along with any additional SELECT instruction/logic needed after the FROM portion of the statement to retrieve the necessary data from the database.

Distinct: When enabled, the SELECT statement becomes a SELECT DISTICT statement so that only unique rows of data will be returned.

Limit rows when mapping: This editable value only impacts the Preview Mapped Data and Browse Source Data buttons under the Filter (SQL WHERE Clause) section of the mappings interface. It limits the number of rows returned by these buttons to only the number defined. The default value is 1,000. To view all rows when Previewing or Browsing the data, enter a "0" zero in this field.

Filter (SQL WHERE Clause)

Use the WHERE clause text input to filter the data returned by the SELECT statement, if necessary. This input is optional. Note that the WHERE portion is implied so enter text into this field as if the SELECT statement already ends with WHERE.

Auto-delete for omitted records: When enabled, objects which are not present in the SQL data source and thus not included in the incoming import data will automatically be deleted from PlanetTogether during the Refresh process. Users may enable this logic for none, some, or all object types that offer the toggle switch.

Preview Mapped Data: Click this button to query the database and display a dialog that previews only the mapped data according to the configured Select From and Filter (SQL WHERE Clause) and Limit rows when mapping and all of the property mappings from the Mappings Grid below.

Browse Source Data: Click this button to query the database and display a dialog that returns all SQL data according to the defined Select From and Filter (SQL WHERE Clause) and Limit rows when mapping settings.

Mappings Grid

Enter SQL Field names or conditional statements into the Source column to map those field values to the appropriate PlanetTogether Property.

Property: The name of the PlanetTogether Property

Type: The data type of the Property

Required: A True/False flag to indicate whether or not the Property is required to have a value imported.

Source: A SQL Field name or SQL conditional statement that may or may not contain a value (many Properties allow NULL values). The data type of this Field or value must match the Property Type.

Sample Data Grid

Preview a row of data from the selected table or view.

Grid columns

Field: The SQL field name.

Type: The data type of the Field.

Sample: The Value of the Field in SQL.

Buttons

Refresh Field List and Sample Data: Fetch one random row of data from the SQL data source and display the data in the grid.

Copy matching fields: Quickly map any SQL Fields to PlanetTogether Properties if they share the same name (i.e. the SQL Field is named the same as the PlanetTogether Property).

Next Sample: Fetch a new row of random data from the SQL data source and display the data in the grid.

Test: Test the import process to see if the current configuration might produce errors.

Perform Import: Import only the mapped data of the current mappings page.

Object Help

Click the Object Help button to be taken to the Knowledge Base article that describes each of the PlanetTogether Properties that can be mapped for the Objects whose mappings are currently being viewed.

Clear All

Remove all entries from the Source column of the Mappings Grid.

Test

Test the connection to the SQL data source using the provided inputs and mappings configuration.

Perform Import

Import data from the current Mappings page and any dependent objects. For example, Perform Import from the Plant Mappings page will only import Plant data (it has no dependencies), whereas Perform Import from the Resource Operation Mappings page will also import all Plant, Department, Resource, Capability, Inventory, and Job objects (or else Resource Operations might not have anywhere to import to).

Save Settings

Save Automatically: Any changes made to any field within the Import Mappings board pages will be saved instantly.

Prompt to save on exit: Changes made to the Import Mappings pages will not be saved automatically. The user will be prompted whether or not to save their changes when they close the Import Mappings board, or when they exit the Client application.

Don't save automatically: Changes made to the Import Mappings pages will not be saved automatically. The user must click the Save Mappings button in order to save.

Page Navigation

Find the Mappings page navigation in the lower right corner. Use Back and Next to move forward or back 1 page at a time, or use the dropdown to find a specific Mappings configuration. The Mappings pages are listed in the order that they get imported into the system (the non-alphabetical sort is intentional!).</div>
        </section>
      
        <section class="article" id="article-304-inventory-plan-board">
          <h3 class="article-title">Inventory Plan Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/inventory-plan-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Proper inventory management is essential to ensure that demands are met while minimizing the costs incurred by carrying excess inventory. In PlanetTogether, the Inventory Plan Board offers detailed inventory-level information for every item and material used throughout the production process and provides users with a visual representation of supply and demands. The inventory plan will allow planners to ensure sufficient materials to supply incoming demands and enough time to purchase or manufacture additional materials. 

Jump to section:

Inventory Grid

Transfer Orders Tile

Inventory Bulk Edit Tile

Forecast Manager Tile

Adjustments Report

Inventory Plot Report

Inventory Grid

The inventory grid contains information about all inventory items, such as where those items are stored, any on-hand quantities, and total supplies and demands for that item. Each row represents a different inventory item. In addition, the inventory grid is searchable, which allows users to quickly find items by typing the item's name in the search box found at the upper-left corner of the grid. 

Select grid rows from the inventory grid when interacting with the other tiles in the board to see data related to the selected grid row.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Transfer Orders Tile

The Transfer Orders tile gives visibility into transfer orders in the data model. Transfer orders represent transfers of inventory from one warehouse to another at designated times so that jobs or operations which require material from a specific warehouse may be scheduled to consume the material from the appropriate warehouse.

Save: Save any pending edits from the in-grid editor.

New: Create a new transfer order.

Delete: Delete the selected transfer order(s).

Clear: Clear all transfer order data from the scenario.

Inventory Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more inventory records. Select one or more rows from the Inventory grid, then choose properties and values that should be applied to each selected inventory record. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

Forecast Manager Tile

Demand forecasting aims to accurately predict the demand and schedule production accordingly. Forecasts represent projected demand for a specific item over time. 

Select any item from the Inventory Grid to manage its Forecasts in the Forecast Manager tile. From the tile users can view, adjust, remove, and/or generate forecasts of demands for the selected item. Forecasts are treated as demand signals for MRP within PlanetTogether so if using MRP to generate jobs, it will generate them according to forecasted demands.

Forecast Orders can be imported from the SQL data source or manually generated in the PlanetTogether Client interface.

Generate Forecasts

Click the button from the Forecasts Manager tile toolbar to bring up the Forecast Generator dialog.

Select or modify each of the inputs according to forecast projections for the selected item.

Forecast interval: Select from quarterly, monthly, weekly, or daily intervals.

Number of intervals to forecast: Enter the number of intervals to be forecasted.

First interval date: Enter the date (Need Date) of the first interval to be forecasted.

Quantity of the first interval: Enter the quantity required of the first forecasted interval.

Consecutive Intervals: 

Equal the first (constant): All forecasts will be generated with the same quantity as the first interval.

Increase: The quantity will increase by the specified percentage amount with each forecasted interval.

Decrease: The quantity will decrease by the specified percentage amount with each forecasted interval.

Click the Generate button to generate forecasts according to the selected parameters.

Adjust Forecasts

Select any forecast from the Forecast Manager tile, then click the button from the toolbar to bring up the Adjust Forecast Quantities dialog.

Value: Adjust the Required Quantity to a specific value.

Scale: Adjust the Required Quantity up or down by a specific percentage of the original quantity.

Up/Down: Select a radio option to scale the quantity up or down.

Click the Adjust button to adjust the quantity of the selected forecast according to the selected parameters.

Include Forecasts in Inventory Calculations

When this toggle switch is enabled, Forecasts will be factored into inventory levels over time. Since Forecasts are demands, they are visualized as negative impacts to inventory. From the Inventory Plot Report, Forecasts can be identified by exposing the Reason column.

Adjustments Report

The Adjustments Report displays demand, supply, and ending (net) inventory for an item over time for a specified time horizon.

Period: The Period determines the time bucket duration for each column. For example, if the period is set to "1 week" then each column represents the inventory adjustments for the item occurring each week.

Horizon: The Horizon defines whether the information included in the report is contained only in the Short-Term span or for the entire Planning Horizon. The Short-Term span and Planning Horizon durations are set in the System Settings under Scheduling Options.

Inventory Warnings: The Net Inventory row is color-coded to show inventory levels at each Period time bucket and how they compare to various factors like Max Inventory, Safety Stock, Shortages, or sufficient supply to meet all demands. 

Above Max Inventory: Represents an item that is overstocked in inventory and is incurring unnecessary carrying costs. The max inventory field triggers this warning flag, and these items are highlighted in orange. 

Below Safety Stock: Represents an item below the safety stock but has sufficient inventory to handle incoming demands. These items are highlighted in yellow.

Shortage: Represents an item in inventory that is beneath the safety stock level, is outside of its lead time and has a demand for that item. These items are highlighted in red.

OK: Represents an item above the safety stock and has enough inventory to handle incoming demands. These items are highlighted in green.

Inventory Plot Report

The Inventory Plot Report offers both a plot chart and a grid view of all inventory adjustments made over the course of the schedule.

Select any item from the Inventory grid to plot its adjustments over time in this plot report tile.

Toggle on Show Adjustments After Planning Horizon to include adjustments in the chart and grid which are scheduled past the planning horizon.

Chart

The chart displayed in the top half of the report displays inventory levels at various points in time. The chart will start at the beginning of the planning horizon with the current on-hand level and will end at the date and time of the last scheduled adjustment.

Controls are offered to adjust the visible start and end date/time by dragging and dropping the circles with blue dots on either side of the condensed chart directly underneath the bar chart:

Plotted Values

The Plotted Values table displays information about inventory adjustments made at each plotted point. This may include combined quantities of two or more adjustments that get applied at the same time and therefore are both contributing to the inventory level at the plotted point on the chart.

Inventory Details

The Inventory Details table displays each specific inventory adjustment made at each point in time. It is the most detailed view of all adjustments from jobs, purchase orders, sales orders, forecasts, etc. over the course of the scheduled planning horizon.

Show Materials: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Show Materials button to open the Materials board with a temporary filter applied to show information about the selected scheduled adjustment.

Open Job: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Open Job button to open the Job Details dialog of the job associated with the selected adjustment.

Find Operation: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Find Operation button to open the Gantt board with a focus on the operation associated with the selected adjustment.

Export: Export the grid in one of the optional formats (HTML, PDF, XLSX, or CSV).

Grid Properties:

Field Name
Description

Available Level
The amount of total inventory that is available to be consumed at the time of the adjustment.

Change Qty
The quantity difference of the inventory level introduced by the adjustment.

Customer
The name of the Customer associated with the Job or Sales Order associated with the adjustment.

Date
The date of the adjustment.

Date and Time
The date and specific time of the adjustment.

Forecast
The name of the Forecast associated with the adjustment.

Inventory Level
The total inventory level at the time of the adjustment.

Item Name
The Name of the Item associated with the adjustment.

Job Id
The ExternalId of the Job associated with the adjustment.

Job Name
The Name of the Job associated with the adjustment.

Lot Code
The Lot Code associated with the Job Product adjustment.

MO Name
The Name of the Manufacturing Order associated with the adjustment.

Need Date
The Need Date of the Job associated with the adjustment.

Operation Id
The ExternalId of the Job Operation associated with the adjustment.

Operation Name
The Name of the Job Operation associated with the adjustment.

Priority
The Priority of the Job associated with the adjustment.

Product Group
The Product Group of the Item associated with the adjustment.

Product Name
The Product Name of the primary product of the Manufacturing Order associated with the adjustment.

Reason
A description of the reason for the adjustment.

Sales Order
The Name of the Sales Order associated with the adjustment.

Sales Order ExternalId
The ExternalId of the Sales Order associated with the adjustment.

Sales Order Line
The Line Number of the Sales Order associated with the adjustment.

Storage Area
The Name of the Storage Area that was impacted by the adjustment.

Storage Area Available Level
The combined amount of available inventory in the impacted Storage Area at the time of the adjustment.

Storage Area Level
The combined amount of all inventories/items in the impacted Storage Area at the time of the adjustment.

Transfer Order
The Name of the Transfer Order associated with the adjustment.

See Also

Warehouse Mappings

Plant Warehouse Mappings

Item Mappings

Inventory Mappings

Lots Mappings

Forecast Mappings

Transfer Order Mappings</div>
        </section>
      
        <section class="article" id="article-212-jobs-board">
          <h3 class="article-title">Jobs Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/jobs-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, jobs represent top-level objects that generate requests for the shop to produce one or more items or products by a specific time. The Jobs Board helps users to visualize the schedule-ability and statuses of the jobs in the data model, allows them to manually adjust or create jobs, and setup custom layouts and metrics and KPI trackers to better visualize throughput, profitability, and schedule execution accuracy.

Jump to section:

Jobs Grid

Job Actions Tile

Create Job Tile

Job Bulk Edit Tile

Job Generator Tile

Job Demand Tile

Job Watch Gantt Tile

Connected Jobs Gantt Tile

Browse Data Tile

Jobs Grid

The Jobs Grid offers a grid view with a plethora of data pertaining to all jobs in the data model, including (but not limited to) its Name or ID, Need Date, Product, Quantity, Scheduled Status (including Start and End Dates), Customer information, Cost and Revenue information, and various flags about the production status to help to quickly see if it's Early or Late or Failing to Schedule for some reason. 

Double-click any grid row to bring up the Job Dialog window to make adjustments to the selected job and its Manufacturing Orders, Alternate Paths, Operations, and Activities.

Right-click any grid row to bring up a menu of Actions that can be performed on the selected job.

Select grid rows from the Jobs grid when interacting with the other tiles in the board to see data related to the selected grid row.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Job Actions Tile

Use the Job Actions tile to perform quick actions on one or more selected jobs from the Jobs grid.

Management

Open: Open the Job Details Dialog of the selected job.

Copy: Copy the selected job. Displays the Job Details Dialog screen to make adjustments to the copy before the copy is created. Users may optionally Cancel the creation of the job copy from the Job Dialog, or proceed to make adjustments to the job and Save and Close from the Job Dialog to create the job copy.

New: Create a new job from scratch via the Job Details Dialog.

Delete: Delete the selected Job(s).

Scheduling

Optimize Selected Jobs: Performs an optimize for only the job(s) selected. This optimize does not include any of the jobs supplying materials for the selected jobs.

Ignore Constraints: Change all stock material requirements on the selected Activity(ies) from Constrained by Available Date to Ignored-Constraint, and from Constrained by Earlier of Lead Time and Available Date to Ignored-LeadTimeConstraint so that subsequent scheduling actions will not enforce material constraints.

Restore Constraints: Change all stock material requirements on the selected Activity(ies) back from Ignored-Constraint to Constrained by Available Date, and from Ignored-LeadTimeConstraint to Constrained by Earlier of Lead Time and Available Date so that subsequent scheduling actions will once again enforce material constraints.

Anchor: Anchor the job and all of its operations to their currently scheduled point in time. See also: Locking and Anchoring

Unanchor: Remove the Anchored status from the job and its operations.

Insert Jobs Individually: Insert each of the selected jobs one at a time into the schedule via CoPilot. A new scenario will be created with the resulting schedule.

Insert Jobs as a Group: Insert each of the selected jobs as a group into the schedule via CoPilot. If any one of the jobs is unable to be scheduled, then all of them will fail to schedule. A new scenario will be created with the resulting schedule.

Hold: Put the job On Hold to effectively prevent scheduling it before a certain date and time. The user will be presented with a Hold Job dialog where they must enter a date and time when the job should be held until. They may optionally provide a Reason for Hold as well, for informational purposes.

Unhold: Remove the Hold status from the job and its operations.

Unschedule: Remove the job from the schedule.

Lock: Lock the selected job and its operations to their currently scheduled resource. See also: Locking and Anchoring

Unlock: Remove the Locked status from the selected job and its operations.

Find in Gantt: Quickly locate the selected job in the Gantt chart on the Gantt board.

Expedite

Do ASAP: Reschedule all Activities of the selected Job(s) to begin as early as possible, as early as the start of the schedule (constraints allowed). Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Preserve the Frozen Span: Reschedule all Activities of the selected Job(s) to begin as early as possible without entering the Frozen Span area. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Preserve the Stable Span: Reschedule all Activities of the selected Job(s) to begin as early as possible without entering the Stable Span area. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

To specific date and time: Reschedule all Activities of the selected Job(s) to begin as close as possible to the specified date. Their Supplying Manufacturing Orders will also be expedited if the user's expedite settings are configured to [x] Include Supplies.

Create Job Tile

Use the Create Job tile to create a job as a copy of an existing job or routing template, or create a new job from scratch.

Copy Job

From the Copy Job tab, select any job row from the Jobs grid to quickly populate the information in the Copy Job form, or select an existing job from the Select job to copy dropdown. Input other basic information as needed, then click Create Job to create a new job as a copy of the selected job.

New Blank Job

Click the New Blank Job button to open the Job Details Dialog to begin creating a new job from scratch.

Job Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more jobs. Select one or more rows from the Jobs grid, then choose properties and values that should be applied to each selected job. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

Job Generator Tile

Use the Job Generator tile to create many copies of one or more selected jobs. Optionally, randomize values of various job properties. This job generation method is meant for creating sample jobs for mock schedules and is not intended to be used for production scheduling purposes.

Number of Copies of each Job: Define how many copies of each selected job will be generated.

Number of Jobs to be copied: The current number of selected jobs from the Jobs grid that will be copied. All selected jobs will be copied.

Job Copy Prefix: Define a prefix for each of the generated job copies Job Names.

Job Start Value: Define a numerical value to start counting from while generating job copies. This value gets appended to the end of the Job Name of the first job created, then subsequent jobs increment up by 1 each time.

Convert any Templates to Jobs: If using the Generator tile from the Routing Templates board then the selected grid rows are job templates. Enable this feature to convert copies of Routing Templates to Jobs, or disable this feature to preserve the Routing Template status and create additional Routing Template copies instead.

Randomize Values: When enabled, various property values can be randomized using the table provided.

Randomize Values

Use the Randomize Values table to set Minimum and Maximum ranges to various property values that the generator may use while creating copies of the selected jobs.

Dates and Numbers

Need Dates

Required Quantity

Revenue

Priority

Minutes per Cycle

Setup Hours

Setup Number

Products

Randomize Product and Colors

Use must also enter Product and/or Color data into the provided table if this option is enabled

Use Color as Operation Attribute

Customers

Randomize Customers

Select which customers to include in the randomization from the multi-select dropdown input.

Other

Randomize Commitments

Randomize Colors of Job Copies

Job Demand Tile

Select a job from the Jobs Grid to see more information about the demand signal(s) that the job is satisfying or pegged to. This can be especially helpful for MRP-generated jobs or lot-pegged jobs to see which demands (sales orders, forecasts, or other job material requirements) are satisfied by the selected job.

Original Demand

The Original Demand lists the forecast or sales order or job that caused the job to be created during MRP.

Pegged Demand

Pegged Demand designates the supply of materials for a specific job. Demand pegging allows you to know you have the materials set aside to complete the job. The allocated materials cannot be used for any other job.

Job Watch Gantt Tile

Select one or more jobs from the Jobs Grid to plot their scheduled operations in the Job Watch Gantt tile. This Job Watch Gantt is very similar to the one in the Gantt Board except the only way to select which jobs are "watched" is to select them in the Jobs Grid.

Each Activity Block on the Gantt chart can be interacted with in the same manner as the Gantt Board charts.

Tooltips are enabled and cannot be disabled.

Show All Eligible Resources: When enabled, all resources which are eligible to schedule any of the activities of any of the watched jobs will appear in the Gantt, even if none of the activities of the watched jobs are scheduled there.

Connected Jobs Gantt Tile

Select one or more jobs from the Jobs Grid to plot their scheduled operations and all operations of other connected jobs in the Connected Jobs Gantt tile. Jobs are considered "Connected" if they supply or receive an item to/from another job.

Each Activity Block on the Gantt chart can be interacted with in the same manner as the Gantt Board charts.

Activity links and tooltips are enabled and cannot be disabled.

Show All Eligible Resources: When enabled, all resources which are eligible to schedule any of the activities of any of the watched jobs will appear in the Gantt, even if none of the activities of the watched jobs are scheduled there.

Browse Data Tile

Browse, search, and export all jobs data for analytical/informational purposes. The visible data in the tile grids is limited to showing only the data related to selected jobs from the main Jobs grid.

Use the export icon near the top of the tile to export any filtered grid to an XLSX, PDF, HTML, or CSV file.

See Also

Job Structure

Job Details Dialog

User Defined Fields (UDFs)

Job Mappings

Manufacturing Order Mappings

Alternate Path & Node Mappings

Resource Operation Mappings

Resource Requirement Mappings

Required Capability Mappings

Material Mappings

Product Mappings

Operation Attribute Mappings</div>
        </section>
      
        <section class="article" id="article-329-kpis-board">
          <h3 class="article-title">KPIs Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/kpis-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The KPIs Board allows users to see the costs and benefits of the current schedule. There are a wide variety of indicators or criteria that can be tracked, and the graph will show how each schedule change affects the tracked criteria. In addition, each point on the graph serves as a possible undo point, and the planner can use the graph to "undo" back to any action by simply right-clicking clicking on the point and selecting "Undo back to this point".

KPIs Grid

Use the KPIs grid on the right side of the page to view and filter the visible plotted KPIs, their current value, and their value just prior to the latest snapshot.

Configure grid layouts and save them for quick access/viewing at a future date. Export the grid to Excel, PDF, or other formats for external analysis.

Toolbar

Save KPI Snapshot

Click this button to manually save a snapshot of the KPI statistics that are produced by the current schedule. The point will be plotted on the KPI chart.

Options

Store KPI Snapshots

After each Publish: When enabled, a KPI snapshot will be saved when any user publishes the schedule.

After each Import: When enabled, a KPI snapshot will be saved when any user imports data via a Data Refresh.

After each schedule change: When enabled, a KPI snapshot will be saved when any user performs any scheduling action (drag/drop, expedite, Optimize, Compress, etc.).

Maximum number of Snapshots to store: Define the number of snapshots that should be stored and plotted at any time.

Tip: Store KPI snapshots automatically at specified times and/or intervals using Automatic Actions in System Settings.

For more information, see: Automatic Actions

KPI Visibility

Use this dialog to select which KPIs should be calculated by the system. The default colors can be configured here for each KPI as well.

Compare Scenarios Mode

When enabled, the KPI data for any scenario with the "Compare Scenario" setting enabled in its settings will be compared to the currently active scenario.

See Also

Predictive KPI Tiles</div>
        </section>
      
        <section class="article" id="article-182-materials-board">
          <h3 class="article-title">Materials Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/materials-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Materials Board offers insights into the data pertaining to material requirements and their sources of all scheduled jobs, manufacturing orders, and operations. Use the data to see where materials are coming from to supply each consuming operation and when they are needed. This data can help material planners to ensure that the release and procurement of materials are in sync to meet demands.

Jump to section:

Materials Grid

Material Requirement Actions Tile

Material Bulk Edit Tile

Materials Grid

The Materials grid displays important information about the materials that are used to supply jobs and operations. For example, columns will display the date the material is needed by, the date in which the material is available, which warehouse is supplying the material, as well as if there is a shortage of material.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Material Requirement Actions Tile

Use the Material Requirement Actions tile to perform quick actions on one or more selected materials/jobs from the Materials grid. Access the same actions from the right-click menu without needing to open the tile.

Reporting

Inventory Plot: Open the Inventory Plot tile from the Inventory Plan board with the selected material in focus. This action only supports one grid row selection at a time. If multiple grid rows are selected, only the most recently selected one will be used, as indicated by the > arrow icon next to the grid row number:

Find in Gantt: Find the operation associated with the selected grid row in the Gantt. The Gantt board will come into focus with the associated operation targeted.

Production

Report Issued Material: Use this to manually update the Issued Quantity on the selected material adjustment. After material is issued, when the operation starts, rather than the entire required quantity of the material requirement being deducted from inventory, the required quantity minus the issued quantity is deducted from inventory as if the issued amount has already been deducted.

For example, if the required quantity of the operation is 50 and the qty of reported issued material is 10, a quantity of 40 will be deducted from inventory when the operation is scheduled to start.

NOTE: This can be visualized by using the Issued Quantity column in the grid.

Issued from Inventory: Similar to Report Issued Material, use this to manually update the Issued Quantity on the selected material adjustment and immediately deduct the specified amount from the current on-hand inventory.

For example, if the required quantity of the operation is 25 and the quantity issued from inventory is 10, then 10 will be deducted from inventory and Issued Quantity on the operation's material requirement will reflect 10 so that when the operation schedules to start it will only consume 15 more pieces from inventory.

Management

Select All: Select all grid rows. Alternatively, use the Ctrl+A keyboard shortcut.

Material Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more material requirements. Select one or more rows from the Materials grid, then choose properties and values that should be applied to each selected requirement. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles</div>
        </section>
      
        <section class="article" id="article-267-metrics-board">
          <h3 class="article-title">Metrics Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/metrics-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Metrics Board offers a dashboard view of all Metrics configured in the scenario. Each metric slide in the Metrics Board offers detailed information about the last scheduling action and how it impacted the metric count, as well as a quick link to navigate to the filtered grid layout which is producing the metric statistics so that users may further analyze why the metric is reporting the statistics that it is.

For information about configuring Metrics and Targets, see: Layouts, Metrics, and Targets.

Jump to section:

Categories and Sorting

Data Analysis

Categories and Sorting

Metrics are separated into categories based on the board grid from which they originate: Jobs, Sales Orders, Inventory Plan, Materials, Purchase Orders, etc.

Each categorized set of metrics is sorted by its configured priority where the highest priority metrics will be listed first.

Data Analysis

Details about the metric, its statistics, and how close it is to meeting its target can be viewed in a popup dialog that appears as users hover their mouse over the various icons and text in each metric slide.

Quick focus

Click anywhere in any of the metric slides to bring its grid layout into focus for deeper analysis of the data.

Metric title

Hover the mouse over the metric title to reveal the name, grid, and applied property filters of the layout that is producing the metric.

Target information

Hover the mouse over any of the target icons to see more detailed information about the target and statistical analysis of how close the current schedule is from reaching the target.

Data change information

When the count or percentage of a metric with Changes Highlighting enabled changes from the last schedule modification, a red or green arrow indicator will appear along with a count and a percentage statistic of the change impact. Hover the mouse over these statistics to see more information about what recent action resulted in the change.

See also:

Layouts, Metrics, and Targets</div>
        </section>
      
        <section class="article" id="article-317-object-bulk-edit-tiles">
          <h3 class="article-title">Object Bulk Edit Tiles</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/object-bulk-edit-tiles" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Bulk Edit object editors allows for the modification of one or more properties applied to one or more objects of the same type (think -- multiple resources or jobs or sales orders or customers; etc.). This tile is especially helpful for creating demos and sample data, but also has some practical production scheduling use cases as well.

Standard Functionality

With the Bulk Edit tile open, select one or more grid rows from the main board grid. All selected rows will have the bulk edit(s) applied to them. Use Ctrl+A to select all visible rows, or use Ctrl+Click or Shift+Click to select multiple rows as needed.

With one or more rows selected, choose a property from the Property dropdown selection. Depending on which property is chosen, the Value input may change to a checkbox for boolean values, a dropdown selection for properties whose values are predeterminate, or a text input for properties which accept numbers or strings of text. Enter or select the desired value for the chosen property.

As soon as one Property to Value combination is chosen, a new dropdown selection will appear under the Property section. This is optional to allow users to choose to update more than a single property's value as needed for all of the selected objects.

Finally, once all Property to Value combinations are ready, click Save to apply the change(s) to all selected grid objects. Alternatively, click Clear to clear all pending changes and start over from a blank Bulk Edit tile.

See Also

Activities Board

Capacity Planning Board

Customers Board

Inventory Plan Board

Jobs Board

Materials Board

Purchase Orders Board

Routing Templates Board

Sales Orders Board

User Management</div>
        </section>
      
        <section class="article" id="article-183-purchase-orders-board">
          <h3 class="article-title">Purchase Orders Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/purchase-orders-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Purchase Orders (sometimes referred to in PlanetTogether as Purchases to Stock) are orders for additional material from external or internal vendors, generally created for raw or intermediate materials. They represent an increase in the supply of materials and help keep the inventory plan up to date with incoming and outgoing inventory when materials are used to supply jobs.

The Purchase Orders Board offers insights into scheduled and received Purchase Orders over the current scheduled planning horizon and allows users to manage their Purchase Orders and/or create new ones as needed.

Jump to section:

Purchase Orders Grid

Purchase Order Actions Tile

Purchase Order Bulk Edit Tile

Purchase Orders Grid

The Purchase Orders grid offers details of each Purchase Order in the data model, including their scheduled receipt and scheduled availability dates, the item being purchased, the quantity, the vendor or buyer, etc.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Purchase Order Actions Tile

Use the Purchase Order Actions tile to perform quick actions on one or more selected purchase orders from the Purchase Orders grid.

Management

Delete: Delete the selected Purchase Order(s).

New: Create a new Purchase Order. This action will bring up a Purchase to Stock dialog with the following fields and options:

Name: Enter a name for the Purchase Order.

External Id: Optionally enter a unique External Id for the Purchase Order. If left blank then one will automatically be generated and assigned when the Purchase Order is created.

Description: A text description of the Purchase Order. Used primarily for informational purposes.

Notes: Additional text notes related to the Purchase Order. Used primarily for informational purposes.

Attributes: Custom attributes assigned to the Purchase Order. Used primarily for informational purposes, though these can be used in conjunction with software customizations/extensions.

User Defined Fields:Custom user defined fields (UDFs) assigned to the Purchase Order. Used primarily in conjunction with software customizations/extensions. For more information, see: User Defined Fields (UDFs).

Purchase Details:

Item: Select the item to be purchased from the dropdown of items from inventory.

Item Description: This field is populated once an Item is selected. Its value comes from the Item Description property that is defined on the item in inventory.

Warehouse: This field is populated once an Item is selected. Its value comes from the Warehouse in which the item is configured to be stored in inventory.

Scheduled Receipt Date: Define a date and time that the Purchase Order is scheduled to be received.

Actual Receipt Date: Optionally, define a date and time that the Purchase Order was received. 

Quantity Ordered: Define the quantity of the item to be ordered.

Quantity Received: Optionally, define the quantity of the item which has already been received.

Vendor ExternalId: A name or other identified of the Vendor of the materials.

Buyer ExternalId: The individual responsible for the purchase.

Lot Code: Optionally enter a lot code to associate with the purchase. For use with Lot Controlled Planning.

Firm: Toggle whether the order is Firm or not.

If using MRP to generate/regenerate Purchase Orders then Firm P.O.s will be preserved during regeneration while non-firm P.O.s will be deleted (and recreated, if necessary according to demand signals).

Closed: Toggle whether the order has been Closed.

Closed orders have no impact on inventory levels but can be helpful for tracking statistics and KPIs over time.

Transfer:

Unload Span: The amount of time it takes to unload the order once it's received. This amount of time will be added to the date and time of the Scheduled Receipt Date to determine the Unload End Date which will also impact the Available Date which determines when the purchased materials can be used for scheduling.

Transfer Span: The amount of time it takes to transfer the material to the Warehouse. This amount of time will be added to the date and time of the Scheduled Receipt Date to determine the Available Date for when the purchased materials can be used for scheduling.

Close: Close the selected Purchase Order(s). Closing without Receiving will not impact inventory levels. This effectively cancels the order if it's scheduled to be received in the future.

Receive Order: Receive and close the selected Purchase Order(s). The order will be closed and the Quantity Ordered will be received in inventory.

Adjustment: This action displays a dialog to allow the user to enter an amount received that may differ from the Quantity Ordered. They are also given the option to Close the order or keep it open. If kept open and the entered Quantity Received is less than the Quantity Ordered then the remaining amount will be added to inventory at the Scheduled Receipt Date (plus transfer time, if any).

Select All: Select all grid rows. Alternatively, use the Ctrl+A keyboard shortcut.

Purchase Order Bulk Edit

Use the bulk edit tile to make changes to one or more properties for one or more purchase order. Select one or more rows from the Purchase Orders grid, then choose properties and values that should be applied to each selected order. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles</div>
        </section>
      
        <section class="article" id="article-265-routing-templates-board">
          <h3 class="article-title">Routing Templates Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/routing-templates-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Routing Templates board is a place to view and configure job templates that can be used to quickly create jobs for items which are produced in the plant. Jobs can be created from templates using MRP or CTP (Capable to Promise), or more manually using other available tools.

As a general best practice, it's recommended to configure each Template to produce "1" (or at least the minimum possible that can be produced) of its product so that MRP, CTP, and other tools used to generate jobs from the template can easily scale to the appropriate demanded quantity.

Jump to section:

Routing Templates Grid

Routing Template Actions Tile

Create Job Tile

Template Generator Tile

Template Route Tile

CTP Estimate Tile

Routing Template Bulk Edit Tile

Routing Templates Grid

Use the Routing Templates grid to view various data associated with each template in the data model.

Double-click any grid row to bring up the Job Dialog window to make adjustments to the selected template and its Manufacturing Orders, Alternate Paths, Operations, and Activities.

Right-click any grid row to bring up a menu of Actions that can be performed on the selected template.

Select grid rows from the inventory grid when interacting with the other tiles in the board to see data related to the selected grid row.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Object Bulk Edit Tiles

Grid Edit Mode

Routing Templates Actions Tile

Use the Routing Templates Actions tile to perform quick actions on one or more selected templates from the Routing Templates grid.

Management

Delete: Delete the selected Template(s).

Copy: Copy the selected Template. Displays the Job Dialog screen to make adjustments to the copy before the copy is created. By default, the [ ] Template indicator is disabled/false in the Job Dialog as if the Copy action is meant to copy the existing Template into an actual Job. If attempting to copy the template as a new template, be sure to manually check the [x] Template indicator. Users may optionally Cancel the creation of the job copy from the Job Dialog, or proceed to make adjustments to the job and Save and Close from the Job Dialog to create the copy.

Open: Open the Job Dialog of the selected job.

New: Create a new job from scratch via the Job Dialog.

Select All: Select all grid rows. Alternatively, use the Ctrl+A keyboard shortcut.

Create Job Tile

Use the Create Job tile to create a job from an existing routing template, or to create a new routing template from scratch.

Job from Template

Select any Routing Template from the Select source routing template dropdown, or click on any grid row from the Routing Templates grid to select it. Adjust other basic information as needed (Name, Customer, Need Date, and Quantity), then click Create Job to create a new job from the template.

New Blank Route

Click the New Blank Job button to open the Job Details Dialog to begin creating a new routing template from scratch. The Template property will be set to True by default when the dialog opens.

Template Generator Tile

Use the Template Generator tile to create many jobs or templates as copies of one or more selected template. Optionally, randomize values of various job properties.

This job and template generation method is meant for creating sample jobs and templates for mock schedules and is not intended to be used for production scheduling purposes.

For more information about each of the properties and settings that can be configured, see: Jobs Board - Job Generator Tile.

Template Route Tile

The Template Route tile gives a quick overview of the route(s) that a product takes to be produced in terms of its sequence of operations.

Double-click any of the operation steps in the Template Route grid to bring up an editor dialog to quickly modify any of the values.

CTP Estimate Tile

"CTP" stands for Capable to Promise. The CTP Estimate tile is meant to offer a quick way to analyze whether or not an ad-hoc customer order can be fulfilled on time based on the current schedule and when the customer needs it. A "Results" breakdown gives details about whether or not the order can be fulfilled on time. If the requested delivery date cannot be met, PlanetTogether will provide a realistic delivery date. Upon initiating the CTP Estimate dialog to simulate whether or note the added demand can be satisfied, a job may optionally be generated from the results so that it may be placed on the schedule.

Select any grid row from the Routing Templates grid to populate the CTP Estimate tile with product information, then enter other required and optional information and settings before finally clicking Submit to perform the CTP simulation.

CTP Options

Naming the CTP

CTP Name: This is an identifier for the CTP job to be created. This is particularly helpful if the option to reserve capacity & material until the option is used.

Description: This is a description of the job to be simulated.

Reservation

Inventory Inquiry: This can be used to check the inventory levels for the particular product to be produced. 

Reserve Capacity and Materials until: This option allows the CTP to reserve capacity and materials until a user-defined date, allowing the customer to have some time to determine whether to go through with the order. By enabling the option, a job will be created in the data model and will be put on the schedule so that the materials and capacity are effectively reserved. If the PlanetTogether clock is advanced to a point in time after the defined date then the CTP job will automatically cancel and will be excluded from scheduling. 

Scheduling Type

Optimize: This option will run an optimize after creating the CTP.

Expedite to Clock: This option will expedite the job to the current clock to do the job ASAP.

Expedite to JIT: Expedites the job to its JIT Start Date. 

Product Availability: This tab allows users to select the Required Quantity, Need Date, and Path ID (for use with Alternate Paths) to be reserved for the simulated job.

Warehouse: This is the warehouse that CTP can draw materials from.

Item: This is the item to be produced.

Required Quantity: This is the required quantity of items to be produced for the simulated job.

Need Date: This is when the simulated job would need to be finished before it is considered late.

Required Path ID: This is the path routing to be used for the simulated job. Every job will have one Alternate Path, but if there is more than one then the desired one can be selected from a dropdown.

Once these elements are in place, the Capable To Promise can be saved by clicking Submit. Submitting the CTP will display the Scheduled Start and Finish Date and the result of the CTP (if the job is projected to be late, on time, early, etc.)

Priority: The priority tab allows the user to control additional aspects of how the CTP might be scheduled by allowing users to define:

Revenue: This is the revenue that the CTP would generate should the job go through. This value can be used in the optimize rules if higher revenue values are given more weight.

Throughput: This number can be used in optimize rules where higher throughput values are scheduled earlier.

Priority: This number can be used in optimize rules where lower numbers have a higher scheduling priority. 

Hot: This will flag the CTP as a Hot Job and take effect if there are optimized rules to prioritize hot flags.

Hot Reason: This is the reason that the CTP is defined as Hot. 

Notes: Include additional notes, if desired.

Warehouses: This tab allows users to define which warehouses CTP can draw materials from, as well as choose a Can Span Plants value (true/false).

This tab lists all available warehouses, their Name, Description, and whether it is eligible to supply the CTP.

The drop-down menu has the following options:

Individual materials must come from the same Warehouse: All materials supplying the CTP must come from the same warehouse if this option is chosen.

Individual materials can come from multiple Warehouses: In this option, the materials requirements of the CTP can be supplied from multiple warehouses is required.

New Job CanSpanPlants Value: Opt to use the value of this property from the template or to set it manually in the CTP dialog.

Bottleneck Constraints:

When the CTP is submitted, constraints that may make the operations late will appear here. Thus, schedulers can quickly see the details of the operation and the number of late days. In addition, listing the bottleneck constraints in this tab allows schedulers to easily identify the bottleneck operations causing the job to be late and see whether the schedule can be changed to produce the item(s) on time. 

Items with Stock Material Constraints

When creating a CTP for item(s) with stock material constraints for products that are manufactured in the plant, the CTP job will be created to produce all of the required supplemental manufactured item(s) if the following prerequisites are met:

The item(s) must be set to be "Manufactured" (Inventory Plan -> Source).

There must be an associated template in the scenario that can be used to produce the item(s).

Successfully satisfying the prerequisite criteria results in one job being generated with multiple manufacturing orders, where each order produces the required manufactured item that needs produced in order to satisfy the entire demand of the CTP request (the "Item" that is submitted for CTP analysis, plus any required Stock Material items which can be manufactured).

Failing to meet the required prerequisite criteria may result in the job scheduling past the planning horizon if the required materials are not available.

Note: CTP will not generate Purchase Orders to satisfy demand for purchased stock material requirements.

Routing Template Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more routing template. Select one or more rows from the Routing Templates grid, then choose properties and values that should be applied to each selected templates. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

See Also

Job Structure

MPS/MRP (Material Resource Planning)

Job Details Dialog

User Defined Fields (UDFs)

Job Mappings

Manufacturing Order Mappings

Alternate Path & Node Mappings

Resource Operation Mappings

Resource Requirement Mappings

Required Capability Mappings

Material Mappings

Product Mappings

Operation Attribute Mappings</div>
        </section>
      
        <section class="article" id="article-286-sales-orders-board">
          <h3 class="article-title">Sales Orders Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/sales-orders-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Sales orders are generally customer orders for finished products. They are used to track demand in the Inventory Plan (as they consume inventory) and are often used in conjunction with the MRP function. 

Use the Sales Orders board to maintain customer orders and make manual adjustments as needed.

Jump to section:

Sales Orders Grid

Sales Order Actions Tile

Sales Order Details Tile

Sales Order Bulk Edit Tile

Sales Orders Grid

The Sales Orders grid offers details of each Sales Order in the data model, including their required available/delivery date, the item and quantity being purchased, customer, and revenue data such as price per unit and total sale amount.

Right-click any grid row to bring up a menu of Actions that can be performed on the selected order.

Select grid rows from the Sales Orders grid when interacting with the other tiles in the board.

Use Grid Edit Mode to modify any details of a Sales Order directly in the grid.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Predictive KPI Tiles

Object Bulk Edit Tiles

Grid Edit Mode

Sales Order Actions Tile

Use the Sales Order Actions tile to perform quick actions on one or more selected sales orders from the Sales Orders grid.

Management

New SO: Create a new Sales Order from scratch.

Delete: Delete the selected Sales Order(s).

Close: Close the selected Sales Order(s). Closing an order effectively prevents it from acting as a demand signal and consuming inventory.

Select All: Select all grid rows. Alternatively, use the Ctrl+A keyboard shortcut.

Scheduling

Ship: Mark the order as shipped (completed). In order to be able to Ship the order there must be enough inventory on hand to fulfill the order.

Ship with Adjustment: Ship an adjusted amount of the order to effectively mark it as partially or wholly complete. In order to be able to Ship any amount of the order there must be enough inventory on hand to fulfill the shipped amount.

Sales Order Details Tile

Use the Sales Order Details tile to manually create new Sales Orders. Manually enter each of the required fields into each of the nested grids, then click Save to save the new order, or Delete to discard all changes.

Required fields:

Name

LineNumber

ItemExternalId

QtyOrdered

RequiredAvailableDate

Required for MRP:

MustSupplyFromWarehouseExternalId

UseMustSupplyFromWarehouseExternalId

Sales Order Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more sales orders. Select one or more rows from the Sales Orders grid, then choose properties and values that should be applied to each selected order. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles

See Also

MPS/MRP Planning</div>
        </section>
      
        <section class="article" id="article-297-scenario-data-board">
          <h3 class="article-title">Scenario Data Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/scenario-data-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Scenario Data Board allows users to manage all data objects and complex rules and constraints in the data model which are not related to customers, jobs, and orders.

Jump to section:

Capacity Intervals Tile

Capacity Intervals (Recurring) Tile

Attributes Tile

Insights Tile

Allowed Helpers Tile

Capabilities Tile

Departments Tile

Plants Tile

Cells Tile

Inventory Management Tile

Product Rules Tile

Resource Connectors Tile

Data Tables Tile

Generalize Data Tile

Clear Scenario Data Tile

Capacity Intervals Tile

Resource capacity is defined by the intervals of time in which resources are available to work on jobs and how much work can be scheduled during each interval. These parameters are defined in Capacity Intervals and Recurring Capacity Intervals which are then assigned to resources. Thus, a resource's capacity is determined by a combination of its Resource Properties and its assigned Capacity Intervals.

Capacity Intervals in PlanetTogether can be configured to represent "Online" or "Offline" spans of time on a resource with special considerations for "Overtime", "Potential Overtime", and "Cleanout" designations.

Use the Capacity Intervals tile to manage non-recurring capacity interval data in the scenario, or to assign non-recurring intervals to one or more resources.

Select grid rows from the Capacity Intervals grid when interacting with the toolbar buttons to perform the toolbar actions on the selected grid row(s).

New: Create a new interval with default values

Open: Open the Capacity Interval editor dialog to edit properties of the selected interval. This dialog can also be accessed by double-clicking any grid row.

Copy: Create a new interval as a copy of the selected interval.

Delete: Delete the selected interval(s).

Clear: Clear all non-recurring capacity interval data in the scenario.

Assigned Resources: View or adjust the assigned resources of the selected interval via the Assigned Resources dialog.

Export: Export the Capacity Intervals grid to the desired available format (XLSX, PDF, HTML, or CSV).

See also:

Capacity Interval Mappings

Capacity Interval Resource Mappings

Capacity Interval Editor Dialog

Use the Capacity Interval editor dialog to edit a capacity interval configuration.

Name: A user friendly name for the interval.

Description: A text description of the interval. For informational purposes.

Interval Presets: Choose between preset capacity interval configuration templates to quickly assign standard settings to common capacity interval types. Once a preset is used, each option and setting may be manually changed, if desired.

Cleanout: An Online interval which only allows for scheduling Cleans. The following settings are set:

Color: Royal blue

Status: Online

Overtime: Disabled

Can Start Activity: Disabled

Prevent Operations from Spanning: Disabled

Reset Attributes Changeovers: Disabled

Use only when Late: Disabled

Used for Setup: Disabled

Used for Run: Disabled

Used for Post Processing: Disabled

Used for Storage Post Processing: Disabled

Used for Clean: Enabled

Online: A typical Online interval with standard options and constraints. The following settings are set:

Color: Green

Status: Online

Overtime: Disabled

Can Start Activity: Enabled

Prevent Operations from Spanning: Disabled

Reset Attributes Changeovers: Disabled

Use only when Late: Disabled

Used for Setup: Enabled

Used for Run: Enabled

Used for Post Processing: Enabled

Used for Storage Post Processing: Enabled

Used for Clean: Enabled

Overtime: The standard Online interval with standard options and constraints plus the Overtime setting enabled. Overtime impacts the costs associated with running activities on the interval according to resource hourly cost settings. The following settings are set:

Color: Dark red

Status: Online

Overtime: Enabled

Can Start Activity: Enabled

Prevent Operations from Spanning: Disabled

Reset Attributes Changeovers: Disabled

Use only when Late: Disabled

Used for Setup: Enabled

Used for Run: Enabled

Used for Post Processing: Enabled

Used for Storage Post Processing: Enabled

Used for Clean: Enabled

Potential Overtime: An Overtime interval which is only utilized to schedule Late activities. The following settings are set:

Color: Light red

Status: Online

Overtime: Enabled

Can Start Activity: Enabled

Prevent Operations from Spanning: Disabled

Reset Attributes Changeovers: Disabled

Use only when Late: Enabled

Used for Setup: Enabled

Used for Run: Enabled

Used for Post Processing: Enabled

Used for Storage Post Processing: Enabled

Used for Clean: Enabled

Maintenance: An Offline interval which disallows operations from spanning across it and resets sequence-dependent Setup and Cleans calculations. The following settings are set:

Color: Orange

Status: Offline

Overtime: Disabled

Can Start Activity: Disabled

Prevent Operations from Spanning: Enabled

Reset Attributes Changeovers: Enabled

Use only when Late: Disabled

Used for Setup: Disabled

Used for Run: Disabled

Used for Post Processing: Disabled

Used for Storage Post Processing: Disabled

Used for Clean: Enabled

Holiday: An offline interval which disallows operations from spanning across it. The following settings are set:

Color: Yellow-orange

Status: Offline

Overtime: Disabled

Can Start Activity: Disabled

Prevent Operations from Spanning: Enabled

Reset Attributes Changeovers: Disabled

Use only when Late: Disabled

Used for Setup: Disabled

Used for Run: Disabled

Used for Post Processing: Disabled

Used for Storage Post Processing: Disabled

Used for Clean: Disabled

Offline: An Offline interval where work cannot be performed by operations which are allowed to span offline intervals may span across it as needed. The following settings are set:

Color: Gray

Status: Offline

Overtime: Disabled

Can Start Activity: Disabled

Prevent Operations from Spanning: Disabled

Reset Attributes Changeovers: Disabled

Use only when Late: Disabled

Used for Setup: Disabled

Used for Run: Disabled

Used for Post Processing: Disabled

Used for Storage Post Processing: Disabled

Used for Clean: Disabled

Capacity:

Interval Status: Select from one of the interval types to determine whether or not work can be performed during the interval.

Online: The resource is available to perform work.

Offline: The resource is not available to perform work. If an Offline interval is placed on top of an Online interval then the Offline interval "wins" and the resource is considered unavailable.

Interval Settings:

Color: Choose any color to assign to the interval. The color can help to distinguish between different interval statuses and configurations when viewed from the Gantt.

Can be dragged/resized: When enabled, the capacity interval is allowed to be dragged and resized in the Gantt by users who have permission to maintain capacity intervals, and who have the similar user settings enabled. When disabled, the capacity interval cannot be dragged and resized in the Gantt by any user.

Can be deleted: When enabled, the capacity interval is allowed to be deleted by users who have permission to maintain capacity intervals. When disabled, the capacity interval cannot be deleted by any user.

Timing: Define the start and end times of the interval.

Start: The date and time that the interval should start.

End: The date and time that the interval should end.

Duration: A calculation of the length of time between the defined Start and End times to determine the duration of each occurrence of the interval.

Capacity: Adjust the amount of capacity hours based on the timing duration and number of people assigned to the interval.

Number of People: Define the number of people available during the Online and Overtime interval. Typically used on labor pool resources where two or more operators may be required to complete an activity, or where multiple activities can schedule at the same time when the work is divided among each person.

Capacity Hours: A calculation of hours between the defined Start and End times multiplied by the Number of People available to determine the total number of capacity hours per each occurrence of the interval.

Capacity Code: A Capacity Code can be set on intervals which should only be used for particular orders or operations. An Operation's Resource Requirement Capacity Code field can be defined so that if it matches the Capacity Code set on the interval then it will be eligible to schedule there. Operations which do not have a Capacity Code defined on the resource requirement, or which have a code which does not match the interval code value will not be allowed to schedule on the interval.

Options and Constraints:

Overtime: When enabled, the resource is available to perform work. Cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. When disabled, cost calculations for performing work on the interval use the Standard Hourly Cost on the resource.

Can Start Activity: When enabled, the interval can be used to start the first process of an activity (either Setup, if applicable, or Cycle).

Prevent Operations from Spanning: When enabled, the resource is not available to perform work, and no idle work is allowed to pause to span across this interval. This is typically a good option for resource maintenance or cleaning where schedulers don't want to start progress on an operation or activity, then pause for its offline maintenance, then pick back up the activity after the offline interval.

Reset Attributes Changeovers: When enabled, calculations which dictate sequence-dependent setups and cleans will be reset to 0.

Use Only when Late: When enabled, activities will only schedule on the capacity interval if they are late (the schedule clock date time is later than the activity’s JIT start date).

Used for Setup: When enabled, the capacity interval can be used to perform Setup processes.

Used for Run: When enabled, the capacity interval can be used to perform Cycle processes.

Used for Post Processing: When enabled, the capacity interval can be used to perform Post-Processing processes.

Used for Storage: When enabled, the capacity interval can be used to perform Storage Post-Processing processes.

Used for Clean: When enabled, the capacity interval can be used to perform Clean processes.

Recurrence:

Recurrence Pattern: 

None: The interval occurs only once and never repeats.

Daily: The interval repeats daily with an option to skip a number of days between each interval.

Weekly: The interval repeats weekly on the defined days of the week with an option to begin the weekly recurrences after skipping a specified number of weeks from the Start date.

Monthly: The interval repeats on the same day of the month each month with an option to begin the monthly recurrences after skipping a specified number of months from the Start date.

Yearly: The interval repeats on the same day of the year each year.

Recurrence End:

End of Planning Horizon: The interval recurs indefinitely according to the defined Recurrence Pattern frequency.

End After [ ] Occurrences: The interval ends after a specified number of recurrences according to the defined Recurrence Pattern frequency.

End By: The interval recurs according to the defined Recurrence Pattern frequency until the specified date and time.

Short Term Capacity: Temporarily change the number of people in a recurring capacity interval. Specify the adjusted number of people and how many intervals this change should be applied to, starting with the first occurrence of the interval on the schedule.

Number of People Override: Specify the number of people who will be available for the short term span.

Number of Intervals to Override: Specify the number of intervals that the Number of People Override should be applied to, starting with the first occurrence of the interval on the schedule.

Notes:

Additional text notes related to the interval. For informational purposes.

Assigned Resources Dialog

Use the Assigned Resources dialog to view or modify the resource assignments of recurring or non-recurring capacity intervals.

From the Scenario Data board tiles, double-click any non-recurring or recurring capacity interval, or click once to select an interval from its grid and click the Assigned Resources button to display the dialog. Alternatively, access the dialog from the Gantt board by right-clicking any capacity interval and selecting the Assigned Resources option.

From the dialog, there are quick buttons at the top to Select All to assign the interval to all resources that are visible in the grid below, or Deselect All to unassign the interval from all visible resources. Each of the visible grid columns may be filtered in the event that a user wants to apply one or more filters so that they may use the Select All or Deselect All buttons to quickly assign or unassign the interval to/from many resources at once which match the filtered criteria (all resources in a specified Department, for example).

Be sure to Save and Close changes before exiting the dialog.

Capacity Intervals (Recurring) Tile

Resource capacity is defined by the intervals of time in which resources are available to work on jobs and how much work can be scheduled during each interval. These parameters are defined in Capacity Intervals and Recurring Capacity Intervals which are then assigned to resources. Thus, a resource's capacity is determined by a combination of its Resource Properties and its assigned Capacity Intervals.

Capacity Intervals in PlanetTogether can be configured to represent "Online" or "Offline" spans of time on a resource with special considerations for "Overtime", "Potential Overtime", and "Cleanout" designations.

Use the Capacity Intervals (Recurring) tile to manage recurring capacity interval data in the scenario, or to assign recurring intervals to one or more resources.

Select grid rows from the Capacity Intervals (Recurring) grid when interacting with the toolbar buttons to perform the toolbar actions on the selected grid row(s).

New: Create a new interval with default values

Open: Open the Capacity Interval editor dialog to edit the properties of the selected interval. This dialog can also be accessed by double-clicking any grid row.

Copy: Create a new interval as a copy of the selected interval.

Delete: Delete the selected interval(s).

Clear: Clear all recurring capacity interval data in the scenario.

Assigned Resources: View or adjust the assigned resources of the selected interval via the Assigned Resources dialog.

Export: Export the Capacity Intervals grid to the desired available format (XLSX, PDF, HTML, or CSV).

See also:

Recurring Capacity Interval Mappings

Capacity Interval Resource Mappings

Attributes Tile

Attributes are custom properties that can be assigned any string or integer value and assigned to various objects. These are meant to be used to track various data that PlanetTogether doesn't already have a standard property for. They can also be used to configure and determine operation setup or clean processes.

At this time, attributes can only be assigned to job operations, but in the future attributes may be expanded to support other functionality on other data objects.

Attributes are similar to User Defined Fields, though they have added native functionality like operation Setup and Clean process calculations, and can be used by various optimize factors to create custom operation sequencing optimization.

The Attributes tile allows users to view settings associated with existing attributes, or to manually configure or reconfigure them. The grid is directly editable in this tile for ease of use.

New: Create a new attribute.

Save: Save edits made to attribute settings via grid edit mode.

Copy: Copy the selected attribute grid row to create a new one.

Delete: Delete the attribute(s) selected in the grid.

Clear: Clear all attributes data

Grid Edit Mode: Grid Edit mode is always enabled in this grid. Use the grid to edit any of the configurable properties of the attributes.

See also:

Attributes

Cleans

Setup Time

Attribute Mappings

Operation Attribute Mappings

Insights Tile

The Insights tile provides insights on how scenario data could impact scheduling. The types of insights users might observe:

Job Lateness Insights: Provides insights into late jobs, detailing when they are needed and when they are scheduled to finish.

Job Hold Insights: Provides insights into why and how long a Job is on hold for.

Operation Material Insights: Provides insights on an operation's material requirements by detailing, which of its material requirements are not Planned and ones with tight supplies.

Operation Latest Constraint Insights: Provides insights on what the latest constraint of an operation and it's date is.

Production Quantity Insights: A large number of transfers to inventory required per producing operation (based on number of cycles and the item's transfer quantity); alerts if there need to be more than 100 transfers

Material Quantity Insights: A large number of overlapping cycles of a consuming operation whose material requirement allows for production overlap by production cycle; alerts if there are more than 100 cycles that may overlap based on the item's transfer quantity and the operation's number of cycles

Activity Scheduled Setup Insights: Provides insights on the total duration of an activity's scheduled setup

Operation Hold Insights: Provides insights into why and how long an operation is on hold for.

Manufacturing Order Hold Insights: Provides insights into why and how long a Manufacturing Order is on hold for.

Allowed Helpers Tile

The Allowed Helpers feature allows users to restrict which helper resources are considered eligible to help a specific primary resource in the event that an operation requires two or more resources to run simultaneously to complete the task. This restriction is enforced as a scheduling constraint only when using the Optimize function. A scheduler may still manually move the helper portion of the operation to another capable resource even if the other capable resource is not listed as an allowed helper of the resource where the primary resource requirement is scheduled.

Use the Allowed Helpers tile to view or manage Allowed Helpers data in the scenario.

"+" New: Create a new Allowed Helper resource association by clicking the "+" plus sign in the tile control pane in the bottom left corner . A new Primary Resource row will appear in the grid.

First, select a primary resource from the dropdown selection 

Next, click the icon next to the primary resource selection

Now choose an eligible Helper Resource from the dropdown selection 

To add more eligible helpers, click the "+" plus icon in hte tile control pane in the bottom left corner with the mouse focussed inside of the Helper Resource grid within the selected Primary Resource.

Save: Click to save pending changes to the allowed helper resource associations.

Delete: Select an Allowed Helper or Primary resource row from the grid, then click Delete to remove the entry. Note that the deletion is not saved until the user clicks the Save button.

Note: The keyboard delete key has the same effect on the selected row(s).

Reload: Click to reload the Allowed Helpers grid to the last saved configuration.

See also:

Allowed Helper Resource Mappings

Resource Requirement Mappings

Required Capability Mappings

Import Mappings Board

Capabilities Tile

A capability is defined by the type of work or skill that a resource can do. Each resource can have multiple capabilities, and each capability can be linked to multiple resources.

Each resource requirement of an operation indicates the required capability(ies) that a resource must have to be considered eligible to perform the operation. If two or more capabilities are required of a single resource requirement o</div>
        </section>
      
        <section class="article" id="article-248-sequence-planning-board">
          <h3 class="article-title">Sequence Planning Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/sequence-planning-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Sequence Planning board is a place to score various optimize factors to help influence the order in which jobs and operations are scheduled, and which resources are used for each task by PlanetTogether's schedule optimization logic. An ideal sequencing plan results in a streamlined production process, minimizes waste, and reduces errors and the need for rework.

Multiple plans can be created and used for experimentation to see what works best, or for resource-specific optimization preferences.

💡 Tip: Before creating any sequencing plans, it's best to read up on PlanetTogether's Optimization logic and to understand how it generates Optimization Scores to help to make informed decisions when choosing which factors to give weight to based on what matters most to your data model and organization.

Jump to section:

Optimize Factors Grid

Scoring

Global Minimum Score

Optimize Factors: Descriptions & +/- Impact

Sequence Planning Actions Tile

Optimize Factors Details Tile

Optimize Factors Category Scaling Tile

Optimize Factor Analysis Tile

Sequencing Plan Mapping Tile

Optimize Factors Grid

The Optimize Factors grid displays the settings and scores that are configured for the currently loaded plan and provides details of all factors that can be configured. Users may quickly switch to view different plans in the scenario from a dropdown menu, similar to loading different layouts on other board grids. There is also the ability to store and switch between grid layouts, and export the grid into various formats.

Users may create as many plans as makes sense for their organization. Each resource in the data model may be assigned up to five plans - one deemed the "Normal" plan and four others deemed "Experimental" plans. Use the Sequencing Plan Mappings Tile to map plans to resources, then choose whether to use the Normal or one of the Experimental plans during optimization in the Schedule dropdown from the main toolbar.

Double-click any of the Factor grid rows to open the Optimize Factor Details tile in order to give pointed weight to any factor.

Use the Sequence Planning Actions tile to create New plans, Copy existing plans, Rename the currently selected plan, Delete the currently selected plan (it must not be mapped to any resource's Normal or Experimental plans), Import a plan from a saved export file, Export a plan to an external file, or to Set a Global Minimum Score.

Grid Properties

Score Impact

The impact of any factor may be designated as positive ("+") or negative ("-"). When positive, the points determined by the Calculation logic will be added to the optimize score at the time of scoring. When negative, the points will be deducted from the optimize score.

Points

This value reflects the number of points assigned to the optimize factor.

Effective Points

This value reflects the Points value adjusted up or down (or not at all) by the Optimize Factors Category Scaling logic.

Category

A general category assigned to each optimize factor for quick sorting and organization.

Constant

If True (checked) then the calculated score will not vary from one operation to the next for this optimize factor. Constant factors require less compute so Optimize may run more efficiently (faster). If False (unchecked) then the calculated score may have different factors to consider at different points in time during scheduling, so Optimize may slow down as a result of the system needing to perform more calculations.

Description

A description of the Optimize Factor.

Calculation

Insights into how the Optimize Factor will impact the Optimize Score.

See Also:

Grid Personalization

Scoring

The points and scoring system is fairly arbitrary in that users get to define the minimum and maximum values. They could choose to adhere to a -100 to +100 scale, or -1,000,000 to +1,000,000 scale according to their personal preference.

Assign point values to any number of the available factors and toggle whether the point value should have a positive or negative impact on optimize scores using the Optimize Factor Details tile. By default, each factor's individual point impact on optimize scores is proportional to the total number of points issued to all factors. For example, if the sum of all Points of all factors is 100 and one of the factors has a score of 25 then that factor's impact on the optimization scores is weighted at 25%. This default factor may be adjusted using the category sliders in the Optimize Factors Category Scaling tile if users would prefer factors of certain categories to be given more or less weight. Even more granularity is offered in the Optimize Factor Details tile which allows a Lock Score toggle switch to be enabled if there are certain factors whose impact should not be altered by the category scaling sliders.

When assigning points to any factor, be sure to read and understand its Calculation since the information will help to understand whether or not the score impact should be set to positive or negative. The Calculation is visible in the Optimize Factors Grid as well as in the Optimize Factors Details tile where points are given when hovering over the calculator icon. It provides details about the mathematical logic used by the factor as it's used to calculate the optimization score.

Global Minimum Score

Choose to set a Global Minimum Score in order to prevent scheduling an operation if its total calculated score does not meet or exceed a minimum value. This feature can be used to leave gaps in resource capacity if operations are released to schedule and eligible at an available point in time but it might be considered more desirable to wait and schedule it later, either closer to it's JIT start date or on another resource when it becomes available.

The minimum score set will be highly variable. By default, it is a very large negative number, essentially meaning there are no constraints on the score and where the activity schedules.

When setting this factor, keep in mind depending on the factors being used, it may make sense to use a negative number for this value.

Note that each individual optimize factor may also be assigned a Minimum Score from the Optimize Factor Details tile, but that option is specific to the factor rather than the global setting which considers the total score of all factors.

💡 Tips:

If it seems that the operations are scheduling later than believed they should, try reducing the global min or possibly making is a negative number.

Exposing the Optimize Score and Score Details on the Activities Board will help find the right score. If a job is expected to schedule sooner, and the optimize score shows as .80, try making the minimum -10 and see how much sooner it moves.

Finding the right number will take some trial and error. Keep in mind, the minimum may be different per resource and/or sequencing plan.

Optimize Factors: Descriptions & +/- Impact

This table lists all standard available factors and their descriptions and an assessment of what the impact would be of applying positive versus negative points on the optimization score.

Factor
Description
[+] vs. [-] Impact

Alternate Path Preference
Give weight to preferred paths

[+]: Alternate Paths with a high Preference property value will be given higher optimize scores.

[-]: Alternate Paths with a low Preference property value will be given higher optimize scores.

Attribute Number

Prioritize based on attribute number value. 

Calculation: [Attribute.Number] * [Effective Points]

[+]: The higher the attribute Number values, the higher the optimize score.

[-]: The higher the attribute Number values, the lower the optimize score.

Attribute Number Sawtooth
Alternates ascending and descending attribute setup numbers for all specified attributes.

[+]: Optimize score increases when the Attribute Number value of the specified attribute is different from the previously scheduled operation's Attribute Number and is in the opposite direction (higher vs lower) of the previously scheduled trend in attribute numbers. Recommended.

[-]: Optimize score decreases when the Attribute Number value of the specified attribute is different from the previously scheduled operation's Attribute Number and is in the opposite direction (higher vs lower) of the previously scheduled trend in attribute numbers.

Clean Cost
Calculates a score based on the sequence-dependent clean cost of scheduling the activity.

[+]: Optimize score increases as the Clean cost increases.

[-]: Optimize score decreases as the Clean cost increases. Recommended.

Clean Duration
Calculates a score based on the sequence-dependent clean duration of the activity.

[+]: Optimize score increases as the Clean duration increases.

[-]: Optimize score decreases as the Clean duration increases. Recommended.

Close to Exceeding Max Delay
Scores operations according to how close they are from reaching or violating their predecessor's assigned Max Delay Hours.

[+]: Optimize score increases the closer the operation gets to reaching the Max Delay Hours. Recommended.

[-]: Optimize score decreases as the operation gets closer to violating Max Delay.

Closest Fit Quantity
Prioritizes operations based on how closely their quantity fits within the range defined by the resource's minimum and maximum quantity.

[+]: Optimize score increases the closer the activity's remaining quantity is to the max quantity of the resource without exceeding the max quantity.

[+]: Optimize score decreases the closer the activity's remaining quantity is to the max quantity of the resource without exceeding the max quantity.

Closest Fit Volume
Prioritizes operations based on how closely their quantity fits within the range defined by the resource's minimum and maximum volume.

[+]: Optimize score increases the closer the activity's remaining quantity is to the max volume of the resource without exceeding the max volume.

[+]: Optimize score decreases the closer the activity's remaining quantity is to the max volume of the resource without exceeding the max volume .

CTP Job
Priority based on whether the job is an estimate for CTP

[+]: If the job was created by CTP and its Commitment level is still Estimate then the optimize score increases.

[-]: If the job was created by CTP and its Commitment level is still Estimate then the optimize score decreases.

Customer Priority
Prioritize based on Job's highest customer priority, if the job has at least one customer. A lower priority number indicates a higher priority.

[+]: Optimize score will increase based on the value of the lowest numbered Priority property (representative of the highest priority customer) of all customers associated with the job. Recommended.

[-]: Optimize score will decrease based on the value of the lowest numbered Priority property (representative of the highest priority customer) of all customers associated with the job.

Eligible Plants
Prioritize based on the number of eligible plants. Negative Effective Points can penalize operations that could schedule in other plants

[+]: Optimize score increases if the operation is eligible to schedule in more than 1 plant.

[-]: Optimize score decreases if the operation is eligible to schedule in more than 1 plant.

Higher Cleanout Grade
Prioritize operations where the cleanout grade is higher.

[+]: Optimize score increases for higher Cleanout Grade values. Recommended.

[-]: Optimize score decreases for higher Cleanout Grade values.

Hot
Additional EffectivePoints for Hot jobs

[+]: Optimize score increases if the job is flagged as a Hot job. Recommended.

[-]: Optimize score decreases if the job is flagged as a Hot job.

Inventory Carrying Cost
Prioritize operations based on their number of eligible resources. Effective Points per 100 units of carrying cost

[+]: Optimize score increases as the cost of carrying inventory increases based on the operation's Carrying Cost property value.

[-]: Optimize score decreases as the cost of carrying inventory increases based on the operation's Carrying Cost property value. Recommended.

Job Commitment
Give weight based on Job Commitment

[+]: Optimize score increases if the job's Commitment matches that of the configured multiplier score.

[-]: Optimize score decreases if the job's Commitment matches that of the configured multiplier score.

Job Entry Date
Prioritize jobs based on entry date

[+]: Optimize score increases with each passing day after it was entered into the data model.

[-]: Optimize score decreases with each passing day after it was entered into the data model.

Job First Shortage Date
Prioritizes jobs based on their First Shortage Date's distance away from the Scheduled Date

[+]: Optimize score increases with each passing day after its First Shortage Date.

[-]: Optimize score decreases with each passing day after its First Shortage Date.

Job Need Date
Prioritizes jobs based on their Need Date's distance away from the Clock Date. Priority increases for Need Dates earlier than the Clock Date and decreases for Need Dates after the clock date.

[+]: Optimize score increases with each passing day after the Job Need Date. Recommended.

[-]: Optimize score decreases with each passing day after the Job Need Date.

Job Priority
A constant score based on the Job's priority

[+]: Optimize score increases the higher the value of the Priority property on the associated job.

[-]: Optimize score decreases the higher the value of the Priority property on the associated job. Recommended to prioritize jobs with smaller/lower Priority property values where lower values indicates higher priority jobs.

Job Throughput

Prioritize based on the job's throughput calculation (the revenues generated by production minus all variable expenses incurred).

[+]: Optimize score increases as the job throughput calculation increases. Recommended.

[-]: Optimize score decreases as the job throughput calculation increases.

Largest Quantity Fit

Prioritize operations based on whether their quantity is enough to fully fill the resource based on its Max Quantity. If the operation is allowed to auto-split based on Resource Quantity Capacity, then prioritize larger capacity resources.

[+]: Optimize score increases the closer the required quantity is to the resource's max quantity without exceeding it. Larger capacity resources are prioritized. Recommended.

[-]: Optimize score decreases the closer the required quantity is to the resource's max quantity without exceeding it. Larger capacity resources are de-prioritized.

Largest Volume Fit

Prioritize operations based on whether their volume is enough to fully fill the resource based on its Max Volume. If the operation is allowed to auto-split based on Resource Volume Capacity, then prioritize larger capacity resources.

[+]: Optimize score increases the closer the required volume is to the resource's max volume without exceeding it. Larger capacity resources are prioritized. Recommended.

[-]: Optimize score decreases the closer the required volume is to the resource's max volume without exceeding it. Larger capacity resources are de-prioritized.

Least Eligible Resources
Prioritize operations based on their number of eligible resources

[+]: Optimize score increases as the number of eligible resources increases.

[-]: Optimize score decreases as the number of eligible resources increases.

Least Waste Quantity Fit
Prioritizes operations based on minimizing the gap between the activity's required quantity and the resource's available quantity, ensuring the best fit to reduce waste.

[+]: Optimize score increases the closer the required quantity is to the resource's max quantity without exceeding it. Recommended.

[-]: Optimize score decreases the closer the required quantity is to the resource's max quantity without exceeding it. 

Least Waste Volume Fit
Prioritizes operations based on minimizing the gap between the activity's required volume and the resource's available volume, ensuring the best fit to reduce waste.

[+]: Optimize score increases the closer the required volume is to the resource's max volumewithout exceeding it. Recommended.

[-]: Optimize score decreases the closer the required volume is to the resource's max volume without exceeding it. 

Low Level Code

Prioritize based on the job products position in the bill of materials.

See also: MPS/MRP Optimize

[+]: Optimize score increases as the Low-Level Code (generated by MRP Optimize plan) increases.

[-]: Optimize score decreases as the Low-Level Code (generated by MRP Optimize plan) increases.

Lower Cleanout Grade
Prioritize operations where the cleanout grade is lower.

[+]: Optimize score increases for lower Cleanout Grade values. Recommended.

[-]: Optimize score decreases for lower Cleanout Grade values.

MO In-Process
Prioritize manufacturing orders based on whether any activity is started, setting up, running, or in post-processing. Finished activities are not In-Process

[+]: Optimize score increases if any activity's status indicates that it is currently in progress. Recommended.

[-]: Optimize score decreases if any activity's status indicates that it is currently in progress.

MO Is Scheduled
Prioritize manufacturing orders with at least one activity currently scheduled.

[+]: Optimize score increases if any activity of the same MO is currently scheduled. Recommended.

[-]: Optimize score decreases if any activity of the same MO is currently scheduled.

MO Released
Prioritize based on the days after the MO Release Date

[+]: Optimize score increases with each day after the MO Release Date. Recomm</div>
        </section>
      
        <section class="article" id="article-311-storage-areas-board">
          <h3 class="article-title">Storage Areas Board</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-areas-board" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Storage Areas Board offers detailed inventory-level information for every item stored in a storage area and material used throughout the production process. It provides users with a visual representation of supply and demands as inventory moves into and out of each storage area. 

Jump to section:

Storage Areas Grid

Storage Area Plot Report

Storage Areas Grid

The storage areas grid contains information about all storage areas and the warehouses they're associated with. Each row represents a different storage area. 

Select grid rows from the storage areas grid when interacting with the other tiles in the board to see data related to the selected grid row.

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Grid Edit Mode

Storage Area Plot Report

The Storage Area Plot Report offers both a plot chart and a grid view of all inventory adjustments made within the selected storage area over the duration of the current schedule. 

Use the provided Item dropdown menu to filter the plotted chart values and the inventory details grid.

Toggle on Show Adjustments After Planning Horizon to include adjustments in the chart and grid which are scheduled past the planning horizon.

Select any item from the Storage Area grid to plot its adjustments over time in this plot report tile.

Chart

The chart displayed in the top half of the report displays inventory levels at various points in time. The chart will start at the beginning of the planning horizon with the current on-hand level and will end at the date and time of the last scheduled adjustment.

Controls are offered to adjust the visible start and end date/time by dragging and dropping the circles with blue dots on either side of the condensed chart directly underneath the bar chart:

Plotted Values

The Plotted Values table displays information about inventory adjustments made at each plotted point. This may include combined quantities of two or more adjustments that get applied at the same time and therefore are both contributing to the inventory level at the plotted point on the chart.

Inventory Details

The Inventory Details table displays each specific inventory adjustment made at each point in time. It is the most detailed view of all adjustments from jobs, purchase orders, sales orders, forecasts, etc. over the course of the current schedule.

Toolbar Options:

Show Materials: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Show Materials button to open the Materials board with a temporary filter applied to show information about the selected scheduled adjustment.

Open Job: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Open Job button to open the Job Details dialog of the job associated with the selected adjustment.

Find Operation: Click to select any Job Product or Job Material row adjustment from the Inventory Details grid, then click the Find Operation button to open the Gantt board with a focus on the operation associated with the selected adjustment.

Export: Export the grid in one of the optional formats (HTML, PDF, XLSX, or CSV).

Grid "Level" Properties:

Inventory level adjustments over time are tracked in two ways: Total Inventory Level and Available Inventory Level. If a job product uses Material Post Processing, then that job's product will display as two entries in the grid: once when the job is scheduled to finish (Reason label reflects "Job Product Stored"), then another after the material post processing duration has passed (Reason label reflects "Job Product Available"). This helps to align consumption with available inventory rather than stored inventory.

Inventory Level: The total stored inventory level of the item in the storage area.

Available Level: The total available inventory level of the item in the storage area.

Storage Area Level: The total stored inventory level of all items in the storage area.

Storage Area Available Level: The total available inventory level of all items in the storage area.

Grid Properties:

Field Name
Description

Available Level
The amount of total inventory that is available to be consumed at the time of the adjustment.

Change Qty
The quantity difference of the inventory level introduced by the adjustment.

Customer
The name of the Customer associated with the Job or Sales Order associated with the adjustment.

Date
The date of the adjustment.

Date and Time
The date and specific time of the adjustment.

Forecast
The name of the Forecast associated with the adjustment.

Inventory Level
The total inventory level at the time of the adjustment.

Item Name
The Name of the Item associated with the adjustment.

Job Id
The ExternalId of the Job associated with the adjustment.

Job Name
The Name of the Job associated with the adjustment.

Lot Code
The Lot Code associated with the Job Product adjustment.

MO Name
The Name of the Manufacturing Order associated with the adjustment.

Need Date
The Need Date of the Job associated with the adjustment.

Operation Id
The ExternalId of the Job Operation associated with the adjustment.

Operation Name
The Name of the Job Operation associated with the adjustment.

Priority
The Priority of the Job associated with the adjustment.

Product Group
The Product Group of the Item associated with the adjustment.

Product Name
The Product Name of the primary product of the Manufacturing Order associated with the adjustment.

Reason
A description of the reason for the adjustment.

Sales Order
The Name of the Sales Order associated with the adjustment.

Sales Order ExternalId
The ExternalId of the Sales Order associated with the adjustment.

Sales Order Line
The Line Number of the Sales Order associated with the adjustment.

Storage Area
The Name of the Storage Area that was impacted by the adjustment.

Storage Area Available Level
The combined amount of available inventory in the impacted Storage Area at the time of the adjustment.

Storage Area Level
The combined amount of all inventories/items in the impacted Storage Area at the time of the adjustment.

Transfer Order
The Name of the Transfer Order associated with the adjustment.

See Also

Items, Inventories, Warehouses, & Storage Areas

Warehouse Mappings

Plant Warehouse Mappings

Storage Area Mappings

Item Mappings

Inventory Mappings

Lots Mappings

Item Storage Mappings

Item Storage Lots Mappings

Forecast Mappings

Transfer Order Mappings</div>
        </section>
      <h2 id="cat-boards-grid-properties" class="category-header">Boards &gt; Grid Properties</h2>
        <section class="article" id="article-205-capacity-planning-board-grid-properties">
          <h3 class="article-title">Capacity Planning Board Grid Properties</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capacity-planning-board-grid-properties" target="_blank">Source</a></p>
          <div class="article-content">Plant

Annual Percentage Rate: This rate is factored into various financial KPIs in the KPIs board.

Attributes: Custom attributes assigned to the Plant. Used primarily for informational purposes, though these can be used in conjunction with software customizations/extensions.

Bottleneck Threshold: Defines the threshold for the percentage of Capacity Bottlenecked Activities that can be scheduled before the Plant is flagged as a bottleneck.

Daily Interest Rate: This rate is factored into various financial KPIs in the KPIs board.

Daily Operating Expense: This rate is factored into various financial KPIs in the KPIs board.

Description: A text description of the Plant. Used primarily for informational purposes.

External Id: A unique identifier for the Plant.

Heavy Load Threshold: Defines the threshold for the percentage of a Plant's capacity allowed to be allocated in the short term before it's flagged as being "Heavily Loaded".

Invested Capital: An informational field to track the amount of money which has been spent to date on equipment, maintenance, loans, etc.

Name: The Name given to the Plant.

Operating Cost for Online Days: Used in various cost calculations and KPIs.

Operating Days: The number of days within the planning horizon in which at least one resource is online according to all online or overtime capacity interval assignments.

Notes: Additional text notes related to the Plant. Used primarily for informational purposes.

Stable Span: A period of time designated for which schedule changes should rarely occur in order throughout the entire Plant. It serves as a visual guideline in the Gantt, and schedule Optimizations can be configured to start outside of this period to ensure any activities scheduled within this time time period are not impacted by the Optimize function. This time span begins at the end of the defined Frozen Span. 

For more information, see: Plant Stability

Stable Span End: The ending date and time of the Plant Stable Span.

User Defined Fields: Custom user defined fields (UDFs) assigned to the Plant. Used primarily in conjunction with software customizations/extensions.

For more information, see: User Defined Fields (UDFs).

Department

Frozen Span: A period of time designated for which schedule changes should rarely occur on all Resources in the Department. It serves as a visual guideline in the Gantt, and schedule Optimizations can be configured to start outside of this period to ensure any activities scheduled within this time time period are not impacted by the Optimize function. This time span begins at the start of the schedule. The Use Department Frozen Span option must be enabled for this value to override the Frozen Span setting that is configured at the scenario-wide level in the System Settings.

For more information, see: Plant Stability

Use Department Frozen Span: When enabled, the Frozen Span for the Resources in the Department will use the Department-specified Frozen Span setting rather than the scenario-wide Frozen Span defined in the System Settings.

Description: A text description of the Department. Used primarily for informational purposes.

Notes: Additional text notes related to the Department. Used primarily for informational purposes.

Attributes: Custom attributes assigned to the Department. Used primarily for informational purposes, though these can be used in conjunction with software customizations/extensions.

User Defined Fields: Custom user defined fields (UDFs) assigned to the Department. Used primarily in conjunction with software customizations/extensions.

For more information, see: User Defined Fields (UDFs).

Resource

Active: When enabled, the resource is considered eligible to schedule activities. When disabled, no activities can be scheduled on the resource.

Activities Scheduled Count: The number of activities currently scheduled on the resource.

Allow Drag and Drops: When enabled, activities scheduled on the resource can be adjusted from the Gantt via drag/drop scheduling.

Assigned Capabilities: An overview of the Capabilities currently assigned to the resource. Quickly add/remove capabilities by clicking the box in the "Assigned" column.

Attribute Code Table Name: The name of the Attribute Code Table assigned to the resource, if any.

Auto Join Span:

Batch Type: Batch Scheduling can be done by percent or by volume. 

Percent: Activities are batched until 100% of the batch is filled. The percent occupied by each activity is calculated by dividing the activity's Required Finish Qty by its Qty Per Cycle.

Volume: Activities are batched until the activities' Required Finish Quantities equals the resource's batch volume.

Batch Volume: The maximum number of units included in a batch when using batch by volume.

Batch Volume: The number of jobs that can be batched together on the resource. If an activity's Required Quantity is larger than this value, the job will fail to schedule.

Bottleneck:

Bottleneck Percent:

Buffer: The length of time to act as a buffer between the operation scheduled on the Drum resource and its predecessor operation. Defines when the predecessor operation (or materials) must be available to supply the drum resource operation.

For more information, see: Drum-Buffer-Rope Scheduling

Can Offload:

Can Work Overtime:

Capacity Type: Specifies whether a resource has infinite or finite capacity. If finite then it also determines and whether the resource is single-tasking or multi-tasking. 

Infinite Capacity: The resource can perform any amount of work simultaneously.

Single Tasking: The resource can only perform one activity at a time.

Multi-Tasking: The resource can perform multiple activities at a time. The number of concurrent activities that can be scheduled is determined by either the Operation's resource requirement Attention Percent where multiple activities could schedule simultaneously as long as the total Attention Percent between them is equal to or less than 100%, or by the Activity's People Usage and Number of People required to perform the Activity and the number of people available on the Capacity Interval where the operations schedule.

For more information, see: Multi-Tasking Resources

Cellular Scheduling:

Compatibility Group:

Consecutive Setup Times: Calculates Setup time on scheduled activities as the sum of all setup time incurred by the various ways to configure Setup.

Current Setup Code: 

Current Setup Number: 

Cycle Efficiency: An efficiency multiplier which indicates whether the resource is capable of performing the Cycle phase of scheduled activities faster or slower than the defined Cycle time set on the Operation. Values greater than "1" represent a resource running slower by a factor of the specified amount, while values less than "1" represent a resource running faster by a factor of the specified amount. 

Department Id: 

Description: A text description of the Resource. Used primarily for informational purposes.

Drum: When enabled, the resource is considered the Drum, setting the pace for the rest of the shop floor. The drum buffer can also be set from this window. Note: Drum-Buffer-Rope release rules must be in effect for these values to impact the optimization engine. 

For more information, see: Drum-Buffer-Rope Scheduling

Exclude from Gantts: Excludes / hides the resource from all Gantt views (Resource Gantt, Job Watch Gantt, Connected Jobs Gantt, etc.).

Experimental Sequencing Plan One:

Experimental Sequencing Plan Two:

Experimental Sequencing Plan Three:

Experimental Sequencing Plan Four:

External Id:

Gannt Row Height Factor:

Head Start: The amount of time that an activity can schedule on this resource before its Just-In-Time Start Date. Lower values will schedule the job closer to its JIT start date. Used in combination with the Release Rule to Use Optimize Setting "JIT With Resource Head Start".

Id:

Image: Specifies the image that represents the resource in various Gantt views.

Image Name:

Limit AutoJoin to Same Shift:

Manual Scheduling Only:

Max Cumulative Quantity:

Max Quantity: The maximum amount of production that the resource can perform in a single activity. For the resource to be considered eligible for an activity to schedule, its required finish quantity must be less than or equal to this value.

Max Quantity Per Cycle: The maximum amount of production per cycle that the resource can perform. For the resource to be considered eligible for an activity to schedule, its operation's quantity per cycle value must be less than or equal to this amount. 

Max Same-Setup Span:

Maximum Volume:

Minimum Number of People:

Minimum Quantity: The minimum amount of production that the resource must produce in a single activity. For the resource to be considered eligible for an activity to schedule, its required finish quantity must be equal to or greater than this value.

Minimum Quantity Per Cycle: The minimum amount of production per cycle that the resource must produce. For the resource to be considered eligible for an activity to schedule, its operation's quantity per cycle must be equal to or greater than this value.

Name:

Normal Sequencing Plan:

Notes: Additional text notes related to the resource. Used primarily for informational purposes.

Omit Setup on First Activity:

Omit Setup on First Activity in Shift:

Online Non-Overtime Costs:

Overtime Hourly Cost: Defines the cost of running activities on the resource that schedule on Overtime capacity intervals. 

Plant Id:

Resource Type: Generally used for reporting purposes and to categorize various costs like Machine vs Labor.

Sequential:

Setup: Define a setup duration to be applied to all activities scheduled on the resource.

Note: This is not related to the "Setup Included" options. If a value is chosen here, it will be applied to all activities scheduled on the resource (even if the "Setup Included" is set to "Never"). The "Setup Included" options are related to operation changeovers.

Setup Code Table Name: The name of the Setup Code Table assigned to the resource.

Setup Efficiency: An efficiency multiplier which indicates whether the resource is capable of performing the Setup phase of scheduled activities faster or slower than the defined Setup time set on the Operation. Values greater than "1" represent a resource running slower by a factor of the specified amount, while values less than "1" represent a resource running faster by a factor of the specified amount. 

Setup Included: Defines when activities scheduled on the resource will incur Setup time, as well as how the Setup duration will be calculated.

Dropdown select options to define when to incur setup:

When Product Changes: Setup is incurred when the manufacturing order's product of the scheduled activity is different from the MO product of the previously scheduled activity.

When Setup Code Changes: Setup is incurred when the scheduled operation's Setup Code is different from the Setup Code of the previously scheduled operation.

When Either Changes: Setup is incurred when either the MO product of the scheduled activity is different from the MO product of the previously scheduled activity, or when the scheduled operation's Setup Code is different from the Setup Code of the previously scheduled operation.

Always: Setup is always incurred, with no exception.

Never: Setup is never incurred.

Note: This is related to operation changeovers. If a "Setup" duration is defined on the resource then setup will still be incurred.

When Setup Number Changes: Setup is incurred when the scheduled operation's Setup Number is different from the Setup Number of the previously scheduled operation.

When Setup Number Increases: Setup is incurred when the scheduled operation's Setup Number is greater than the Setup Number of the previously scheduled operation.

When Setup Number Decreases: Setup is incurred when the scheduled operation's Setup Number is less than the Setup Number of the previously scheduled operation.

Use Setup Code Tables: Setup is incurred based on the scheduled operation's Setup Code and how it might be impacted by applicable Setup Code Table logic.

Use Operation Attributes: Setup is incurred based on the scheduled operation's Attribute logic.

Boolean properties that define how Setup duration is calculated:

Use Operation Setup Time: The amount of setup incurred is based on the Operation's configured Setup time.

Consecutive Setup Times: The amount of setup incurred is the sum of all configured sources of Setup time (the Resource's Setup duration, the Operation's Setup time, Operation Attributes, and/or Setup Tables).

Omit Setup on First Activity: If enabled, Setup is omitted on the first scheduled activity on the resource.

Omit Setup on First Activity in Shift: If enabled, Setup is omitted on the first scheduled activity of each shift/capacity interval recurrence. 

Stage: 

Standard Hourly Cost: Defines the cost of running activities on the resource that schedule on normal Online capacity intervals.

Tank:

Transfer Span:

Use Operation Setup Time:

Work Center:

Work Center External Id:

Custom Properties

Custom attributes and UDFs can be displayed in the Resources grid.

Attributes: Custom attributes assigned to the Resource. Used primarily for informational purposes, though these can be used in conjunction with software customizations/extensions.

For more information, see: Resource Attribute Mappings

User Defined Fields: Custom user defined fields (UDFs) assigned to the Resource. Used primarily in conjunction with software customizations/extensions.

For more information, see: User Defined Fields (UDFs).

See Also

Capacity Planning Board

Plant Mappings

Department Mappings

Resource Mappings</div>
        </section>
      
        <section class="article" id="article-285-customers-board-grid-properties">
          <h3 class="article-title">Customers Board Grid Properties</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/customers-board-grid-properties" target="_blank">Source</a></p>
          <div class="article-content">Customer Name

Specify the name of the Customer or company.

Description

A text description of the Customer. Used primarily for informational purposes.

External Id

A unique identifier of the Customer. Used to associate the Customer with Job, Sales Order, Purchase Order, or Forecast objects.

Type

Define the customer type for informational purposes.

Customer: These types purchase goods from the plant.

Supplier: These types supply materials to the plant.

Vendor: These types are typically resellers of goods produced in the plant.

Color Code

Define a color code for better tracking and visibility in grids throughout the software interface.

ABC Code

An informational field that can be used in various ways.

Group Code

An informational field that can be used in various ways.

Priority

Define a priority for the customer. This can optionally be factored into the system's optimize factors and sequencing plans to prioritize orders for certain customers. Typically, lower priority values are treated with more urgency/priority during scheduling.

Region

An informational field that can be used in various ways.

Notes

Additional text notes related to the Customer. Used primarily for informational purposes.

Attributes

Custom attributes assigned to the Customer. Used primarily for informational purposes.

User Defined Fields

Custom user defined fields (UDFs) assigned to the Customer. Used primarily in conjunction with software customizations/extensions. For more information, see: User Defined Fields (UDFs).

See Also

Customers Board</div>
        </section>
      <h2 id="cat-concepts-analytics" class="category-header">Concepts &gt; Analytics</h2>
        <section class="article" id="article-306-analytics-with-power-bi">
          <h3 class="article-title">Analytics with Power BI</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/analytics-with-power-bi" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Detailed production, scheduling, inventory, and sales reports via Power BI are made available to qualifying customers at https://app.planettogether.com. Explore the plethora of standard reports that PlanetTogether has designed and published, or create custom reports using Power BI Embedded technology directly from the web application. Each customer organization has the freedom to customize how the reports are presented to their team in the web application, from organization and categorization of each report, to user permissions to grant access per user to specific report categories.

More information about each available report can be found here: Web App Reports.

Availability

Detailed scheduling reports with Power BI are available for all PlanetTogether customers with Pro licenses whose software instances are hosted in PlanetTogether's cloud environment.

Access the Web Application

Qualified customers may contact PlanetTogether support to gain access to the web application.

See Also

Web App Reports</div>
        </section>
      
        <section class="article" id="article-180-predictive-kpi-tiles">
          <h3 class="article-title">Predictive KPI Tiles</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/predictive-kpi-tiles" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Many boards contain predictive KPI tiles which allow users to create and track data related to their preferred Key Performance Indicators over time. The data plotted in these KPI tiles will update in real time with changes made to the Board's primary grid and give insights into the KPI data over the course of the scheduled horizon. Each KPI Tile can be opened simultaneously to allow users to visualize multiple KPI charts at the same time.

KPI Tile Visibility

Find the predictive KPI tiles labeled as "Object KPI # N" in each respective Board's tile menu.

The number of visible KPI tiles per board can be configured per user in their User Preferences. Each user may choose to hide KPI tiles or view as few as zero or as many as 10 per board.

Predictive KPI tiles are offered on the following boards:

Activities

Capacity Planning

Inventory Plan

Jobs

Materials

Purchase Orders

Sales Orders

Chart Properties

Choose one or two date properties to plot along with a KPI property.

Duration

Select the time bucket duration for each plotted data point, as well as the timeline or time window to plot.

Show Only Selected Objects

When disabled, the plotted data includes statistics for all rows from the Board grid. When enabled, only data for rows which the user has selected is plotted.

Scenario Comparison

Compare data for the predictive KPI across multiple scenarios if/when there are other scenarios in the instance which have Compare Scenario enabled in their settings.</div>
        </section>
      <h2 id="cat-concepts-constraints" class="category-header">Concepts &gt; Constraints</h2>
        <section class="article" id="article-300-allowed-helpers">
          <h3 class="article-title">Allowed Helpers</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/allowed-helpers" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Allowed Helpers feature allows users to restrict which helper resources are considered eligible to help a specific primary resource in the event that an operation requires two or more resources to run simultaneously to complete the task. This restriction is enforced as a scheduling constraint only when using the Optimize function. A scheduler may still manually move the helper portion of the operation to another capable resource even if the other capable resource is not listed as an allowed helper of the resource where the primary resource requirement is scheduled.

If no allowed helpers are defined, then any resource with the appropriate capabilities specified in the resource requirement of the operation can be used as the scheduled helper for the primary resource. 

Jump to section:

Configuring Allowed Helpers

Scheduling Operations with Allowed Helpers

Configuring Allowed Helpers

Allowed Helpers logic may be imported from the connected data source via the Allowed Helper Resource Mappings, or manually configured in the Scenario Data Board's Allowed Helpers tile.

Scheduling Operations with Allowed Helpers

The same scheduling and capacity restrictions as apply to scheduling any operation with Helper Resource requirements applies here as well, except when using Allowed Helpers the helper resource(s) chosen by the Optimize function must always be one of the specified eligible helpers. If the required capacity constraints cannot be satisfied on all required resources (the primary and all of its helpers) then the operation will schedule past the planning horizon.

From the Gantt chart, if any scheduled helper activity is selected then some visual cues may help the scheduler select an eligible and capable resource to help should they choose to reschedule the activity manually. Note that they will also be able to drag it to schedule on a capable but ineligible resource according to Allowed Helper rules, so beware of the cues to help guide any schedule change decisions.

Eligibility Visibility

In the Eligibility column of the Resource Grid, users may see the following after they've selected one or more Activities in the Gantt chart:

Eligibility Indicators:

 A green arrow indicates that the Resource is eligible to schedule the selected Activities.

 A purple arrow indicates that the Resource is eligible per capability requirements, and is configured as an Allowed Helper based on where the primary requirement is scheduled.

 An orange arrow indicates that the Resource is eligible per capability requirements, but is not considered an Allowed Helper based on where the primary requirement is scheduled.

 A blue arrow indicates that the Resource is eligible as the defined Default Resource.

 A yellow circle indicates that the Resource is eligible to schedule the selected Activities on an Alternate Path.

Visualizing Helper Resources in the Gantt:

If an operation uses one or more helper resources, clicking once on any scheduled activity block in the Gantt with the Show Activity Links option enabled will draw a blue activity link between the two scheduled activities.

See Also

Helper Resources

Capacity Planning Board

Scenario Data Board

Gantt Board

Resource Mappings

Allowed Helper Resource Mappings

Resource Requirement Mappings

Required Capabilities Mappings</div>
        </section>
      
        <section class="article" id="article-346-compatibility-codes">
          <h3 class="article-title">Compatibility Codes</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/compatibility-codes" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Compatibility Code Tables define lists of Operation Compatibility Codes which are either allowed or disallowed to schedule concurrently within a group of resources. Resources may be assigned one or more Compatibility Code Tables, and each table may be assigned to any number of resources.

All resources which are assigned a common table are considered to be part of a group. Resources that are part of the compatibility group of the table which is scheduled at any point in time will only be able to process operations concurrently if the operations are configured with a compatibility code that complies with the table logic, or if the operation is configured to not use a compatibility code.

Allowed list tables contain the set of codes that can be scheduled concurrently. Disallowed list tables define a set of codes that cannot schedule together. Multiple allowed and/or not allowed list tables can be assigned to the same resource. If there is more than one Allowed list table assigned to a resource, the tables will be treated as incompatible with each other. Only codes within the same Allowed list table can schedule concurrently. Disallowed list table logic will override any Allowed list combinations.

This may be helpful to model multiple food processing lines which are located in the same room, for example, requiring that the same product be processed at the same time on the independent lines. In order to prevent cross-contamination, this solution can prevent allergen products and non-allergen products from being processed at the same time on different lines.

This could also be helpful in cases where the same material input line feeds two machines. Compatibility codes could be used to ensure that the two machines can only run operations which use the same material concurrently at any point in time.

Jump to section:

Compatibility Code Table Management

Job Operation Configuration

Standard Configurations

Advanced Configurations

Setups and Cleans Considerations

Sequence Optimization Considerations

Compatibility Code Table Management

Compatibility Code Tables are created manually in the client user interface, or imported from an ERP/SQL master data source. Each compatibility code table may define a compatible (allowed) code list, or an incompatible (disallowed) code list. An allowed list defines the complete set of codes that can be scheduled concurrently. A disallowed list defines a set of codes that can never schedule together.

Data Import

Compatibility Code Tables are imported via Compatibility Code Table Mappings logic. 

Manual Creation

Compatibility Code Tables can be created or deleted manually from the Data Tables tile from the Scenario Data Board.

The table type is CompatibilityCodeTable. Select a table and click the Open button, or double-click the grid row to open the editor dialog. Toggle on the Allow List option if the code table will be used to list codes which are allowed to schedule concurrently, otherwise toggle it off. Enter one CompatibilityCode grid row for each code that should be associated with the table. Navigate to the Resources using this table tab to select which resources should use the table. Be sure to Save changes when finished.

Job Operation Configuration

Job Operations must be configured with a Compatibility Code in order to restrict resources to only perform compatible work concurrently. If specified, any scheduled Operation's Compatibility Code must match one of the compatibility codes of other operations scheduled on resources with the compatibility group. 

Each operation must also have the Use Compatibility Code property set to True. 

Operations whose Use Compatibility Code property is set to False are allowed to schedule concurrently with other operations which use compatibility code logic.

For importing these data, see: Resource Operation Mappings.

Standard Configurations

Standard configurations are those with two or more Allowed code lists assigned to each resource in a group where each list defines a separate list of codes which can schedule together but cannot schedule with other codes in other Allowed lists. 

Keep in mind that when an operation with a code from an Allowed list schedules, only operations with codes in the same allowed list are eligible to schedule concurrently on other resources in the group. This remains true even if the operation's code is not part of any Allowed or Disallowed list.

Example

In this simple example, compatibility codes NonKosher and NonAllergen are allowed to schedule together, while codes Kosher, Dairy, Soy, and Peanuts are not allowed to schedule with any other code.

Table configuration:

Allow List
Compatibility Code List
Assigned Resources

TRUE

NonKosher

NonAllergen

All resources

TRUE

Kosher

All resources

TRUE

Dairy

All resources

TRUE

Soy

All resources

TRUE

Peanuts

All resources

All code tables are assigned to all resources in the plant. All resources are capable of running any of the operations. All operations are released to schedule at the start of the schedule clock.

After optimization, we see the various compatibilities being enforced: Codes NonAllergen and NonKosher are scheduled concurrently, and each of the other unique codes schedule independently from one another even though capable resources have capacity to schedule more work.

Sample Scenario File

Download and load the Scenarios_CompatibilityCodes_12.2.0.25.dat and login as user "admin" (no password) and activate the SimpleCodes scenario.

Advanced Configurations

Multiple Allergen Groups

If there are more than one Allowed lists assigned to a resource, the lists will be treated as incompatible with each other. Only codes within the same allowed list can schedule concurrently.

Disallowed lists will override any Allowed list combinations.

Consider this example where there are multiple allergen groups combined with an incompatible allergen code list. Allergen Group 1 table is an allowed list of allergens that can schedule together. Allergen Group 2 is an allowed list of allergens that can schedule together, but not with Allergen Group 1 allergens. Incompatible Allergens is a disallowed list.

Allergen Group 1 
Allergen Group 2
Incompatible Allergens

A
E
A

B
F
D

C
G
G

D
H
H

Assume that each of the tables are assigned to resources 1, 2, and 3.

If an operation with Compatibility Code A schedules first on a resource, then the other two resources can only schedule codes A, B, and C. Nothing from Allergen Group 2 is allowed to schedule concurrently, and code D is incompatible with A according to the Incompatible Allergens list.

If an operation with Compatibility Code F schedules first on a resource, then all of Allergen Group 2 are allowed to schedule at the same time on the other resources since code F is not included in the Incompatible Allergens list. Alternatively, if either G or H schedule first on a resource, it will limit the allowed codes for the other two resources to codes E and F since both G and H are incompatible to schedule together according to the Incompatible Allergens list.

Sample Scenario File

Download and load the Scenarios_CompatibilityCodes_12.2.0.25.dat and login as user "admin" (no password) and activate the ComplexCodes scenario.

Same Allergen Codes, Different Groups

If resources that use the same allergen codes should be in separate groups, duplicate tables can be used.

Multiple Tables, Overlapping Values

Multiple Allowed tables which are assigned to the same resources can have overlapping values. For example, Allergen Group 2 from the table above could also have code A. In this case, codes from either table can initially schedule. Once a shared code is scheduled, only codes shared between the tables will be allowed. When there are no more concurrent operations scheduled, the codes will reset, again allowing codes from either table. 

Visualizing Compatibility Codes

Compatibility Codes of scheduled operations can be visualized in the Gantt or in the Activity Scheduling grids.

Gantt

The label text of any Gantt segment can display the Operation Compatibility Code value and/or the Resource Compatibility Group values (where groups are defined by the Compatibility Code Table names which are assigned to the resource).

Optionally, the Compatibility Code can also be imported onto the operation as a custom Attribute and assigned a unique Color according to the Code value, then this combination of color-coded visibility can be displayed in the Attribute Segment from the Segments section of User Settings.

Activity Scheduling Grids

The activity scheduling grid tiles in the Activities board can be configured to show Resource Compatibility Group assignments as well as Operation Compatibility Codes of scheduled operations.

Setups and Cleans Considerations

It's often sensible to configure change-overs in the form of Setups or Cleans whenever there is a change in compatibility codes scheduled on a resource or resource group. For the most flexible and dynamic solutions, it's recommended to incorporate custom Operation Attributes into the operations which utilize compatibility code logic and configure the attributes to trigger</div>
        </section>
      
        <section class="article" id="article-315-item-compatibility">
          <h3 class="article-title">Item Compatibility</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/item-compatibility" target="_blank">Source</a></p>
          <div class="article-content">This functionality is deprecated in software versions 12.2.0.1 and newer. For more robust functionality related to compatibility code scheduling, see:

Compatibility Codes

Key Concept

Item Compatibility Groups can be assigned to resources and designated on production operations in order to force all resources within the group to focus on producing a single product or group of products at a time. When set up correctly, resources that are part of the compatibility group will only be able to process operations simultaneously if the operations are configured with the same compatibility code.

This may be helpful to model multiple food processing lines which are located in the same room, for example, requiring that the same product be processed simultaneously on the independent lines. In order to prevent cross-contamination, there may need to be a way to prevent allergen products and non-allergen products from being processed simultaneously on different lines.

Another use case is if the same material input line feeds two machines, then they can only run operations that use the same material at any point in time.

Jump to section:

Configure Resource Groups

Configure Job Operations

Configure Resource Groups

Resources must be grouped together by assigning them to a Compatibility Group. Resources which are part of the same compatibility group can only run operations concurrently if the operations have the same Compatibility Code specified in their job operation's settings.

Each resource may only be assigned to a single Compatibility Group.

For importing these data, see: Resource Mappings.

Configure Job Operations

Job Operations must be configured with a Compatibility Code in order to restrict resources to only perform compatible work simultaneously. If specified, any scheduled Operation's Compatibility Code must match the Compatibility Code of other Operations scheduled on resources with the Compatibility Group of the same name. 

Each operation must also have the Use Compatibility Code property set to TRUE.

For importing these data, see: Resource Operation Mappings.

Example

Use the compatibility code "Allergen" on all operations of the process to produce food items that contain peanuts, then use the code "Non-Allergen" for all other food types. Set the "Allergen" Compatibility Group on the appropriate resources which are impacted by the contamination containment requirement. This way, no other food type could schedule at the same time as an item categorized as "Allergen." 

See Also

Resource Mappings

Resource Operation Mappings

Job Details Dialog</div>
        </section>
      
        <section class="article" id="article-171-resource-connectors">
          <h3 class="article-title">Resource Connectors</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-connectors" target="_blank">Source</a></p>
          <div class="article-content">Old Article Versions

This article is updated to reflect the latest software functionality. For older software versions, download and refer to the appropriate document version:

Software Versions
Download Link

12.2.0 and 12.2.1
 ResourceConnectors_12.2.1.pdf

Key Concept

Resource connectors specify a flow relationship between two or more resources. A resource can have connections to one or more downstream resources which can enforce a constraint during scheduling to restrict which resource(s) successor operations of the same manufacturing order can be scheduled.

A resource can be considered a From Resource or a To Resource in multiple connectors where the From Resource is the upstream resource where the work starts, and the To Resource is a downstream resource where the work is considered eligible to continue. It's possible to configure multiple connectors which define the same From/To resource connections in order to add multiple simultaneous material connections. This is practical when modeling a solution for single or some other finite number of pipe feeds from a tank resource, for example.

Jump to section:

Resource Connectors Management

Scheduling Behavior

Resource Connectors Management

Resource Connectors are created manually in the client user interface, or imported from an ERP/SQL master data source. These are dependent on existing Resource objects in the data model.

Data Import

Resource Connectors are imported via Resource Connector Mappings logic. 

Manual Creation

Resource Connectors can be created or deleted manually from the Resource Connectors tile in the Scenario Data Board.

The grid in this tile is always editable, so users may use the grid to fine-tune the default connector settings. Be sure to Save any changes before closing the tile or running a simulation. See descriptions of each property in the Resource Connector Mappings page.

Scheduling Behavior

Successor links between resources act as a scheduling constraint during optimization whereby a successor operation of a manufacturing order may only be allowed to schedule on one of the defined To Resources when the predecessor is scheduled on the defined From Resource. This is not a hard constraint, however, as a scheduler may still drag and drop the successor operation to another capable resource if they wish. The Eligibility column in the Gantt grid will act as a warning that the move violates the resource connector logic.

See Also

Scenario Data Board

Capacity Planning Board

Resource Connector Mappings

Resource Mappings

Department Mappings

Plant Mappings

Storage Areas as Tanks

Storage Area Connectors</div>
        </section>
      
        <section class="article" id="article-243-storage-area-connectors">
          <h3 class="article-title">Storage Area Connectors</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-area-connectors" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Storage Area Connectors act as constraints on when, how, and if inventory can be transferred between specific Resources and Storage Areas. Connectors can define storage area in-flow (storage) rules which determine whether a product produced on a resource can be stored in a particular storage area, and/or storage area out-flow (withdrawal) rules which determine which storage area can supply operation stock material requirements based on which resource the operation is scheduled on. Typically, these rules help shape how storage tanks and silos are used in a manufacturing facility and how PlanetTogether can use them during scheduling.

A single Connector may define only in-flow rules or out-flow rules, or may specify both in-flow and out-flow for the resources and storage areas defined in the Connector. A single connector will only ever use one Resource at a time, but can use multiple Storage Areas simultaneously, depending on the flow limit configuration.

A single Connector must specify at least one Storage Area and at least one Resource, but may specify many Storage Areas and/or many Resources. The relationship does not need to be 1-to-1; it may be 1-to-many or many-to-1 or 1-to-1. For example, one Connector might specify one Resource that can use many Storage Areas to store its products.

For Resources that can use many different Storage Areas for either in-flow or out-flow, flow limits can be defined which determine how many simultaneous interactions can take place. For example, a Resource has the possibility of feeding into 6 separate Storage Areas, but only 3 of the 6 can be used simultaneously by the connector, the in-flow limit would be 3.

Jump to section:

Storage Area Connectors Management

Connector Usage Timing

Storage Flow Limits

Use Cases & Examples

Storage Area Connectors Management

Storage Area Connectors are created manually in the client user interface, or imported from an ERP/SQL master data source. These are dependent on existing Resource and Storage Area objects in the data model.

Data Import

Storage Area Connectors are imported via Storage Area Connector Mappings. Each Storage Area Connector must define one or more of the following in-flow and/or out-flow combinations:

In-flow (storage): Storage Area Connector In Mappings and Resource Storage Area Connector In Mappings

Out-flow (withdrawal): Storage Area Connector Out Mappings and Resource Storage Area Connector Out Mappings

It's invalid to have only a Storage Area In and Resource Out (or Storage Area Out and Resource In) combination; Each Storage Area In mapping must be accompanied by one or more Resource In mappings, and vice-versa.

Manual Creation

Storage Area Connectors can be created or deleted manually from the Storage Area Connector tab of the Warehouses section of the Inventory Management tile in the Scenario Data Board.

The grids in this tile are always editable, so users may use the grid to fine-tune the connector settings. Be sure to Save any changes before closing the tile or running a simulation. See descriptions of each property in the Storage Area Connector Mappings page.

Connector Usage Timing

When a Connector gets used is determined by the Inventory Available Timing on an operation's product (an in-flow connection), and/or the Material Used Timing of a consuming operation's stock material requirement (an out-flow connection).

When multiple Connectors might be available for inventory storage or withdrawal by a scheduled operation, all compatible Connectors will be considered, but only one connector will be used.

When using Production Overlap (Inventory Available Timing on the product is set to By Production Cycle), if Item Transfer Qty is set, then material will be moved to storage in batches of that quantity as the operation completes its cycles. Otherwise, it will be moved at the end of each cycle in quantities equal to the Quantity Per Cycle. This results in the connector being in use for the entire duration of the operation while material is being transferred into the storage area.

Any of the other available Inventory Available Timing options will move the product to storage instantaneously at the specified production timing event (At Run End, Post-Processing End, etc.) plus any time required for Material Post Processing.

The same concept is valid for withdrawing material out of a Storage Area using a Connector. If the Material Used Timing is set to either During Setup, By Production Cycle or First And Last Cycle, the connector will be in use during that material transfer. All the other options, such as Production Start, moves the material instantaneously.

When a connector is in use because it is moving material to or from a Storage Area, it cannot be used by another operation.

Storage Flow Limits

For Resources that can be use many Storage Areas for either in-flow or out-flow, flow limits can be defined which determine how many simultaneous interactions can take place. Simultaneous flows can also be disabled, if desired.

The following Storage Area Connector settings dictate simultaneous flow configurations:

CounterFlow: A boolean (true/false) flag to indicate whether material can flow in both directions at once.

CounterFlowLimit: A numerical value that indicates how many Storage Area receipts and distributions (combined in-flows and out-flows) can occur simultaneously among all Storage Areas configured in the Connector.

StorageInFlowLimit: A numerical value that indicates how many in-flow Storage Area receipts can occur simultaneously among all Storage Areas configured in the Connector.

StorageOutFlowLimit: A numerical value that indicates how many out-flow Storage Area distributions can occur simultaneously among all Storage Areas configured in the Connector.

To summarize, StorageInFlowLimit and StorageOutFlowLimit constrain how many Storage Areas can be used by the connector simultaneously. CounterFlow limits whether the connector can be used to move material in and out of storage simultaneously, constrained by the CounterFlowLimit.

Use Cases & Examples

Case 1: A Single-Item Tank supplied and replenished by the same Resource

This case demonstrates an example of a tank that is only allowed to store one item at a time andnd is always supplied from the same resource.

Scenario:

A paint manufacturing company creates custom paint colors in 500-gallon batches. A batch of "Deep Ocean Blue" is mixed in a Blending Machine (a Resource) and then held in a specific Holding Tank before being sent to the Canning Line. It is absolutely critical that this Holding Tank is completely empty before the next batch, perhaps "Sunset Orange," is produced and stored in it. Mixing even a small amount of leftover blue paint with the orange would ruin the new batch.

Data Model Configuration:

The 500-gallon Holding Tank is configured as a Storage Area with Single Item Storage enabled.

Job operation Products for various paint colors are configured to output units measured in Gallons (e.g. an output of "1" equals 1 gallon). 

Each item that might be stored in the 500-gallon Holding Tank is configured with an Item Storage Max Quantity of 500 units.

A Storage Area Connector is created to define the relationship between the equipment.

An in-flow rule on the Connector links the Blending Machine (Resource) to the Holding Tank (Storage Area). 

StorageAreaConnectorIn = Blending Machine

ResourceStorageAreaConnectorIn = Holding Tank

One or more out-flow rules (StorageAreaConnectorOut + ResourceStorageAreaConnectorOut) can optionally be set on the Connector to link the Holding Tank to one or more specific Canning Line resources, although this isn't necessary unless the Holding Tank can only be used by specific Canning Line resources.

Defining a StorageInFlowLimit is not necessary in this case. The system would only ever allow a single operation to schedule on the Blending Machine resource.

Scheduling Impact:

This configuration enforces a critical quality control rule. The scheduling logic is constrained from scheduling any batch on the Blending Machine until a Canning Line resource has consumed all 500 gallons of the currently stored batch. Setup on the next scheduled production batch is modeled to account for cleaning of the storage area before the next batch of content is stored within it.

Case 2: A WIP item produced by many resources may be stored in one of many tanks in a tank farm which are connected via a shared pipe network; Packaging lines are limited to withdraw from specific tanks

This case demonstrates a situation where a particular liquid gets produced by many processing resources before being stored in one of many interconnected tank storage areas. It also limits which packaging lines can withdraw the liquid from specific tanks.

Scenario:

A facility has a "tank farm" with ten holding tanks for a liquid product. These tanks are all connected to a single, complex manifold system that leads to three different packaging lines. Due to the physical piping, Packaging Line A can only draw product from Tanks 1-4, Line B can only draw from Tanks 5-8, and Line C, a specialized line, can only draw from Tanks 9 and 10.

Data Model Configuration:

10 Storage Areas are configured which can each store the same raw material. This is the "tank farm".

Connector 1: Storage to Packaging Line A out-flow connections allow distribution to Packaging Line A from Tanks 1-4.

Connector 2: Storage to Packaging Line B out-flow connections allow distribution to Packaging Line B from Tanks 5-7.

Connector 3: Storage to Packaging Line C out-flow connections allow distribution to Packaging Line C from Tanks 8-10.

Scheduling Impact:

This configuration ensures that packaging lines which are only within range of specific holding tanks schedule to consume material only from the appropriate holding tanks.

Case 3: Multiple resources can fill a Storage Area with various materials

This case demonstrates a situation where 3 resources might each produce different products or materials that can each be stored simultaneously in a single Storage Area within a Warehouse.

Scenario:

In a plastics factory, three different machines are preparing materials to be used by a large injection molding press.

Extruder #1: Produces blue PVC pellets

Extruder #2: Produces red PVC pellets

Grinder: Processes factory scrap and old parts into grey regrind pellets

Right next to the large injection molding machine is a single elevated platform called the "Molding Feed Zone" (a single, partitioned Storage Area). On this platform sit three separate large hoppers. While they are all in one functional area, each hopper is a distinct partition that must hold only one specific type of material to prevent color contamination in the final product.

Partition A: Hopper for up to 500 blue pellets

Partition B: Hopper for up to 500 red pellets

Partition C: Hopper for up to 500 grey regrind pellets

Data Model Configuration:

A Storage Area is created called the Molding Feed Zone to represent the partitioned hopper

Item Storage configuration for each of blue, red, and gray pellets define a MaxQty in the Molding Feed Zone of 500 units each

A Storage Area Connector allows each of Extruder #1, Extruder #2, and Grinder resources to supply the Molding Feed Zone storage area with in-flow connections. With only one connector in, only one resource will be able to fill into the Molding Feed Zone at a time. If all three resources are able to fill the Molding Feed Zone at once, there would be three separate connectors.

Scheduling Impact:

When these resources produce these products, they will be required to store them in the specified storage area. If the storage area's inventory levels for any one of the products has reached its maximum, no jobs will be allowed to schedule to produce the product until the hopper has been emptied. This prevents over-production of any specific pellet color.

See Also

Items, Inventories, Warehouses, & Storage Areas

Item Mappings

Warehouse Mappings

Inventory Mappings

Storage Area Mappings

Item Storage Mappings

Storage Area Connector Mappings

Storage Area Connector In Mappings

Resource Storage Area Connector In Mappings

Storage Area Connector Out Mappings

Resource Storage Area Connector Out Mappings</div>
        </section>
      
        <section class="article" id="article-179-successor-manufacturing-orders">
          <h3 class="article-title">Successor Manufacturing Orders</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/successor-manufacturing-orders" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Manufacturing orders can optionally be given predecessor-successor relationships to act as scheduling constraints so that one order never gets scheduled to start before its predecessor is completely finished. When a manufacturing order is configured as a successor of another, all operations of the predecessor order must be scheduled to finish before the first operation of the successor is allowed to be released to schedule. Other release rules still apply to the successor order (just-in-time start date minus JIT slack allowance); this successor manufacturing order logic adds a scheduling constraint to other existing constraints.

Any manufacturing order may be configured to be the successor of any other - the two may be part of the same job, or may be orders of different jobs.

Configuration

Successor manufacturing orders can be manually configured from the Successor M.O.s tab of the Job Details Dialog in the grid in the lower half of the dialog. Click the "+" plus icon in the lower left corner to add a new Successor MO requirement, or select an existing grid row and click the "-" minus icon or press "Delete" on the keyboard to delete the selected Successor MO requirement.

At minimum, each successor requirement must specify the SuccessorJobExternalId and the SuccessorManufacturingOrderExternalId. Optionally, the SuccessorPathExternalId and SuccessorOperationExternalId may be defined.

Circularities

Beware of creating circular successor relationships where each order becomes the required successor of the other. This creates an impossible scheduling constraint and can cause optimize to slow dramatically as it loops through the logic until finally leaving the associated jobs in a "failed to schedule" state.

See Also

Successor Manufacturing Order Mappings

Job Mappings

Manufacturing Order Mappings

Alternate Path & Node Mappings

Resource Operation Mappings</div>
        </section>
      <h2 id="cat-concepts-custom-object-properties" class="category-header">Concepts &gt; Custom Object Properties</h2>
        <section class="article" id="article-264-attributes">
          <h3 class="article-title">Attributes</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/attributes" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Attributes are custom properties that can be assigned any string or integer value and assigned to various objects. These are meant to be used to track various data that PlanetTogether doesn't already have a standard property for. They can also be used to configure and determine operation setup or clean processes.

At this time, attributes can only be assigned to job operations, but in the future attributes may be expanded to support other functionality on other data objects.

Attributes are similar to User Defined Fields, though they have added native functionality like operation Setup and Clean process calculations, and can be used by various optimize factors to create custom operation sequencing optimization.

Jump to section:

Attribute Object Management

Attribute Setups and Cleans

Visualizing Attributes

Sequence Optimization using Attributes

Attribute Object Management

Attributes are created or imported as data objects, then can be associated with other data objects such as Job Operations. Certain properties of each attribute can be imported with a default value, and optionally these values can be overridden when the same attributes are associated with other objects. For example, the Attribute object can be assigned a default Color, but the assigned Color can also be overridden by defining a different Color when the attribute is associated with a specific Operation.

Data Import

Attribute objects are imported via Attribute Mappings logic, then can optionally be associated with job operations via Operation Attribute Mappings.

Manual Creation

Attributes can be created or deleted manually from the Attributes tile from the Scenario Data Board.

The grid in this tile is always editable, so users may use the grid to fine-tune the default attribute settings. See descriptions of each property in the Attribute Mappings page.

Once attributes are created, they can be added to job operations where they can be given numerical or string values via the Job Details Dialog. Any properties or settings configured at the Operation level will override the default values of the same properties set in the Attributes tile of the Scenario Data board.

The same Job Details Dialog is used to delete attribute associations from operations. To delete one or more attributes, select one or more rows from the operation attributes grid, then press the Delete key on the keyboard, or click the - minus button near the bottom of the grid.

Attribute Setups and Cleans

Attributes may optionally be used to dictate operation Setup and Clean processes. An individual attribute may only be used for either Setups or Cleans; it cannot be used for both. The AttributeType property defines whether the attribute should be used for Setup or Clean processes, then the AttributeTrigger property defines when the attribute should trigger a Setup or Clean process. Many of the triggers are sequence-dependent, meaning the attribute will incur Setup or Clean time depending on the order in which operations are scheduled on the same resource. When a sequence-dependent process is applied to an operation, it is always applied to the successor or latest scheduled operation in the sequence which triggers the process to to be incurred.

In order for attribute-defined operation Setups and Cleans to schedule on a resource, the resource must have one or both of the following properties defined:

SetupIncluded must be set to UseOperationAttributes for Setup processes

UseAttributeCleanouts must be set to True for Clean processes

For more information, see:

Setup Time

Cleans

Attribute Mappings

Resource Mappings

Visualizing Attributes

While managing attribute objects is done in the Attributes tile of the Scenario Data board, operation attributes and their values may be visualized in various grids and in Gantt segments and labels.

Gantt

The Gantt board offers users an optional Attribute Segment which can be enabled to display details of each attribute assigned to a scheduled operation in the scheduled activity block on the Gantt. Users have options to show the attribute Name, Code, and/or Number. The color of each segment will match the attribute's assigned Color. Only attributes whose ShowInGantt property is set to True can be visualized in the Gantt.

When all options are enabled, each attribute assigned to an operation whose ShowInGantt property is set to True will be displayed in its own individual segment. The data will be written to the segment in the following format:

[AttributeName] [AttributeNumber] [AttributeCode]

For example, this Gantt block shows a single attribute:

Here is an example of two attributes assigned to the same operation:

Activities Board Grids

Attribute Code, Number, and Color values may be visualized in the Activities board primary and secondary scheduling grids. Only attributes whose HideInGrids property is set to False can be visualized in the grids.

When selecting columns of properties to visualize in the grid, each attribute is represented by 3 column names (where "AttributeName" will match that of the attribute):

AttributeName Code

AttributeName Color

AttributeName Number

Sequence Optimization using Attributes

Attributes may be factored into PlanetTogether's schedule sequencing optimization. This gives schedulers ultimate flexibility to customize schedule optimization logic to tailor it to specific business and operational needs. Only attributes whose UseInSequencing property is set to True can be used during schedule optimization.

From the Sequence Planning board, the applicable optimize factors can be identified by their Category assignment, Attributes. Each factor may be assigned some number of points from the Optimize Factor Details tile, then each individual attribute that should be factored into optimize scoring for that particular optimize factor can be selected. If certain attributes should be weighted higher than others, an additional Multiplier option is available.

For more information, see:

Optimization

Sequence Planning Board

See Also

Setup Time

Cleans

Optimization

Attribute Mappings

Operation Attribute Mappings

Resource Mappings

Scenario Data Board

Gantt Board

Activities Board

Sequence Planning Board</div>
        </section>
      
        <section class="article" id="article-211-user-defined-fields-udfs">
          <h3 class="article-title">User Defined Fields (UDFs)</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/user-defined-fields" target="_blank">Source</a></p>
          <div class="article-content">Old Article Versions

This article is updated to reflect the latest software functionality. For older software versions, download and refer to the appropriate document version:

Software Version(s)
Download Link

12.1.4.x thru 12.2.1.x
UserDefinedFields_12.2.1.pdf

Key Concept

User Defined Fields can be used to include extra data or information about objects imported into PlanetTogether for which the software does not already offer a property. Any number of UDFs can be added to Jobs, Manufacturing Orders, Operations, Resources, and more. They can be made visible in various board grids (Jobs, Activities, Sales Orders, etc.) and can be added to Gantt Labels and Tooltips. Custom software extensions can also access them.

Jump to section:

Adding and Modifying User Defined Fields

Visualize User Defined Fields

Adding and Modifying User Defined Fields

Data Import

Each user field must first be defined via the User Field Mappings, then they can be assigned to their respective data objects in the various Import Mappings Board pages per each object type which supports them (Jobs Mappings, Resource Operation Mappings, etc.).

Manual Entry

A User Fields board is accessible via the settings dropdown of the main toolbar:

This board allows users to create user fields which can later be assigned to objects that match the field's defined Object Type. Use the grid to edit the object property values.

Once the fields are created, they can be assigned to Jobs and Operations via the Job Details popup dialog. From the Job Properties tab, find a User Fields tab which includes controls to add or remove UDFs. Once a UDF is added, its properties and values can be edited in the User Fields grid directly.

All other objects require users to input UDFs via the object grid editors where the syntax must be carefully followed.

Syntax

Each UDF has two parts:

field_externalid: The unique ExternalId of the UDF

value: The UDF's value

The two definitions must be separated by a "~" tilde. Multiple user fields assigned to the same object must be separated by a ";" semi-colon. SQL statement concatenations are supported in the import mappings, if necessary. Here is a template to use for each imported UDF:

field_externalid~value

Note that int, long, double, and decimal types will be formatted with thousand-separators every 3rd digit when viewed in grids (commas in English, or decimals or spaces in other languages as appropriate). Use string type for numbers which should not be formatted.

UDFs can be configured for the following objects:

Capabilities

Capacity Intervals

Cells

Customers

Departments

Forecasts

Items

Jobs

Job Operations

Manufacturing Orders

Plants

Product Rules

Purchase to Stock

Resource Connectors

Resources

Sales Orders

Transfer Orders

Users

Warehouses

EXAMPLE

This would assign one Field called "UnitOfMeasure" whose value is set to that of the SQL field named "UOM".

'UnitOfMeasure~' + UOM

This example would create two Fields, "UnitOfMeasure" and "Revenue":

'UnitOfMeasure~' + UOM + ';Revenue~' + Revenue

The imported UDF can then be visualized in the associated grid (Sales Orders in the example above):

Note that after adding one or more new UDFs via manual entry or data refresh the user's PlanetTogether Client application must be restarted before the new fields can be visualized in the associated object grid(s).

Visualize User Defined Fields

After adding one or more new UDFs to any data object via the Client UI or via Data Refresh, the user's active Client application must be restarted before the new UDFs can be visualized in the interface. Simply exit or logout of the application, then sign back in.

Grids

UDFs whose display_in_UI flag is TRUE can be visualized in any grid which displays the related object data. For example, the Customers board grid can display any UDFs that were imported on any of the existing Customer objects in the data model. Simply use the Column Chooser to hide/show any of the custom UDF properties in the grid layouts. They are named the same in grid columns as the assigned UDF Name property.

Gantt Segment Labels

Various UDFs can be visualized in Gantt segment labels from the User Settings ➡️ Segments section. Click the appropriate [ Label ] button to customize a segment label and add any UDF by searching for the field name in the search box of Available Fields, or manually with the following syntax:

[<object_type>.<FieldName>]

Example of a Job UDF called CustomerStatus:

[Job.CustomerStatus]

For more information, see: Activity Blocks - Segments & Labels

See Also

Import Mappings Board

Layouts, Metrics, and Targets

Grid Personalization

Gantt Board</div>
        </section>
      <h2 id="cat-concepts-jobs" class="category-header">Concepts &gt; Jobs</h2>
        <section class="article" id="article-189-alternate-paths">
          <h3 class="article-title">Alternate Paths</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/alternate-paths" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, Alternate Paths specify the precedence relationships between operations, thus indicating the path or route that is followed through the plant to produce a product. A manufacturing order may have one path, or may be configured with many possible paths. Each path represents a unique way for the same work to be done, thus PlanetTogether will only schedule the job on one of the defined paths. When multiple paths are used, each path may be configured to be allowed to be scheduled automatically by PlanetTogether's sequence optimization logic, or each may be configured so that it only schedules on the path via a manual schedule adjustment by the scheduler. Some common use cases for utilizing multiple paths are:

Define variations in the Bill of Materials (BOM) between paths in order to allow for different materials or material sources or costs

Define variations in the resource(s) which perform the work

Define one or more paths that include a sub-contractor which may increase costs but will be able to help to finish the job faster

Jump to section:

Alternate Path Configuration

Path Requirements

Preference

AutoUse

Linear Sequence vs. Parallel Operations

Operation Overlap

Max Delay

Operation Transfer

Path Validity

Automatic Alternate Path Selection

Manual Alternate Path Selection

Incompatible Features with Automatic Path Selection

Alternate Path Configuration

Access an MO's paths from the Alternate Paths tab of the Job Details dialog:

Path Requirements

Each Manufacturing Order of each Job will have at least one Path. If an MO is imported without a specified path, the system will create a linear path according to the order in which each of the MO's operations are imported.

Each Path must contain at least one Operation. There is no maximum limit to the number of Operations per Path.

Each Path may only contain unique operations. If multiple Paths require the same process or operation then their Operation Names and all settings may be identical, but their External Ids must be unique.

Optional Path Configurations

Preference: Assign a numerical value to each path which can optionally be factored into a Sequencing Plan to give higher optimize scoring to the first operation of paths with a higher preference (see factor: Alternate Path Preference).

AutoUse: Specify when each path may be considered for scheduling during schedule optimization. Accepted values:

IfCurrent: The Path may only be chosen only if it is marked as CurrentPath of the Manufacturing Order. Other paths may still be chosen unless the MO's LockToCurrentAlternatePath setting is TRUE.

RegularRelease: The Path is released for scheduling based on standard operation release timing and optimize settings (JIT start date minus JIT slack days minus offline capacity on eligible resources).

ReleaseOffsetFromDefaultPathsLatestRelease: The Path is released for scheduling only after the number of scheduling days defined in the AutoUseReleaseOffsetDays have passed since the Manufacturing Order's Default Path has been released. This can help to ensure that the Default Path is released for scheduling before other paths.

Linear Sequence vs Parallel Operations: Any Path may be configured with two or more linear or parallel operations.

A linear sequence assumes that one operation must complete before the next operation is allowed to start (though Operation Overlap may be configured to allow linear sequenced operations to at least partially overlap). Define the linear sequence using predecessor and successor relationships via PredecessorOperationExternalId and SuccessorOperationExternalId properties in the path's operation nodes. 

Example:

Op010 has no predecessors (no operation defines it as its successor), so it starts the sequence

Op020 is defined as the successor of Op010

Op030 is defined as the successor of Op020

Op070 is defined as the successor of Op030

Op070 has no successor, so is the last in the sequence

Running parallel operations assumes that two or more operations of a path may run simultaneously. Parallel operations which run at the start of the path may be configured using basic Predecessor/Successor logic where none of the parallel operations are configured to be the successor of any other operation, and each of the parallel operations may optionally define the same operation to be their successor. Alternatively, if at least one operation must run before any parallel operations are able to start then it's most logical to configure a linear sequence, but use Operation Overlap to allow the parallel operations to overlap with one another. 

Example:

Neither Op040 nor Op050 have a predecessor, and both define Op060 as their successor. In this case, both operations Op040 and Op050 may schedule to run in parallel.

Finally, Op060 may start only after both Op040 and Op050 are completed since it is configured as a successor to both operations.

Operation Overlap: Linear operations of a Path may be configured to partially or completely overlap with one another. To achieve this, first define the OverlapType, then define by how much the operations are allowed to overlap via either the OverlapTransferHrs or OverlapPercentComplete depending on the OverlapType defined.

OverlapType options:

NoOverlap: The entire Predecessor Operation must complete before the Successor Operation can begin.

TransferQty: The Successor Operation can begin once the first Operation has produced a specified quantity (specified in the OverlapTransferQty field in the Operation Mappings).

TransferSpan: Successor Operation can begin after the first Operation has been running for a specified time (specified in the OverlapTransferHrs field of the Alternate Path Node).

AtFirstTransfer: Successor Operation can start once a specified number of items is produced and transferred to inventory (specified in the TransferQty property in the Item Mappings for the product produced by the operation).

TransferSpanAfterSetup: Successor can begin after the OverlapTransferHrs plus any Setup time.

PercentComplete: Successor can begin after the predecessor operation has been completed to a percent specified in the OverlapPercentComplete field in the Alternate Node Mappings.

Example: Overlap Production

Operation Op040 starts the sequence; its successor is Op050

Op040 is configured to allow Op050 to overlap with it after it's 50% completed via settings OverlapType: PercentComplete and OverlapPercentComplete: 50

Operation Op060 is the last operation in the sequence and must wait for Op050 to complete before it can start.

Example: Overlap Setup

It's possible to allow the successor operation to overlap with the predecessor by precisely the amount of time required to setup the successor operation, even if setup is dynamically calculated by an attribute code table or other means of dynamic setup duration.

In this example, an attribute called "Setup" is configured to incur 2 hours of setup with the code changes from "A" to "B", or 4 hours of setup with the code changes from "B" to "A". Each job is only 2 operations and the second operation is allowed to only overlap with its predecessor the duration of its setup.

To achieve this result, the path route must be configured with the following:

Overlap Type is set to Transfer Span

Overlap Transfer Hours is set to 0 hours

Transfer Start is set to End of Post Processing

Transfer End is set to End of Setup

This configuration allows the successor to be released so that there is zero time span between the end of post-processing of the predecessor operation and the end of the setup of the successor operation.

Max Delay: The Max Delay feature specifies the maximum amount of time that the start of a successor operation can be delayed after its predecessor is scheduled to end. For example, when MaxDelayHrs is set to 0, the successor operation in the Path should schedule to start immediately after the predecessor is scheduled to finish.

Warning:

Using Max Delay may slow down optimization and scheduling performance, especially if using it between many operations.

If the MaxDelayHrs setting cannot be enforced during optimization, the job may schedule past the planning horizon, or it may schedule within the horizon and a warning will be logged for the scheduler to review and act upon.

To configure a maximum delay between two operations, define a value for the MaxDelayHrs property in the predecessor operation's settings of the Alternate Path Node.

Note:

In order for Max Delay to be enforced during scheduling, an option in System Settings ➡️ Scheduling Options must be enabled:

Example:

Operation Op050 is the successor of Op040. The materials that Op040 are producing may expire or go bad if they are not used by Op050 within ~2 hours of being produced, so MaxDelayHrs will be set to 2 in order to ensure that operation Op050 will schedule in time to consume the material before it expires.

Tip:

The Max Delay Gantt segment, label text, and scheduling hint lines can help schedulers visualize Max Delay settings and violations and help them adhere to Max Delay settings when performing drag/drop moves in the Gantt.

User Settings ➡️ Segments

Use segments to give visual cues to violations of Max Delay settings between operations.

Label Text

Scheduling Hints

Start After: When the predecessor operation is selected in the Gantt, a Start After hint indicates the earliest point in time that the predecessor can start in order to adhere to the defined Max Delay Hours.

Start Before: When the successor operation is selected in the Gantt, a Start Before hint indicates the latest point in time that the successor can start in order to adhere to the defined Max Delay Hours

Operation Transfer: For various processes, there may be a required minimum amount of time between when one operation ends and its successor begins. It's a sort of "Minimum Delay" as it acts in the opposite manner of Max Delay. This delay or transfer can be modeled via the TransferHrs property on any alternate path node. This property specifies the minimum number of hours to delay the start of the successor operation after the predecessor finishes. The successor operation will be delayed by at least number of hours specified after the end of the predecessor operation's post-processing step.

Optionally, the TransferStart and TransferEnd properties can be used to alter the default logic of starting the transfer at the end of post-processing. This may allow the successor operation to overlap some of the transfer time.

TransferStart: The point in time when the transfer from this operation to its successor should start.

TransferEnd: The point in time when the transfer from this operation to its successor should end. Choose StartOfOperation for a standard calculation from the TransferStart.

Accepted values for each of these fields:

StartOfOperation: At the start of the operation.

EndOfOperation: At the end of the operation.

EndOfPostProcess: At the end of the operation's post-processing.

EndOfStorage: At the end of the operation's Tank Storage.

EndOfRun: At the end of all cycles/run.

EndOfSetup: At the end of the operation's setup.

Example: The predecessor operation is configured with a 2-hour transfer span, but also incurs 1 hour of post-processing. The transfer can begin as soon as the Run or Cycles are complete (EndOfRun), so the successor operation is allows to start 2 hours after the completion of the predecessor's Run, leaving only a 1-hour gap between the two operations rather than 2 hours:

Additionally, the optional TransferDuringPredecessorOnlineTime property specifies that the TransferHrs should occur during the Predecessor Operation's Online capacity interval instead of calendar hours. For example, if an Operation completes at the end of a shift and has four hours of transfer time, the transfer time will not occur until the start of the next shift. If False, the transfer time will start immediately and could be completed before the next shift.

Path Validity: Each path can be configured with a Validity Start and Validity End date. On an optimize, the system will pick the valid path at the time of scheduling. On a manual move, when Show Move Validation is enabled (User Settings ➡️ Move Settings) the system will constrain the move based on the start and end dates of the scheduled path. It will show a warning when trying to drag and drop to a time where the scheduled path is not valid. In order to move to another path that is valid during the desired time, user will need to use ALT+drag and drop to move to another path.

There is a Gantt region setting available in User Settings ➡️ Scheduling Hints ➡️ Gantt Regions. Turning on the Show Before Path Validity Region and Show After Path validity Region will show a red shaded region on the Gantt where the scheduled path is not valid when the job is clicked.

Automatic Alternate Path Selection

Certain configuration options may enable the standard Optimize function to consider two or more Paths of any Manufacturing Order.

Configuring automatic path selection

System Settings

Under the Scheduling section of the Scheduling Options section of the System Settings is an important option that can be used to enable automatic path selection:

Allow jobs with at least one unsatisfiable path to schedule on an eligible path: When toggled ON, if an order with two or more paths has at least one path which is not eligible to schedule, then only paths which are eligible to schedule will be considered during optimization. When toggled OFF, if an order has one or more paths which are not eligible to schedule then the entire job will fail to schedule.

Manufacturing Order Settings

It's recommended to define the preferred path via the DefaultPathExternalId property on the Manufacturing Order. This enables the use of the AutoUse property value ReleaseOffsetFromDefaultPathsLatestRelease to help with Path selection prioritization.

In order for the Optimization logic to consider other paths in the order, the LockToCurrentAlternatePath property must be set to FALSE.

Alternate Path Settings

Only two of the three AutoUse settings support automatic path selection:

RegularRelease: The Path will be released according to standard scheduling release logic of the first operation in the Path (Need Date minus Standard Hours minus JIT Slack minus offline resource capacity). It's recommended to use this setting for the preferred or default Path.

ReleaseOffsetFromDefaultPathsLatestRelease: Combine this with the AutoUseReleaseOffsetDays property to define a number of days that this Path should be ignored during scheduling from the time that the default Path is released to schedule. For example, if the DefaultPath of the Manufacturing Order is released to schedule on May 1 and an alternate path is configured with AutoUse setting ReleaseOffsetFromDefaultPathsLatestRelease and AutoUseReleaseOffsetDays set to 3, then the alternate path will be released for scheduling no earlier than May 4 (+3 days after the release of the default path).

IfCurrent: A Path whose AutoUse is set to IfCurrent will only be considered eligible for automatic selection if it is already the currently scheduled path at the time that optimization is performed.

Preference: Optionally give a numerical preference value to each path. This may come into play when the first operation of multiple paths may be eligible to schedule on the same resource and are both released to schedule. The optimize factor Alternate Path Preference can be configured to give extra points to the first operation of the preferred path.

The following conditions will cause the Manufacturing Order to be scheduled on its Current Path Only during optimize and expedite:

Any activity progress is reported

The MO has one or more finished activities

The MO has one or more started activities

The MO's LockedToCurrentPath property is set to TRUE

Any activities are Locked to the currently scheduled resource(s)

Any activities are Anchored

The MO is scheduled to start before the optimized start time

Note: When using the expedite function, there are two exceptions to the list above:

Resource Locks will not prevent the manufacturing order from being scheduled on different alternate paths.

An Anchor won't restrict a manufacturing order to the current path if the Anchor After Expedite Setting is turned on.

Manual Alternate Path Selection

When an Activity Block is selected in the Gantt, the Eligibility column of the Gantt grid will display a yellow circle if the resource is eligible for one or more of the MO's Alternate Paths to schedule there. A scheduler may hold the Alt key on their keyboard, then click and drag and drop the selected activity block onto a resource with a yellow circle in order to reschedule the order on the eligible alternate path. 

If more than one alternate path are eligible to schedule on the resource where the activity block is dropped, then the user will be presented with a popup window to select which path they'd like to schedule the order.

Warning:

Keep in mind that optimizing the schedule may result in the order moving to another path if certain settings are enabled to allow optimization to select alternate paths. This behavior can be prevented by setting the LockToCurrentAlternatePath setting to TRUE on the Manufacturing Order.

Incompatible Features with Automatic Path Selection

Job.CanSpanPlants

MO.CanSpanPlants

Multi-Plant Scenarios

MO.LockedPlant

Batching Manufacturing Orders

Successor and Predecessor Manufacturing Orders

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Alternate Path & Node Mappings

Job Details Dialog

Gantt Board</div>
        </section>
      
        <section class="article" id="article-260-job-details-dialog">
          <h3 class="article-title">Job Details Dialog</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/job-dialog" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The job details dialog is a popup view of all of the data that defines a single job. It can provide critical details and insights to help identify bottlenecks, or can be used as a means to update certain settings or values of a job or any of its manufacturing orders or operations. The dialog can be accessed by many different methods from many different screens typically by double-clicking or right-clicking and choosing to "Open" any component related to the job (the job entry itself in the Jobs Board grid; one of its scheduled activities on the Gantt or in the Activities grid; from the Inventory Plot tile that references the job; from a material requirement entry in the Materials Board grid; etc.).

Jump to section:

Job Properties

Gantt View

Grid View

Operation Details

General

Status

Scheduling

Batching/Setups

Advanced

Resources

Buy-Direct Materials

Stock Materials

Products

Subassemblies

Attributes

User Fields

Notes

Job Properties

Job Name: A user-friendly name to identify the job.

External Id: A unique identifier for the job. 

Id: A system-generated unique identifier for the job.

Need By: The date and time which the job must be completed by before it is considered late.

Customer: One or more customers that the job is associated with. 

Destination: An indication of the geographical region or address where the products that are produced by the job will be sent. For informational purposes.

Description: An optional text description of the job. For informational purposes.

Order Number: This can be used to specify the customer order number (the Sales Order(s) that the job is supplying). If using MRP in PlanetTogether to generate jobs then this field will be populated by MRP with the Job Name(s) and/or Sales Order Name(s) of the demand signal(s) which initiated MRP to generate the job. For informational purposes.

Note: If using MRP in PlanetTogether to generate jobs to satisfy demand from other jobs, this field does not necessarily represent which job(s) its produced material will be allocated to. The only way to predict and enforce hard-pegged material production to consuming jobs is to use Lot Controlled Planning. 

Commitment: This is mostly an informational field, though a job's Commitment can influence how other scheduling actions interact with the job if certain optional settings are defined. For example, jobs with certain commitments can be excluded from optimization or prioritized during optimization. A job can be designated to be in one of four possible commitment levels at any time:

Estimate: A job with this commitment level typically represents an experimental job like a Capable to Promise (CTP) job which can be used to estimate whether or not work can be done, and if so by when. These are typically less of a priority than jobs which are scheduled to supply firm orders.

Planned: A job with this commitment level is usually a computer-generated order that a planner has not yet fully committed to. The most common example is an MRP-generated job created to satisfy a material requirement for a higher-level job, but which still may require additional review before the planner and scheduler can commit to doing the work. Planned jobs can be imported or generated when using MRP within PlanetTogether to generate jobs.

Firm: A job with this commitment level is typically one that has been firmed by a planner and which the plant is committed to producing or completing.

Released: A job with this commitment level is typically one that has been released to the shop floor to begin work as soon as capacity allows.

Hold Until: When the Hold Until checkbox is checked, the job's operations will not be released to schedule until after the date specified in the box below the checkbox. 

Color Code: The color code assigned to the job. This color can optionally be visualized in the Jobs Board grid or in Gantt labels.

Finished: A true/false indicator to show whether or not the job is finished. If any operation of the job is in progress (some quantity or time has been reported on one or more activities) then a total job completion percentage will be displayed.

Flags:

Reviewed: A true/false indicator to show if a planner has reviewed the Job. Only set during import for NEW Jobs and thereafter is expected to be controlled manually.

Printed: A true/false indicator to show if the Job’s Traveler Report has been Printed.

Shipped: A true/false indicator to show if the job has been shipped to the recipient. For informational purposes.

Cancelled: A true/false indicator to show if the job has been cancelled. If True, the job will not be scheduled.

Do Not Schedule: A true/false indicator to determine if the job should be scheduled. If True, the job will not be scheduled. 

Do Not Delete: A true/false indicator to determine if the job should not be allowed to be deleted. If True, then the job cannot be deleted by the system during MRP job generation, or manually by any user.

Template: A true/false indicator to show if the job is designated as a routing template for use by MRP and CTP functions. Job templates are not scheduled as jobs and can only be visualized from the Routing Templates Board (not the Jobs Board).

Invoiced: A true/false indicator to show if an invoice has been sent for the Job. For informational purposes.

Additional Job Properties

The tabular pane to the right of the main job properties offer additional insights into the job's scheduling status, financials, and other analytical data.

Scheduling: This tab displays the scheduling status of the Job, including a list of the Latest Constraints, the Start Date, and the End Date of the Job.

Financials: This tab is used to control and display financial information about the job, including Revenue, Throughput, Profit, and Costs. 

Performance: This tab displays an overview of the Job's performance, calculated to compare the Expected Run and Setup Hours with the Standard Hours where Standard Hours are the combined total number of hours of Setup plus Run/Cycle time. The Expected number of hours may vary depending on which resource(s) the job schedules on and those resource's capacity and efficiency ratings.

Entry

Entry Date: The date the job was created or imported into the data model.

Maintenance Method: This property can be used to track how the jobs are maintained.

ERP/Imported: The job was imported into PlanetTogether.

MRP Generated: The job was created by MRP in PlanetTogether.

Manual: The job was manually created in PlanetTogether.

Max Early Delivery Days: The maximum number of days the job should be allowed to schedule early before it is considered "Too Early". This is not a scheduling constraint.

Almost Late Days: The number of days before the job's need date that the job should be flagged as "Almost Late". Jobs which are scheduled to finish "Almost Late" can be visualized in the Jobs Board grid and in Gantt labels.

Can Span Plants: A true/false indicator to determine if the job is allowed to split its operations between two or more plants in the data model. If false then all operations of the job must schedule within the same plant.

Priority

Priority: A numerical value used to specify a combination of importance and urgency. Lower numbers are considered more urgent/important wherever PlanetTogether might use them (Gantt labels, optimize factors, etc.).

Importance: A numerical value used to indicates the value of the job relative to other jobs.

Class: The job's classification which can be used to distinguish the purpose of the work request. For informational purposes.

Production Order: The job produces items to supply demand.

Quote: The job is an estimate to determine potential finish dates and costs to produce items.

Safety Stock: The job is meant to replenish inventory to reach desired safety stock levels.

Transfer Order: The jobs is a request or means for items to be transferred from one warehouse to another.

Template: The job is used as a template to create other jobs from.

Buffer Stock Replenishment: The job uses the buffer penetration of the primary product's inventory instead of the drum or shipping buffer penetration. 

Sales Order: The job is a customer order for finished products. 

Type: A free-form input to allow a PlanetTogether user to specify a custom job type of their choosing. For informational purposes.

Hot: A true/false indicator to flag a job as "Hot", meaning it should be treated as a very high priority. Optimize factors can be given weight to prioritize scheduling "Hot" jobs, and they can be visualized in the Jobs Board grid and on the Gantt. An additional text field is supplied for notes as to why the job is flagged as "Hot".

Supplied Sales Jobs:

Notes: Additional text notes related to the job. For informational purposes.

User Fields: Custom user defined fields (UDFs) assigned to the job. Used primarily in conjunction with software customizations/extensions. For more information, see: User Defined Fields (UDFs).

History: A brief history of the job since being entered.

Analysis: A more in-depth look at the scheduling information. This tab details all of the job's operations, whether they are bottlenecked, and how late the operation is.

Gantt View

This view provides a graphical (read-only) overview of the structure of the Job as well as the Start and End dates for the scheduled Jobs. In addition, the information is displayed in the Gantt View for the following:

Job: If the Job is scheduled, then the top row of the Gantt is shown in green and indicates the total duration of the Job.

Manufacturing Order: If the Manufacturing Order is Scheduled, then a blue row is drawn to indicate the total duration of the Manufacturing Order.

Alternate Path: A row is drawn for each Alternate Path in each Manufacturing Order. The Current Path is expanded automatically to show the Operations within it. In addition, red arrows are drawn between Operations and their Successors as defined in the Alternate Path.

Operation: A row is created and a block drawn for each Operation in each Manufacturing Order. If the Operation is Scheduled, then the blocks are drawn at the Scheduled Start and Scheduled End times. If the Operation is not Scheduled, then the blocks are drawn to start at the current PC time, and their length is based on the Work Content of the Operation. Operations that are Scheduled and Late are colored Orange. In addition, each block is labeled with the Operations: Name, Description, Resources Used, and Work Content. You can also see this text in the tool-tip displayed when you point the cursor at the Operation.

The timeline along the top of the Gantt can be scrolled and zoomed. By default, it starts at the current PC clock for unscheduled Jobs and at the Job Scheduled Start for scheduled Jobs. You can scroll by using the arrows at either side of the timeline or by dragging the timeline using the mouse. You can change the zoom by holding the Ctrl key and dragging the mouse along the timeline.

Grid View

The Grid View provides a hierarchical view of all of the job's data. For example, its Manufacturing Orders, each Manufacturing Order's Operations, Alternate Paths, and Successor Manufacturing Orders and all data related to each of those objects.

When a Manufacturing Order is selected from the Manufacturing Orders grid, its operations, alternate paths, and successor MO data can be viewed in the respective tabs of the Manufacturing Order Details section.

While browsing the grids it's important to note that:

Cells with white backgrounds can be edited while those with gray backgrounds are calculated fields. 

Use the "+" add and "-" delete controls at the bottom of each grid to add or delete table rows

An alternate way to delete a row in a table is to click once anywhere within the row to select it and press the Delete key on the keyboard.

Columns can be reordered within a grid by clicking and holding the mouse over the column header and dragging it to the desired location.

Users may use the standard grid Column Chooser to hide, show, or rearrange the sort order by right-clicking any column header and selecting Column Chooser.

Each horizontal and vertical line separating the grid cells can be dragged to resize the cells and display more information. 

Operation Details

The Operation tab of the Job Details dialog displays the configuration settings of each operation of each manufacturing order of a job. 

Load the configuration of various operations by selecting the Grid View option from the lower half of the Job Details dialog, then selecting the Operations tab. Each operation in the grid below can be selected by clicking once anywhere in the grid row.

Jump to section:

General

Status

Scheduling

Batching/Setups

Advanced

Financials

Resources

Buy-Direct Materials

Stock Materials

Products

Subassemblies

Attributes

User Fields

Notes

General

General information about the Operation.

Name: Editable text identifier for the Operation.

External Id: The External identifier of the Operation. Must be unique to the associated Manufacturing Order.

Description: Additional text for describing the Operation.

Unit of Measure: The defined mode of quantity. Used for informational purposes only.

Required Qty: The quantity of product that the Operation must produce. 

Qty Per Cycle: The quantity of product produced during each production cycle.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Start Qty: A calculated field that indicates the total amount of product that the operation will produce based on the Required Qty plus the expected scrap quantity (calculated by the defined Planned Scrap % times the Required Qty). 

Planned Scrap %: Percent of parts expected to be scrapped. Used to calculate Start Qty.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Time Standards:

Setup: The amount of time required to prepare the resource to run the Operation.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Cycle: The time required to perform one production cycle. This is used with Qty Per Cycle to determine the run the length of the Operation based on the Expected Good Qty.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Post Processing: The amount of time that a resource may be occupied after Processing has been completed. This can be used to model cleanup time, drying time, cool down time, etc. The release of material may be constrained by the Post Processing time, and no operations can schedule on the resource during post-processing. Whether a resource will be occupied also depends on the Resource Requirement's UsageStart and UsageEnd settings. 

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Tank Post Processing: Deprecated in software version 12.3.0 and newer. The amount of time a Tank Resource is unavailable after all of the material has been removed.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Storage: The amount of time that a resource may be occupied after Post Processing has completed. This is typically used to model WIP storage when the storage of material needs to consume the resource's capacity and prevent other operations from scheduling.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value.

Clean Time: The amount of time that a resource may be occupied after the operation's Cycle, Post Processing, and Storage have completed. For more information, see: Cleans.

Clean-out Grade: A numerical Grade value to assign to the Clean Time. This grade is a way to numerically rank which cleanout should be scheduled in the event that multiple cleans would otherwise need to be scheduled simultaneously. Under these conditions, the highest grade value takes precedence. For more information, see: Cleans.

Manual Update Only: When enabled, a data refresh will not overwrite the property's value. Applies to both Clean Time and Clean-out Grade.

Status

View and/or report progress on the operation and each of its activities.

Finished: An indication that the selected activity of the operation is or is not yet finished.

Time Based Reporting: When enabled along with automatic progress reporting, reported Setup, Run, and Post-Processing Hours will be automatically updated in addition to reported finished quantity as the schedule clock is advanced beyond the start of the activity. 

Rework: A flag that can be set to track operations which are required due to a previously failed effort to produce the same product for the same order.

Automatically Report Progress when Clock Advances past Scheduled Start: When enabled, progress on the activity will automatically be reported as the clock advances beyond its scheduled start date.

Automatically Finish when Clock Advances past Scheduled End: When enabled, the activity will be marked Finished and its products added to inventory when the clock is advanced past its scheduled end date.

Finish All Activities: A button to mark all activities of the operation as finished.

Percent Finished: A visual indication of the progress made toward the completion of the operation.

Omitted: A flag to manually omit the operation to prevent it from scheduling, or an indication that the operation was omitted from scheduling due to other settings or incompatibilities with its configuration.

Not Omitted: The operation is not omitted from scheduling.

Omitted by User: The user has flagged the operation to be omitted from scheduling.

Omitted Automatically: The scheduling engine has omitted the operation from scheduling

On-Hold: A flag to put the operation on hold from scheduling. Users can choose from a list of reasons which can be configured in System Settings.

Hold Until: Use "Not Set" to leave the operation on hold indefinitely, or define a date and time when the operation should be released to be scheduled.

Split: An indication of whether or not the selected activity was created by a split of the operation.

Whole Number Splits: An indication of whether activities must be split into quantities with whole numbers, this is only possible if the original quantity is a whole number.

Prevent Splits from Incurring Setup: When True, split activities of this operation will not incur any Setup time.

Prevent Splits from Incurring Clean: When True, split activities of this operation will not incur any Clean time.

Activities Grid Properties

Id: A system-generated unique ID associated with the activity object.

External Id: The assigned External Id of the activity, unique to the Operation.

Production Status: A dropdown selection of various statuses of production.

Waiting: The activity is waiting for all constraints to be met before it can be released to schedule.

Ready: There are no constraints besides capacity preventing it from scheduling.

Setting-Up: The activity has started and is in the "Setup" phase.

Started: The activity has started but is not currently running. Maybe some quantity is finished but the activity is on hold.

Running: The activity is currently in progress on the scheduled resource.

Post-Processing: All cycles have completed for the activity and it's in its final Post Processing phase.

Finished: The activity is finished.

Manual Update Only: A Boolean flag which indicates whether the activity's Status and Reported Quantities can only be updated manually or not. If True then the status will not be impacted by updates made during a data Refresh unless the System "Incoming Data" Option to "Allow ERP Production Status to override manually updated status" is configured to allow the ERP production status to override the manual updates made in the PlanetTogether Client. See: System Settings - Incoming Data.

ActualResourcesUsed: A list of resource External Ids which were used to perform the work of a finished operation.

Anchored: A Boolean flag to indicate whether or not the activity is anchored at the currently scheduled time. Schedulers can effectively anchor the activity using this dialog.

Anchor Start Date: The date that the activity is anchored to start.

Anchor Drift Hrs: The number of hours of Anchor Drift that was caused by the most recent scheduling action.

BatchAmount:

CleanOutGrade: The Cleanout Grade of the associated Activity. Inherited from the Operation.

CleanTimeHrs: The Clean duration of the Activity. Typically inherited by the Operation's time standard, but can be overridden at the activity level.

CleanTimeManualUpdateOnly: When True, CleanTimeHrs is assumed to be manually controlled by the user so data refreshes will not override the activity's CleanTimeHrs setting.

CleanTimeOverride: When True, the Activity's CleanTimeHrs will override the Operation's CleanTimeHrs.

Comments: Optional comments about the activity can be entered here.

Comments2: Optional comments about the activity can be entered here.

CycleHrs: The number of hours required to perform one production cycle. Typically inherited by the Operation's time standard, but can be overridden at the activity level.

CycleSpanManualUpdateOnly: When True, CycleTimeHrs is assumed to be manually controlled by the user so data refreshes will not override the activity's CycleTimeHrs setting.

CycleSpanOverride: When True, the Activity's CycleTimeHrs will override the Operation's CycleTimeHrs.

Expected Finish Qty: The calculated quantity of product that is expected to be produced by the activity.

In Production: A Boolean flag to indicate whether or not the the activity is currently running.

Jit Start: Calculated JIT (Just-In-Time) start date of the activity based on the job's Need Date and the required work hours of all of the job's operation in relation to this activity.

Late: A Boolean flag which indicates whether or not the activity is scheduled to finish later than its need date.

Locked: An indication of whether the activity is Locked to a specific resource or Unlocked and free to schedule on any capable resource.

People Usage: Define which People Usage strategy the activity should adhere to when scheduling.

Use All Available: The activity will consume all available people from the capacity interval where it is able to schedule.

Use Specified Nbr: The activity will consume only the specified number of people defined in the "Nbr Of People" property from the capacity interval where it is able to schedule. If it does not consume all of the people available and the resource has Multi-tasking capacity then other operations may schedule to run on the same resource at the same time if capacity allows. This is not a scheduling constraint. If there are fewer people available on a capacity interval on an eligible resource then the activity may still schedule there but it will take longer to run by a factor of the missing number of people and the defined run rate.

See also: Multi-tasking Resources.</div>
        </section>
      
        <section class="article" id="article-299-job-structure">
          <h3 class="article-title">Job Structure</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/job-structure" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, each job has the following multi-level structure: 

Job: A Job is the highest level of the structure. It specifies the total number of products ordered by one or more customers and the date the order needs to complete and ship. A job can specify one manufacturing order for a product or can be divided into multiple manufacturing orders.

Manufacturing Order: A Manufacturing Order is a request to manufacture a specific quantity of a single product. A job may have multiple manufacturing orders as a way to group several orders into a single object (for example, several orders for parts required to make a single finish good product, or perhaps several finish good products for a single customer). Manufacturing orders can be linked together by creating successor MO relationships which act as a scheduling constraint to ensure that the work for one MO completes before its successor is allowed to start. MOs can also run concurrently with their predecessor by using overlapping MO configuration logic.

Alternate Paths: Alternate Paths indicate the path followed through the shop to produce a product by specifying precedence relationships between operations. Each manufacturing order has one or more alternate paths.

Path Nodes: Each alternate path comprises one or more Nodes that specify an operation and one or more successor operations, if applicable.

Operation: An Operation is a single processing steps of a manufacturing order. Each manufacturing order contains one or more operations. Operations can be connected by establishing predecessor-successor relationships using the alternate path of the manufacturing order. Operations specify the Cycle Time, Setup Time, Expected Yield, Resource Requirements, Material Requirements, etc. 

Resource Requirements: Specifies the number of production resources that are required to operate. Each operation must have at least one resource requirement, considered the primary requirement. Requirements for additional resources can be configured to help the primary resource and may be configured to help for the entire duration of the operation or for only a portion of the primary requirements work (for example, only during setup or only during cycle time, etc).

Capability Requirements: Specifies the required capabilities of each resource requirement. A capability is a type of work that can be performed. Each resource is assigned various capabilities that it is capable of performing. Each resource requirement must have at least one capability requirement. When two or more capability requirements are defined on a resource requirement, PlanetTogether must find a resource which has each of the required capabilities assigned to it in order to schedule the resource requirement.

Material Requirements: Specifies the materials needed to perform the operation (effectively its Bill of Materials). Material requirements can be configured as scheduling constraints to prevent operations from scheduling or starting before the material is available.

Products: Specifies the product(s) produced by the operation. 

Activities: An Activity is the duration of work scheduled on the resource(s) defined by the Operation's Resource Requirements. It uses resource capacity and has a defined start and end date. An Operation has only one activity unless the work has been split into multiple parts, where each activity schedules a portion of the operation's required production. Activities specify the Production Status, Reported Quantity, Reported Time, etc. 

Resource Usage (Blocks): Resource Usage Blocks are the time reserved on a resource to perform a single activity. Multiple blocks may belong to a single activity, based on the operation's Resource Requirements. Blocks are seen as rectangles on the Gantt Chart. Each activity has one block for each resource requirement in operation.

Successor Manufacturing Orders: Successor Manufacturing Orders are manufacturing orders from either the same or different job that are constrained from scheduling until their predecessor manufacturing orders have finished.

See Also

Jobs Board

Job Details Dialog

Activities Board

Gantt Board</div>
        </section>
      
        <section class="article" id="article-230-stock-materials-bill-of-materials">
          <h3 class="article-title">Stock Materials (Bill of Materials)</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/stock-material-requirements" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Stock Material Requirements, often referred to as the Bill of Materials (BOM), specify the materials needed for an operation (processing step) within a job. These requirements are essential for production planning and can be configured to act as a constraint during the scheduling process. A single job operation can be configured to require one or more stock material requirements. Each Stock Material Requirement details the name and unique ID of the required item as well as the quantity needed.

All demands specified as Stock Material Requirements are tracked in inventory and can be visualized in the Inventory Plot tile of the Inventory Plan Board. The Materials Board grid provides a granular, operation-level view of every material requirement that is scheduled to be consumed, showing the material name, required quantity, the job that needs it, and key dates and other data like when the material is needed and when it is projected to be available.

Data Object Management

Stock Material Requirements are created manually or imported as data objects. 

Stock Material Requirements: Define the materials needed for an operation (processing step) within a job.

Operations: Job operations define processing steps of a manufacturing order. Each manufacturing order contains one or more operations.

Data Import

Stock Material Requirements are imported via Material Mappings logic

Operation objects are imported via Resource Operation Mappings logic

Manual Creation

Stock Material Requirements can be created and modified from the Stock Materials tab of any Operation within the Job Details dialog.

Operations can be created and modified by creating or editing a Job from the Jobs Board. Operations are created and modified from the Job Details Dialog. 

See Also

Job Structure

Material Mappings 

Resource Operation Mappings

Job Details Dialog</div>
        </section>
      <h2 id="cat-concepts-manual-scheduling" class="category-header">Concepts &gt; Manual Scheduling</h2>
        <section class="article" id="article-345-compress-the-schedule">
          <h3 class="article-title">Compress the Schedule</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/compress-the-schedule" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

Compress Idle Time

JIT Compress

Compress Idle Time

Key Concept

This feature removes idle time in the schedule by "compressing" all unanchored activities to schedule to start earlier on their currently scheduled resource(s) without changing their sequence or violating any constraints. This effectively fills in gaps of online resource capacity between scheduled operations. 

Options

Compress operations starting between: Use the two dropdowns provided to specify the scope of the compress to avoid impacting more scheduled operations than desired. Depending on the selection made in the first dropdown, the options that are made available in the second dropdown may be reduced to prevent an illogical range configuration.

Upon performing the Compress action, all operations which are scheduled to start within the specified points in time will be compressed to schedule as early as possible while preserving the current sequence of scheduled operations and while enforcing relevant constraints (material availability, release rules, etc.). Keep in mind that this may result in operations compressing to an earlier date and time than the specified "starting between" boundary settings which may impact the schedule in the frozen zone.

Start of the schedule: The start of the schedule clock will act as the earliest boundary that operations will be considered for compressing.

End of Frozen Span: The end of the frozen span can be set as the earliest or latest point in time that operations will be considered for compressing. If it's set as the earliest point in time, then no operations scheduled to start within the frozen span will be compressed. If it's set as the latest point in time, then any operation which is scheduled to start before the end of the frozen span and after the configured earliest time to consider will be considered for compressing.

End of Plant Stable Span: The end of the plant stable span can be set as the earliest or latest point in time that operations will be considered for compressing. If it's set as the earliest point in time, then no operations scheduled to start within the plant stable span will be compressed. If it's set as the latest point in time, then any operation which is scheduled to start before the end of the plant stable span and after the configured earliest time to consider will be considered for compressing.

End of the Short Term Span: The end of the Short Term Span can be set as the earliest or latest point in time that operations will be considered for compressing. If it's set as the earliest point in time, then no operations scheduled to start within the Short Term Span will be compressed. If it's set as the latest point in time, then any operation which is scheduled to start before the end of the short term span and after the configured earliest time to consider will be considered for compressing.

End of schedule: This option can only be set as the latest time to consider compressing. All operations which are scheduled to start later than the configured earliest time to consider will be considered for compressing.

Specific Date/Time: A specific date and time can be set as either the earliest or latest point in time that operations will be considered for compressing. When defining the earliest point in time, any operation that is scheduled to start later than the specified date and time will be considered for compressing. When defining the latest point in time, any operation that is scheduled to start earlier than the specified date and time and later than the configured earliest time to consider will be considered for compressing.

Compress Limit to Resources: Select which resources should be considered by the compress functionality. If no resources are selected, then all resources will be included in the compress process.

Release Rule to use: Specify the release rule to use in order to prevent operations from being compressed to a point where they are starting too early.

JIT with Resource HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the Head Start Span specified for each resource.

JIT with Global HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the number of JIT Slack days specified in the text input. This logic is applied to all resources.

Drum-Buffer-Rope: Each manufacturing order is released based on its DBR Release Date minus the JIT Slack Days specified in the text input.

Account for Offline Intervals: When enabled, the Head Start Span or global JIT Slack days will factor into the release date of each order in terms of the number of hours of online capacity on each resource. When disabled, the Head Start Span or global JIT Slack days will factor into the release date of each order simply in terms of calendar days.

More information on release rules can be found in the Optimize Settings page.

JIT Compress

Key Concept

The JIT (Just In Time) Compress function will move all unanchored scheduled activities out to a later date and time if they are currently scheduled to start before their JIT start date, or earlier in time if they are currently scheduled to start after their JIT start date and there is available capacity for it to schedule earlier. The sequence of all scheduled activities will remain intact while each eligible activity moves out to start as close as possible to its JIT start date without making it or other scheduled operations late.</div>
        </section>
      
        <section class="article" id="article-294-locking-and-anchoring">
          <h3 class="article-title">Locking and Anchoring</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/locking-and-anchoring" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Locking and Anchoring are manual scheduling features. Locking allows for activities to remain scheduled on a particular resource when optimization is performed. Anchoring allows for activities to remain scheduled at a point in time when optimization is performed. Activities which are not locked or anchored are free to move around the schedule during optimization according to the standard optimization procedures.

Jump to section:

Locking

How to Lock or Unlock an Activity

How to Visualized Locked Status

Anchoring

Anchor Drift

How to Anchor or Unanchor an Activity

How to Visualize Anchored Status

Locking

An individual Activity or all activities of a Job, Manufacturing Order or Operation may be Locked to its currently scheduled resource. This feature is useful when multiple eligible resources are available, but a scheduler wants a specific resource to be used for a particular job or operation. When an activity is locked and a user performs an Optimize Schedule command, the ensuing optimization will ensure that the locked activity remains scheduled on the resource that it is locked to. When the activity is only locked and not also anchored, it may schedule earlier or later in time than it was previously scheduled.

If an activity is locked, it may still be moved manually to a different resource via drag/drop in the Gantt, or from the Activities board. After the move is complete, the activity will be locked to the newly scheduled resource. 

Note: Locking an Anchored activity may greatly restrict when an activity can schedule. Locking is a scheduling constraint, while Anchoring is not; an activity may still be eligible to schedule at dates later than its Anchor Date. Locking an anchored activity may increase the chance of the activity scheduling later than its anchor date as fewer resources are available. For more information, review the Anchor Drift section of this article.

How to Lock or Unlock an Activity

Automatic Locking

The Lock Move setting can be enabled in the Move Settings section of User Settings so that all activities which are manually moved via drag/drop in the Gantt or from the Activities board will be locked to the destination resource.

This may also be toggled on/off from the Gantt board Options menu 

The Lock Activities scheduled to start within the Frozen Zone can be enabled in the Scheduling Options section of System Settings so that all activities which schedule inside of the Department Frozen Span will automatically be locked to their currently scheduled resource.

Manual Locking and Unlocking

From the Gantt, right-click any scheduled activity block and click or hover over the Lock to current Resource option to expand an additional menu. From the expanded menu, select to lock all activities of a Job, Manufacturing Order, or Operation, or choose to only lock the selected Activity.

If the selected activity is already locked, the menu will reflect unlocking options rather than locking.

Job: Lock all scheduled Activities of the Job(s) associated with the selected Activity(ies) to their currently scheduled Resource(s).

Manufacturing Order: Lock all scheduled Activities of the Manufacturing Order(s) associated with the selected Activity(ies) to their currently scheduled Resource(s).

Operation: Lock all scheduled Activities of the Operation(s) associated with the selected Activity(ies) to their currently scheduled Resource(s).

Activity (All Resources): Lock the selected Activity(ies) to all Resources that they are currently scheduled on (applicable to Activities with one or more Helper Resource requirements).

Activity (This Resource Only): Lock the selected Activity(ies) scheduled on the Resource where the selected Activity(ies) are scheduled (Helper Resource requirements may not be locked to their scheduled Resource when using this option).

From the Jobs board, all activities of jobs can be locked by selecting one or more grid rows, then selecting the button from the Job Actions tile, or by right-clicking any of the selected grid rows and selecting the option.

If the selected job is already locked, the menu option will reflect Unlock rather than Lock.

From the Activities board, users have options to lock all activities of a Job, Manufacturing Order, or Operation. Select one or more grid rows from the Activity Scheduling (Primary) grid, then select one of the Lock buttons from the Activity Actions tile, or right-click one of the selected grid rows and expand the Lock to current Resource menu and select one of the options from the menu.

If the selected activity is already locked, the menu will reflect unlocking options rather than locking.

How to Visualize the Locked Status

Users can see which activities are locked from various software boards and tiles.

Gantt Board

From the Gantt, each locked activity's block will have a thick purple border across the top. It's also possible to optionally add the Locked/Unlocked status text to any segment's label text.

Jobs Board

From the Jobs board grid, the Locked column can be displayed to indicate whether the entire job is locked, unlocked, or partially locked (only some activities or operations of the job are locked). The Resource Names column might also be helpful to see which resource(s) the job is locked to.

Job Details Dialog

The Locked status and current resource can be found in two of the grids of the Job Details dialog:

Activities Board

Each of the Activity Scheduling (Primary) and Activity Scheduling (Secondary) tile grids from the Activities board have related columns which can be exposed:

Job Locked

MO Locked

Operation Locked

Activity Locked

Anchoring

An individual Activity or all activities of a Job, Manufacturing Order or Operation may be Anchored to its currently scheduled point in time. When an activity is anchored and a user performs an Optimize Schedule command, the ensuing optimization will ensure that the anchored activity remains scheduled as close as possible to its anchored date. Anchored activities are not released to schedule before their anchor date.

If an anchored activity is manually moved or expedited, it will be re-anchored to its new scheduled start date.

Anchor Drift

An anchor date is not a hard scheduling constraint. It does prevent the activity from scheduling earlier than the anchor date, but not later. It's possible that the anchored activity may move out to a later date and time as optimization regenerates the schedule if the optimizer finds available capacity before the anchored activity where another released and eligible activity can schedule. When this occurs, the newly scheduled activity may run long enough that it has to push the anchored activity to schedule later so that the new activity can complete. This movement of an anchored activity is referred to as "Anchor Drift". 

If an anchored activity drifts during optimization, then subsequent optimizations will continue to try to schedule the activity back to its anchored date to prevent it from drifting out too far.

Anchor drift can be visualized in the Gantt and in the Activities board Activity Scheduling grids.

The more resource requirements an activity requires, the larger the drift is likely to be. This is because it will be harder to find a time when all required resources are simultaneously available to start the activity. For more information, see: Helper Resources.

How to Anchor or Unanchor an Activity

Automatic Anchoring

The Anchor Move setting can be enabled in the Move Settings section of User Settings so that all activities which are manually moved via drag/drop in the Gantt or from the Activities board will be anchored to the newly updated scheduled start date.

This may also be toggled on/off from the Gantt board Options menu 

The Anchor Activities scheduled to start within the Frozen Zone can be enabled in the Scheduling Options section of System Settings so that all activities which schedule inside of the Department Frozen Span will automatically be anchored to their currently scheduled start date.

Manual Anchoring and Unanchoring

From the Gantt, right-click any scheduled activity block and click or hover over the Anchor in Time option to expand an additional menu. From the expanded menu, select to anchor all activities of the Job and supplying Manufacturing Orders, the Manufacturing Orders only, the Operation, or only the selected Activity.

If the selected activity is already anchored, the menu will reflect Unanchor options rather than anchor.

Job and Supplying Manufacturing Orders: Anchor all Activities of all Jobs and their supplying Manufacturing Orders associated with the selected Activity(ies) to their currently scheduled start date.

Manufacturing Orders: Anchor all Activities of all Manufacturing Orders associated with the selected Activity(ies) to their currently scheduled start date.

Operation: Anchor all Activities of the Operation(s) associated with the selected Activity(ies) to their currently scheduled start date.

Activity: Anchor the selected Activity(ies) to their currently scheduled start date.

From the Jobs board, all activities of jobs can be anchored by selecting one or more grid rows, then selecting the button from the Job Actions tile, or by right-clicking any of the selected grid rows and selecting the option.

If the selected job is already anchored, the menu option will reflect Unanchor rather than Anchor.

From the Activities board, users have options to anchor all activities of a Job and its supplying Manufacturing Orders, associated Manufacturing Orders only, only the Operation, or only the Activity. Select one or more grid rows from the Activity Scheduling (Primary) grid, then select one of the Anchor buttons from the Activity Actions tile, or right-click one of the selected grid rows and expand the Anchor in Time menu and select one of the options from the menu.

If the selected activity is already anchored, the menu will reflect Unanchor options rather than anchor.

How to Visualize the Anchored Status

Users can see which activities are anchored from various software boards and tiles.

Gantt Board

From the Gantt, each anchored activity's block will have a thick royal blue vertical border across the left side. It's also possible to optionally add the Anchored/Free status text to any segment's label text.

For Activities that have drifted, the royal blue left border is replaced by a yellow border if the drift is within the same day, or orange if the activity drifts a full day or more. 

Jobs Board

From the Jobs board grid, the Anchored column can be displayed to indicate whether the entire job is anchored, free (unanchored), or partially anchored (only some activities or operations of the job are anchored). 

Job Details Dialog

The Anchored status and current Anchored Start Date and Anchor Drift Hours can be found in the Activities grid on the Operation Status tab of the Job Details dialog:

Activities Board

Each of the Activity Scheduling (Primary) and Activity Scheduling (Secondary) tile grids from the Activities board have related columns which can be exposed:

Job Anchored

MO Anchored

Operation Anchored

Activity Anchored

Activity Anchor Date

Activity Anchor Drift

See Also

Gantt Board

Jobs Board

Activities Board

System Settings

User Settings

Resource Capacity

Helper Resources</div>
        </section>
      
        <section class="article" id="article-279-splitting-and-joining-jobs-manufacturing-orders-an">
          <h3 class="article-title">Splitting and Joining Jobs, Manufacturing Orders, and Operations</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/splitting" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Manufacturing Orders and Operations occasionally need to be split into multiple Manufacturing Orders or Operations with smaller quantities. For example, manufacturing orders may need to be split when a partial shipment is made to a customer when there isn't enough capacity to finish the full order in time. In addition, operations may need to be split among multiple eligible resources so that the order is completed in one shift or one day. Splits can also be useful when different production resources are used to produce parts of the full order. Operations are often split to complete them faster as split activities can be scheduled in parallel, in sequence, on the same resource, or multiple resources, resulting in a shorter lead-time for the operation. 

There may be other times when consecutively scheduled operations on a resource are producing the same item and it may be desirable for them to be joined together as one.

Splitting and joining can be done from the Gantt by right-clicking an activity block, selecting Splitting, and then selecting which level of the selected block should be split or joined.

Jump to section:

System Settings

Split a Job

Split a Manufacturing Order

Split an Operation

Join Job or Manufacturing Order

System Settings

Manual split capabilities can be enabled and disabled in the Scheduling Options section of System Settings.

Split Operation: When enabled, operations can be split.

Split Job: When enabled, jobs can be split.

Split MO: When enabled, manufacturing orders can be split.

Join: When enabled, jobs and manufacturing orders can be joined together to create a merged job or manufacturing order.

Expedite after Split: When enabled, MOs, Jobs, or Operations are automatically expedited after they are split.

Split a Job

A Job may be split into two jobs based on the number of cycles required of the selected operation. A job may only be split if it has only one associated manufacturing order. Otherwise, each MO must be split separately. A job which has previously been split may be split again, if desired.

To split a job, right-click a scheduled activity block in the Gantt and choose the Job option from the Splitting menu. From the resulting popup dialog, enter the number of cycles per each split portion of the job, then click the Split Job button:

The Split Job popup dialog allows users to input the number of cycles for the first split. Then, the remaining cycles will be calculated to become the number of cycles of the second job. Splitting a job has the following outcomes:

A new job is created with a name automatically generated from the original job's name.

Each operation of the job is split at the same ratio defined in the Split Job popup dialog of the selected operation.

If an operation in the original job is finished, the corresponding operation in the new job will also be finished. 

Note: 

During imports, if a job has been split but the split jobs are not included in the import, they are still preserved to protect the changes made internally in PlanetTogether without requiring the split jobs to be imported. If the quantity or routing of the imported job is different from the original, the job will be updated to the new quantity and routing, and any unfinished jobs will be removed. 

Split a Manufacturing Order

A Manufacturing Order may be split into two based on the number of cycles required of the selected operation. An MO which has previously been split may be split again, if desired.

To split a MO, right-click a scheduled activity block in the Gantt and choose the Manufacturing Order option from the Splitting menu. From the resulting popup dialog, enter the number of cycles per each split portion of the MO, then click the Split MO button:

The Split Manufacturing Order popup dialog allows users to input the number of cycles for the first split. Then, the remaining cycles will be calculated to become the number of cycles of the second MO. Splitting a manufacturing order has the following outcomes:

A new MO is created within the same job with a name automatically generated from the original MO's name.

Each operation of the MO is split at the same ratio defined in the Split Manufacturing Order popup dialog of the selected operation.

If an operation in the original MO is finished, the corresponding operation in the new MO will also be finished. 

The split MOs can be visualized in the Manufacturing Orders tab of the grid view of the Job Details Dialog. Each MO's required quantity are split according to the ratio of split cycles to total number of cycles as defined in the Split Manufacturing Order popup dialog. In addition, the original manufacturing order will have two new fields: 

Split Count: The number of manufacturing orders split from the manufacturing order.

Deep Split Count: The number of manufacturing orders from the manufacturing order or its splits. 

MOs generated by splitting have their Split field set to true in the job dialog to indicate that they are split.

Note: 

During imports, if a manufacturing order has already been split, but the split MO's are not included in the import, they are still preserved to protect the changes made internally in PlanetTogether without requiring the split MO's to be imported. If the quantity or routing of the imported manufacturing order is different from the original, the manufacturing order will be updated to the new quantity and routing, and any unfinished MO's will be removed. 

Split an Operation

To split an Operation among multiple resources, right-click on an activity block on the Gantt and choose the Operation option from the Splitting menu. This will open the Operation Splitting dialog:

This dialog is used to split an operation into multiple activities or to un-split an operation, consolidating split activities into one. When an operation is split, the Remaining Finish Quantity is divided among the activities that make up the split operation. The way these quantities are divided is determined by the options selected in operation splitting dialog.

Split off a % of the remaining finish qty: The specified percentage of the remaining quantity of all operation activities is split off to create a total of 2 activities: one with the specified percentage and the other with the remainder. 1 to 99% of the operation can be split off. 

Split into this number of activities: The operation is split into the specified number of activities, each receiving an equal portion of the required quantity. For example, specifying the number of "1" will un-split the activity. The maximum number of splits is 500 to prevent accidentally large numbers from disrupting the schedule. Note: if the option "Split into whole number quantities" is checked, then the maximum split count is limited to the current required quantity of the operation.

Split so that all activities are less than. First, the operation is split using the maximum duration to determine how many activities to split across. Then, the maximum number of cycles that can be performed within the specified duration is calculated.

Note: the resulting activities may be longer than the specified maximum duration when considering the setup and post-processing time, as only the standard run span will be less than the duration specified. In addition, resources may have values set for the cycle efficiency multipliers, which increase the standard run span so that the scheduled run span would exceed the maximum duration specified.

Split among the eligible resources: The operation is split into the specified total number of eligible resources, with each activity receiving an even portion of the required quantity. Thus, the number of activities is limited by the number of eligible resources that can operate.

Split into whole number quantities: If checked, quantities that are split off to create new activities are always integer (non-decimal) values. For example, if the remaining quantity was 10.5 and you wanted to split the operation into 2 activities, this would result in the split-off activity having a required finish quantity of 5. In contrast, the original activity would have a remaining quantity of 5.5. If this option were unchecked, then the same split would result in both activities having quantities of 25.25. 

Buttons

Split: Performs the split as specified by the current dialog settings. Note: If an operation is already split, it will be un-split first and then split again.

Un-Split: Deletes all but the original activity, moving all required finish quantities and reported values to the remaining activity. 

Join Job or Manufacturing Order

Operations of different manufacturing orders may be joined with the one(s) scheduled immediately to their left (there can be a gap in the schedule between them, but no other operations may be scheduled between them). Only a single Join action between two manufacturing orders may be performed at a time (although operations which have been joined already may again be joined with other adjacent operations, if desired).

Two operations are considered eligible to join together if they are both scheduled on the same resource and are both producing the same product into the same warehouse and are either each part of separate jobs, or are each part of an already split manufacturing order of the same job. Two manufacturing orders of the same job are not eligible to be joined together unless they are the result of an already split MO.

In order to join two MOs together, right-click the desired downstream (rightmost) activity block in the Gantt and choose the Join Job or Manufacturing Order option from the Splitting menu. Two MOs cannot be joined if the upstream activity block is selected.

For manufacturing orders with multiple operations, a Join initiated on one operation of one resource will join together all operations of that MO with all operations of the earlier adjacent scheduled operation's MO.

When two adjacent MOs are merged into one, the downstream MO (the one scheduled later) is merged into the upstream MO and is effectively removed from the data model. When joining two MOs from different jobs, this results in the downstream job being deleted, leaving behind only the upstream job. The output quantity of the resulting joined MO is the combined total of each of the joined MOs.

Multi-operation selection

Selecting two or more operations and using the Join feature gets a bit unpredictable. For example, the system will choose which two operations to join together depending on the order in which the operations are selected when using Ctrl+Click to select multiple (it will attempt to join the last one which was selected, regardless of which one was right-clicked or which one is actually downstream). If using Shift+Drag to select, then it seems a bit random which ones it might join together. The system also doesn't allow the user to Join a group of operations twice without un-selecting and re-selecting them after the first Join completes.

For these reasons, it's advisable to only select one operation at a time to Join with its earlier adjacent scheduled MO.

See Also

Gantt Board

Job Structure

System Settings</div>
        </section>
      <h2 id="cat-concepts-modeling-techniques" class="category-header">Concepts &gt; Modeling Techniques</h2>
        <section class="article" id="article-348-multi-plant-data-model">
          <h3 class="article-title">Multi-Plant Data Model</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/multi-plant-data-model" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Generally speaking, a Plant is meant to represent an entire facility or location where production occurs. It is usually synonymous with a single physical factory. However, in PlanetTogether, a Plant consists of any number of Departments that contain any number of Resources used to produce goods.

PlanetTogether allows plants which are interdependent on one another to be modeled together in order to take advantage of Multi-Plant Scheduling features. The multi-plant system allows for collaboration between plants whose processes are interconnected.

When to Consider a Multi-Plant Model

The following interdependencies between plants might motivate an organization to consider using PlanetTogether's multi-plant model:

Certain orders can be fulfilled by one plant or another, depending on which has capacity.

Some products require some intermediate components to be manufactured in one site, then transferred to another site for completion.

The plants are physically close enough and equally capable that some operations of some orders may run in one plant and other operations of the same order in another nearby facility.

When two or more plants share a warehouse and each needs to consider inventory levels when scheduling orders which depend on common materials.

Multi-Plant Scheduling Features

Can Span Plants

The job and manufacturing order Can Span Plants properties must be set in order to allow operations of a single manufacturing order to schedule in different plants. If a Job's Can Span Plants property is set to True, then all of its manufacturing orders are eligible to be scheduled across different plants.

However, each operation within the manufacturing order will be scheduled in the same plant unless the manufacturing order's Can Span Plants property is also set to True. 

Note:

Individual operations cannot span plants unless the operation has been split. The application does not currently support, for example, a primary resource requirement to be scheduled in one plant while a helper resource requirement is scheduled in another plant. 

Lock Manufacturing Order to a Plant

A manufacturing order can be locked to a plant to ensure that it is started and finished within that plant. A common reason for locking a manufacturing order to a plant is proximity to the customer who ordered the product. If a manufacturing order is locked to a plant, every operation belonging to the manufacturing order will also be locked to the specified plant. 

Schedule Optimization

Single-pass optimization via the Schedule menu option generates a synchronized schedule across all plants. Plants can also be optimized individually using the Optimize Plant dropdown, if desired.

Data Integration

When multiple plants are modeled in the same instance workspace, all import data mappings are shared among all plants. When data is published to the publish database, data from all plants are published simultaneously unless the option to Ask which resources to publish when publishing is enabled which will prompt the user to select which resources they wish to publish. This will allow them to select resources from a single plant to only publish their schedule, if desired.

Users and Data Visibility

Users can see data from multiple plants in one session from the Gantt, various board grids, and the Metrics Board. User permissions and plant permissions can dictate whether individual users are able to schedule in one plant or both plants.

Each user may hide or show various resources from various plants, as needed, in their Gantt view by creating custom Gantt layout configurations from User Settings.

Drag-and-drop scheduling in the Gantt can occur within a plant as well as between plants.

Software License Considerations

The number of plants that can exist in a single data model is limited at the software license level. Each license is typically allowed a single plant unless it was negotiated to allow for more during the sales cycle. Contact a PlanetTogether sales representative or the PlanetTogether Support team to assist with resolving any license-related issues.

Limitations of Multi-Plant Scheduling

Performance can be impaired with high data volumes as plant data is combined.

Data imports are generally performed across all plants (system-wide). 

Data access permission flexibility is limited. Plant permissions can be set so that a user can be a viewer or editor per plant.

The system settings are shared across all plants, which creates less flexibility across multiple plants.</div>
        </section>
      <h2 id="cat-concepts-planning" class="category-header">Concepts &gt; Planning</h2>
        <section class="article" id="article-250-mps-mrp-optimize-plan-settings">
          <h3 class="article-title">MPS/MRP Optimize Plan Settings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/mps-mrp-optimize-plan-settings" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, Material Requirements Planning (MRP) is an automated process that compares the demand for materials and finished goods to the existing on-hand inventories and planned supply to create jobs and purchase orders to satisfy those demands which cannot be satisfied by existing inventory. The MPS/MRP Optimize Plan feature can be configured to create jobs and/or purchase orders and then schedule them according to the configured Optimize Settings and the rules defined in the selected Sequencing Plan(s).

Be conscious of whether you're using Shared Optimize Settings or Personal Optimize Settings, especially if working in a collaborative environment with multiple schedulers.

Switching between Shared or Personal settings is done in the User Preferences dialog.

Quickly visualize whether Shared or Personal settings are in use by expanding the Schedule dropdown from the main toolbar and observing the icon next to each of the setting headers. If the icon is the bust of a single person , then Personal settings are enabled. If the icon reflects the busts of 3 people , then Shared settings are enabled.

For more information, see the User Preferences section of the User Management page.

Jump to section:

MPS/MRP Settings

Preserve jobs during generation

Purchase Order rule

Access MPS/MRP Optimize Plan Settings from any of the following:

The Plan dropdown from the Main Toolbar

The MPS/MRP Settings section of System Settings (if using Shared settings)

The MPS/MRP Settings section of User Settings (if using Personal settings)

MPS/MRP Settings

MRP Start Type: Specifies where in the schedule MRP planning should begin based on the demand signal's need date.

FirstDemand: Plan all demands regardless of the need date.

Clock: Plan demands whose need date is equal to or later than the current schedule clock.

ShortTerm: Plan demands whose need date is no earlier than the end of the Short Term Span.

SpecificDate: Choose a date and time to begin planning. Use the MRP Start Date to set the date and time.

MRP Start Date: This input becomes active when MRP Start Type is set to the SpecificDate option.

MPS/MRP Cutoff Duration: Only inventory requirements for a specified duration will be considered to generate jobs and/or purchase orders during the MRP process. Shorter-term MRP Cutoff dates are preferred in situations where demands further in the future do not need to be included in the schedule. The cut-off duration options are:

Short-Term: The system will only plan for demand signals that can be satisfied within the Short-Term Span defined in the System Settings.

Planning Horizon: The system will plan for demand signals that can be satisfied within the Planning Horizon defined in the System Settings.

No Cutoff: The system will plan for all demand signals in the data model. 

Specific Duration: The system will plan for demand signals that can be satisfied within the duration selected by the user.

Note: When the clock is advanced, the MRP Cutoff Date is extended by an amount of time equal to the clock advance duration to preserve the "horizon." If Personalized Optimize Settings are used, then these are not altered during clock advances.

Net Change: When enabled, the system will only plan for demand signals that have changed since the last MPS/MRP Optimize Plan was executed. This reduces the time required for MRP to process and preserve jobs and purchase orders previously created for inventory plans that have not changed since the last MRP run. Inventories for items are excluded from the Net Change MRP run unless one or more of the following have changed for that item or one of its parent items:

Sales Orders

Forecasts

Transfer Orders

On-Hand Inventory

Safety Stock

Safety Stock Priority

Jobs created, deleted, or changed in quantity (producing or consuming the item) 

JIT Compress: When enabled, the system will execute JIT Compress after each MPS/MRP Optimize Plan operation and cause MRP to generate lower-level supplies based on the JIT schedule of the jobs that consume them.

Use JIT Dates: When enabled, demand signals from preserved jobs will use the jobs' JIT Start Date as the Demand Need Date. So, if a new job is created by MRP to satisfy a demand from a preserved job, the new job's Need Date will equal that of the preserved job's JIT Start Date. When disabled, the demand need date is determined by the scheduled start date of the preserved job.

Source from Firm Orders: When enabled, demands can be sourced from Firm and Released orders, even if the material may not be available to satisfy the demand on time.

Set sub-job Need Dates: Sub-jobs are jobs that are created to fulfill material requirements for successor jobs. The need dates for those jobs can be updated according to where the successor/parent job schedules using the following options:

Use System Options: The Set Sub-Job Need Dates value set in the Scheduling Options section of the System Settings will dictate the behavior.

To earlier of JIT and scheduled start date: The need date of the sub-job is set to the earlier of its JIT start date or its parent job's scheduled start date.

To JIT date: The need date of the sub-job is set to the JIT start date of its parent job.

To start date: The need date of the sub-job is set to the scheduled start date of its parent job. 

To bottlenecked Operation start date: The need date of the sub-job is set to the start date of whichever operation is causing a bottleneck.

To overlap supply sources: The need date of the sub-job is set to the end date of the parent job minus the amount of time required for the sub-job to make its first transfer of product to inventory.

Consume Forecasts: Forecast consumption will reduce (consume) forecast demand as sales orders are entered to avoid duplicating demand. When enabled, running MRP will cause forecasts to be consumed by Sales Orders before the main MRP logic is executed which will prevent MRP from creating jobs to satisfy both Sales Order PLUS the full forecasted demand.

Generate Jobs to satisfy demand and material requirements: When enabled, MPS/MRP Optimize Plan will create all jobs necessary to fulfill all demand signals.

Preserve jobs during generation

There are benefits to preserving some stability in production and purchase plans in most situations. For example, once jobs are released to the shop floor, it can be problematic to have them be deleted by MRP and replaced with new jobs. In addition, once a purchase order has been placed to a vendor, it may not be possible to change or cancel it. 

Toggle any of the available switches to preserve jobs with certain property values during MRP so that they will not be deleted by the system when generating new jobs to satisfy demand and material requirements:

Released: Preserve jobs whose Commitment is Released.

Planned: Preserve jobs whose Commitment is Planned.

Firm: Preserve jobs whose Commitment is Firm

Estimate: Preserve jobs whose Commitment is Estimate.

Starting in the Plant Stable: Preserve jobs which have any activity scheduled to start within the Plant Stable Span.

Previously Generated Jobs: Preserve jobs which were previously generated by MRP.

Anchored: Preserve jobs which have any activity anchored in time.

Locked: Preserve jobs which have any activity locked to a resource.

Printed: Preserve jobs whose Printed flag is True.

CTP: Preserve jobs which were created from a CTP (Capable To Promise) estimate.

Note: The following jobs are always preserved:

Jobs which are Started or Running

Jobs whose Do Not Delete flag is True

When running a Net Change MRP, jobs which produce inventories are not included in the Net Change MRP process.

Purchase Orders with status Firm or Closed.

Purchase Order rule

Generate Purchase Orders to satisfy demand and material requirements: When enabled, MRP will create purchase orders to buy materials as needed based on the item and inventory planning fields.

See Also

MPS/MRP Planning

Optimize Settings</div>
        </section>
      
        <section class="article" id="article-302-mps-mrp-planning">
          <h3 class="article-title">MPS/MRP Planning</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/mps-mrp-planning" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, MRP (Material Requirements Planning) is an automated process that compares the demand for materials and finished goods to the on-hand and planned supply to generate planned jobs and/or purchase orders which can help to plan to satisfy unmet demands.

Jump to section:

When to use MRP

MRP Data Requirements

MRP Settings

Batching

The MRP Process

When to use MRP

The MRP Process is often performed by a business' ERP system. In this case, PlanetTogether is not used for this process, and jobs and purchase orders are imported from their external system. However, there may be times where performing MRP in PlanetTogether rather than the ERP system is preferable. Here are some points to consider when deciding which platform is best suited to perform MRP:

How well is the ERP system's MRP function working for your business? If the current MRP process is working well for your business, it is probably better to continue using it as converting to a new MRP process requires an additional effort that may not be worth the time or cost. However, if the current process does not work, it would be preferable to use PlanetTogether to perform the MRP process.

Do the jobs and/or purchase orders created in PlanetTogether need to be created in the ERP system as well? If yes, then there are two options to include the jobs/purchase orders in the ERP system: (1) manually enter them based on the suggestions from PlanetTogether or (2) import them from PlanetTogether. Option (1) is acceptable for small order volumes, but it is highly error-prone and time-consuming for large order volumes. Option (2) is usually preferred since it reduces time and the error risk of manual entry; however, some ERP systems do not have the ability to import this type of data.

Does the MRP process in PlanetTogether offer benefits over the ERP-based or manual processes? Some of the common benefits of using PlanetTogether's MRP are (1) the simplicity of a "single-click" process than plans materials and resources in a cohesive system, (2) the speed of the MRP process performed by PlanetTogether, and (3) the plan that results from planning material and capacity together, rather than creating an infinite capacity material plan in an ERP system and then planning finite capacity in PlanetTogether.

MRP Data Requirements

To run MRP in PlanetTogether, the following data elements are required to be used as inputs:

Warehouse(s). One or more warehouses must exist in the data model.

Item(s). One or more items must exist in the data model.

Inventory(ies). One or more inventories must exist in the data model. Inventories which must be processed by MRP need to have some properties defined:

MrpProcessing: This specifies whether MRP should generate Purchase Orders or Jobs to supply the Item.

Set this to GenerateJobs for items whose demands need jobs generated. The assigned TemplateJobExternalId routing template will be used to generate jobs to satisfy demands.

Set this to GeneratePurchaseOrders for items whose demands need purchase orders generated. Assign a PurchaseOrderSupplyStorageAreaExternalId to define which storage area the purchase orders should be stored in.

ForecastConsumption is an optional property. This specifies how MRP should consume forecasts before the MRP logic is executed. For more information, see: Inventory Mappings.

Routing Template(s). Any item whose demands need jobs generated to satisfy must have an associated routing template which produces the item. A routing template (or job template) is best configured to be the minimum amount of time and material in order to produce the minimum amount of the product or item. When MRP generates jobs, it scales up required quantities and product output quantities according to the values defined in the template and the required quantity of the demand signals. The routing template must contain at least one manufacturing order, one operation, and produce a product.

If using MRP to generate supplies for dependent demand (materials used by jobs), then material requirements are required in job operations.

Using MRP to generate supplies for independent demand requires preserved jobs, sales orders, forecasts, and/or inventory safety stock to represent the demand.

MRP Settings

See the MPS/MRP Optimize Plan Settings page for detailed information on the various settings which can be customized to achieve the most desirable behavior.

Batching

MRP can be configured to support the batching of multiple demand signals into fewer supplying jobs or purchases. In order to enable batching, each of the four Item properties must be given a value greater than zero:

Batch Size: The incremental size of each batch that can be produced or purchased. Jobs and purchase orders must be in integer multiples of this value.

Batch Window: The amount of time from the need date of the first demand that other demands should be considered for batching. 

Minimum Order Quantity: The minimum job or purchase order quantity for each MRP-generated supply for the item.

Maximum Order Quantity: The maximum job or purchase order quantity for each MRP-generated supply for the item.

During MRP job and purchase order generation, demands will be batched together based on the criteria defined in the four properties noted above.

Portions of demand signals can be batched into a job or purchase order in order to stay within the item's Maximum Order Quantity constraint. The remainder of partially batched demands will become part of another batch.

Batch Rounding

After all adjustments fitting into a batch are calculated, batch rounding occurs to round up the job's quantity to an integer multiple of the item's batch size. If the resulting batched total quantity is less than the item's Minimum Order Quantity, the batched quantity will round up to meet the Minimum Order Qty requirement. Rounding notes are added to the job, and any rounded-up quantity can be used for further allocation.

The MRP Process

When using the MPS/MRP Optimize feature, the system will create jobs and/or purchase orders and then schedule them according to the optimization settings and sequencing plan(s) rules defined. Additional information on the MRP Optimization settings can be found here. 

The MRP Process steps include:

Jobs/POs are deleted: If generating jobs, all jobs not marked as "Preserved" in the MRP/MPS Settings are deleted. Likewise, all purchases to stocks which are neither Firm nor Closed are deleted if generating purchase orders.

MRP Notes are cleared: MRP notes from the previous MRP run are cleared from inventory records in all warehouses.

Material Constraints set to Non-Constraint: All scheduled jobs have their material requirement constraint type set to "Non-Constraint" to remain where they are in the MRP process if they are supplying jobs or purchase orders are deleted. 

Low-Level Codes are calculated: If generating jobs, Low-Level Codes are calculated in the following way:

Each item has its LLC initialized to -1.

A Level-Zero list is created using templates and is not used as materials for other templates. These items have their LLC set to zero.

Each level-zero item has its list of materials scanned to set the LLC of the materials used by it and its materials. The LLC of each item is increased if it is deeper in the level-zero item's BOM than all of the previous level-zero items analyzed so far.

Any item that still has its LLC set to -1 has its LLC set to one number higher than the highest LLC number.

Note: In versions 11.45.1 and later, the Job's Low-Level Code can be displayed in the Jobs View column.

Initial Optimization is performed: This creates a starting point with the current demands and supplies that have not been deleted.

If generating Jobs: The following occurs for each low-level code from zero to the maximum number:

Jobs are created at the current low-level code. This is done for each inventory that has it is MRP Processing set to "Generate Jobs" and has a template manufacturing order:

MRP Notes: The inventory's MRP Notes are set to "MRP Processed as Manufactured/JobTemplate Item: <timestamp>."

Inventory Adjustments up to the MRP Cutoff are used: An inventory adjustment is a decrease or an increase in the projected inventory based on a demand (sales order, forecast, job material requirement, transfer out) or a supply (job product, purchase to stock, transfer in). Negative and positive inventory adjustments up to the MRP Cutoff date are used.

Inventory is allocated: Any on-hand inventory above the Safety Stock is chronologically allocated to negative adjustments from the earliest to the latest. Partial allocations can also occur if there is not enough inventory to cover a single adjustment fully.

Un-allocated positive adjustments are allocated: Any unallocated positive adjustments (not safety stock jobs) are allocated to the remaining negative adjustments not covered by the on-hand inventory. If a positive adjustment is a job product allocated to one or more negative adjustments and is not released, then the job's need date is set to the first date on which the allocation occurs.

New Jobs are created to supply remaining negative adjustments: If there are remaining negative adjustments after allocating on-hand inventory, existing positive adjustments, or new/unscheduled/excluded/failed to schedule jobs, then a new job is created the following way:

Need Date: The job's need date is set to one of the following, depending on what is being supplied: Activity Scheduled Start Date, Sales Order Distribution Required Date, Forecast Shipment Required Date, or the Transfer Order Distribution Scheduled Ship Date. Note: The job's need date is not changed if its commitment is set to Release or Firm.

Priority: The job's priority is the priority of the sales order, forecast, or job that it was created for. If the adjustment was for a transfer order, the job's priority is set to "5".

Classification: The job's classification is set to sales order, forecast, or transfer order if the adjustment was one of these.

Name and External Id: The job's name and external Id are set to "MRP x," where x is the auto-incrementing numeric Id of the job.

Entry Method: The job's entry method is set to "MRP Generated."

Template and Flags: The job's template and Do Not Schedule flags are set to false.

Commitment: The job's commitment is set to "Planned."

Quantity: If the adjustment's remaining allocation quantity is less than 0.00005, it is increased to that minimum allowed value. Otherwise, the quantity of the first manufacturing order (with the lowest ID based on its creation sequence) is set to the adjustment's remaining allocation quantity. The manufacturing order's quantity is adjusted in the following way:

The MO's Required and Requested quantities are set to the new quantity.

A ratio of the new quantity to the MO Template Required Qty is calculated.

For every path in the MO and every operation in each path, the products, activities, and material requirements are adjusted to the new quantity. Note: rounding may occur here based on the scenario options precision settings.

Operation Attributes: The operation attributes are "rolled-up" into the job recursively as needed based on each item's setting for "RollupAttributesToParent." 

Warehouse: For each product of each operation in the job, the warehouse is set to the warehouse where the source negative adjustment occurs. Note: if the item in a product is not stocked in the adjustment's warehouse, then it is not changed from the original template value for the warehouse.

Batching: If an item is set up for Batching (when Batch Size, Batch Window, and MinOrderQty > 0 and MaxOrderQty >= MinOrderQty), then the following occurs to batch together multiple negative adjustments in one job:

Adjustments are batched chronologically into one job as long as the following are true:

The adjustment date/time is within the Batch Window (all Job Need Dates <= Adjustment DateTime < New Job Need Date + Item Batch Window)

The combined quantity of the resulting job is equal to or less than the item's Max Order Qty.

A portion of an adjustment can be batched into a job rather than the full adjustment quantity to stay within the item's MaxOrderQty constraint.

Batch Rounding: After all adjustments fitting into a batch are calculated, batch rounding occurs to round up the job's quantity to an integer multiple of the item's batch size. If the resulting batched total quantity is less than the item's MinOrderQty setting, the batched quantity will round up to meet the Min Order Qty requirement. Rounding notes are added to the job, and any rounded-up quantity can be used for further allocation.

Notes are added to each job to indicate the reasons for the jobs being created.

Safety Stock Requirement: If the inventory has a safety stock requirement greater than zero, then the following steps are taken:

Optimize: If new jobs were created, then a schedule optimization occurs to create an updated inventory plan.

A safety stock job is created if the on-hand inventory plus excess scheduled production is less than the safety stock.

Need Date: The job's need date is set to the PlanetTogether clock.

Priority: The job's priority is set to the inventory safety stock job priority.

Classification: The job's classification is set to "Safety Stock."

Operation Attributes: The operation attributes are "rolled-up" into the job recursively as needed based on each item's setting for "RollupAttributesToParent."

Warehouses: For each product of each operation in the job, the warehouse is set to the warehouse where the source negative adjustment occurs.

Auto-Splitting: Jobs are auto-split if the item's job auto-split quantity is greater than the job's first manufacturing order's required quantity. New manufacturing orders are created for the job by splitting off manufacturing orders with a JobAutoSplitQuantity until the JobAutoSplitQuantity is reached for the original manufacturing order. Notes are added to the new manufacturing orders to indicate Auto-Splitting created them. 

If any manufacturing order has a required quantity less than the item's Min Order Quantity, then:

If the quantity short is less than or equal to the item's Min Order Qty Roundup Limit, the manufacturing order's required quantity is increased to the Min Order Qty.

Otherwise, the job is marked as "Do Not Schedule," and notes are added to indicate that the required quantity is too low.

Material Requirements & Optimization: Material requirements are set to "Non-Constraint," Optimization is performed to schedule the newly generated jobs and update the resulting inventory plans.

If generating Purchase Orders:

Purchase to Stocks are generated in the following way for each warehouse and each inventory that has its MRP processing set to "Generate Purchase Orders":

MRP Notes: The inventory's MRP Notes are set to "MRP Processed as Purchased Item: <timestamp>."

Optimize: If job generation was not enabled in the optimize settings, then an optimize is performed here to reflect the optimize results on the purchase orders generation. This is, so the purchase order dates are based on the schedule after being optimized with the new settings.

Delete purchase orders: Any purchases to stocks that are not set to Firm or Closed are deleted.

Inventory Adjustments up to the MRP Cutoff are used.

Inventory is Allocated: Any on-hand inventory is allocated to negative adjustments. If an adjustment is within the lead time, then all on-hand inventory may be allocated to it. Only inventory above the safety stock may be allocated if an adjustment is outside the lead time. The rest is reserved for safety stock. Partial allocations are allowed.

Purchase To Stocks are created for the remaining adjustments to satisfy safety stock requirements:

Name and External Id: Are set to "MRP x," where x is the next numerically generated Id.

Qty Ordered: The quantity ordered is set to the quantity needed.

Required Date: The required date for the safety stock purchase order is set on the PlanetTogether clock.

Min Order Quantity is set the following way:

If the quantity short is less than or equal to the item's Min Order Quantity Roundup Limit, then the Purchase To Stock Quantity Ordered is set to the item's Min Order Quantity, and the purchase to stock notes are modified to indicate this.

If the quantity short is greater than the item's Min Order Quantity Roundup Limit, then the Purchase To Stock Quantity Ordered is set to the original quantity ordered plus the item's Min Order Qty Roundup Limit, and the purchase to stock notes are modified to indicate this.

Batch Rounding is performed.

Material Requirements returned to their original values: Material requirements that were changed to "Non-Constraint" are set back to their original values if new jobs and purchases to stocks were created. 

Optimization: a final optimization is performed to create a constrained and optimized schedule based on all information and constraints applied.

Warnings: If any warnings are needed due to data issues, then the warnings are shown in the user interface System Message window. 

Each job created during MRP now stores the original demands that led to the job's creation and shows both of these in the Job Dialog:

Original Demand: For level-zero jobs, these are the demands (i.e., sales orders, forecasts, etc.) that caused the job to be created. For level 1+ jobs, these are the original demands of the parent jobs at the time of the sub-job's creation.

Pegged Demands: These are the demands of jobs currently supplied by the job (through material relationships or successor manufacturing order relationships). 

Special Cases and Considerations:

If an item is specified as a material in a template, it is assigned the lowest Low-Level Code. This means that the item is planned after other levels and can potentially miss demand for itself.

If an item has multiple templates, then the template with the lowest Job ID (the first created) is used to set the Low-Level Codes for its inventories. 

See Also

MPS/MRP Optimize Plan Settings

Warehouse Mappings

Item Mappings

Inventory Mappings

Job Mappings

Material Mappings

Product Mappings

Forecast Mappings

Sales Order Mappings</div>
        </section>
      <h2 id="cat-concepts-publishing" class="category-header">Concepts &gt; Publishing</h2>
        <section class="article" id="article-323-export-and-publish-overview">
          <h3 class="article-title">Export and Publish Overview</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/export-publish-overview" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Data from any scenario within an instance workspace may be exported to various external sources. Data exports are primarily used for creating custom reports and updating external systems. The Exports can be invoked from the Publish menu in the user interface, or even programmatically from a custom program by submitting a Transmission to PlanetTogether requesting a Publish to occur.

Data can be exported to a primary SQL publish database, or it can be exported to an Analytics SQL database. The exported data in either case is the same and is exported in the same format, but the Analytics database can be used more strategically for reporting purposes while the primary publish destination might be configured to only retain the most recently published schedule.

Prerequisites

Publish and/or Analytics Database Creation

A SQL Server administrator must first create the Publish and/or Analytics export destination databases. It's recommended they follow the guidelines in the Standard Publish Database article to do so.

Instance Workspace Configuration

A PlanetTogether server administrator must first configure the instance workspace from the Instance Manager with database connection string information to connect to the instance workspace to the desired export destination database(s).

Export data to Publish or Analytics destinations

Publish options are available from the Publish menu in the main toolbar of the user interface:

Ask which Resources to Publish when publishing: When enabled, a popup dialog will appear each time a user clicks to Publish or Publish Analytics which allows them to select one or more resources whose schedule should be published. When disabled, the schedule data of all resources is published.

Publish objects dated within the next: Define the length of time from the start of the current PlanetTogether schedule clock that the publish logic should consider when publishing schedule data.

Scheduled jobs data will be published if their scheduled start date is within this time period.

Purchases to stock data (purchase orders) will be published if their scheduled receipt date is within this time period.

Sales order data will be published if their required available date is within this time period.

All objects without a date association are published (Plants, Departments, Resources, Customers, etc.).

Browse Publish Data: Open a popup dialog to preview the data that will be published. The data is presented in grid form where each SQL table is presented as a separate grid.

Publish: Initiate a data export to the configured Publish Destinations (from Publish Options). This will also simultaneously publish to the Analytics database if the publish option to Publish to Analytics Database is enabled.

Publish Analytics: Initiate a data export only to the configured Analytics database.

Detailed settings are available from the Publish Options section of System Settings:

See Also

Standard Publish Database

System Settings

Main Toolbar

Instance Manager</div>
        </section>
      <h2 id="cat-concepts-reporting" class="category-header">Concepts &gt; Reporting</h2>
        <section class="article" id="article-206-automatic-activity-reporting-and-finishing">
          <h3 class="article-title">Automatic Activity Reporting and Finishing</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/automatic-activity-reporting" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether allows users to automatically update the progress of activities as work is completed on the shop floor. Automatic activity reporting occurs whenever the clock is advanced beyond the start of a scheduled activity. Optionally, activities may also be configured to automatically finish if/when the clock is advanced beyond the scheduled end date of the activity.

There are two types of activity reporting: Quantity-Based Reporting which reports progress based solely on quantities completed, and Time-Based Reporting which reports progress based on both quantities and hours of work completed.

If a Time (Hours) or Quantity is reported, but the activity status is not set to "Finished", then the scheduled length of the activity block will be adjusted based on the reported values. 

Note: This feature is based on operation cycles. For any progress to be reported, one cycle must be completed. The amount of progress reported will be determined by the number of full cycles of the activity can be completed in the amount of time between the scheduled start date and the PlanetTogether schedule clock date after the clock advance completes.

Example:

Cycle Time = 1 Hour

Job = Scheduled for 3 Hours (i.e. 3 cycles)

Scenario 1: Clock advances +30 mins

Because the clock advanced by less than a complete cycle time, no quantities or hours will be reported, and the Gantt activity block will not shrink. However, the start time will be reported. 

Scenario 2: Clock advances +1 hour

In this case, the clock advances by one complete cycle, so the activity block on the Gantt will shrink by one-third (depending on the resource capacity intervals). Therefore, there will also be a Reported Goods Qty equal to the quantity produced after 1 cycle and a Reported Hrs of 1 hour.

Configuration

There are two options to configure automatic activity progress reporting in your data model:

A global setting can be configured in a user's preferences which will apply to all jobs

Individual operations can be configured to be allowed to report progress when the clock advances 

User Preferences

A user administrator may edit any user's preferences from the User Preferences tile on the Users board, or any individual user may access and edit their own user preferences from the User Preferences dialog accessible from the User Menu of the main toolbar. Options under the Clock Advance section are available to Auto Report Progress and Auto Finish:

Auto Report Progress: When enabled, progress will be automatically reported when the clock is advanced beyond the scheduled start date of any scheduled activities. 

Auto Finish: When enabled, activities will be finished automatically when the clock is advanced past their scheduled end date/time.

Operation Settings

Automatic activity progress reporting can be configured for specific job operations if/when it may not be appropriate to enable globally for all operations. Time-based reporting can also optionally be enabled at the operation level. These settings can be imported into the data model via the Resource Operation Mappings, or configured or visualized in the client application from the Status tab of the Operation settings in the Job Details Dialog:

Automatically Report Progress when Clock Advances past Scheduled Start: When enabled, progress will be automatically reported when the clock is advanced beyond the scheduled start date of any scheduled activities. The Reported Quantities and Hours are subtracted from the Required Quantity and Required Hours fields to calculate the Remaining Quantity and Hours.

Automatically Finish when Clock Advances past Scheduled End: When enabled, activities will be finished automatically when the clock is advanced past their scheduled end date/time.

See Also

Activities Board

User Management

Job Details Dialog

Resource Operation Mappings</div>
        </section>
      <h2 id="cat-concepts-resources-departments-plants" class="category-header">Concepts &gt; Resources, Departments, &amp; Plants</h2>
        <section class="article" id="article-238-capabilities">
          <h3 class="article-title">Capabilities</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capabilities" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

A capability is defined by the type of work or skill that a resource can do. Each resource may have one or more capabilities, and individual capabilities may be assigned to multiple resources.

Each operation's resource requirement indicates one or more required capabilities that a resource must have to be considered eligible to run the operation. Therefore, for an activity to schedule on a resource, the operation must reference the number of resources required and those resources' capabilities.

Capabilities typically correspond to work centers in an ERP system. Still, they can also be created for special product attributes such as item classes, material types, or other constraints that defined whether a resource can perform a particular task. 

Data Object Management

Capabilities, Capability Assignments, Operations, Resource Requirements, and Capability Requirements are created or imported as data objects. 

Capabilities: Define the type of work or skills.

Capability Assignments: Assign capabilities to resources to indicate what type of work each resource is eligible to perform.

Operations: Job operations define processing steps of a manufacturing order. Each manufacturing order contains one or more operations.

Resource Requirements: Resource requirements specify the number of production resources that are required to operate. Each operation must have at least one resource requirement, considered the primary requirement.

Capability Requirements: Capability requirements specify the required capabilities of each resource requirement. Each resource requirement must have at least one capability requirement.

Multiple Capability Requirements

If two or more capabilities are required for a single resource requirement of an operation, a resource must have all of the required capabilities assigned to it in order for it to be considered eligible to perform the work. 

Data Import

Capability objects are imported via Capability Mappings logic

Capability Assignment objects are imported via Capability Assignment Mappings logic

Operation objects are imported via Resource Operation Mappings logic

Resource Requirement objects are imported via Resource Requirement Mappings logic

Capability Requirement objects are imported via Required Capabilities Mappings logic

Manual Creation

Capabilities can be created and modified from the Capabilities tile of the Scenario Data Board. The same time is used to assign capabilities to resources.

Operations can be created and modified by creating or editing a Job from the Jobs Board. Operations are created and modified from the Job Details Dialog. This is where Resource Requirements and Capability Requirements of the operation are also configured.

See Also

Job Structure

Plants, Departments, and Resources

Capability Mappings

Capability Assignment Mappings 

Resource Operation Mappings

Resource Requirement Mappings 

Required Capabilities Mappings 

Scenario Data Board

Jobs Board</div>
        </section>
      
        <section class="article" id="article-268-helper-resources">
          <h3 class="article-title">Helper Resources</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/helper-resources" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Operations which require more than one resource to complete the work are considered to have a Primary resource along with one or more Helper resources. The Primary resource is defined by the resource that is time-constrained as it determines the run time of the operation. The Helper resources can be machines or laborers or both.

Jump to section:

Configuration

Scheduling

Visualize in Gantt

Configuring Helper Resources

Define Primary Resource: The user can define primary resources in the Job dialog (Operation ➡️ Resources ➡️ Resource Requirements ➡️ Primary), or the value may be imported via the PrimaryRequirement property of the Resource Requirement Mappings. Only one requirement can be deemed the Primary.

Adding a Helper Resource for an Operation:

Click the "+" plus sign in the bottom left corner of the Resource Requirements grid

Select which capabilities are required of the new helper resource from the pop-up pane

Save and Close

Setting Usage Start and End for Helper Resources:

Helper resource requirements can be configured to start and end at different times than the Primary resource by changing the UsageStart and UsageEnd properties. The Primary resource requirement must always start at Setup and end at PostProcessing, Storage, or StoragePostProcessing (one of the latter if the operation produces a product that gets stored in a Tank resource).

UsageStart defines when the Operation starts using the required resource. This must be less than or equal to the UsageEnd value.

UsageEnd defines when the Operation is finished using the required resource. This must be greater than or equal to the UsageStart value.

Setup: Start or End usage of the resource during the Operation's Setup phase

Run: Start or End usage of the resource during the Operation's Run/Cycle phase

PostProcessing: Start or End usage of the resource during the Operation's Post-Processing phase

Storage: Start or End usage of the resource during the Operation's Tank Storage phase. This is not valid to use on any operation that does not produce a product that is stored in a tank resource.

StoragePostProcessing: Start or End usage of the resource during the Operation's Tank Storage Post-Processing phase. This is not valid to use on any operation that does not produce a product that is stored in a tank resource.

Example: If a worker (labor Helper resource) is required only during the setup phase of an operation, then the UsageStart and UsageEnd fields would both be set to Setup.

Scheduling Operations with Helper Resource Requirements

The Online Capacity (calendars) of the required resources may dictate which gets set as the Primary and which are considered the Helpers. The Primary resource and its Helper resources must all be available (Online) at the same time for the operation to schedule. Therefore, when running an optimize, the PT scheduler uses the Online capacity of the Primary resource requirement to determine when the Helper(s) must also be Online. Any length of time where the PT scheduler can schedule the operation on an Online interval on the Primary requirement, the Helper(s) must also be Online for the same duration. If not (if there is any interruption at all and the Helper goes offline while the Primary is Online), then the operation is not considered eligible to schedule at that point in time.

As a best practice, the capacity of the Helper(s) and the Primary resources should be in sync so that they're always Online and Offline at the same time, though this may not always be practical.

Note: A Helper resource's Online capacity must be able to match that of the Primary resource in order for a job to be eligible to schedule at any point in time. If the Helper resource's Online capacity does not align with the Primary resource's Online capacity where a job first tries to schedule then the system will continue to attempt to schedule the job at a later point in time to where the Helper resource capacity matches that of the Primary. If there is no such point in time then the job will be scheduled past the planning horizon. 

Visualizing Helper Resources in the Gantt

If an operation uses one or more helper resources, clicking once on any scheduled activity block in the Gantt with the Show Activity Links option enabled will draw a blue activity link between the two scheduled activities.

See Also

Resource Requirement Mappings

Allowed Helpers

Gantt Board</div>
        </section>
      
        <section class="article" id="article-281-multi-tasking-resources">
          <h3 class="article-title">Multi-Tasking Resources</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/multi-tasking-resources" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Multiple operations running concurrently on the same resource can be modeled in PlanetTogether with a combination of resource, operation, and capacity interval configurations. A single resource in PlanetTogether may be restricted to running a specific number of operations at any given time (the number of which may even change over time), or a resource can be configured to run an infinite number of simultaneous operations.

While there are many possible use cases for multi-tasking resources, one practical use case is modelling a labor resource as a pool of laborers. There may be an expected number of people working each shift who all have the same capabilities to work on certain jobs or operations, in which case they might all be modeled as a single labor pool resource whose capacity to handle multiple operations simultaneously scales up and down with the number of people available on each shift and the number of people required to work on each job or operation.

Jump to section:

Resource Configuration

Attention Percent

Number of People

Infinite Capacity Resources

Resource Configuration

A multi-tasking resource's Capacity Type property must be set to one of these values depending on whether its capacity is finite or infinite:

Multi-Tasking: A finite number of activities can be scheduled to run at the same time based on available capacity and each operation's requirements.

Infinite: Any number of activities may be scheduled to run at the same time.

Sequence Dependent Setup is not allowed for Infinite or Multi-tasking resources, so when either of these Capacity Types are defined, the resource must also be configured to either Always or Never incur setup time on its scheduled operations via the Setup Included property.

Always: Setup time is always incurred on scheduled operations according to the operation's configured setup time.

Never: Setup time is never incurred on scheduled operations.

These values can be imported via Resource Mappings, or modified manually from the Capacity Planning Board's Resources grid tile when switched to Edit Mode:

Special Considerations

Setup time may be scheduled on a multi-tasking resource, but cannot be calculated in a sequence-dependent manner.

When multiple activities schedule to run simultaneously their activity blocks stack on top of each other in the Gantt chart. If many activities schedule to run at the same time then it can be difficult or impossible to read the Gantt labels or to even select a specific desired activity block from the stack. This is especially true of Infinite capacity resources.

Multi-tasking resources can create confusion when moving scheduled jobs around because the activities on the multi-tasking resources may switch their position in the Gantt chart from top to bottom or vice-versa based on the exact timing.

Scheduling many operations on multi-tasking resources can significantly slow down the performance of the Optimize function since it has to factor in additional levels of capacity complexity. If performance becomes an issue, consider converting multi-tasking resources into many separate single-tasking resources.

Multi-tasking resources support the "IfSchedulable" customization. If the function returns false, it won't be used to satisfy the resource requirement, regardless of the resource. 

It's possible for the Optimize logic to encounter a situation where a released operation repeatedly cannot be scheduled at the time the optimizer tries to schedule it due to its attention percent or number of people being greater than what is available on the resource due to other scheduled operations. It may continuously find other operations to schedule on the resource which are eligible but which then cause the same effect the next time the optimizer tries to schedule the original operation that it tried earlier. This may continue indefinitely until the operation is forced to schedule past the planning horizon due to a lack of available capacity. Keep this in mind if one or more jobs that require a multi-tasking resource are scheduling past the planning horizon, especially if they don't have any constraining material requirements.

Attention Percent

One option to schedule multiple operations to run simultaneously is to define the Attention Percent on each operation which is eligible to run on a multi-tasking resource. The Attention Percent is the amount of the resource's "attention" or capacity required to run the operation.

A resource is assumed to have a maximum attention percent of 100%, so the number of operations that may schedule simultaneously on a multi-tasking resource will be determined by how much of the resource's attention is required to perform each operation. The sum of the attention percent of all concurrently scheduled operations at any point in time may never exceed 100%.

The Attention Percent of the operation can be imported via the Resource Requirement Mappings, or set manually in the Operation ➡️ Resources ➡️ Resource Requirements tab of the job dialog. 

Number of People

Another option to schedule multiple operations to run simultaneously is to define the number of people that are required to run each operation, then also define the number of people that are available at each online capacity interval shift. The PlanetTogether optimizer will then allow multiple activities to schedule on the resource as long as it has at least the required number of people available on the capacity interval.

Activity Settings

There are two properties of the operation's activity(ies) that need updated in order to configure it to use a specific number of people:

People Usage: Set the property to one of two values:

Use Specified Nbr: Only up to this number of the Resource's Capacity Interval's available people are allocated to the Activity.

This is not a scheduling constraint. If there are fewer than this number available and there are no other activities scheduled on the resource, all of the people in the capacity interval will be allocated to the Activity and the activity's cycle time will be lengthened by a factor of the missing number of people.

Use Multiple Of Specified Nbr: A multiple of NbrOfPeople will be used. For instance, if an activity's NbrOfPeople is 4 and the resource's capcity interval has 11 people . 8 people will be used to process the activity.

This is a scheduling constraint. If the capacity interval does not have at least the specified number of people available then the activity will be considered ineligible to schedule there. 

Nbr of People: Define the specific number or the multiple increment that should be used when scheduling the operation.

These properties are imported via the Internal Activity Mappings, or configured manually from the Operation ➡️ Status section of the job dialog:

Capacity Interval Settings

A specific Nbr of People can be defined on each occurrence of each Capacity Interval assigned to the multi-tasking resource. This will determine the maximum number of operations that may be able to schedule to run simultaneously on the capacity interval according to each operation's required number of people.

This property is imported via Capacity Interval Mappings or Recurring Capacity Interval Mappings, or configured manually from the Capacity Interval Dialog which is accessible from the Capacity Interval management tiles of the Scenario Data Board, or from the Gantt Board by right-clicking any capacity interval and choosing either the Open Occurrence or Open Series option.

Infinite Capacity Resources

A resource whose Capacity Type is designated as Infinite is assumed to be able to schedule as many operations to run concurrently as demand requires of it at any point in time during an online (or overtime) capacity interval.

See the Resource Configuration section of this article for details on how to configure a resource to have infinite capacity.

The Gantt chart may get a bit crowded with many activity blocks stacked on top of one another.

See Also

Capacity Planning Board

Resource Capacity

Gantt Board

Scenario Data Board

Resource Mappings

Resource Operation Mappings

Capacity Interval Mappings

Recurring Capacity Interval Mappings</div>
        </section>
      
        <section class="article" id="article-181-plant-stability">
          <h3 class="article-title">Plant Stability</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/plant-stability" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

When creating a schedule, it may be preferable to avoid making last-minute disruptions unless there is a problem such as a machine breaking down or a need to rush a crucial order through. Having too much volatility in the schedule in the short term is inefficient as it can create confusion and nervousness on the shop floor. PlanetTogether provides options to control the stability of the short-term schedule using "Frozen" or "Stable" time spans to prevent too many last minute changes.

Jump to section:

Department Frozen Span

Plant Stable Span

Department Frozen Span

The Frozen Span represents a window of time at the beginning of the schedule, typically representative of a time span which should only ever have very few, if any, schedule changes made to it. With the appropriate settings in place, the Frozen Span can be reserved for manual scheduling so that Optimize and other automated functions do not impact any operations already scheduled there, but operations may be manually dragged and dropped in and around the Frozen Span area. 

The Frozen Span is assigned per Department and is visualized in the Gantt by a light blue overlay which starts at the beginning of the schedule and ends after the specified Department Frozen Span duration.

In order to preserve the scheduled order of operations inside of the Frozen Span, schedule optimization can be configured to start optimizing at the end of the Frozen Span. From the Schedule dropdown, choose the option to Optimize Activities Starting At the End of the Frozen Span, then each time Optimize Schedule is performed, the Optimize logic will preserve the activities which are scheduled to start inside of the Frozen Span and will only optimize the sequence of the schedule thereafter.

A similar setting can be configured for the Compress function which will result in only those activities scheduled within the Frozen Span being compressed while all other scheduled activities remain scheduled at their current time:

Each Department in the data model is to be assigned a Frozen Span duration. This duration is typically imported with each department configuration via the Department Mappings, or the Frozen Span value can be edited in the user interface using Grid Edit mode in the Departments tile of the Scenario Data Board.

Since it's not possible to filter on unique grid rows only, a single Department or Plant may be represented in the Resources grid many times (as in the screenshot above where there is 1 Plant and 2 unique departments but 12 grid rows - one row per Resource in each Department). In these cases, when editing a Department or Plant property in Grid Edit mode, only one of the grid rows needs to be modified, then when the edit is saved the change will automatically be applied to all relevant grid rows.

System Settings

Two System Settings can be configured for all users to enforce automatic locking and/or anchoring of activities which are scheduled to start inside of the Frozen Span to further enhance the stability of the schedule inside of the Frozen Span.

Plant Stable Span

The Plant Stable Span is specific to each plant in the data model and functions much like the Frozen Span does. It applies to all Resource of all Departments within the Plant and acts as an additional buffer to the Department Frozen Span. The Plant Stable Span is visualized in the Gantt by a light green overlay which starts at the end of the Department Frozen Span (or at the beginning of the schedule if no Department Frozen Span is defined) and ends after the specified Plant Stable Span duration.

In order to preserve the scheduled order of operations inside of the Plant Stable Span, schedule optimization can be configured to start optimizing at the end of the Stable Span. From the Schedule dropdown, choose the option to Optimize Activities Starting At the End of the Plant Stable Span, then each time Optimize Schedule is performed, the Optimize logic will preserve the activities which are scheduled to start inside of the Plant Stable Span and Department Frozen Span and will only optimize the sequence of the schedule thereafter.

A similar setting can be configured for the Compress function which will result in only those activities scheduled within the Plant Stable Span and Department Frozen Span being compressed while all other scheduled activities remain scheduled at their current time:

The Plant Stable Span duration is typically imported with each department configuration via the Plant Mappings, or the Stable Span value can be edited in the user interface using Grid Edit mode in the Plants tile of the Scenario Data Board.

See Also

Locking and Anchoring

Capacity Planning Board

Scenario Data Board

System Settings</div>
        </section>
      
        <section class="article" id="article-193-plants-departments-and-resources">
          <h3 class="article-title">Plants, Departments, and Resources</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/plants-departments-resources" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Resources in PlanetTogether represent the machines, laborers, workstations, tools, or other equipment which perform the work required on the factory floor. Each are assigned one or more Capabilities which determines the type of work that the resource is allowed to perform.

Departments are a means to help to organize the grouping of resources in whatever manner makes the most sense for an organization. Their only impact on scheduling is the ability to set a frozen zone unique to each Department. Typically, Departments in PlanetTogether correspond to ERP work centers.

Lastly, a Plant is meant to represent an entire facility or location where production occurs. It is usually synonymous with a single physical factory. However, in PlanetTogether, a Plant consists of any number of Departments that contain any number of Resources used to produce goods. A Plant also defines the scope of an Optimization. Optimization can be run on one or more Plants simultaneously, but not limited to only part of a Plant. PlanetTogether is designed to accommodate manufacturers with multiple plants whose processes are interconnected with one another. 

Data Object Management

Plants, Departments, and Resources are created or imported as data objects. Note that once Resources are created, they cannot be assigned to other departments. Similarly, Departments cannot be reassigned to other Plants in multi-plant models. When reassignments are necessary, the Departments or Resources which need reassigned must be deleted and recreated under the appropriate Plant or Department parent object.

Data Import

Plant objects are imported via Plant Mappings logic; Department objects via Department Mappings; And Resource objects via Resource Mappings.

Manual Creation

Plants can be created and their properties modified from the Plants tile of the Scenario Data Board.

Departments can be created and their properties modified from the Departments tile of the Scenario Data Board.

Resources can be created and their properties modified from the Resources grid of the Capacity Planning Board.

See Also

Plant Stability

Capacity Planning Board

Gantt Board

Scenario Data Board</div>
        </section>
      
        <section class="article" id="article-234-resource-capacity">
          <h3 class="article-title">Resource Capacity</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-capacity" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Resource capacity is defined by the intervals of time where resources are available to work on jobs and how much work can be scheduled at each interval. Thus, resource capacities are determined by a combination of the Resource Properties and Capacity Intervals. 

Jump to section:

Associated Resource Properties

Capacity Intervals

Types of Capacity

Associated Resource Properties

If necessary, resource properties may manually be modified via Grid Edit Mode from the Capacity Planning board.

Capacity Type: Specify if a resource has an infinite or finite capacity and whether the resource is single-tasking or multi-tasking. 

Infinite: The resource can perform any amount of work simultaneously.

SingleTasking: The resource can only perform one activity at a time. That activity must be completed before additional work can be done.

MultiTasking: The resource can perform multiple activities simultaneously based on the Number of People assigned to Online or Overtime capacity interval shifts assigned to the resource, or based on the operation's resource requirement Attention Percent property value. The attention percent is a numerical value for how much of the resource's attention is devoted to that activity.

This feature can accommodate resources that have many people working at the same time. For example, if you have a resource with four people during the work shift, you can have four jobs running on the resource simultaneously. Suppose one person is not available for a change. In that case, you can quickly change the number of people assigned to that resource by modifying the number of people available on the capacity interval. The schedule will automatically update to allow fewer operations to run simultaneously on the resource. 

Efficiency Multipliers: These are resource-wide modifiers of the setup and cycle times that can be changed to reflect whether resources run faster or slower than usual.

Setup Time: This value can be changed to reflect whether the setup time of the resource is faster or slower than usual. Values greater than one represent a resource setup that is faster than usual, while values less than one represent a resource setup that is slower than usual. 

Cycle Time: This value can be changed to reflect whether the run/cycle time of the resource is faster or slower than usual. Values greater than one represent a resource running faster than usual, while values less than one represent a resource running slower than normal. 

Understanding "25% Faster"

Speed Increase: If something is 25% faster, it means the speed has increased by 25%.

Time Decrease: However, this does not mean the time decreases by 25%. Instead, the time decreases by a factor related to the inverse of the speed increase.

Why the Time Doesn't Decrease by 25%

When you increase the speed by 25%, you're multiplying the original speed by 1.25. Since time and speed are inversely proportional (assuming the same amount of work or distance), the new time is calculated by dividing the original time by the speed multiplier.

Mathematically:

New Time=Speed MultiplierOriginal Time​

Calculating the New Runtime

Given:

Original Runtime = 60 minutes

Speed Multiplier = 1.25 (25% faster)

Step-by-Step Calculation:

Calculate the New Runtime:

New Runtime=1.2560 minutes​=48 minutes

Determine the Percentage Decrease in Time:

Time Decrease Factor:

Time Decrease Factor=1−(Speed Multiplier1​)Time Decrease Factor=1−(1.251​)=1−0.8=0.20 or 20%

Time Decreased by 20%, Not 25%

Verify the Decrease in Time:

Time Reduction=60 minutes×20%=12 minutesNew Runtime=60 minutes−12 minutes=48 minutes

Addressing Your Calculation

When you calculated 25% of 60 minutes as 15 minutes and subtracted it from 60 minutes to get 45 minutes, you're assuming that a 25% increase in speed results in a 25% decrease in time. However, due to the inverse relationship between speed and time, this isn't the case.

To achieve a 25% reduction in time, you need a greater increase in speed.

Calculating the Required Speed Multiplier for a 25% Time Reduction:

Desired Time Reduction Factor:

Desired Time Reduction Factor=1−0.25=0.75

Calculate the Required Speed Multiplier:

Required Speed Multiplier=Desired Time Reduction Factor1​=0.751​≈1.3333

Check the New Runtime:

New Runtime=1.333360 minutes​≈45 minutes

Therefore, to reduce the runtime to 45 minutes (a 25% decrease in time), you need a speed multiplier of approximately 1.3333, meaning the system is 33.33% faster, not just 25% faster.

Conclusion

A speed increase of 25% (multiplier of 1.25) results in a time decrease of 20%, reducing the runtime from 60 minutes to 48 minutes.

To reduce the runtime to 45 minutes (a 25% time decrease), you need a speed increase of approximately 33.33% (multiplier of 1.3333).

Capacity Intervals

Capacity Intervals define whether a resource is Online (capable of performing work), or Offline. They may recur, or they may be configured as a one-time capacity setting or shift. They are visually represented in the Gantt board at the bottom of each resource row. 

Capacity intervals may be maintained manually from the Scenario Data board, or from the Capacity Tools tile in the Gantt board. Each interval or occurrence of a recurring interval may also be edited directly from the Gantt by double-clicking the specific interval, or by right-clicking and choosing to Open Occurrence or Open Series to modify its settings.

From the Capacity Tools tile on the Gantt, there are two options that can be turned on; Production Stage Indicator and Constraints Indicator.

Production Stage Indicator will add a color to the capacity intervals denoting which production stages the interval can be used for. If it can be used for all stages, the interval will stay its' assigned solid color. 

💡 Tip

The colors displayed for each process align with each user's Process Segment colors in the User Settings ➡️ Segments ➡️ Process Segment.

Constraint Indicator will add a color segment to the capacity based on which constraints are active for the interval.

Overtime: Maroon

Can Start Activity: Yellow

Prevent Operations from Spanning: Purple

Reset Attributes Changeover: Dark Blue

Use only when Late: Mauve

The Capacity Interval Dialog and all of the settings that can be configured is documented in detail in the Scenario Data board page.

Interval Status

Online: The resource is available to perform work according to the configured interval settings and constraints.

Offline: The resource is not available to perform work. If an Offline interval is placed on top of an Online interval then the Offline interval "wins" and the resource is considered unavailable. Activities whose operation allows them to span offline intervals may be scheduled here but no progress will be made on the completion of the activity for the duration of the Offline interval.

Interval Settings

Color: Choose any color to assign to the interval. The color can help to distinguish between different interval statuses and configurations when viewed from the Gantt.

Can be dragged/resized: When enabled, the capacity interval is allowed to be dragged and resized in the Gantt by users who have permission to maintain capacity intervals, and who have the similar user settings enabled. When disabled, the capacity interval cannot be dragged and resized in the Gantt by any user.

Can be deleted: When enabled, the capacity interval is allowed to be deleted by users who have permission to maintain capacity intervals. When disabled, the capacity interval cannot be deleted by any user.

Timing:

Start: Define the start date and time of the capacity interval.

End: Define the end date and time of the interval.

Duration: A calculation of the duration of the interval for quick reference.

⚠️ Note

Recurring capacity intervals cannot be configured with a duration longer than 24 hours in order to prevent recurrences from overlapping with one another.

Capacity

Nbr of People: Defines the number of people available for the duration of the interval. If the Resource Type is set to Multi-tasking, this number will determine how many operations can run simultaneously during the interval based on each operation's People Usage and Nbr of People settings, or the resource requirement's Attention Percent setting. 

Capacity Hours: The interval's total capacity hours is calculated as a multiple of its Nbr Of People by its Duration. For example, if the interval duration is 8 hours and the NbrOfPeople is 2, then the interval equates to 16 hours of total capacity. 

Capacity Code: A Capacity Code can be set on intervals which should only be used for particular orders or operations. An Operation's Resource Requirement Capacity Code field can be defined so that if it matches the Capacity Code set on the interval then it will be eligible to schedule there. Operations which do not have a Capacity Code defined on the resource requirement, or which have a code which does not match the interval code value will not be allowed to schedule on the interval.

Options and Constraints

Overtime: When enabled, the resource is available to perform work. Cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. When disabled, cost calculations for performing work on the interval use the Standard Hourly Cost on the resource.

Can Start Activity: When enabled, the interval can be used to start the first process of an activity (either Setup, if applicable, or Cycle).

Prevent Operations from Spanning: When enabled, the resource is not available to perform work, and no idle work is allowed to pause to span across this interval. This is typically a good option for resource maintenance or cleaning where schedulers don't want to start progress on an operation or activity, then pause for its offline maintenance, then pick back up the activity after the offline interval.

Reset Attributes Changeovers: When enabled, calculations which dictate sequence-dependent setups and cleans will be reset to 0.

Use Only when Late: When enabled, activities will only schedule on the capacity interval if they are late (the schedule clock date time is later than the activity’s JIT start date).

Used for Setup: When enabled, the capacity interval can be used to perform Setup processes.

Used for Run: When enabled, the capacity interval can be used to perform Cycle processes.

Used for Post Processing: When enabled, the capacity interval can be used to perform Post-Processing processes.

Used for Storage: When enabled, the capacity interval can be used to perform Storage Post-Processing processes.

Used for Clean: When enabled, the capacity interval can be used to perform Clean processes.

For more detail, see the Capacity Interval section of the Scenario Data board page.

Capacity Interval Presets

Online: The resource is available to perform work. Cost calculations for performing work on the interval use the Standard Hourly Cost on the resource.

Offline: The resource is not available to perform work. If an Offline interval is placed on top of an Online interval then the Offline interval "wins" and the resource is considered unavailable. Activities whose operation allows them to span offline intervals may be scheduled here but no progress will be made on the completion of the activity for the duration of the Offline interval.

Overtime: The resource is available to perform work. Cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource.

Potential Overtime: The resource is available to perform work. Cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. By default, Potential Overtime is no different from Overtime intervals, but with a software extension the two can have different or conditional logic applied to them.

Maintenance: The resource is not available to perform work. No activity may be scheduled here, not even those which are allowed to span offline intervals. Any sequence-dependent setup or clean calculations will be reset when the first operation schedules after the end of the cleanout interval. This is typically a good option for resource maintenance or cleaning where schedulers don't want to start progress on an operation or activity, then pause for its offline maintenance, then pick back up the activity after the offline interval.

Holiday: The resource is not available to perform work. No activity may be scheduled here, not even those which are allowed to span offline intervals. This is typically a good option for forcing work to finish before a holiday or extended break, but where the sequence-dependent setup or cleanout calculations should not be reset once work resumes.

Cleanout: The resource is only available to perform Clean processes. It is considered online.

For more detail, see the Capacity Interval section of the Scenario Data board page.

Overlapping Capacity Intervals

If capacity intervals overlap on the same resource, then the following rules are applied:

Offline intervals will always override other types of intervals. No activities can schedule when an offline interval is present.

Overlapping regular online and overtime intervals will increase the total capacity for the overlapping duration. In addition, the Nbr of People for each overlapping capacity interval will be added, which will increase the total capacity hours.

Note: It is recommended to avoid having multiple instances of overlapping capacity intervals. If the total resource capacity needs to be increased, it is better to modify the series of intervals to reflect the desired number of people and capacity. 

Note: Recurring capacity intervals are also called a "series." On the Gantt, recurring and single occurrence capacity intervals can be differentiated by their appearance. Periodic intervals (series) will have diagonal lines throughout the interval block, whereas single occurrences will have a solid background color. 

See Also

Capacity Planning Board

Gantt Board

Scenario Data Board

Multi-Tasking Resources

Helper Resources

Resource Mappings

Capacity Interval Mappings

Recurring Capacity Interval Mappings</div>
        </section>
      
        <section class="article" id="article-251-tank-resources">
          <h3 class="article-title">Tank Resources</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/tank-resources" target="_blank">Source</a></p>
          <div class="article-content">⚠️ Alert

Tank resources described in this article are deprecated in software version 12.3.0. Tanks can now be modeled as Storage Areas where Storage Area Connectors can set constraints on which resource(s) can supply or consume from which Storage Areas.

Key Concept

Tank Scheduling is intended for manufacturers that use large storage vats to hold liquids such as beverages, chemicals, or formula blends for an indeterminate amount of time. These tanks are considered "in use" until downstream operations empty them. With Tank scheduling, the normal Item/Warehouse inventory plan is bypassed since the storage of the material is being recorded in the tank and ultimately emptied from the tank -- the material is never stored in any warehouse.

Tanks are used as indefinite storage but come with the caveat that only a single item may be stored until the tank's contents are emptied. Emptying a tank entails creating job operations that consume the item which is stored in the tank, or allowing the contents of the tank to expire based on the stored item's configured shelf life duration.

Jump to section:

Tank Scheduling Overview

Tank Resource Configuration

Job Operation Configuration

Item Configuration

Tank Drainage

Tank Storage Inventory Tracking

Tank Scheduling Overview

Tank operations utilize two unique processes: Storage and Storage Post-Processing. Storage is the amount of time that the item is stored in the tank after it's been produced and before consuming operations have consumed all of its contents or it has otherwise been drained or emptied. All tank operations must have some amount of storage or else they are immediately drained and no operations are allowed to consume the items produced. Storage Post-Processing or Tank Post-Processing is an optional phase which can be configured to act as a sort of cleanout of the tank before another operation is allowed to schedule to refill it with a new item or batch.

An operation which schedules on a tank will consume its online capacity for the entire Setup, Run, Post-processing, Storage, and Tank Post-processing steps. Only one operation may schedule at a time on a tank resource, and only one item may be stored in the tank.

A tank's contents must be completely drained or depleted before another operation will be allowed to schedule on the tank resource. Its contents may be consumed by other scheduled operations, or its storage duration limit may be reached at which point the tank will automatically drain. The storage duration limit is defined via the Shelf Life property on the item which gets stored in the tank.

When using tanks with MRP or with Lot Control, the tank's contents may automatically be drained if there are no known demands that need scheduled to consume it.

Tank storage minimum and maximum capacity limits may optionally be defined at the resource level.

Tank Resource Configuration

A property called Tank must be set to True in order for a resource to be allowed to store material within it. Optionally, the Resource Type may also be set to Tank for informational purposes, though it is not required.

A tank resource's storage capacity may be defined using the Minimum Quantity and Max Quantity properties. Only operations which produce quantities of items within this range will be allowed to schedule on the tank resource.

A tank resource's Capacity Type must be set to SingleTasking.

See also:

Resource Mappings

Job Operation Configuration

Product

The operation must be configured to produce a product. The product must be configured to be stored in a tank via the StoreInTank Boolean flag set to True.

Resource Requirement

The operation's primary resource requirement must be configured to end (UsageEnd) at either Storage or Storage Post-Processing.

Stock Material Requirement

The stock material requirement of the operation(s) which consume material from a tank resource must not have a Warehouse (WarehouseExternalId) defined since the tank resource is not considered a warehouse. This will allow the system to supply the material from any warehouse or tank resource when it is made available.

If an operation requires more volume or quantity than are stored in a single tank resource then multiple tanks may need to supply material to the operation. Since PlanetTogether treats each tank resource as separate warehouses, the [x] MultipleWarehouseSupplyAllowed Boolean option must be set to True on the Stock Material requirement to allow multiple tanks to supply the operation.

By default, material is consumed from a tank resource at the scheduled start of the consuming operation. This timing can be altered by setting a different value on the TankStorageReleaseTiming property on the material requirement. The accepted values are:

AtActivityStart: Release the tank's material when the activity consuming the material starts.

AtEndOfActivitySetup: Release the tank's material when the activity consuming the material has finished Setup.

AtEndOfProcessing: Release the tank's material when the activity consuming the material has finished processing.

AtEndOfPostProcessing: Release the tank's material when the activity consuming the material in the tanks has finished its post-processing.

See also:

Product Mappings

Resource Requirement Mappings

Material Mappings

Item Configuration

For any item which gets stored in a tank, its Shelf Life (ShelfLifeHrs) property must be set to define the maximum amount of time the item may remain in storage in a tank resource. If the item is stored in a tank for this amount of time without being consumed by other operations, then the tank's contents will empty automatically.

See also:

Item Mappings

Tank Drainage

Tanks empty automatically under the following conditions:

If there is only a fractional remainder left (determined by scenario rounding settings), or

When using MRP or Lot Pegging, if the simulation logic cannot identify any consuming operations which require the lot that is stored in the tank then it will automatically drain after the last scheduled operation consumes material from the tank.

A sample custom software package is available which allows for specifying a drainage quantity on the producing operation so that if the stored amount drops to or below the specified quantity then the tank will be drained. The drained amount will appear in the inventory plan as a negative adjustment.

To request the sample package, please contact PlanetTogether Support and specify for which software version it will be used.

Tank Storage Inventory Tracking

Since items which are stored in tanks are never stored in a standard PlanetTogether warehouse, each tank resource's production and consumption can be tracked from the Inventory Plan Board where each tank resource is visually represented as a warehouse with inventories equal to each item that may be stored within the tank resource(s). The grid can expose certain scheduled inventory properties such as number of adjustments, total demand, total supply, etc., and the specific details of each adjustment can be visualized from the Inventory Plot Report or the Adjustments Report tiles. The Inventory Plot Report in particular will list production, consumption, and emptying adjustments, including timestamps and job details for each adjustment over time.

These apparent warehouses are simply visual representations of inventory adjustments for tank resources; they do not actually become warehouse objects in the data model.

See Also

Resource Mappings

Product Mappings

Resource Requirement Mappings

Material Mappings

Item Mappings

Inventory Plan Board</div>
        </section>
      <h2 id="cat-concepts-scenarios" class="category-header">Concepts &gt; Scenarios</h2>
        <section class="article" id="article-274-scenario-management">
          <h3 class="article-title">Scenario Management</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/scenario-management" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Scenarios contain all the data for the factory model, including plants, departments, resources, items, inventories, operations, and financial information. In any planning area Workspace there is allowed to be one "production" scenario which typically acts as the master data and schedule. Users may create copies of scenarios in order to perform "what-if" analyses in order to test various features or functionality or changes to production and then assess the impact of the changes.

Scenarios of a Workspace are presented in a dropdown menu which is accessible from the Main Toolbar. From this dropdown menu, users can see all of the scenarios from the Workspace that they have permission to view or edit. Of those available to them, users may load them into memory, copy them, view or edit them (depending on the configured permissions), unload them from memory, delete them, and/or view various metadata related to each scenario at a quick glance (the clock date and the last action(s) performed). 

Jump to section:

Edit Settings

Share a Scenario

Copy a Scenario

Load and Unload a Scenario

Activate a Scenario

Convert to Production

Delete a Scenario

Edit Scenario Settings

From the Scenario Edit dialog, users can change the scenario name, assign a unique color label, isolate it from clock advances, isolate it from data imports, and enable or disable Scenario Comparison. 

This option is removed from software version 12.2.1 and newer since only one production scenario is now allowed to exist. A new Convert to Production button is added to swap non-production scenarios with the Production scenario when a non-production scenario should be promoted to become the new production scenario.

"Production" Flag

Enable the Production option in the Scenario Edit dialog to show a flag in the Scenarios dropdown to indicate that it's considered a Production scenario. There are no restrictions beyond what can be defined in the Share permissions related to what users may be able to do with a scenario that is flagged as a Production scenario (including deleting it). A single Workspace is permitted to contain more than one Production scenario and is also permitted to contain no Production scenarios at all.

Compare Scenario

Data can be compared between the currently active scenario and any others which have the Compare Scenario option enabled. Scenario comparisons are visible in the following areas of the software:

All configured Metrics via the Metrics Board

All KPIs from both the KPIs Board as well as each individual KPI Tile

Isolate from Import

Enable the Isolate from Import option to only allow data refreshes to the scenario if the Refresh is performed when the scenario is active. If a user clicks to Refresh All Scenarios from another scenario which is not isolated, then any isolated scenarios will not have their data refreshed.

Isolate from Clock Advance

Enable the Isolate from Clock Advance option to only allow clock advances in the scenario if the Advance is performed when the scenario is active. If a user clicks to Advance All Scenarios from another scenario which is not isolated, then any isolated scenarios will not have their clock advanced.

Scenario Color

Changing the color of Scenarios helps users differentiate between them. Lighter colors may not be easy to see in lighter themes of PlanetTogether so if a lighter color is selected then a warning message may appear:

Share Scenario Permissions

Next to the Edit link is a number of users. This is the number of uses with whom the scenario is currently shared. Click it to edit the share permissions.

From the Share dialog, users can define the Scenario Owner and elect whether or not to share the scenario to make it visible and/or editable to other users. The share permissions can be defined on a user-by-user basis, user permissions group-by-user permissions group basis, or can be quickly toggled on/off for all users. Quick actions let users choose to make the scenario Read-Only or Editable to the users with whom the scenario is shared.

Scenario Owner

Only the scenario owner and users in a permission group with permission to Manage all scenarios are allowed to edit the scenario settings, modify the scenario share permissions, and delete the scenario. Other users can only view or edit the data within the scenario, or they can create a copy of an existing scenario that is shared with them which will make them the owner of the newly created scenario.

Share Scenario

When the setting is toggled on, the scenario can be shared with other users. The share permissions per user are defined in the Permission Options column of the table below.

Certain user permission groups can be configured to be allowed to Manage all scenarios which enables them to always be allowed to view, edit, or delete all scenarios in a Workspace. Permission Options for these users will always revert to Can Edit.

Make Read-Only

This button quickly updates all Permission Options settings to View Only for all users who are not part of a permission group that is allowed to Manage all scenarios.

Made Editable

This button quickly updates all Permission Options settings to Can Edit for all users

Permissions Grid

The Name column groups users by the Name of the User Permission Group that each user is assigned.

The Permission Options column offers dropdown selection options for sharing with all users of a group, or specific users within any permission group.

Use Group Access: The user's permissions are assumed by the user permission group's configured permission level (Can Edit/View Only/No Access).

Can Edit: The user has permission to view and edit data in the scenario according to their User Permissions settings.

View Only: The user has permission to view the scenario data according to their User Permissions settings.

No Access: The user can't access the scenario. They don't even see it in the scenario dropdown list.

Create a Copy of a Scenario

Additional scenarios are created as copies of existing scenarios. Click the plus icon from any scenario panel to create a copy of it. This will present the user with a dialog to specify the new scenario name, color, and settings. 

Once copied, the new scenario can be activated and any data modifications to the scenario copy will not affect the original scenario it was copied from.

If the "+" sign is grayed out and the button is disabled, the planning area Workspace has likely reached its maximum number of allowed scenarios. A scenario will have to be deleted before one can be created.

The number of scenarios allowed in a Workspace is configured by a server administrator in the Other tab of the Instance Settings from the Instance Manager.

Load and Unload a Scenario

Scenarios can be loaded into or unloaded from memory in order to reduce the RAM consumption and improve performance of the desktop application.

For any unloaded scenarios, click the Load icon to load it into memory. Note that this does not automatically activate the scenario after it's loaded.

For any scenario which is currently loaded into memory, click the Unload icon to unload it and regain some memory. Note that there must be at least one loaded scenario at all times so this option may not be available if there is currently only one loaded.

Activate a Scenario

Click the Activate icon from any scenario panel displayed in the dropdown menu to switch between scenarios. If necessary, load the scenario into memory first before activating it.

The name of the currently active scenario is displayed in the main toolbar next to the Boards menu.

Convert to Production

Click the Convert to Production icon to convert the non-production scenario to become the new Production scenario.

Once clicked, the user will be prompted to proceed or cancel, and will have an opportunity to also opt to swap the name of the non-production scenario with the current production scenario.

Delete a Scenario

Click the delete icon to delete the scenario from the Workspace. 

WARNING

This action cannot easily be undone. The only way to restore a deleted scenario is for a server administrator to restore the Workspace to a previous point in time from a recorded backup.

Scenarios flagged as Production scenarios are eligible to be deleted by any user who has permission to delete, so use caution to double-check that the selected scenario is the one intended for deletion.

Only a scenario owner or a user in a permission group which is allowed to Manage all scenarios can delete a scenario.

See Also

User Management

Instance Manager

Restore a Scenario from a Recording Backup</div>
        </section>
      <h2 id="cat-concepts-sequencing" class="category-header">Concepts &gt; Sequencing</h2>
        <section class="article" id="article-227-auto-split-operations">
          <h3 class="article-title">Auto-Split Operations</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/auto-split-operations" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Operations may be split into two or more activities automatically during optimization based on many configurable factors. Splitting operations allows the work to be spread across multiple resources in order to complete the work faster (as each split part may be run in parallel), or can be used to split the work across gaps in resource capacity. Splitting can also be used to break larger operations down into smaller parts so that each part may comply with maximum quantity or volume constraints across capable resources.

Jump to section:

Split by Resource Quantity

Split by Resource Volume

Split by Primary Resource Capacity Availability

Split Successor by Predecessor Material

Split Successor by Predecessor Quantity Ratio

Resource Prioritization

Split Setup

Split by Resource Quantity

Operations may be configured to split based on a resource's configured Maximum Quantity and/or Minimum Quantity values. As the optimization logic considers scheduling an operation on a resource, if the operation's Required Finish Quantity exceeds that of the resource's Maximum Quantity then it will be split according to its Min Auto Split Amount and Max Auto Split Amount settings.

Configuration

The Resource(s) must be configured with a Maximum Quantity greater than 0 which defines the largest allowed activity that can schedule there in terms of the activity's Required Finish Quantity. Optionally, the resource may be given a Minimum Quantity greater than 0 (but no more than the defined Maximum Quantity) if activities must also be restricted by how small they are.

The job's Operation must have its Auto Split Type property set to ResourceQtyCapacity. It's also required that the Operation define a Min Auto Split Amount and/or a Max Auto Split Amount in order to define an allowed range in the size of each split activity in terms of its Required Finish Quantity. The maximum split amount must be set to a value that is equal to or greater than the defined minimum amount.

Sample Scenario File

Download and load the Scenarios_AutoSplit_12.2.0.25.dat and login as user "admin" (no password) and activate the SplitByQty scenario.

Split by Resource Volume

Operations may be configured to split based on a resource's configured Maximum Volume and/or Minimum Volume values.

Measuring operation output in Volume can be more flexible than Quantity since Volume can take into account the item being produced without the need to change the operation quantity.

Each Item can be assigned a Unit Volume property value which is used to calculate the volume produced by an operation. The total volume output is equal to Item.UnitVolume * OperationProduct.TotalOutputQty. Alternatively, a Unit Volume value may be set on the operation product directly via the UnitVolumeOverride property.

As the optimization logic considers scheduling an operation on a resource, if the operation's product's UnitVolume * TotalOutputQty exceeds that of the resource's Maximum Volume then it will be split according to its Min Auto Split Amount and Max Auto Split Amount settings.

It's expected that a resource either uses Volume or Quantity constraints, but not both. In the event that there is a Maximum Quantity constraint on a resource which also has a Maximum Volume constraint, if the operation is configured to split on Volume then it may not be able to schedule if the total operation required quantity is not less than the Maximum Quantity set on the resource.

Configuration

The Resource(s) must be configured with a Maximum Volume greater than 0 which defines the largest allowed activity that can schedule there in terms of the activity's Required Finish Quantity. Optionally, the resource may be given a Minimum Volume greater than 0 (but no more than the defined Maximum Volume) if activities must also be restricted by how small they are.

The job's Operation must have its Auto Split Type property set to ResourceVolumeCapacity. Optionally, the Operation may also define a Min Auto Split Amount and/or a Max Auto Split Amount in order to define an allowed range in the size of each split activity in terms of its Required Finish Quantity. If Min Auto Split Amount is set, then the Max Auto Split Amount must be set to a value that is equal to or greater than the defined minimum amount.

The Item produced by the operation should have its UnitVolume property set to some value greater than 0. Alternatively, a Unit Volume value may be set on the operation product directly via the UnitVolumeOverride property.

Sample Scenario File

Download and load the Scenarios_AutoSplit_12.2.0.25.dat and login as user "admin" (no password) and activate the SplitByVolume scenario.

Split by Primary Resource Capacity Availability

This option is only available in pre-release version 12.2.1.19 and newer

Operations may be configured to split based on the capacity availability of the resource(s) chosen to schedule the primary resource requirement. As the optimization logic considers scheduling an operation on a resource, if the operation is not allowed to span offline intervals (Can Pause for Offline Intervals is False) and the scheduler encounters an offline span, the operation will split so that it finishes at the end of the online span and resumes at the next online interval. The operation may also be configured with Min Auto Split Amount and Max Auto Split Amount settings as needed. If the Min and Max amounts are not defined, then it will be split based on the online capacity of capable resources.

Configuration

The Resource(s) must have a mix of online and offline (or cleanout) capacity assigned.

The job's Operation must have its Auto Split Type property set to PrimaryCapacityAvailability. Optionally, the Operation may also define a Min Auto Split Amount and/or a Max Auto Split Amount in order to define an allowed range in the size of each split activity in terms of its Required Finish Quantity. If Min Auto Split Amount is set, then the Max Auto Split Amount must be set to a value that is equal to or greater than the defined minimum amount.

In order for the auto-split logic to trigger, either the job's Operation must be configured to disallow pausing for offline intervals (Can Pause for Offline Intervals is False) and an Offline capacity interval will interrupt the scheduled operation, or a Cleanout capacity interval is scheduled to interrupt the scheduled operation. The lack of online capacity and ability so span the offline interval forces the operation to be split.

Split Successor by Predecessor Material

Successor operations within a manufacturing order which are dependent on materials produced by a split predecessor operation can be split based on the number of split activities of the predecessor operation. As the optimization logic considers scheduling a successor operation whose predecessor was split, if the predecessor operation produces an item which the successor consumes and the successor's Auto Split Type is PredecessorMaterials, then the operation will be split into the same number of activities as the predecessor was split.

Configuration

A manufacturing order must have at least two operations which run sequentially. The predecessor operation must be split into two or more activities, either by one of the auto-split options, or manually. The predecessor operation must produce an item or product which the successor is configured to consume as a stock material requirement. It's expected that the quantity produced by the predecessor and the quantity consumed by the successor are identical. Finally, the successor operation must have its Auto Split Type property set to PredecessorMaterials.

Sample Scenario File

Download and load the Scenarios_AutoSplit_12.2.0.25.dat and login as user "admin" (no password) and activate the SplitByPredecessorMaterial scenario.

Split Successor by Predecessor Quantity Ratio

Successor operations may be configured to split into an equal number of parts as its predecessor is split into. If the quantities of the predecessor and successor operation are not the same, then the system calculates a ratio of the quantities for the successor splits equal to the quantity ratio of the predecessor splits. For example, if a predecessor operation requires 15 production units and it's split into 3 activities which each produce 5, then it's quantity ration is 5/15 = 1/3. Consider then if its successor operation requires 30 production units and is split into the same number of activities (3) at the same ratio (1/3) then each of the split activities of the successor will produce 10 units.

This option is only compatible between predecessor-successor operations of the same manufacturing order.

Configuration

The job's Predecessor Operation must have its Auto Split Type property set to any value and scheduling conditions must result in the operation splitting into multiple activities. Additionally, the Successor Operation must have its Auto Split Type property set to PredecessorQuantityRatio. Optionally, the predecessor operation may also define a Min Auto Split Amount and/or a Max Auto Split Amount in order to define an allowed range in the size of each split activity in terms of its Required Finish Quantity, but note that these properties are not enforced on the successor operation which splits according to the predecessor's quantity ratio.

Resource Prioritization

Additional optimize factors are added to the Sequence Planning Board which allows users to prioritize the scheduling of activities based on various quantity or volume associations. For example, when an operation is split, it might be preferred to have the largest resources or vessels be filled first. In these cases, optimize factor points can be assigned to prioritize the largest quantity or volume fit first.

Closest Fit Quantity: Prioritizes operations based on how closely their quantity fits within the range defined by the resource's minimum and maximum quantity.

Closest Fit Volume: Prioritizes operations based on how closely their volume fits within the range defined by the resource's minimum and maximum volume.

Largest Quantity Fit: Prioritizes operations based on whether their quantity is enough to fully fill the resource based on the resource's Max quantity. If the operation can automatically split based on ResourceQuantityCapacity, then prioritize larger resources.

Largest Volume Fit: Prioritizes operations based on whether their volume is enough to fully fill the resource based on the resource's Max Volume. If the operation can automatically split based on ResourceVolumeCapacity, then prioritize larger resources.

Least Waste Quantity Fit: Prioritizes operations based on minimizing the gap between the activity's required quantity and the resource's available quantity, ensuring the best fit to reduce waste.

Least Waste Volume Fit: Prioritizes operations based on minimizing the gap between the activity's required volume and the resource's available volume, ensuring the best fit to reduce waste.

Smallest Quantity Fit: Prioritizes operations based on whether their min quantity is enough to fully fill the resource based on the resource's Min quantity. If the operation can automatically split based on ShiftSize, then prioritize smaller resources.

Smallest Volume Fit: Prioritizes operations based on whether their volume is enough to fully fill the resource based on the resource's Min Volume. If the operation can automatically split based on ResourceVolumeCapacity, then prioritize smaller resources.

Split Setup

When an operation which incurs setup is split, each resulting activity of the split will incur the full amount of setup time by default. A Setup Split Type property set on the operation allows for additional flexibility to either schedule all of the operation setup on the first scheduled activity of the split operation, or to split the setup between each activity proportionally according to each split activity's required quantity.

Configuration

The operation which incurs setup must have its Setup Split Type property set to one of the following values:

FirstActivity: All operation setup will be incurred by the first scheduled activity

SplitByQty: Operation setup will be divided proportionally between each split activity according to its required quantity.

Sample Scenario File

Download and load the Scenarios_AutoSplit_12.2.0.25.dat and login as user "admin" (no password) and activate the SplitSetup scenario.

See Also

Capacity Planning Board

Gantt Board

Sequence Planning Board

Job Details Dialog

Resource Mappings

Resource Operation Mappings</div>
        </section>
      
        <section class="article" id="article-216-cleans">
          <h3 class="article-title">Cleans</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/cleans" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Resource cleans or cleanouts may be configured to schedule at the end of an operation. The clean duration may be defined explicitly on the scheduled operation, or the system can be configured to determine when cleans are needed and for how long based on the sequence of scheduled operations on a resource. More specifically, Clean Time can be defined as one of an operation's standard timed processes (along with Setup, Cycle, and Post-Processing), or operation Attributes can be used to model sequence-dependent cleanouts. A combination of both is also possible, and in the event that more than one cleanout event is triggered to be scheduled at the same time, the one with the highest Grade value will be scheduled. When a sequence-dependent clean is scheduled, it is scheduled at the end of the operation which precedes the operation that triggers the necessity to clean. Scheduled cleans are visible as part of the Process segment in the Gantt.

Note

A new UsageEnd value Clean on an operation's resource requirement is required in order to schedule clean processes.

Jump to section:

Cleanout Grade

Resource Clean Time

Operation Clean Time

Operation Attribute Cleans

Cleanout Trigger Tables

Product Rules

Sequence Dependency at the Start of the Schedule

Visualizing Cleans

Cleanout Grade

Cleans can be modeled in a number of different ways. There may be times when multiple cleanouts could be triggered to schedule at the same time, but PlanetTogether will only ever schedule a single cleanout per operation. Each possible source of a cleanout can be assigned a Cleanout Grade value. This grade is a way to numerically rank which cleanout should be scheduled in the event that multiple cleans would otherwise need to be scheduled simultaneously. Under these conditions, the highest grade value takes precedence. If two cleanouts of the same grade are slated to be scheduled together, the longest duration clean is scheduled. After a cleanout completes, it effectively resets all cleanout triggers which have an equal or lower Cleanout Grade assigned as the one that was scheduled.

Resource Clean Time

Cleans may be configured at the resource level. These cleanouts will be considered for scheduling at the end of every operation that schedules on the resource. This might make sense if there needs to be a minimum cleanout duration scheduled after each operation completes on the resource.

From Resource Mappings, the related properties to import this configuration are StandardCleanHours and StandardCleanoutGrade. They can also be configured in the client interface from the Capacity Planning Board via Grid Edit Mode from the properties Standard Clean Duration and Cleanout Grade.

Operation Clean Time

Cleans may be configured in the operation's time standards settings. These will be considered for scheduling at the end of the operation as long as the resource where the operation is scheduled is configured to Use Operation Clean Time.

From Resource Operation Mappings, the related properties to import this configuration are CleanHours and CleanOutGrade. They can also be configured in the client interface from the Activities Board via Grid Edit Mode from the properties Standard Clean Span (Operation) and Cleanout Grade (Operation), or from the operation configuration tab of the Job Details Dialog.

Resources must also be configured to use the operation time standard settings. From Resource Mappings, the UseOperationCleanout property must be set to True. Alternatively, the Use Operation Clean Time property can be enabled from the Capacity Planning Board via Grid Edit Mode.

Operation Attribute Cleans

Operation attributes can be used to trigger sequence-dependent cleans. This means that the cleans will be scheduled only under certain conditions based on the order or sequence of scheduled operations on a resource. For example, if a custom attribute called "Color" updates from code "White" on one operation to code "Black" on the next scheduled operation on the resource, then a cleanout could be triggered based on the change in the Color attribute's code value.

There are a handful of basic triggers that can be configured for situations where changes in the sequence will always trigger the same amount of cleanout time. Users also have the option to configure complex matrices which can dictate how much clean time should be scheduled based on changes in specific values of specific attributes between one scheduled operation and the next on the same resource.

Each of these options requires that one or more Clean type attributes are imported into the data model and assigned to the relevant operations. See also:

Attributes

Attribute Mappings

Operation Attribute Mappings

Option 1: Attribute Code Changes

A fairly straightforward option is to force a clean to schedule each time an attribute code changes from one scheduled operation to the next. In this case, the AttributeTrigger property associated with the attribute must be set to CodeChanges. Each operation which needs to consider this attribute when evaluating sequence-dependent cleans must be given a unique Code value in the operation attribute assignment. Whenever the attribute code changes from one scheduled operation to the next, the attribute's DefaultDurationHrs or the operation attribute's DurationHrs will determine the duration of the clean which gets scheduled at the end of the predecessor operation.

Example

In this example, an attribute called CodeChange has an assigned Code value of X on the first scheduled operation, and an assigned Code value of Z on the next scheduled operation. This triggers a 2-hour cleanout:

Option 2: Attribute Number Changes

A similar option is to force a clean to schedule each time an attribute number changes from one scheduled operation to the next. In this case, the AttributeTrigger property associated with the attribute must be set to NumberChanges. Each operation which needs to consider this attribute when evaluating sequence-dependent cleans must be given a unique numerical Number value in the operation attribute assignment. Whenever the attribute number changes from one scheduled operation to the next, the attribute's DefaultDurationHrs or the operation attribute's DurationHrs will determine the duration of the clean which gets scheduled at the end of the predecessor operation.

Example

In this example, an attribute called NumberChange has an assigned Number value of 2 on the first scheduled operation, and an assigned Number value of 3 on the next scheduled operation. This triggers a 3-hour cleanout:

Option 3: Attribute Number Increases

A more specific option is to force a clean to schedule each time an attribute number increases from one scheduled operation to the next. In this case, the AttributeTrigger property associated with the attribute must be set to NumberHigher. Each operation which needs to consider this attribute when evaluating sequence-dependent cleans must be given a unique numerical Number value in the operation attribute assignment. Whenever the attribute number increases from one scheduled operation to the next, the attribute's DefaultDurationHrs or the operation attribute's DurationHrs will determine the duration of the clean which gets scheduled at the end of the predecessor operation.

Example

In this example, an attribute called NumberHigher has an assigned Number value of 1 on the first scheduled operation, and an assigned Number value of 10 on the next scheduled operation. This triggers a 30-minute cleanout:

Option 4: Attribute Number Decreases

Alternatively, it's possible to force a clean to schedule each time an attribute number decreases from one scheduled operation to the next. In this case, the AttributeTrigger property associated with the attribute must be set to NumberLower. Each operation which needs to consider this attribute when evaluating sequence-dependent cleans must be given a unique numerical Number value in the operation attribute assignment. Whenever the attribute number decreases from one scheduled operation to the next, the attribute's DefaultDurationHrs or the operation attribute's DurationHrs will determine the duration of the clean which gets scheduled at the end of the predecessor operation.

Example

In this example, an attribute called NumberLower has an assigned Number value of 10 on the first scheduled operation, and an assigned Number value of 1 on the next scheduled operation. This triggers a 2-hour and 30-minute cleanout:

Option 5: Attribute Code Change Matrix

Finally, it's possible to define varying clean durations in an attribute code table matrix so that the duration may differ depending on the specific attribute code values that change from one operation to the next. In this case, the AttributeTrigger property associated with the attribute must be set to LookupByCode. Each operation which needs to consider this attribute when evaluating sequence-dependent cleans must be given a unique Code value in the operation attribute assignment, and an attribute code table matrix must be configured to define specific code value changes and the clean duration associated with each specific change. Whenever the attribute code changes from one scheduled operation to the next and the change in code values is mapped in the attribute code table, a clean will be scheduled at the end of the predecessor operation based on the defined DurationHours in the code table matrix (or DurationMinutes if configured in the client interface).

Example

In this example, an attribute called CodeTable has an assigned Code value of A on the first scheduled operation, and an assigned Code value of B on the next scheduled operation. This triggers a 2-hour cleanout based on the attribute code table matrix match:

Sample Scenario File

Download scenarios_Cleans_12.2.0.25.dat and login as user "admin" (no password) and activate the AttributeCleans scenario.

Cleanout Trigger Tables

Cleanout trigger tables can be used to schedule cleans at incremental intervals based on various factors such as:

The number of operations completed since the last clean;

The number of product units produced since the last clean (either units of volume or quantity);

The number of production cycles run since the last clean;

The amount of time a resource has spent processing or running operations since the last clean; or

The amount of calendar time that has passed since the last clean was run

Note

A cleanout type capacity interval can also be used to reset the count since the last clean.

Cleanout trigger tables can be viewed and configured from the Data Tables tile of the Scenario Data Board.

See also:

Cleanout Trigger Table Mappings

Option 1: Operation Count

A data table whose type is OperationCountTrigger can define a cleanout Duration, Grade, Cost and TriggerValue interval. In this case, the TriggerValue specifies the number of operations which must schedule on a resource since the last cleanout was scheduled (either a cleanout process at the end of an operation, or a cleanout capacity interval).

Option 2: Production Units

A data table whose type is ProductionUnitTrigger can define a cleanout Duration, Grade, Cost, TriggerValue interval, and a ProductionUnit. Options for the ProductionUnit field are:

Cycles: In this case, the TriggerValue specifies the total number of operation cycles scheduled on a resource since the last cleanout was scheduled.

Quantity: In this case, the TriggerValue specifies the total output quantity of primary products produced by operations scheduled on a resource since the last cleanout was scheduled.

ProductUnits: In this case, the TriggerValue specifies the total output production units (product Total Output Quantity * UnitVolume) of primary products produced by operations scheduled on a resource since the last cleanout was scheduled.

Option 3: Time

A data table whose type is TimeCleanOutTrigger can define a cleanout Duration, Grade, Cost, TriggerValueHours interval, whether or not to consider Processing time or Post-Processing time in the calculation, and whether or not to trigger the cleanout at the end of the last scheduled operation on a resource.

UseProcessingTime: When True, operation run/cycle time will be used to calculate when cleans needs to be scheduled according to the TriggerValueHours setting. 

UsePostProcessingTime: When True, operation post-processing time will be used to calculate when cleans needs to be scheduled according to the TriggerValueHours setting. This can be combined with UseProcessingTime.

When both UseProcessingTime and UsePostProcessingTime are False, the system will simply use calendar time/hours to calculate when cleans should be scheduled.

TriggerAtEnd: When True, the clean is scheduled at the end of the operation which triggers the clean. When False, the clean is scheduled at the end of the operation which is scheduled just prior to the operation which triggers the clean.

Sample Scenario File

Download scenarios_Cleans_12.2.0.25.dat and login as user "admin" (no password) and activate the TriggerTableCleans scenario.

Product Rules

Product rules can be used to influence clean duration when specific products are produced on specific resources. Product rules override Operation Clean Time settings but do not impact clean durations derived from operation attributes. In order to alter operation clean duration, define the duration in the CleanHrs property of the product rule, and set UseCleanHrs boolean property to True.

Unit volume produced by an operation can also be manipulated by product rules. Where Volume = OperationProduct.TotalOutputQty * Item.UnitVolume (or OperationProduct.TotalOutputQty * OperationProduct.UnitVolumeOverride), the volume output by an operation can be altered via Product Rules where specific products that run on specific resources might output a different volume than the standard calculation. To override the volume calculation, define the unit volume multiplier in the CleanoutUnitsRatio property of the product rule, and set UseCleanoutUnits boolean property to True. The product rule ratio will override the item's unit volume ratio and/or the operation product's unit volume ratio override.

For more information, see:

Product Rules

Product Rules Mappings

Sequence Dependency at the Start of the Schedule

Since many options to trigger a clean to be scheduled are sequence-dependent, it's important to consider whether or not a clean needs to be scheduled at the start of the PlanetTogether schedule. In order for the system to use its sequence-dependent logic to trigger a clean at or near the start of the schedule, a certain amount of finished job history must be preserved and/or imported into the system. PlanetTogether will use the finished job data on each resource in the same way that it uses scheduled jobs and operations downstream to determine when a clean needs to be scheduled.

The amount of finished job history to preserve may vary depending on whether the configured sequence-dependent cleans need only a single previously-scheduled operation, or many. Ultimately, however much history is deemed necessary, it should either be kept in the system and deleted manually when it's no longer needed, or a certain number of finished jobs should be imported in order to meet the historical data requirement. 

When importing finished jobs, it's important to import the finished activity data via the Internal Activity Mappings. It's especially important to import the ReportedStartDate, ReportedFinishDate, and ActualResourcesUsed for each finished activity, along with any operation attribute data which may be used by the Cleans scheduling logic.

Finally, it's important to enable Track Actuals in the Data Options section of System Settings. This setting allows users to define a maximum age of finished operations for the system to keep track of and make visible in the Gantt. The duration defined here should be long enough that enough historical schedule data can be preserved in order for the system to accurately calculate and schedule cleans near the start of the schedule. Track Actuals Gantt blocks may also be enabled in the Block Settings area of User Settings.

Visualizing Cleans

Scheduled Cleans can be visualized in the Gantt or in the Activity Scheduling grids.

Gantt

The Process Segment of the Gantt blocks can be enabled from the Segments section of User Settings to show the various processes or steps of an individual operation, including the Clean process. Cleans will always be scheduled at the end of the operation after all other processes are complete.

The label text of any segment can also be updated to include clean duration and grade values.

Activity Scheduling Grids

The activity scheduling grid tiles in the Activities board can be configured to show scheduled clean durations and grades, as well as other various cleans data (costs, reported clean time, etc.).

See Also

Attributes

Product Rules

Capacity Planning Board

Gantt Board

Activities Board

System Settings

User Settings

Attribute Mappings

Resource Mappings

Operation Attribute Mappings

Resource Operation Mappings

Resource Requirement Mappings

Cleanout Trigger Table Mappings</div>
        </section>
      
        <section class="article" id="article-249-manufacturing-order-production-overlap">
          <h3 class="article-title">Manufacturing Order Production Overlap</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/manufacturing-order-production-overlap" target="_blank">Source</a></p>
          <div class="article-content">Old Article Versions

This article is updated to reflect the latest software functionality. For older software versions, download and refer to the appropriate document version:

Software Version(s)
Download Link

12.1.4.x thru 12.2.1.x
ManufacturingOrderProduction Overlap_12.2.1.pdf

Key Concept

Operations from different manufacturing orders may be configured to partially or completely overlap and run concurrently with one another. This is helpful when one operation of an order is meant to supply an operation of another order with some material and the producing operation is able to produce and transfer its completed production to inventory in batches as it completes cycles. While the producing operation is still in process, its completed materials are added to inventory and the consuming operation is able to start its production once enough materials become available. It's also possible to release all of an operation's production to inventory at the start of the producing operation so that the consuming operation is allowed to schedule to start at the same time.

⚠️ WARNING:

Overlapping jobs or operations can become processor and memory intensive under certain conditions. Having many transfers of small quantities can lead to system performance issues so it's advisable to transfer in larger increments whenever logical.

Jump to section:

Partial Overlap Based On In-Process Production

Item Transfer Quantity

Operation Product Inventory Available Timing

Operation Stock Materials Settings

Complete Overlap via Immediate Inventory Release

Operation Product Inventory Available Timing

Operation Stock Material Constraint Type

Partial Overlap Based On In-Process Production

Two operations of different manufacturing orders may be allowed to partially overlap their production based on inventory transferring from one operation to the other while the producing operation is still in process. This requires a few different properties of various objects to be configured to allow in-process production to transfer its completed material to inventory, then the consuming operation to be able to consume it while the producing operation is still ongoing.

Item Transfer Quantity

In order for job operations to be able to transfer in-process materials to inventory, the item record for the product must have a Transfer Quantity defined. This quantity determines the amount of in-process materials that can be transferred to inventory while an operation is producing it. It may be set to as small a value as 1, although small transfers of in-process materials to inventory for large orders (1,000 units or more) can significantly impact optimization performance as it must calculate frequent on-hand material inventory adjustments to determine where consuming operations are eligible to schedule.

Transfer Quantity and Operation Cycles

In-process materials can only be transferred to inventory at a rate no faster than the operation's Quantity Per Cycle. For example, if Transfer Quantity at the Item level is set to 10 but the Quantity Per Cycle of the Operation is 100, then completed in-process materials will be added to inventory in batches of 100 as each cycle of the operation completes. Conversely, if Transfer Quantity is set to 100 and the producing operation's Quantity Per Cycle is 10, then completed in-process materials will be added to inventory in batches of 100, requiring 10 operation cycles to have completed before the consuming operation is eligible to schedule.

Operation Product Inventory Available Timing

For any operation which produces an item that should be transferred to inventory while the operation is in process, the operation product's Inventory Available Timing must be set to any of these available options which support production overlap:

At Operation Run End: All produced inventory is considered available at the end of the Operation's last run/cycle, plus any Resource Transfer time. This can ensure that the consuming operation can overlap with post-processing and storage.

At Operation Post-Processing End: All produced inventory is considered available at the end of the Operation's post-processing step, plus any Resource Transfer time. This can ensure that the consuming operation can overlap with storage.

By Production Cycle: If the item's Transfer Quantity is set, material will be moved to storage in batches based on that quantity. Otherwise, it will be moved at the end of each cycle. 

During Post-Processing: Material is transferred evenly over the full duration of Post-Processing. If Item Transfer Quantity is set, the material will be moved to storage based on that quantity.

During Storage: Material is transferred evenly over the full duration of Storage. If Item Transfer Quantity is set, the material will be moved to storage based on that quantity.

Operation Stock Materials Settings

The Stock Material requirement of operations which consume materials from in-process operations must be constrained by the material's available date and and must allow for production overlap. Fulfill these requirements by setting the Constraint Type on the material requirement to Constrained by Available Date, and define at what point during the operation's processing that it should be allowed to consume the material via the Material Used Timing field. The options that enable overlapping with the producing operation are:

During Setup: Material is required evenly over the duration of the setup. The item's Transfer Quantity will be used if set.

By Production Cycle: A proportional amount of the material is required at each production cycle start. The quantity required per cycle is equal to the material requirement Total Required Quantity divided by number of cycles of the operation (multiplied by the ratio of the material requirement Total Required Quantity and the Operation Required Finish Quantity, which is typically 1). 

Last Production Cycle: All material is required on the final operation cycle start.

First And Last Production Cycle: Confirms that the first cycle has enough material and that all remaining material is available for when the last cycle starts. This can be used when the material overlap doesn't need to check every cycle, but the consuming operation is delayed by the first production cycle material and delayed by the full required material at the end of the operation. This option is the best for production overlap optimization performance.

💡 Tip

If the operation consumes material by production cycle but material is required during setup, then enable the Require First Transfer At Setup setting on the material requirement so that the first transfer is allowed to happen during setup rather than being calculated from the start of run/production.

Complete Overlap via Immediate Inventory Release

Two operations of different manufacturing orders may be constrained so that one is only released to schedule once the other has been scheduled. This can be modeled by using a constraining material requirement on the dependent operation where the predecessor operation is configured to produce the material but releases it to inventory immediately upon starting its run cycles. This ensures that the required material of the successor is made available as soon as the predecessor operation is scheduled to start so that (resource capacity permitting) the two operations are allowed to schedule concurrently.

Operation Product Inventory Available Timing

In order to allow the entire output quantity of an operation's product to be made available in inventory for consuming operations as soon as the operation is scheduled to start, the Inventory Available Timing property must be set to the value At Operation Run Start. This will allow the consuming operation to start at the same time as the producing operation when the consuming operation is constrained to start based on the item's available date.

Operation Stock Material Constraint Type

To complete the modeling of the constraint, a Stock Material requirement must be added to the successor operation which consumes the inventory from the predecessor which is made available at the operation's run start. Achieve this by ensuring that the Constraint Type on the material requirement is set to Constrained by Available Date.

See Also

Item Mappings

Product Mappings

Material Mappings

Inventory Plan Board

Gantt Board

Job Details Dialog</div>
        </section>
      
        <section class="article" id="article-219-operation-batching">
          <h3 class="article-title">Operation Batching</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/operation-batching" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Operation Batching is used when multiple identical jobs are simultaneously grouped on the same resource. For example, processes such as dye baths that group together different products can be processed simultaneously. In this case, the grouping is based on an operation attribute such as the color of the dye. For example, all operations with the same color attribute will be grouped and dyed as a single batch.

One significant limitation is that batching operations require that all jobs in the batch have the same number of cycles, run rates, and batch codes. Therefore, batched operations will be represented as a single activity block on the Gantt.

Configuring Operation Batching

Resources must be set up for operation batching by defining the Batch Type property, and optionally the Batch Volume.

For importing these data, see: Resource Mappings.

Batching can either be done by Percent or by Volume:

Percent: Activities are batched until 100% of the batch is filled. The percent occupied by each activity is calculated by dividing the activity's Required Finish Qty by its Qty Per Cycle. For example, a batch scheduled by percentage can have two jobs with a Batch Percent of 50%, three jobs with a Batch Percent of 33%, and so on. The accumulated jobs cannot exceed 100% of the operation's Cycle Qty.

Volume: Activities are batched until the activities' Required Finish Quantities equals the resource's batch volume. Jobs can be batched together if the cumulative Required Qty does not exceed the resource's batch volume.

Batch Volume: This is the maximum number of units included in a batch when using batch by volume.

Note:

When using the Percent Batch Type, the batch volume will be the minimum Required Qty, and the Qty Per Cycle of the operation will be the maximum batch size. When using the Volume Batch Type, the batch volume will be the maximum batch size (the sum of the Required Qty of all operations in the batch).

Next, a Batch Code must be set on the operations. This can be done in the client interface by opening the Job Details dialog and navigating to the Batching/Setups tab of the Operation tab: 

For importing these data, see: Resource Operation Mappings.

With the configurations in place, schedule optimization will batch operations together if they meet the appropriate criteria. 

Visualizing Batched Operation Details

When operations are batched together, their batch quantity, batched job names, and batch product list can be visualized in the Gantt Board, either in the Tooltips dialog or in the Gantt label text or in the Activity tab of the Job Properties tile.

Special Considerations

Batch resources can only schedule activities that fit in one batch. Therefore, if an activity has a larger batch size than the resource's capacity, it will remain unscheduled.

Batch resources can create and schedule the entire resource based on the last operation added to the batch.</div>
        </section>
      
        <section class="article" id="article-333-optimization">
          <h3 class="article-title">Optimization</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/optimization" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Optimization is the process by which PlanetTogether creates a minute-by-minute schedule by assigning job operations to resources at points in time across a planning horizon duration. Optimization logic can be tailored to each organization's needs by adjusting various preferences and settings, using any number of available scheduling constraints, and defining a scoring mechanism in the form of a Sequencing Plan in order to ensure operations that meet certain criteria are prioritized over others.

By understanding how optimize logically works through the queue of operations and puts them on the schedule, users will be able to better fine-tune their sequencing plan(s) to accommodate their most important business needs.

Jump to section:

High-Level Overview

Operation Eligibility

Capacity Eligibility

Operation Release Rules

Optimize Scoring

Step-By-Step Optimize Process

High-Level Overview

Optimization is a linear process whereby PlanetTogether's simulation logic starts at a point in time and moves forward in time as resource capacity becomes available. The starting point can be configured in Optimize Settings. At each earliest moment in time where there is resource capacity on any resource, all operations which are released to schedule at that time are scored across all resources which have available online capacity. The operation with the highest optimize score is then scheduled to start at that point in time on the resource where it scored the highest. The remaining scored operations are then scheduled to fill capacity on all other available resources at that time, descending from the highest scored operation to the lowest. Once either resource capacity is filled at that point in time, or there are no more eligible operations to schedule, the process moves forward in time in 1-second increments to the next point where there is both available resource capacity and eligible operations released to schedule. This process repeats until there are no more operations to schedule.

Operation Eligibility

An operation is considered eligible to schedule on a resource at a point in time if all of the following criteria are met:

Time constraint: The operation must be released to schedule according to its Just-In-Time start date minus all applicable JIT slack.

Capability constraint: Each required resource must be assigned each of the required capabilities of the operation's resource requirement. This constraint is removed if the resource requirement defines a Default Resource.

Capacity constraint: Each required resource must have available eligible capacity. The amount of available capacity required may vary depending on whether only one resource is required or more than one, and/or whether the operation is configured to be allowed to span offline capacity intervals. When more than one resource is required, each of the required helper resources must have at least as much available eligible capacity as the primary resource. If at any time for the duration of the operation while the primary resource is online one or more of the helpers goes offline, the operation is not considered eligible to schedule.

Resource capacity is not considered a constraint when operations are scheduled past the planning horizon.

Material constraint: Each of the operation's constraining material requirements must be able to be fulfilled at the point in time being considered.

Material constraints are not considered when operations are scheduled past the planning horizon.

Resource constraint: The operation must meet all of the resource's configured constraints (minimum/maximum quantities and quantities per cycle, cell eligibility, batch code eligibility, resource connector eligibility, attribute number range eligibility).

Capacity Eligibility

A capacity interval may have constraints in place which determine what type of work can be scheduled there. At minimum, the interval must be configured to allow activities to start (CanStartActivity) in order to schedule an unscheduled operation, and must be able to either perform Setup (UsedForSetup) or run cycles (UsedForRun). 

Operation Release Rules

Operations are released to schedule according to their calculated JIT Start Date minus any allowed JIT slack, and only after all other configured constraints have been satisfied.

JIT Start Date

An operation's Just In Time (JIT) Start Date is represents the latest date and time that the operation can start while still allowing it to finish on time (at or before its Need Date). PlanetTogether calculates an operation's JIT start date based on several factors:

Job Need Date: The job's need date acts as the need date of the last sequential operation of the job.

Total required work span: The total span of time required for Setup (standard or operation), Run, and Post-Processing are factored in so that the operation has enough time to complete all steps of its required processes and still finish on time.

If the operation requires more time to run on certain resources based on Product Rules or Resource Efficiency settings, then PlanetTogether will calculate the JIT Start Date based on the longest required work span across all eligible resources.

Sequence-dependent Setup and Clean durations are not factored into JIT Start Date calculations.

Resource capacity: The duration of offline capacity of a resource is factored in since each of the required processes are only allowed to progress during online resource capacity. When multiple resources are capable and eligible to schedule an operation, the operation's JIT Start Date calculation uses the resource with the least amount of online capacity prior to the operation's Need Date.

In the event that the sample resource lacks the capacity to fulfill the operation's capacity requirement to still complete the operation on time, the JIT Start Date will be set to the start of the resource's first online capacity interval minus the capacity that the resource lacks.

Material post-processing: If the operation produces a product and it's configured to require material post-processing before the product is available in inventory to use by consuming jobs or operations, the material post-processing duration is factored into the JIT Start Date so that any consuming job or operation is not late due to having to wait for this post-processing period to pass.

Transfer span: If the operation is configured with a transfer span between it and its successor operation, then this transfer duration is factored into the JIT Start Date so that the successor is not scheduled late due to the transfer span constraint.

Overlap: The amount of overlap is taken into consideration. For example, if the predecessor operation runs for 24 hours, and the successor can overlap 12 hours, then the 12 hours of overlap will be considered in the JIT calculation. Therefore the JIT for successor operations will be 12 hours later than if there was no overlap.

JIT Buffer Days: If the operation is configured with a JIT Buffer Days duration (JITStartDateBufferDays) then this time is factored into the JIT Start Date.

Notes

If there is a DefaultResource set and UseDefaultResourceJITLimit is set to false, JIT date will only calculate based on the capacity and work hours on the default resource. If UseDefaultResourceJITLimit is set to true, it will use capacity and work hours of all capable resources in JIT calculation.

When calculating JIT before the first capacity interval, capacity is considered to be 24x7 online.

Sequence dependent setup is not considered in JIT calculation. Only standard or operation setups.

Formula

Operation Need Date minus the Operation Total Work Span of itself and all predecessor operations minus unavailable resource capacity (on the eligible resource with the least amount of capacity if there are more than one capable resource and one has less capacity than the rest) minus the operation's Product Material Post Processing minus the Operation Transfer Span minus Operation JIT Start Date Buffer Days

Op Need Date
- Op Total Work Span(accounting for overlap time)
- Offline Resource Time
- Post Processing Time
- Transfer Span

- JIT Start Buffer Days
----------------------------------
= Op JIT Start Date

JIT Slack Options

JIT Slack refers to the number of hours or days that an operation can be released to schedule prior to its JIT Start Date. There are a few options to configure JIT Slack at a global level and at the individual operation level.

Optimize Setting: Release Rule

A setting from the Schedule dropdown of the main toolbar can quickly change the global JIT Slack rules applied during schedule optimization. The Release Rule to Use options are as follows:

JIT with Resource HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the Head Start Span specified for each resource.

JIT with Global HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the number of JIT Slack days specified in the text input. This logic is applied to all resources. The duration is defined in the JIT Slack Days input field.

Drum-Buffer-Rope: DBR calculations are used to manage the release date for operations that use one or more capacity-constrained resources flagged as Drum resources. Each manufacturing order is released based on its DBR Release Date minus the JIT Slack Days specified in the text input.

Operation JIT Buffer Days

If global settings may not be appropriate, then individual operations may be assigned a JIT Buffer Days value. This can be imported via the Resource Operation JITStartDateBufferDays property, or manually configured from the Job Details dialog or the Activity Scheduling grid editor. Technically, this setting deducts time from the JIT Start Date of the operation, so any number of buffer days or hours applied here are added to the JIT slack days defined in the optimize setting release rules.

Constraints

Many constraints may also impact the release date and time of an operation, including but not limited to:

Predecessor operation completion

Availability of constraining material requirements

Lack of online resource capacity on the primary and any required helper resources

Manufacturing Order release date

Jobs excluded by Optimize Settings or the job's Do Not Schedule setting

Optimize Scoring

A key component to creating an optimal schedule is the scoring logic that PlanetTogether uses to sequence each scheduled operation. The Optimize Score is a numerical value calculated based on each of the configured optimize factors of the sequencing plan that is used during schedule optimization. Activities with higher Optimize Scores are selected to schedule earlier than those with lower scores (unless constraints are applied). 

The Optimize Score is recorded and represents the score that was calculated for the operation at the simulated time during the optimization when the activity was scheduled. The Optimize Score values can be seen in:

The Activity Scheduling grids

The Publish Database

Gantt labels

The Gantt tooltip window

Optimization is a linear process whereby PlanetTogether's simulation logic starts at a point in time and moves forward in time as resource capacity becomes available. At each earliest moment in time where there is available resource capacity, all operations which are released to schedule at that time are scored across all resources which have available online capacity. The operation with the highest optimize score is then scheduled to start at that point in time on the resource where it scored the highest. The remaining scored operations are then scheduled to fill capacity on all other available resources at that time, descending from the highest scored operation to the lowest. Once either resource capacity is filled at that point in time, or there are no more eligible operations to schedule, the process moves forward in time in 1-second increments to the next point where there is both available resource capacity and eligible operations released to schedule. This process repeats until there are no more operations to schedule.

Optimization scores can be manipulated by altering sequencing plan configurations. Plans can be curated to meet specific business needs, and may even be tailored to specific resources so that the scoring logic may be different per resource. Each resource may be assigned up to five separate sequencing plans - one "Normal" plan and four "Experimental" plans. Schedulers may choose to use a single plan for all resources during optimization, or they may choose to use the Normal or any one of the Experimental plans from the Schedule settings dropdown from the main toolbar. Experimenting with various sequencing plans can be a great practice to test different configurations which might produce different schedules for different business needs.

For more details of how the optimize factor point assignments can impact the scores of operations, see the Scoring section of the Sequence Planning Board article.

Step-By-Step Optimize Process

PlanetTogether's optimization process requires many steps and takes in several considerations along the way. Here is a breakdown of each step of the process:

Step 1: Available resource capacity is found

Starting from the configured Optimize Activities Starting At setting in the Schedule dropdown of the main toolbar, the simulator searches for the earliest point in time where a resource has available capacity. 

Note

If any jobs or operations are already scheduled at or after the defined Optimize Activities Starting At setting, they will be unscheduled so that they can be re-sequenced.

Beginning of the Schedule: All of the jobs in the data model will be scheduled or rescheduled and sequencing will begin at the beginning of the schedule. 

End of the Frozen Span: All unscheduled jobs and all jobs which are scheduled to start after the Frozen Span will be scheduled or rescheduled. Sequencing will begin at the end of the Frozen Span. This is helpful when you want to prevent rescheduling jobs at the beginning of the schedule. For more information, see: Plant Stability.

End of the Stable Plan Span: All unscheduled jobs and all jobs which are scheduled to start after the Plant Stable Span will be scheduled or rescheduled. Sequencing will begin at the end of the Plant Stable Span. This is helpful when you want to prevent rescheduling jobs at the beginning of the schedule. For more information, see: Plant Stability.

Specific Date/Time: The user can set a specific date and time to start the optimization process. All unscheduled jobs and all jobs which are scheduled to start after the selected date and time will be scheduled or rescheduled. Sequencing will begin at the selected date and time.

Step 2: Release Dates are calculated

Once available resource capacity is found, release dates are calculated for each unscheduled operation of each job. All operations which are released to schedule are added to a work queue.

Step 3: Queued operations are assessed for eligibility

All released operations are assessed for eligibility to schedule on each resource which has capacity at the simulation schedule time. Each resource is then assigned their own individual work queue of eligible operations.

Step 4: Operations are scored

Each resource's work queue of eligible operations are scored according to the resource's configured sequencing plan.

Step 5: Operations are scheduled

Beginning with the operation which scored the highest among all available resources, operations are scheduled to start until either resource capacity is filled at that point in time, or there are no more eligible operations to schedule.

Step 6: Repeat

The process moves forward in time in 1-second increments to the next point where there is available resource capacity and repeats all of the steps until there are no more operations which can possibly be scheduled.

Example

Data:

Two Resources: Resource 1 and Resource 2, each with the same Capability.

Two Jobs:

Job 1

Need By 01/15

Priority = 1

Two Operations:

Op 10: 1 day of work, requires 1 unit of Material A.

Op 20: 3 days of work.

Job 2

Need By 01/15

Priority = 3

Two Operations:

Op 10: 1 day of work, requires 1 unit of Material A.

Op 20: 3 days of work.

Inventory

1 unit of Material A is On-Hand.

1 unit of Material A is On-Order with a purchase order due on 01/06.

Optimize Parameters:

Release Rule: JIT with 7 days slack

Current Clock Date: 01/01

Optimize Rule: 50% weight on Need Date and 50% weight on Priority.

Process:

Release Dates are calculated for each job. Since both jobs have the same need date (01/15) and the same work hours (4 days total), their JIT release dates are identical = 01/04. (Need Date of 01/15 minus 4 days of work minus 7 days of slack).

The first "event" to occur is the release of the two jobs on 01/04. The result of this event is that Op 10 for both jobs is added to the work queues for both resources.

The next event is for the resource with the highest Id to review its queue and see if any work can be scheduled at the simulated event time.

This resource calculates a "score" for the operations in its queue. The results are:

Job 1, Op 10 Score = 11 (Need Date minus event date) x 50% + 1 (Priority) x 50% = 6

Job 2, Op 10 Score = 11 (Need Date minus event date) x 50% + 3 (Priority) x 50% = 7

Job 1 has a lower score and is selected first by Resource 1 since it was the first resource to select. Since there are enough materials on hand, the operation is scheduled to run on 01/04. The material is allocated to Job 1, reducing the on-hand material to zero. No other operations can schedule at this time, and since this is the only operation that can start (Job 2 is still awaiting material), it is scheduled to start on 01/04.

The next event is the completion of Job 1 Op 10 on 01/05. This causes Resource 1 to become available, and it causes Job 1 Op 20 to become ready and added to the queues. The scores are again computed, and since this is the only operation that can start (Job 2 Op 10 is still waiting on materials), it is scheduled to start on 01/05.

The next event is the arrival of the purchase order on 01/06. This triggers the resources to evaluate their queues. At this point, Job 2 Op 10 can start since the material was received. Since Resource 2 is the only idle resource at this time, it selects Job 2 Op 10 and schedules it to run on 01/06.

The next event is the completion of Job 2 Op 10, which causes Op 20 to become ready and to schedule, completing the scheduling process.

The events and resulting schedule are illustrated below:

See Also

Sequence Planning Board

Optimize Settings

Plant Stability

Gantt Board

Activities Board</div>
        </section>
      
        <section class="article" id="article-339-optimize-settings">
          <h3 class="article-title">Optimize Settings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/optimize-settings" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Schedule optimization initiates a process of automatically reconstructing all or part of the schedule to improve its quality and incorporate all recent data updates into the schedule. Optimization is performed based on the configured Optimize Settings and the rules defined in the selected Sequencing Plan(s).

Be conscious of whether you're using Shared Optimize Settings or Personal Optimize Settings, especially if working in a collaborative environment with multiple schedulers.

Switching between Shared or Personal settings is done in the User Preferences dialog.

Quickly visualize whether Shared or Personal settings are in use by expanding the Schedule dropdown from the main toolbar and observing the icon next to each of the setting headers. If the icon is the bust of a single person , then Personal settings are enabled. If the icon reflects the busts of 3 people , then Shared settings are enabled.

For more information, see the User Preferences section of the User Management page.

Jump to section:

Optimize Activities Starting At

Jobs to Exclude

Sequencing Plan(s) to use

Release Rule to use

Set Sub-Job Need Dates

Access Optimize Settings from any of the following:

The Schedule dropdown from the Main Toolbar

The Optimize Settings section of System Settings (if using Shared settings)

The Optimize Settings section of User Settings (if using Personal settings)

Optimize Activities Starting At

This specifies the starting point for the optimization, and only activities that start after this specified time are included in the rescheduling. This feature may be useful if the schedule must remain stable in the short term for shop floor logistics or other reasons. The following options are available:

Beginning of the Schedule: All of the jobs in the data model will be scheduled or rescheduled and sequencing will begin at the beginning of the schedule. 

End of the Frozen Span: All unscheduled jobs and all jobs which are scheduled to start after the Frozen Span will be scheduled or rescheduled. Sequencing will begin at the end of the Frozen Span. This is helpful when you want to prevent rescheduling jobs at the beginning of the schedule. For more information, see: Plant Stability.

End of the Stable Plan Span: All unscheduled jobs and all jobs which are scheduled to start after the Plant Stable Span will be scheduled or rescheduled. Sequencing will begin at the end of the Plant Stable Span. This is helpful when you want to prevent rescheduling jobs at the beginning of the schedule. For more information, see: Plant Stability.

Specific Date/Time: The user can set a specific date and time to start the optimization process. All unscheduled jobs and all jobs which are scheduled to start after the selected date and time will be scheduled or rescheduled. Sequencing will begin at the selected date and time.

Jobs to Exclude

This section gives planners control when choosing which Jobs are placed on the schedule. Any Jobs that match the toggled selections will not be scheduled during optimization. If they were previously scheduled, then they will be unscheduled.

For example, a planner might want to only include Firm Jobs in the schedule as these are sure to be executed. However, a planner may also wish to see how the workload will be affected if Estimates, CTP, and/or Planned Jobs are included.

Note: Individual Jobs can also be Excluded from the schedule by flagging them using the Do Not Schedule property.

The following Exclude options are available:

Planned: The job’s Commitment is Planned (MRP-generated jobs are created with this commitment level).

New: The job is newly created or imported and has never been scheduled.

Estimates: The job’s Commitment is an Estimate (Capable To Promise jobs are created with this commitment level).

Unscheduled: The job was previously unscheduled by a planner.

On-Hold: The job’s On-Hold status is set to On-Hold. (A status of "Some Operations On-Hold" does not qualify).

Note: if on-hold jobs are included in optimization, they will only be considered eligible to schedule after their defined Hold-Until date.

Sequencing Plan(s) to Use

This setting specifies which sequencing rules to use during optimization. Each resource may have up to five sequencing plan assignments - a Normal plan and up to four Experimental plans. For more information or to adjust sequencing plan assignments per resource, see: Sequencing Plan Mappings.

Use one Plan for all Resources: The Sequencing Plan specified here will be used for all resources. Select a plan from the dropdown selection. Click the green icon to jump to the Sequencing Plan Board to edit the optimize factors of the selected plan.

Use Normal Resource Rules: Use each resource's assigned Normal Sequencing Plan during the optimization.

Use Experimental Resource Plan (One | Two | Three | Four): Use each resource's assigned Experimental Sequencing Plan (one, two, three, or four) during the optimization.

Release Rule to Use

Operations of a manufacturing order are not considered eligible to schedule by the Optimize function until the date and time that the MO is released. Release Rules determine when manufacturing orders are released for scheduling during optimization and therefore supersede the optimize rules.

By default, a MO is released at its calculated Just In Time (JIT) start date which is calculated based on its Need Date, the expected duration of each of its operations, and the amount of online capacity on all required resources (when there are multiple capable resources to consider, PT calculates the JIT start date based on the resource(s) with the least amount of online capacity). 

Release Rules are one way to add "JIT Slack" to effectively allow the MO to be released to schedule earlier than its JIT start date.

JIT with Resource HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the Head Start Span specified for each resource (imported via the HeadStartHrs property in the Resource Mappings, or manually set via the Capacity Plan editor).

JIT with Global HeadStart: Each manufacturing order will be released to schedule based on the lead Activity's JIT Start Date minus the number of JIT Slack days specified in the text input. This logic is applied to all resources.

Drum-Buffer-Rope: DBR calculations are used to manage the release date for operations that use one or more capacity-constrained resources flagged as Drum resources. Each manufacturing order is released based on its DBR Release Date minus the JIT Slack Days specified in the text input.

Account for Offline Intervals: When enabled, the Head Start Span or global JIT Slack days will factor into the release date of each order in terms of the number of hours of online capacity on each resource. When disabled, the Head Start Span or global JIT Slack days will factor into the release date of each order simply in terms of calendar days.

This feature is useful in data models whose resources are offline for multiple days at a time (i.e. on weekends or for holidays). When PT only considers calendar days to calculate release dates, it considers these offline spans of time which may result in orders being released to schedule too late to get done on time since the multiple days of offline capacity was not taken into account when the JIT date was calculated.

Example:

Job A is due for shipment on Monday, June 12 at 8:00 PM. The most capacity constrained resource which is required to run the final operation of Job A is online for 16 hours each day, Monday through Friday and remains offline Saturday and Sunday. The operation requires a full 16 hour shift to complete.

The plant is aggressively trying to plan for JIT scheduling so only allows for 1 day JIT slack on all resources.

When not accounting for the resource offline time which span Friday at 8pm through Monday at 4am, the job's release date is calculated to be Saturday at 6:00pm. If the resource were online then maybe this wouldn't be a problem, but since the resource doesn't come online until Monday at 4am, the operation is not allowed to start until Monday at 4am. As long as there are no other operations considered eligible to schedule between Friday at 8pm and Monday at 4am, this one operation can schedule to finish on time. If there are any other eligible operations though then one of them will be scheduled late.

Alternatively, if accounting for the resource offline time then the activity is released to schedule on Thursday at 12:00pm which allows it to finish at 12:00pm on Friday before the weekend. This gives plenty of time for other operations to schedule for the last 8 hours of online capacity on Friday, then the full 16 hour shift on Monday before the job is due.

Set Sub-Job Need Dates

This option is only available in User Settings and is only used to determine the manual adjustment action to Set Sub-Job Need Date and JIT that is available from the Gantt and Activities boards right-click menu and Actions tile.

Sub-jobs are jobs that are created to fulfill material requirements for successor jobs. The need dates for those jobs can be updated according to where the successor/parent job schedules using the following options:

Use System Options: The Set Sub-Job Need Dates value set in the Scheduling Options section of the System Settings will dictate the behavior.

To earlier of JIT and scheduled start date: The need date of the sub-job is set to the earlier of its JIT start date or its parent job's scheduled start date.

To JIT date: The need date of the sub-job is set to the JIT start date of its parent job.

To start date: The need date of the sub-job is set to the scheduled start date of its parent job. 

To bottlenecked Operation start date: The need date of the sub-job is set to the start date of whichever operation is causing a bottleneck.

To overlap supply sources: The need date of the sub-job is set to the end date of the parent job minus the amount of time required for the sub-job to make its first transfer of product to inventory.

See Also

MPS/MRP Optimize Plan Settings

System Settings</div>
        </section>
      
        <section class="article" id="article-198-product-rules">
          <h3 class="article-title">Product Rules</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/optimization/product-rules" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Product Rules can be used to define varying production rates, yields, and preferences for items which are produced in the plant based on which resource is used to produce them. These rules override the standard values set at the Job Operation, Resource, or Item level.

Product rules provide additional flexibility for companies with varying production speeds, quantity or volume constraints, inventory transfer rates, or resource priority depending on the machine or labor personnel completing each operation.

Jump to section:

Standard Functionality

Manual Configuration

Standard Functionality

Dependencies

In order for an Item to be eligible to define one or more product rules for, its Item Source property must be set to Manufactured or PurchasedOrManufactured.

Configuration Options

Each product rule defines any number of the available production efficiency overrides for a single Product 🔁 Resource association.

There may be cases where the same Product 🔁 Resource association may be necessary for multiple rules where the particular operation also becomes a variable factor. In these cases, the operation can be assigned a Product Code which can be referenced from the Product Code property in the Product Rules table, effectively creating a Product 🔁 Resource 🔁 Operation association.

Each rule can be used to override the following fields:

SetupSpan / UseSetupSpan: Overrides the Operation SetupSpan when UseSetupSpan is True.

ProductionSetupCost / UseProductionSetupCost: Overrides the cost of setting up when UseProductionSetupCost is True.

CycleSpan / UseCycleSpan: Overrides the Operation CycleSpan when UseCycleSpan is True.

QtyPerCycle / UseQtyPerCycle: Overrides the Operation QtyPerCycle when UseQtyPerCycle is True.

PostProcessingSpan / UsePostProcessingSpan: Overrides the Operation PostProcessingSpan when UsePostProcessingSpan is True.

StorageHrs / UseStorageHrs: Overrides the Operation Storage Hours when UseStorageHrs is True.

CleanSpan / UseCleanSpan: Overrides the Operation CleanSpan when UseCleanSpan is True.

CleanoutUnitsRatio / UseCleanoutUnits: Overrides the item's Unit Volume ratio and/or the operation product's unit volume ratio override when UseCleanoutUnits is True.

CleanoutCost / UseCleanoutCost: Overrides the cost of running a cleanout when UseCleanoutCost is True.

MinVolume / UseMinVolume: Overrides the Resource's MinVolume when UseMinVolume is True.

MaxVolume / UseMaxVolume: Overrides the Resource's MaxVolume when UseMaxVolume is True.

MinQty / UseMinQty: Overrides the Resource's MinQty when UseMinQty is True.

MaxQty / UseMaxQty: Overrides the Resource's MaxQty when UseMaxQty is True.

PlanningScrapPercent / UsePlanningScrapPercent: Overrides the Operation PlanningScrap Percent when UsePlanningScrapPercent is True.

HeadStartSpan / UseHeadStartSpan: This will override the Operation HeadStartSpan when UseHeadStartSpan is True.

This field can be used to specify a preference to run the item on the resource. For example, higher HeadStartSpan values will indicate that operations can be scheduled to the resource further before the Operation’s JIT Slack. This will result in the resource being assigned to the operation earlier than resources with lower HeadStart values.

Note: It is required to also define an Product Code on the product rule in order for the Headstart Span to be enforced.

MaterialPostProcessingSpan / UseMaterialPostProcessingSpan: Overrides the Operation MaterialPostProcessingSpan if UseMaterialProcessingSpan is True.

TransferQty / UseTransferQty: Overrides the Item's Transfer Quantity when UseTransferQty is True.

Priority / UsePriority: Overrides the Resource's Priority when UsePriority is True.

Behavior

Whenever an operation associated with a manufacturing order which produces a Product is scheduled to run on a Resource which has a Product Rule configured for that product, the defined production efficiency overrides from the Product Rule are used to calculate the values of whichever properties have the "UseThis" property set to True in the Product Rule.

In order for any operation of a manufacturing order to be considered eligible to be impacted by a product rule, one or more of the M.O.'s operations must produce the product defined in the product rule. Simply assigning a Product Name to the M.O. without also configuring at least one of the operations to produce the product to inventory is not sufficient to trigger a product rule.

All operations of a manufacturing order which produce the product which schedule on the resource defined in the Product Rule will have the same overrides applied to it unless the Product Rule also specifies a Product Code. If a Product Code is specified, then the Product Rule will only affect the efficiencies of the defined operation where the operation has its Product Code defined which matches the product rule's Product Code.

If there is a product rule being used for the operation, it can be easily found by using the Find Product Rule button on the Products tab of the job dialog box.

Manual Configuration

Typically, Product Rules are imported via the Product Rules Mappings, though they can also be configured and maintained manually from the Product Rules tile of the Scenario Data Board.

The tile is divided into 3 tables of data. On the top half, all manufactured items which are eligible for product rules are displayed on the left side. All resources are displayed on the right side. Across the bottom half of the tile, all currently configured Product Rules and their settings are displayed.

Create a Product Rule

To create a new Product Rule, first select a manufactured item from the top left grid. Next, select a resource from the top right grid that the rule should apply to. Optionally, enter a Product Code into the text input in between the 3 grids (though this can be edited later). Click the New button from the tile toolbar to add a grid row to the Product Rules grid based on the current selections.

Edit a Product Rule

Edit the production efficiency properties as desired by editing them in the grid cells directly. Be sure to check the box to "UseThis" which is associated with the property whose operation setting should be overridden by the Product Rule. For example, to use the Product Rule to define a CycleSpan of "10 minutes", enter "00:10:00" into the CycleSpan property cell and check the box in the UseCycleSpan grid cell, as shown here:

Once the settings are defined, be sure to click the Save button from the tile toolbar to save the configuration.

Delete Select Product Rules

Click to select 1 or more grid rows from the configured Product Rules grid, then click the Delete button from the tile toolbar. Confirm Yes to delete the rule(s) if prompted.

Clear All Product Rules

Use the Clear button from the tile toolbar to clear all Product Rules data from the scenario.

See Also

Product Rules Mappings

Item Mappings

Resource Mappings

Resource Operation Mappings

Scenario Data Board

Inventory Plan Board

Capacity Planning Board

Cleans</div>
        </section>
      
        <section class="article" id="article-175-schedule-clock-planning-horizon">
          <h3 class="article-title">Schedule Clock &amp; Planning Horizon</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/planning-horizon" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In PlanetTogether, scheduling constraints are enforced within a time period referred to as the Planning Horizon. The Planning Horizon starts at the current Schedule Clock date and time, and ends after a defined duration. Within this horizon, material and capacity constraints are enforced by various scheduling processes (optimization, drag/drop, etc.). Beyond the end of the Planning Horizon, though, these constraints are ignored and operations which are short on their required materials or which need to schedule on resources which do not have available capacity within the horizon will be allowed to schedule without these constraints enforced.

Operations and activities cannot be scheduled any earlier than the Schedule Clock which also defines the start of the Planning Horizon. It is possible, using Track Actuals, to view finished work in the Gantt and various grids from dates and times before the current Schedule Clock, but since the system has no concept of Resource Capacity earlier than this date, no required work can be scheduled there.

Jump to section:

Planning Horizon

Advancing the Schedule Clock

Planning Horizon

The Planning Horizon duration is defined in the Scheduling Options section of the System Settings board within a planning area. This setting impacts all scenarios within the planning area.

When optimizing, work is scheduled no earlier than the start of the planning horizon (defined by the Schedule Clock date and time), and may be scheduled far beyond the planning horizon. While capacity and material constraints are only enforced within the planning horizon, operations are not released to schedule until after their dependent predecessors' scheduled end date, and/or until they are released to schedule according to their Need Date minus JIT slack allowance.

The Planning Horizon can be visualized in the Gantt Board. Dates and times before the start of the horizon are shaded a solid gray color. The horizon itself has clear horizontal borders drawn on each resource row with alternating light blue and white shaded areas representing each row, as well as vertical time interval indicators which assist with placement of drag/drop scheduling and drawing the eye to the particular date and time according to the current zoom level. The horizon is also the only area where capacity intervals are scheduled and visible. The area beyond the planning horizon is shaded a solid light yellow color. While operations and activities may schedule out here, note that they are potentially not adhering to any configured material or resource capacity constraints.

Advancing the Schedule Clock

The Schedule Clock is only advanced manually unless Automatic Actions are configured to advance it on a schedule. This enables flexibility in determining what schedule process works best for each organization. For example, some might work with daily schedules and thus are advancing the Schedule Clock daily, while others might work with weekly schedules and only advance once per week.

It's important to note that once the clock has been advanced forward, there is no way to advance it backwards due to the system not being able to properly restore capacity intervals. The only way to revert a clock advance is to Undo the clock advance action, or restore the entire planning area data back to an earlier restore point on the PlanetTogether server.

To advance the clock to a future date and time, use the Clock dropdown on the right side of the Main Toolbar.

From the dropdown of options, users may select a specific date and time with quick buttons to update the selections to Today and Now or to Add 1 Day to the specified date and time. These buttons will not trigger any actual Clock Advance, they will simply update the date and time in the dropdown in preparation for the user to click one of the Advance Scenario(s) buttons.

When there are multiple scenarios in the Workspace, users will see two options - Advance All Scenarios or Advance Active Scenario.

The Advance All Scenarios button will advance the clock to the specified date and time for all scenarios in the Workspace which are not configured to be isolated from clock advances.

The Advance Active Scenario button will only advance the clock to the specified date and time in the currently active scenario.

If Quick Actions are enabled then the Clock quick action button advances the date of the clock for all scenarios in the planning area which are not configured to be isolated from clock advances to today's date, but preserves the same time of day that was set previously.

See Also

Main Toolbar

System Settings

Scenario Management</div>
        </section>
      
        <section class="article" id="article-272-setup-time">
          <h3 class="article-title">Setup Time</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/setup-time" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Accurately modeling setup time is crucial to creating an accurate schedule. Setup Time in PlanetTogether is meant to represent the amount of time required to prepare a resource for a production run. It gets executed at the start of a scheduled operation, and can be configured in many ways, including sequence-dependent setup which allows for varied setup to be configured where the setup time is determined by the sequence of the scheduled operations on a resource. Setup time is incurred at the start of an operation, before the first cycle begins. It is a fixed duration which does not scale according to the total number of cycles that the operation will complete.

Considering there are a plethora of ways to configure when setup time should be incurred, it's possible that multiple configurations of setup will apply to the same scheduled operation at the time it schedules. When this occurs, PlanetTogether assumes that the longest setup duration of all applicable sources should be incurred.

Consecutive Setup can be configured in various areas which, when enabled, will combine together all applicable setup time configurations which are configured with consecutive setup.

Jump to section:

Resource Setup

Operation Setup

Operation Attribute Setup

Setup Table: Setup Code Table

Setup Table: Attribute Code Table

Setup Table: Attribute Number Range Table

Product Rules

Visualizing Setup Time

Optimizing the Schedule to Reduce Setup Time or Cost

Resource Setup

Each resource has many configuration options which determine when setup is to be incurred on the resource and which setup time configuration strategy to use when determining how much setup to incur on scheduled operations.

Setup Span

A SetupHrs property can be imported via Resource Mappings, or the Setup duration may be defined from the Capacity Planning Board on any resource. This setup duration will be applied to an operation according to the Setup Included property value. If Consecutive Setup Times is marked True then this duration of setup may be added to other sources of incurred setup time.

Setup Included

WhenProductChanges: Setup will be incurred when the MO Product of the scheduled operation's associated MO is different from that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

WhenSetupCodeChanges: Setup will be incurred when the Setup Code of the scheduled operation is different from that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

WhenEitherChanges: Setup will be incurred when either the MO Product or the Setup Code of the scheduled operation is different from that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

Always: Setup time is always incurred on all operations scheduled on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

Never: Setup time will never be incurred on any operation scheduled on this resource.

WhenSetupNumberChanges: Setup will be incurred when the Setup Number of the scheduled operation is different from that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

WhenSetupNumberIncreases: Setup will be incurred when the Setup Number of the scheduled operation is higher than that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

WhenSetupNumberDecreases: Setup will be incurred when the Setup Number of the scheduled operation is lower than that of the previously scheduled operation on this resource. The amount of setup time incurred is defined in the Setup property on the resource by default. The operation's defined setup time may also be considered if the Use Operation Setup Time property is set to True on the resource.

UseSetupCodeTable: Setup will be incurred according to applicable Setup Code table logic.

UseOperationAttributes: Setup will be incurred based on Operation Attribute configurations of each operation scheduled on this resource.

Use Operation Setup Time

When True, the scheduled operation's defined setup time will be considered as a possible source of incurred setup time.

Consecutive Setup Times

When True, the resource's configured SetupHrs or Setup duration will be added to other sources of incurred setup as if each source of setup duration must be completed one after the other (rather than one or the other).

Omit Setup on First Activity

When True, the first scheduled activity on the resource will never incur setup time.

Omit Setup on First Activity in Shift

When True, the first scheduled activity of each online or overtime capacity interval will never incur setup time.

Current Setup

This functionality is deprecated in software version 12.2.0 and newer. The recommended approach to configuring the system to calculate setup at the start of the schedule is to use Track Actuals and import one or more finished activities on each resource where setup should be incurred at the start.

Current Setup codes can be defined in order to create a setup sequence for the first scheduled activity on the resource. The first scheduled activity's Product or Setup Code or Setup Number will be compared to the Current Setup property value to determine if and/or how much setup time to incur on the first scheduled activity. These values are typically imported to represent the Product or Setup Code or Setup Number value of the last finished activity on the resource since otherwise there is no point of reference when comparing differences between the previously scheduled activity and the first scheduled activity on the resource's schedule.

Product: The External ID of the product which was produced on the most recently finished activity on this resource.

Setup Code: The Operation Setup Code of the most recently finished activity on this resource.

Setup Number: The Operation Setup Number of the most recently finished activity on this resource.

Max Same-Setup Span

⚠️ Warning

This feature is removed from software version 12.3.0 where Setup Code has also been removed. The same behavior can be mimicked by using the Same Attribute Code Runtime sequencing factor when Attributes are used to incur setup.

This feature acts as a scheduling constraint which forces operations with varying setup codes to be scheduled on the resource after the specified duration in terms of combined operation run time. When set to any duration greater than 00:00:00, operations with the same Setup Code will only be allowed to schedule one after the other on the resource as long as their combined Run Time does not exceed the Max Same-Setup Span duration. An operation will not be considered eligible to schedule on the resource if its Setup Code matches that of the previously scheduled operation and its Expected Run Time when combined with previously scheduled operations' Run Times would exceed the Max Same-Setup Span duration.

When combined with the Same Setup Code sequencing factor, this setting can force a sort of sawtooth schedule with regards to the Setup Code value between operations after the specified duration.

Setup Time Efficiency Multipliers

This feature impacts the setup time setup incurred by operations on the resource. This value can be changed to reflect whether the setup time of the resource is faster or slower than usual. Values greater than one represent a resource setup that is faster than usual, while values less than one represent a resource setup that is slower than usual.

For example, if an operation is configured to incur 2 hours of setup time but the resource is configured with a Setup Time Efficiency Multiplier of "0.5" then the operation will actually incur (1/0.5) * 2 = 4 hours of setup time.

Adjust the ActivitySetupEfficiency property value to impact setup duration which is incurred by Operation or Activity Setup time standards, or Operation Attributes (excluding attribute table logic). Adjust the ChangeoverSetupEfficiency property value to impact setup duration which is incurred by Attribute Table configurations.

See Also

Resource Mappings

Capacity Planning Board

Track Actuals 

Internal Activity Mappings

Operation Setup

An operation's setup span is a simple way to define a static amount of setup that must be incurred by the operation. It may be imported via the SetupHrs property of the Resource Operation Mappings, or configured manually in the Job Details Dialog.

In order for a Resource to incur Setup from the Operation Setup setting, the UseOperationSetupTime property of the resource must be set to TRUE.

Activity Setup Override

If an operation is split into multiple activities, each activity's setup duration may be configured independently of other activities of the same operation.

See Also

Resource Operation Mappings

Job Details Dialog

Internal Activity Mappings

Operation Attribute Setup

Custom Attributes can be configured on the Job Operation to incur setup time under various conditions. In order for the system to consider an attribute when determining Setup duration or cost, the attribute's AttributeType property must be set to Setup (which is the default value if no value is imported for the property). The conditions under which setup is to be incurred by the attribute is determined by the AttributeTrigger property value. If ConsecutiveSetup is marked True then the duration of setup incurred by the Attribute may be added to other sources of incurred setup time.

AttributeTrigger options are as follows:

Always: Setup will be incurred whenever an operation with this attribute is scheduled.

CodeChanges: Setup will be incurred whenever this attribute's Code changes from one scheduled operation to the next on the same resource.

NumberChanges: Setup will be incurred whenever this attribute's Number changes from one scheduled operation to the next on the same resource.

NumberHigher: Setup will be incurred when this attribute's Number increases from one scheduled operation to the next on the same resource.

NumberLower: Setup will be incurred when this attribute's Number decreases from one scheduled operation to the next on the same resource.

LookupByCode: Uses an Attribute Code Table to determine the setup duration. 

LookupByRange: Uses an Attribute Number Range Table to determine setup duration.

Never: The attribute is not used for Setup duration calculations.

The setup duration is determined by either the DefaultDurationHours property of the Attribute, or the value of the DurationHrs property of the Operation Attribute when the DurationOverride property on the Operation Attribute is set to True. Attribute Code Tables or Attribute Number Range Tables will override these other sources of duration if the attribute is configured to trigger setup based on the table logic.

The setup cost is determined by either the DefaultCost property of the Attribute, or the value of the Cost property of the Operation Attribute when the CostOverride property on the Operation Attribute is set to True. Attribute Code Tables or Attribute Number Range Tables will override these other sources of cost if the attribute is configured to trigger setup based on the table logic.

See Also

Attributes

Attribute Mappings

Operation Attribute Mappings

Job Details Dialog

Setup Table: Setup Code Table

Setup Code Tables may still be used in software versions 12.2.1 and older, but are removed from software version 12.3.0 and newer. Attribute Code Tables should be used instead.

Each Operation may be assigned a Setup Code. The Setup Code is allowed to be any text string identifier, such as the color of the paint on a paint line or a batch code associated with the operation. 

Setup Code Tables define a matrix of code change relationships and the setup time and/or cost which should be incurred based on the Setup Code values of two consecutively scheduled operations on the same resource. This may result in varying setup duration and/or cost depending on the sequence of scheduled operations. For example, switching from Setup Code "Yellow" to code "Blue" will incur a setup time, but switching from "Yellow" to "Yellow" will have zero setup.

Each Setup Code Table may be assigned to one or more resources. Only the resources in which the table is assigned will use its matrix logic to calculate setup time between operations.

An operation's SetupCode property can be imported via the Resource Operation Mappings, or manually configured or maintained in the Batching/Setups tab of the Operation section of the Job Details Dialog.

A Setup Code Table matrix can be imported via the Setup Code Table Mappings, or manually configured or maintained from the Data Tables tile of the Scenario Data Board.

Setup Code property values can be visualized in Gantt block label text or the Activity Scheduling grids of the Activities Board.

See Also

Resource Operation Mappings

Setup Code Table Mappings

Job Details Dialog

Scenario Data Board

Setup Table: Attribute Code Table

This solution assumes that custom Attributes exist in the data model and are configured for Setup calculations. See the Operation Attribute Setup section of this page for configuration information.

Attribute Code Tables define a matrix of code change relationships and the setup time and/or cost which should be incurred based on the Code values of one or more Attributes of two consecutively scheduled operations on the same resource. This may result in varying setup duration and/or cost depending on the sequence of scheduled operations.

For example, an Attribute named "Color" may be configured so that switching from code "Yellow" to code "Blue" will incur a setup time, but switching from "Yellow" to "Yellow" will have zero setup.

A wildcard value can be defined on the table if there are values that need a setup or clean to or from any unspecified value. In this screenshot the wildcard symbol is defined as *.

Precedence defines whether the setup or clean time and/or cost incurred in the event that a lookup matches two different wildcard entries is defined by the wildcard entry whose wildcard character or string is used in the PreviousOp or the NextOp code column.

Example

If the scheduled sequence changes from Code "A" to Code "B" and the Code Table defines these wildcard rules (where "*" is the wild code character):

A to *

* to B

then Previous precedence would use the duration and cost incurred by the * to B entry while Next precedence would use the A to * entry.

Each Attribute Code Table may be assigned to one or more resources. Only the resources in which the table is assigned will use its matrix logic to calculate setup time between operations.

Attributes can be imported via Attribute Mappings, or manually configured or maintained in the Attributes tile of the Scenario Data Board.

Operation Attributes can be imported via Operation Attributes Mappings, or manually configured or maintained in the Attributes tab of the Operation section of the Job Details Dialog.

An Attribute Code Table matrix can be imported via Attribute Code Table Mappings, or manually configured or maintained from the Data Tables tile of the Scenario Data Board.

Custom attributes and their Code values can be visualized in Gantt block label text or the Activity Scheduling grids of the Activities Board.

See Also

Attributes

Attribute Mappings

Operation Attribute Mappings

Attribute Code Table Mappings

Scenario Data Board

Job Details Dialog

Setup Table: Attribute Number Range Table

This solution assumes that custom Attributes exist in the data model and are configured for Setup calculations. See the Operation Attribute Setup section of this page for configuration information.

Attribute Number Range Tables define a matrix of numerical range change relationships and the setup time and/or cost which should be incurred based on the Number values of one or more Attributes of two consecutively scheduled operations on the same resource. This may result in varying setup duration and/or cost depending on the sequence of scheduled operations.

For example, an Attribute named "Size" may be configured so that switching from number "5" to number "10" will incur some amount of setup time, while switching from number "10" to "20" might incur even more setup time.

Each Attribute Number Range Table may be assigned to one or more resources. Only the resources in which the table is assigned will use its matrix logic to calculate setup time between operations.

Attributes can be imported via Attribute Mappings, or manually configured or maintained in the Attributes tile of the Scenario Data Board.

Operation Attributes can be imported via Operation Attributes Mappings, or manually configured or maintained in the Attributes tab of the Operation section of the Job Details Dialog.

An Attribute Number Range Table matrix can be imported via Attribute Number Range Table Mappings, or manually configured or maintained from the Data Tables tile of the Scenario Data Board.

Custom attributes and their Number values can be visualized in Gantt block label text or the Activity Scheduling grids of the Activities Board.

See Also

Attributes

Attribute Mappings

Operation Attribute Mappings

Attribute Number Range Table Mappings

Scenario Data Board

<a href="https://www.planettogether.com/knowledge-v12/job-d</div>
        </section>
      <h2 id="cat-concepts-warehouses-items-inventory" class="category-header">Concepts &gt; Warehouses, Items &amp; Inventory</h2>
        <section class="article" id="article-187-items-inventories-warehouses-storage-areas">
          <h3 class="article-title">Items, Inventories, Warehouses, &amp; Storage Areas</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/items-inventories-warehouses" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Items represent the individual products, raw materials, or components that are involved in the production process and are tracked and managed within PlanetTogether. Warehouses are areas where the items are stored. Storage Areas are separate sections within the warehouse for storing items, and may represent storage tanks or silos where material can be stored. When an Item is mapped to a Warehouse in PlanetTogether, the mapping is considered an Inventory record. When an Item is mapped to a Storage Area, the mapping is considered an Item Storage record.

PlanetTogether is capable of forecasting inventory levels per warehouse over the time horizon of the schedule, and can be configured to constrain operations from scheduling until their required material is forecasted to be available. This helps to create accurate schedules which consider material availability.

Tools are available in the user interface to display details of each item's inventory level over time. Metrics and Targets can also be configured to quickly alert planners and schedulers of material shortages, expired material consumption, or over-production or over-stock at points in time within the schedule horizon.

Jump to section:

Key Features and Functionality

Multi-Warehouse Configurations

Storage Areas as Tanks

Data Object Management

Key Features and Functionality

Jump to sub-section:

Storage Areas

Job Operation Stock Material Requirements

Job Operation Products

Material Requirements Planning (MRP)

Tracking Material Consumption

Tracking Inventory Levels

Purchase Orders (Purchases to Stock)

Sales Orders

Lot Control

Shelf Life

Storage Areas

A Storage Area represents an area within a warehouse to store material. Each area can be configured as to what can be stored there, when, and how much.

Single Item Storage defines whether or not the Storage Area can store multiple items at once. If this field if true, only one item can be stored at a time, material must be withdrawn or disposed before another item can be stored. If false, there is no limit to how many different items can be stored together.

Within a storage area, a Max Quantity can be set per item. The system will not allow anymore than this value to be stored in the area for that item. If a Max Quantity is not set, it is assumed there is no maximum.

A Disposal Quantity can also be set. When the value in the storage area drops below this amount, the field Dispose Immediately will define what happens. If the field is True, the remaining quantity is removed from the area as soon as it fall below the value. If set to False, it will remain in the storage area until the area is needed for another item, then will be disposed of to make room.

Storage In Flow Limit and Storage Out Flow Limit fields define how many sources can fill or withdraw material from the storage area simultaneously. In order to enforce these constraints, the fields Constrain In Flow and/or Constrain Out Flow need to be true.

Counter Flow defines if the storage area can be both filled and withdrawn from at the same time. Counter Flow Limit is the total number of simultaneous storage and withdrawal sources. If 0, only one direction can occur at a time. In order to constrain the counter flow, Constrain Counter Flow must be set to true.

A storage area can be constrained to only fill from or supply materials to certain resource. This is defined by Storage Area Connectors. To see more about these constraints, see the article Storage Area Connectors.

For more information, see: Storage Areas Board.

Job Operation Stock Material Requirements

Job operations can be configured to require one or more stock materials. These material requirements comprise what might be called the "bill of materials" (BOM) in other systems. Each requirement may specify:

The name or unique ID of the Item

The quantity required

Which warehouse the item should be sourced from (optional)

Which storage area the item should be sourced from (optional)

Whether the required item should be considered a scheduling constraint based on the item's availability or lead time, or if it's a non-constraint

Other more detailed settings and configurations may also optionally be defined. These options are detailed in the Material Mappings page and/or the Job Details Dialog page.

Job Operation Products

Job operations can be configured to produce one or more products to inventory. The inventory can be made available in batches while the operation is running, or it can be made available all at once at the start or end of the operation. Each operation product may specify:

The name or unique ID of the Item

The quantity produced

Which warehouse the item will be stored in

Which storage area the item will be stored in (optional)

When the product will be available for other operations to use it

Other more detailed settings and configurations may also optionally be defined. These options are detailed in the Product Mappings page and/or the Job Details Dialog page.

Material Requirements Planning (MRP)

In PlanetTogether, MRP (Material Requirements Planning) is an automated process that compares the demand for materials and finished goods (jobs, sales orders, forecasts, and safety stock) to the on-hand and planned supply to generate planned jobs and/or purchase orders which can help to plan to satisfy unmet demands.

Details of how to configure an environment to use the MRP feature can be found in the MPS/MRP Planning article.

Tracking Material Consumption

Each stock material requirement that is consumed from inventory over the course of the entire schedule horizon is listed in the Materials Board grid. Use the data to see where materials are coming from to supply each consuming operation and when they are needed. This data can help material planners to ensure that the release and procurement of materials are in sync to meet demands, and can be used to flag inventory shortages or expired material consumption.

Tracking Inventory Levels

Inventory levels per Warehouse over the span of the schedule horizon can be tracked in detail from the Inventory Plot Report tile of the Inventory Plan Board. This interactive tile loads in-depth details of all adjustments (production, purchases, and consumption) of the inventory that is selected in the Inventory grid. The resulting Inventory Details grid can be filtered as needed to gain specific insights on those adjustments over the course of the schedule horizon.

For a detailed view of inventory levels per Storage Area, use the Storage Areas Board and the plot report available there.

Purchase Orders (Purchases to Stock)

Purchase orders represent an increase in the stock of materials added to inventory at specific dates and times. The Purchase Orders Board offers insights into scheduled and received Purchase Orders over the current schedule horizon and allows users to manage their Purchase Orders and/or create new ones as needed. Details of each configurable setting can be found in the Purchases to Stock Mappings page.

Sales Orders

Sales orders generally represent customer orders for finished products. They are used to track demand in the Inventory Plan (as they consume inventory) and are often used in conjunction with the MRP function. 

Use the Sales Orders board to maintain customer orders and make manual adjustments as needed.

Lot Control

When an item is lot controlled, each positive adjustment to inventory levels (on-hand lots, purchase orders, and job products) may optionally be assigned a lot code for tracking and pegging purposes. Similarly, each negative adjustment to inventory levels (job material requirements or sales orders) may be assigned one or more allowed lot codes which allow them to source their material from a specific production lot that matches the allowed code(s).

The Lot Controlled Planning article details how to configure this feature and how it can be used to control inventory production and material consumption in batches.

In software version 12.3.0 and newer, all items are lot controlled, though the use of lot codes for pegging production to consumption remains optional.

Shelf Life

Shelf life is a type of lot control which allows the system to calculate (or the scheduler to define) an expiration date on each lot that gets produced or added to inventory so that it may either be consumed before its expiration date, or else will expire and be discarded so that no operation may use its material. Operations may also be configured to be allowed to consume expired material which can help to bring awareness to the scheduling impact of materials expiring when combined with schedule analytics available in the Materials Board that can show which operations are consuming expired goods.

Multi-Warehouse Configurations

PlanetTogether supports tracking, sourcing, and supplying inventory from/to multiple warehouses. Any number of warehouses can be created and configured to supply one or more of the plants in the data model.

Stock Material Requirements

Job operation stock material requirements may either specify which warehouse the material must be sourced from via the WarehouseExternalId field, or allow the system to allocate any source from any available warehouse at the time of scheduling.

Supply from multiple warehouses can be enabled via the MultipleWarehouseSupplyAllowed field.

Job Item Production

All job operation products must specify which warehouse the produced item will be stored in via the WarehouseExternalId field. If part of the batch needs to go into one warehouse and other parts to other warehouses, multiple product objects can be defined per operation with varying WarehouseExternalId destinations.

Transfer Orders

Transfer Orders can be used to model inventory transfers between two warehouses.

Storage Areas as Holding Tanks

Tank scheduling is intended for manufacturers that use large storage vats or silos to hold materials such as beverages, chemicals, or formula blends for an indeterminate amount of time. Storage areas and Storage Area Connectors can be used to show tank storage and consumption over time, and to model various constraints that each tank may adhere to. For example: which item(s) may be stored in it; its maximum storage quantity; whether it can store more than 1 item at a time; whether it can be filled and drained simultaneously; how many connections are allowed to fill or drain it simultaneously; and which resource(s) are allowed to supply or consume from it.

Item Storage

Use Item Storage Mappings to define which items are allowed to be stored in the tank storage area.

Single Item Storage

Typically, tanks and silos may only store a single material at a time. Set the SingleItemStorage setting on the Storage Area to True in order to enforce this constraint during scheduling so that scheduled job operations will never add materials to a storage area when it's occupied by another material. When this is true, all stored material must be withdrawn or disposed before another item can be stored.

Automatic Disposal

It's quite common for small amounts of material left over at the end of a large batch to be disposed of. Define a minimum quantity threshold to be stored in the tank via the DisposalQty setting on the Item Storage. If the stored inventory level of the item in the storage area ever drops below this quantity, then the system will be allowed to discarded the remaining material. Set the DisposeImmediately setting to True on the same Item Storage to trigger the disposal immediately upon breaching the minimum threshold. Otherwise, when this is disabled (False), the inventory will not be disposed until a scheduled job needs to use the tank to refill it with new material.

Additionally, it may be prudent to dispose of expired materials so that a fresh batch of material can be stored in the tank. Each Item can be configured with a shelf life duration via the ShelfLifeHrs property. The system's default behavior is to automatically immediately dispose of all expired material according to its production date and the configured shelf life duration. 

Note that expired material may be preserved in the system if there are any job operations whose stock material requirement is configured to allow expired material to supply it via the AllowExpiredSupply property.

Disposals can be visualized in the Inventory Plan's On-Hand Plot Report tile, or the Storage Area board's Plot Report tile.

Maximum Inventory Threshold

Each Item Storage mapping within a Storage Area can be configured with a Maximum Quantity via the MaxQty property. This becomes a scheduling constraint so that no job operation may schedule to store material in the storage area if it will violate this maximum inventory threshold for the item that it's producing.

Storage Flow Constraints

Storage In Flow Limit and Storage Out Flow Limit fields define how many sources can fill or withdraw material from the storage area simultaneously. In order to enforce these constraints, the fields Constrain In Flow and/or Constrain Out Flow need to be true.

Counter Flow defines if the storage area can be both filled and withdrawn from at the same time. Counter Flow Limit is the total number of simultaneous storage and withdrawal sources. If 0, only one direction can occur at a time. In order to constrain the counter flow, Constrain Counter Flow must be set to true.

✅ Example

Storage Area can be filled and pulled from simultaneously

This case demonstrates a situation where a holding tank can be filled by as many as 3 resources while material is also being withdrawn from the tank as it supplies other resources with material.

Scenario:

In a craft brewery, the final stage before packaging is holding the finished, filtered beer in a Bright Beer Tank (BBT). This tank acts as a buffer to ensure the packaging lines have a continuous, uninterrupted supply.

3 fermentation vessels are each finishing the production of the same flagship IPA. As each batch finishes, it is transferred to a central holding tank. The brewery's piping allows only one fermenter to transfer beer into the BBT at a time.

While the BBT holding tank is being filled from the fermentation vessels, the beer is also being fed through pipes to each of the Canning, Bottling, and Kegging lines. All three packaging lines can run simultaneously if needed.

Data Model Configuration:

A BBT holding tank acts as the Storage Area. 

The Storage Area is configured with flow limits:

StorageInFlowLimit is set to 1. This constrains the Storage Area to only be filled by one of the 3 connectors at a time.

StorageOutFlowLimit is set to 3. This allows the Storage Area to be drained by 3 connectors simultaneously.

CounterFlowLimit is set to 4 since there is one source filling the area plus as many as 3 draining.

ConstrainInFlow, ConstrainOutFlow, and ConstrainCounterFlow are all set to True.

Scheduling Impact:

Only one Vessel is allowed to schedule at any time to supply the BBT tank. Each of the Canning, Bottling, and Kegging lines are allowed to consume from the tank at the same time.

IPA beer is added to the BBT tank in batches. Once there is enough liquid in the tanks for the canning and bottling lines to consume it, they are allowed to schedule even while the tank is still being filled.

Storage Area Connectors

Storage Area Connectors establish in-flow and out-flow connections between Storage Areas and Resources. Each connector can define which resource(s) can fill which storage area(s) via in-flow connections, as well as which storage area(s) can feed or supply which resource(s) via out-flow connections. Each connector is required to have at least one in-flow connection or one out-flow connection defined. Connectors can also enable or disable counter-flow (simultaneous in-flow and out-flow), and can optionally be configured to limit the number of simultaneous in-flow and out-flow connections.

For more information, see: Storage Area Connectors.

Job Operation Product Configuration Options

RequireEmptyStorageArea: Set this operation product property to True to prevent tank storage areas from being "topped off" with the same material that is currently stored in the tank if there is room to add more. Set it to False if adding to a non-empty tank storage area is acceptable.

Storage Visibility in the Gantt

When a Storage Area Connector is configured with an in-flow relationship between a resource and a storage area, a Storage Level indicator can be visualized in the Gantt on the connected resource.

The Storage Height slider in the Capacity Tools tile in the Gantt must be increased to the desired height for the storage level to be drawn on the Gantt.

⚠️ Warning

This functionality has limitations in when storage levels will be drawn:

Storage Area limitation: This is only compatible with storage areas that are configured with an in-flow connection in a single storage area connector. If a storage area is configured with in-flow connections in multiple storage area connectors, then storage will not be drawn in the Gantt.

Resource limitation: This is only compatible with resources that are configured with an in-flow connection in a single storage area connector. If a resource is configured with in-flow connections in multiple storage area connectors, then storage will not be drawn in the Gantt.

Data Object Management

Items, Warehouses, Inventories, Storage Areas, and Item Storages are manually created or imported as data objects.

Data Import

Item objects are imported via Item Mappings;

Warehouse objects are imported via Warehouse Mappings which are then associated with Plants via Plant Warehouse Mappings;

Inventory objects via Inventory Mappings.

Storage Area objects are imported via Storage Area Mappings;

Item Storage objects are imported via Item Storage Mappings;

For lot controlled items, on-hand inventory must be imported as lots via Lots Mappings;

In software version 12.3.0 and newer, all items are lot controlled, therefore on-hand inventory must be imported as lots via a combination of Lots Mappings to define the lot object, and Item Storage Lots Mappings to define which Storage Area(s) the lot is stored in and how much inventory is stored in each (one lot may be stored in multiple storage areas).

Manual Creation

Warehouses should be created first and configured to supply one or more Plants. These can be created and their properties modified from the Warehouses and Inventories tab of the Inventory Management tile of the Scenario Data Board. Be sure to expand the grid to show nested grids after creating the warehouse in order to view and configure the supplied plants. Be sure to Save all changes via the button in the top left corner.

Items and Inventories are best created from the Items and Inventories tab of the Inventory Management tile of the Scenario Data Board. Similar to the warehouse creation process, after adding an item to the model, click the "+" sign to view the nested grids to allow for the assignment of the item to one or more warehouses. For lot controlled items, click the "+" sign next to the warehouse name to expand another nested grid to allow for viewing and defining inventory Lots associated with the inventory record. Be sure to Save all changes via the button in the top left corner.

After Items and warehouse inventories are created, Storage Areas and their Item Storages can be created. At least one storage area is required per warehouse, and at least one item storage is required per storage area. These are created and their properties modified from the Warehouses and Inventories tab of the Inventory Management tile of the&n</div>
        </section>
      
        <section class="article" id="article-200-lot-controlled-planning">
          <h3 class="article-title">Lot Controlled Planning</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/lot-controlled-planning" target="_blank">Source</a></p>
          <div class="article-content">Old Article Versions

This article is updated to reflect the latest software functionality. For older software versions, download and refer to the appropriate document version:

Software Version(s)
Download Link

12.1.4.x thru 12.2.1.x
LotControlledPlanning_12.2.1.pdf

Key Concept

A material lot refers to a batch of a product or material which was either manufactured or received together. Lots typically share a common characteristic, such as being purchased or produced on the same date or on the same production line, or by using the same batch of component materials. Each lot is identified by a unique code or ID that can be used for tracking its production and consumption over time. As a result, lot control helps with quality control and traceability and enables schedulers and planners to create schedules which adhere to specific constraints such as "first in, first out" or "last in, first out" allocation and shelf life duration. Assigning lot codes to material and product batches also aids in minimizing the impact of product recalls issued by vendors and manufacturers alike.

In PlanetTogether, all items and inventories are lot controlled so that any positive adjustment to inventory levels (on-hand lots, purchase orders, and job products) of the material is stored and distributed as a unique lot. 

Each lot may optionally be assigned a Lot Code for tracking and pegging purposes. Similarly, each negative adjustment to inventory levels (job material requirements or sales orders) may be assigned one or more Allowed Lot Codes which allow them to source their material from specific production lots that matches one or more of the allowed codes.

Shelf life lot control adds another dimension by forcing a lot to expire after a certain amount of time since it was received or produced so that consuming jobs or sales orders can't use expired materials.

Jump to section:

Configuration Options

On-Hand Inventory

Lot Production

Lot Consumption

Lot Traceability and Visibility

MRP & Lot Control

Configuration Options

Lot Codes

Imported Lots of on-hand inventory and Job Product lots may each be assigned a Lot Code. Lot code enforcement is handled by also setting the LimitMatlSrcToEligibleLots property to True on the Lot or Job Product.

Lot codes enforce pegging of a specific lot to a specific consuming job operation. If a Lot has a Code assigned and LimitMatlSrcToEligibleLots is True, then it will only be allowed to be consumed by job operations whose material requirement specifies the lot code in the Allowed Lot Codes property (see below).

Allowed Lot Codes

The AllowedLotCodes property is set on the Stock Material Requirement of a job operation. It accepts a comma-separated list of Lot Codes that the operation is allowed to source material from.

⚠️ Caution

Be sure to only separate the list of values with commas; do not follow the commas with spaces. For example:

✅ Good:

LotCode1,LotCode2

❌ Bad:

LotCode1, LotCode2

Shelf Life

The ShelfLifeHrs property of an Item can define by when the item's lots should be consumed or else expire after a certain duration after their production. The system will use this value to calculate how long after a lot is produced that it can be stored in inventory and used to satisfy job operation material requirements.

Shelf life is enforced as a scheduling constraint by default, but setting the AllowExpiredSupply property on the stock material requirement to True will prevent the item's lots from expiring and allow operations to consume expired material. When expired material is consumed, it can be visualized in the Materials board grid via columns Expired Material Used and Expired Quantity Used. These allow for alerts and metrics to be configured to alert schedulers and planners of expired materials being used so that they may make necessary manual adjustments to the production and/or consumption of the lot(s) as needed to ensure that the most of its inventory gets used before it expires.

On-hand lots can optionally be assigned an ExpirationDate, but if this value is omitted then the system will use the LotProductionDate property (required) plus ShelfLifeHrs to determine the lot's expiration date.

After a lot's expiration date has passed, if no operations are allowed to consume expired material, then a negative adjustment will be visible in the Inventory Plot Report of the Inventory Plan board which shows the amount of the lot that expires.

A ShelfLifeWarningHrs property can be set that will trigger a warning when a material is scheduled to be consumed within this number of hours of its expiration date. Warnings can be visualized in the Materials Board grid where the field NearExpiry will be checked/true. The Activities Board grids also show a MaterialsNearExpiry field that will list all materials that are scheduled to be consumed within their warning range.

On-Hand Inventory

Since storage area inventory is tracked by production lots, on-hand inventory must also be represented by lots. On-hand lots can be imported (import lot objects via Lot Mappings and then set the quantity and storage destination via Item Storage Lot Mappings), or they can be created manually using the Inventory Management tile of the Scenario Data board. 

Lot Production

Jobs

Each job operation Product output is added to warehouse storage as a new Lot according to the operation's scheduled status and the operation product's Inventory Available Timing setting. Each job product may optionally be assigned a Lot Code which will require that consuming operations or sales orders also have the lot code listed as one of their Allowed Lot Codes in order to be eligible to consume from the lot.

If no lot code is defined and the option to Limit Material Source to Eligible Lots is False (and combined with the UseLimitMatlSrcToEligibleLots property set to True), any job or sales order with a requirement for the item may consume the lot so long as the consuming demand does not have an Allowed Lot Code defined.

Note: This functionality is not currently compatible with MRP-generated jobs. MRP will always set a lot code on all production of lot-controlled items.

Purchase Orders

Purchase orders may also be assigned a Lot Code. While typically imported via Purchases to Stock Mappings, lot codes may also be assigned to existing purchase orders in grid edit mode from the Purchase Orders board, or assigned at the time of manual creation via the New Purchase to Stock popup dialog.

Lot Consumption

Stock Material Requirements

Job operation materials may be pegged to one or more lots of material by defining one or more lot codes in the Allowed Lot Codes property. Use a comma-separated list to define more than one allowed code (do not include a space between the values). If the expectation is to source material partially from one lot and partially from another (or partially from many), then the Allow Partial Supply property must be set to True. Additionally, if the allocation logic is expected to source from the oldest lot first or from the most recently produced lot, then the Material Allocation property must also be set accordingly.

Use Oldest First: Source material from the oldest produced lot(s) first.

Use Newest First: Source material from the most recently produced lot(s) first.

Material consumption may optionally be delayed by a specified number of hours from the allowed lot(s) production date(s) in the condition that some amount of time needs to pass after the lot is produced or received before it can be consumed. Use the MinAgeHrs property to specify the delay duration.

Material consumption of shelf-life controlled items may also optionally be configured with the MinRemainingShelfLifeHrs property which requires that the lot must have at least this number of hours of shelf life remaining before it expires in order for it to be considered eligible to be consumed by the operation.

If it's desirable to allow expired materials to be consumed to give schedulers and planners better visibility into expiring lots, setting the AllowExpiredSupply property on the stock material requirement to True will prevent the item's lots from expiring and allow the operation to consume expired material.

In cases where an operation is expected to consume a specific amount of an item from one lot and a specific amount of the same item from another lot, multiple material requirement entries can be assigned to an operation which list the same required item but different Required Quantity and/or Allowed Lot Codes values. In these cases, it is not necessary to flag Allow Partial Supply to True.

Sales Orders

Sales Orders for lot-controlled items may be assigned one or more Allowed Lot Codes in an effort to hard-peg the order to one or more production jobs. Similar to stock material requirements, the Allowed Lot Codes property accepts a comma-separated list of codes when more than one are allowed to be distributed to the order. If multiple sources are allowed, then the Allow Partial Allocations property must be set to True, and the Material Allocation property may optionally be set according to the desired allocation order:

Use Oldest First: Source material from the oldest produced lot(s) first.

Use Newest First: Source material from the most recently produced lot(s) first.

Note: This pegging is not a scheduling constraint for the production job(s), nor is it a sales order distribution constraint; it's mostly for informational purposes. The job(s) which produce the lot(s) will schedule according to standard release rules, sequencing factors, resource capacity, material availability, and other constraints while the sales order inventory adjustment will be listed in the Inventory Plot Report tile grid at the date and time that it is needed according to its Required Available Date rather than the date and time that the supplying job(s) are scheduled to finish.

💡 Tip

When hard-pegging firm production orders to sales orders using lot codes, it's advisable to set the OrderNumber property on the job equal to the associated sales order(s) Name or External Id so that schedulers may easily see which sales order(s) are fulfilled by which job from the Jobs Board grid.

More custom solutions and data can be included in custom job or sales order User Defined Fields as well to make other data visible in the respective board grids.

Lot Traceability and Visibility

Inventory Plan Board

A useful tool for tracking lot production and consumption is the Inventory Plot Report tile of the Inventory Plan board. In particular, the Inventory Details section grid offers the following insights:

Dates and times of all production or consumption adjustments (property: Date and Time)

The amount of material which was added or removed from inventory (property: Change Qty)

The source of the production or consumption (property: Reason)

The job name of the associated job, if applicable (property: Job Name)

The sales order name of the associated sales order, if applicable (property: Sales Order)

The lot code of the associated lot, if applicable (property: Lot Code)

Filter criteria may be applied to any one of the grid columns in order to hone in on specific adjustments. For example, a filter could be applied to the Lot Code property to show all adjustments for a specific lot code.

Materials Board

Lot consumption and production of all scheduled jobs may be tracked from the main grid of the Materials Board. In particular, the following grid properties offer valuable insights:

Lot Codes (Material)

Lots Used

Operation Product Lot Code

Supply Description

Earliest Expired Usage

Expired Material Used

Uses Expired Material

Expired Quantity Used

Shelf Life Warning Hours

Near Expiry

Materials Near Expiry

Filter criteria may be applied to any grid column, and many associated job, manufacturing order, path, operation, and activity properties may optionally be exposed to offer detailed insights into each scheduled material consuming operation.

Gantt Board

Certain details of lot production and consumption can be visualized in the Gantt by exposing certain operation properties in segment labels and/or tooltip text. In particular, the following grid properties offer valuable insights:

Operation Product Lot Code

Operation Material Requirement Lot Codes

Operation Material Requirement Lots Used

Activity Produced Lot Expiration

Additionally, with Activity Links enabled from the Gantt (and Inventory Links enabled in User Settings), selecting a scheduled activity block which produces a lot will draw links from it to each consuming scheduled activity block.

The Job Watch Gantt tile may be helpful to isolate the production and consumption of a lot as well. To add a job to the Job Watch Gantt, right-click a scheduled activity block and select Analysis ➡️ Watch Job. From the resulting Job Watch Gantt tile, choose the option in the top left corner to Show Related Jobs to see all job production and consumption associated with the selected job.

Sales Orders Board

Sales orders can be imported or manually configured to specify which lot codes are allowed to supply it. The allowed lot codes can be exposed in the main Sales Orders grid to help track sales order pegging.

Purchase Orders Board

Purchase orders can be imported or manually configured to include a lot code to act as a production lot. The lot code can be exposed in the Purchase Orders grid from the Purchase Orders board to assist with tracking PO lot production.

User Defined Fields and Attributes

User Defined Fields (UDFs) can be imported or manually added to Job, Operation, Item, and Sales Order objects. Similarly, custom Attributes may be imported or manually added to job Operations.

These are custom fields that allow users to see and track data that matters most to them in the relevant boards and grids where PlanetTogether's default properties may fall short. Each UDF and Attribute can be exposed in any associated grid layout when configured to do so, so the inclusion of UDFs and Attributes related to lot production and consumption can assist in curating tools for planners and schedulers alike within the interface which otherwise would not be possible.

MRP & Lot Control

PlanetTogether's MRP/MPS Planning feature adheres to some specific logic when it's used to generate jobs and/or purchase orders to satisfy demands from preserved jobs, sales orders, forecast orders, or safety stock. Some basic principals of MRP with regard to lot controlled planning:

MRP won't generate jobs or purchase orders for demands which already specify allowed lot codes. In these cases, it is assumed that firm orders or purchase orders will be imported or manually created to supply the demands.

When MRP generates jobs or purchase orders to satisfy any demand, it will assign MRP-generated lot codes to the original demand and the created supply.

Each time MRP is re-run, it will regenerate and assign new MRP lot codes to any preserved demand which does not have a preserved supply as long as the lot code follows the pattern of an MRP lot code (starts with "MRP" followed by a space, then some number of digits). 

See Also

Item Mappings

Lot Mappings

Item Storage Lots Mappings

Product Mappings

Material Mappings

Sales Order Mappings

Purchase Order Mappings

MPS/MRP Planning

Inventory Plan Board

Materials Board

Jobs Board

Gantt Board

Sales Orders Board

Purchase Orders Board

MPS/MRP Planning</div>
        </section>
      <h2 id="cat-concepts-workspaces" class="category-header">Concepts &gt; Workspaces</h2>
        <section class="article" id="article-296-board-tile-settings">
          <h3 class="article-title">Board Tile Settings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/board-tile-settings" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Each board has a set of tiles and a tile menu that spans the vertical space of the board along its left side. This document offers information about each of the tile settings that can be toggled for each board's tile menu.

Access the Tile Settings by clicking the gear icon in the lower left corner of any board.

Open tiles undocked as movable windows

When enabled, each tile will open as an undocked window.

Close open tiles

Click this button to close all open tile of the local board. Open tiles on other boards which are not open or not currently in focus will not be impacted.

Toggle Inline Menu

When enabled, the tile menu will display "Inline" when opened or expanded, meaning it will displace the contents of the open tiles to make room for the tile menu to be fully visible alongside the tile windows. The menu will remain expanded until the user clicks the "hamburger" menu icon in the top left corner to collapse it.

When disabled, the tile menu will display as an "Overlay" when opened or expanded, meaning it will expand visually over the top of any open tile window. The menu will collapse itself as soon as the user selects one of the tiles to open it, or if they click the "hamburger" menu icon in the top left corner.</div>
        </section>
      
        <section class="article" id="article-280-download-scenario">
          <h3 class="article-title">Download Scenario</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/download-scenario" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Users with appropriate user permissions may download the latest scenario file to their local system. This may be a way to create a scenario backup, or to fetch the latest scenario file so that it can be shared with PlanetTogether Support or a server administrator for troubleshooting purposes, etc.

Simply click the menu option and choose a folder to write out the scenario to.

See Also

User Management

Delivering Files to PlanetTogether Support

Instance Manager

Restore a Scenario from a Recording Backup</div>
        </section>
      
        <section class="article" id="article-269-grid-personalization">
          <h3 class="article-title">Grid Personalization</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/grid-personalization" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Grids in Version 12 are highly customizable. This article will detail how to use each grid customization feature to give users a personalized experience.

Most grid customizations are stored as part of the active grid Layout which is stored in the active user's Workspace Profile. For more information about managing layouts and workspace profiles (including sharing them with other users), see:

Layouts, Metrics, and Targets

Workspace Profile Management

Jump to section:

Filter Editor

Conditional Formatting

Grouping

Auto Filter Row

Column Chooser

Footer Row

Column Locks and Anchors

Export Grid Data

Keyboard Shortcuts

Select All: Use Ctrl+A to quickly select all grid rows.

Filter Editor

Use a right-click menu option Filter Editor… to display an advanced filter editor dialog which allows users to manage all filter criteria in the same dialog.

The Filter Editor is best interacted with in the top section. The text input in the lower half offers the code view of the applied filter but is not necessary to interact with - the code will build itself as the filter groups and conditions are managed above by interacting with the various components.

The Filter Editor displays filter criteria as a tree structure where nodes are filter conditions. The entire expression is organized as a tree where parent nodes are logical operators that link individual filter conditions.

Each component can be interacted with - the Field Name, the Criteria Operator, and the Operand Value to build a precise query. Simply click on the component and use the predictive suggestions or type to enter the desired criteria. Hover the mouse over the Group Operator in order to see Add/Delete controls to add a condition or delete the entire group of conditions. Depending on the type of property selected in the Field Name, the Criteria Operator may offer different options (i.e. "Exactly"; "Begins with"; "Contains"; etc. for text properties, or "Equals"; "Greater than"; "Less than"; etc. for numerical properties). Use the Apply button to preview the filter in the grid while keeping the editor open, or click OK to save the filter and close the editor dialog.

Conditional Formatting

Conditional formatting logic can be applied to each grid column. Access the Conditional Formatting Rules via a right-click menu option Conditional Formatting. The formatting rules will be applied based on the values of the property that was clicked.

The Conditional Formatting options are very similar to the Microsoft Excel application's formatting options. First, expand the Conditional Formatting menu and choose to format based on Unique/Duplicate values, or various predefined rules, or even opt to build a custom condition.

Depending on which option is chosen, a dialog will appear with inputs to specify both the criteria for when to apply formatting, as well as the style of formatting to apply when the criteria is met. There is also an option to Apply formatting to the entire row which will help to draw visibility to the condition by formatting the entire row rather than the specific cell that matches the criteria.

The Custom Condition dialog offers a similar interaction as the Filter Editor. For ease of use, it is advisable here to select criteria using the top half of the dialog rather than the text/code section.

Use the Manage Rules dialog to manage all rules applied to the grid. This dialog offers some more advanced functionality which allows users to customize the formatting style, apply rules to multiple columns, move prioritization of each rule up/down (helpful when multiple rules may apply to the same cell), or delete or unset a rule. Access the Manage Rules dialog from the Conditional Formatting sub-menu from the right-click menu:

Here is a preview of the available options:

Note that multiple conditions can be applied to the same cells/rows. If multiple conditional formatting rules match a cell's value then the one that is lowest down in the list of rules from the Manage Rules dialog will "win" and its formatting will be applied to the cell/row. The rule priority can be adjusted via the Manage Rules dialog by clicking once to select a rule and using the Up or Down buttons to move it Up in the list (lower priority) or Down in the list (higher priority).

Grouping

Use a right-click menu option Group By This Column to quickly group the grid data by the selected column property, or choose Show Group By Box to allow for one or more property columns to be dragged into the Group By Box to enable grouping and nested grouping of the data.

Here is an example of the Jobs board grid grouped by Product Name:

Group By Box

With the Group By Box displayed, column headers can be dragged into the box to create grouping logic.

When multiple columns are dragged into the Group By Box, nested groups of data are created. The hierarchy of parent-to-child nested grouping can be arranged by dragging and dropping the the column header either to the left of any existing grouped property to assign the new property as the parent, or to the right of the existing property to assign the new property as the child or secondary group. The hierarchy can be visualized by connected lines between each of the grouped properties.

Right-click menu options are available to expand or collapse or clear all grouped data by clicking in any empty space within the Group By Box.

A Group Summary Editor can be accessed by right-clicking any of the grouped properties and choosing the Group Summary Editor option. This dialog can be used to customize the visibility of various groups of data including the total grouped item count, as well as various statistics like the sum or average or minimum or maximum value, etc. of the grouped data depending on the property type that is being grouped.

Auto Filter Row

Use a right-click menu option Show Auto Filter Row to display a quick filter applicator that will appear near the top of each column.

When enabled, the auto-filter row will appear along the top of the grid just underneath the column headers. The filter row offers a quick means to perform searches of each specific column data. Simply click the mouse into the white space and begin typing to search for some data from the associated column property.

Click the icon to the left of the empty space to quickly select the filter application criteria. Different options may be displayed depending on the type of data that may be displayed in the column (dates, strings of text, numbers, etc.).

The Filter Editor may be used to quickly clear out any/all applied filters, or select Clear Filter from the right-click menu of the property column header.

Column Chooser

The Column Chooser is accessible via the right-click menu from any grid column header. 

This dialog allows users to hide/show property columns in their current grid layout. Each board's grid may offer different properties to display relevant to the data objects associated with the board.

Hidden/Shown Columns

The dialog is split with the currently hidden columns on the left side and the currently visible columns on the right. Users may click once on any one or more properties from either side to select them, then drag and drop from one side to the other to either show the selected properties in the grid (if dragging from Hidden to Shown) or hide them (if dragging from Shown to Hidden).

A quick way to hide or show a property column is to double-click the column name from either the Hidden or Shown side and it will move itself to the opposite side.

Each property column name from the Shown side can be click+dragged up or down to reorder the selected property among the other properties.

Quick and arrow buttons are available to quickly hide or show all columns in a single click.

Use the search inputs at the top of each of the Hidden Columns and/or Shown Columns to search for specific property names.

Click the Preview button in the lower left corner of the dialog to apply the changes to the grid in the background without actually saving them.

Click Save and Close to save the changes and close the Column Chooser dialog, or click Cancel to revert all changes and close the dialog.

Footer Row

A Footer can be displayed across the bottom of any main board grid to offer data such as summations of numerical values, average of all numerical values, minimum values, maximum values, or a count of the number of objects in each row. Right-click any column header from any main board grid and choose the option to Show Footer.

When enabled, a blank footer row will appear at the bottom of the grid. Users may then right-click underneath any grid property column in the blank footer space and choose which data to display in that column's footer.

If one property summary is already displayed, then an option to Add New Summary will be given so that more than one of the data summary options can be displayed at the same time.

Different data summary options will be available depending on the type of data in the property column (dates, plain text, numbers, etc.).

The footer can be hidden by right-clicking any of the grid column headers and choosing Hide Footer.

Column Locks and Anchors

Grid columns may be locked to the left or right of the screen or anchored in their currently ordered position so that those columns are always in view as users scroll left to right to view the various grid data. To lock or anchor a grid column, right click its grid column header and choose either Lock Left, Lock Right, or Anchor.

A solid vertical border will be drawn on the grid when it's displaying a locked or anchored column. All locked columns will remain visible on the screen as the user scrolls left/right. Anchored columns will remain anchored to their current grid position as the user scrolls left, but will remain in view as the user scrolls to the right past the anchored property column.

To disable locks or anchors, right-click the locked or anchored column and re-select the appropriate lock or anchor option.

Export Grid Data

Any grid layout can be exported to various formats: XLSX, CSV, PDF, or HTML. To export a grid layout, click the export icon to the right of the grid layout dropdown selection, then choose the desired format.

A prompt will appear to select a folder to save the exported file. Choose an appropriate folder and rename the file if desired, then click Save.

See Also

Layouts, Metrics, and Targets

Workspace Profiles Dashboard

Grid Edit Mode</div>
        </section>
      
        <section class="article" id="article-342-layouts-metrics-and-targets">
          <h3 class="article-title">Layouts, Metrics, and Targets</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/layouts-metrics-targets" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Metric indicators can be configured from any one of the main board grids (Jobs, Sales Orders, Materials, Inventory, Purchase Orders, etc.) to quickly visualize statistics related to any applied filtered layout/view of a grid. Simply apply a custom filter to one or more of the grid columns to create a filtered grid layout, then enable metrics to track the number of objects that match the filtered criteria at any given time. Each tracked metric will update with each scheduling change to give schedulers real-time feedback about how their changes are impacting what matters most to them and their organization.

Take it a step further and define a target (goal) for the desired number of filtered layout results and the corresponding metric tile will include information about how close the current schedule is to meeting that target.

Even more detail can be tracked by adding metric aggregate summaries - sum, average, minimum, or maximum values of any of the numerical columns which are visible in the associated grid layout.

Jump to section:

Layouts

Metrics, Targets, and Summaries

Sharing Metrics

Metrics Board

Layouts

Layouts are custom configured views (filtered or not) of any grid data in PlanetTogether. Users can create as many layouts as needed from any of the various grid tiles. Each layout may contain unique configurations of visible columns and filters to hide and show the desired data in the order that it's most important to the user. 

Layouts are selected and configured from the layout dialog box visible at the top of each grid.

Switch between existing layouts

Quickly switch from one layout to another using the down arrow icon in the layout dialog box to expand the dropdown of options, then clicking on any of the layouts in the list to select it.

Create a new layout

Click the "+" icon in the layout dialog box to open the New Layout dialog. Enter a name for the new layout, then click Accept and Close to create a new layout as a copy of the currently selected one.

The newly created layout will automatically be activated to allow for customization of the columns, filters, and metrics settings.

Customize a layout

Use any of the Grid Personalization features to hide or show particular columns, reorder columns, apply filters to one or more of the columns, add column grouping logic, add conditional formatting, etc. to create the perfectly curated layout that shows precisely the data that matters.

Any pending edits made to a layout must be saved before they are stored in memory. When edits are pending that need saved, two icons will appear in the layout dialog box next to the name of the currently selected layout:

Use the checkmark icon to Save all changes, or use the back arrow to Revert all changes back to the previously saved version.

Delete a layout

Click the red "x" icon from the layout dialog box to delete the currently selected layout. Deleted layouts cannot be recovered except through importing or activating a shared Workspace Profile.

Metrics, Targets, & Summaries

A Metric in PlanetTogether is a custom performance indicator which helps to evaluate the performance of some specific object data property or sum of many properties based on the current data and schedule. A Target is a desired value or goal for the particular metric. A Summary metric may also be tracked to track the Sum, Average, Minimum, or Maximum value of any numerical property that is visible in the associated grid layout.

Enable and configure a metric and target

Metrics are enabled or activated from Layouts, so first create a grid layout which represents the data that should be tracked over time using a metric. Next, enable metric tracking on the layout data by clicking the icon next to the selected layout name. A dialog will appear where the metric can be configured:

Metric Active: Toggle the switch to On to activate the metric for tracking in the Metrics Board.

Priority Level & Color: Use the slider to select a Priority which will determine the sort order of the metric in the Metrics Board. Leave the preset color as-is, or toggle the Use Custom Color switch to reveal a color picker to choose any color desired.

Counts: Configure how the metric count should appear in the metric slide in the Metrics Board.

Show as: Select to show the count as a Number or a Percent

Show Zeros: When enabled, if the associated grid layout has no matching grid rows, the metric will still be visible in the Metrics Board with a value of 0. When disabled, the metric will not appear in the Metrics Board if its value is 0.

Show On Change Only: When enabled, the metric will only appear in the Metrics Board if the most recent scheduling change made an impact on the metric's value. Otherwise, if a schedule change did not impact the metric's value then it will not appear in the Metrics Board.

Show Changes Highlighting: Toggle whether or not to show an indicator in the metric slide when the value increases or decreases.

Changes Highlight Settings: When Changes Highlighting is enabled, choose whether Lower or Higher values are preferred so that preferred progress (up or down) shows a green indicator while unfavorable progress shows a red indicator.

Targets: Toggle the option to Enable Targeting in order to see a quick comparison of the current metric value versus the desired target or goal value. Choose whether the target is represented as a Percentage or a Decimal, then set the Value of the desired target. Optionally set a Tolerance level as well to allow some flexibility in what gets reported as missing the target.

Metric Preview: As the metric settings are configured, the metric preview will update in real time to give the user an idea of what to expect the metric to look like.

Metric Summaries: Click the "+" plus sign in the top right corner of the Metrics Settings dialog to create a new Metric Summary, or use the tabular navigation in the same window to switch the view between existing metric summaries.

💡 Tip

In software version 12.3.0, this is made a bit more obvious and moved to the lower left corner as a button with text Add new summary metric.

Column Summary Settings

Column: Choose which numerical column's data should be tracked.

Aggregate Type: Select from Sum, Average, Minimum, or Maximum aggregate types to track of the selected column.

Metrics Shortcuts

Right-click options are available from the Metrics Board. Simply right-click any metric tile in the Metrics Board to see quick options to edit Metric Settings or Disable Metric.

Disable a metric or target

To disable a target within a metric, navigate to the metric layout (click on the metric slide from the Metrics Board to quickly bring it into the forefront) and click the icon next to the layout dialog box to bring up the metric configuration dialog. Simply flip the Enable Targeting toggle to Off and save the change.

To disable the entire metric, navigate to the metric layout, click the icon next to the layout dialog box to bring up the Metrics Settings dialog, then toggle the Metric Active switch at the top to the off position and save the change.

Sharing Metrics

Layouts and metrics and any related target information is stored as part of a user's Workspace Profile, so to share layouts and metrics with other users the relevant Workspace Profile settings must be shared.

Once a workspace profile is shared, other users may import all of the profile settings or they may select to only import metrics and layouts into their existing profile.

For more information about exporting, sharing, and importing workspace profiles, see: Workspace Profiles Dashboard.

Metrics Board

The Metrics Board offers a categorized dashboard of all configured Metrics. Hover the mouse cursor over any of the titles or numbered statistics or target icons to see more detailed information about the metric or target data. Click anywhere in any of the metric slides to bring its grid layout into focus for deeper analysis of the data.

For more information, see: Metrics Board.

See Also

Grid Personalization

User Settings

Metrics Board

Workspace Profiles Dashboard</div>
        </section>
      
        <section class="article" id="article-244-system-settings">
          <h3 class="article-title">System Settings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/system-settings" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Use the System Settings to configure Workspace-wide settings and options (they impact all scenarios within the Workspace).

Access System Settings via the dropdown option from the Main Toolbar.

Jump to Section:

Automatic Actions

System

Scheduling

CoPilot

Automatic Actions

Configure certain actions to be performed at defined time intervals to allow the system to perform basic tasks on a schedule.

Each of the Settings slides contains a toggle switch to enable/disable the action to run automatically, and a textbox entry to enter a custom CRON scheduling statement.

CRON expression syntax looks a bit odd to the untrained eye. It's recommended to use this CRON expression generator to assist with curating the Automatic Actions schedule:

CRON Expression Generator - Quartz

Each CRON expression must provide 7 values separated by spaces. Here is a list of represented values, arranged from left to right in the CRON expression:

Second

Minute

Hour

Day Of Month

Month

Day Of Week

Year

* * * * * * *
| | | | | | | 
| | | | | | +-- Year (range: 1970-2099)
| | | | | +---- Day of the Week (range: 1-7 or SUN-SAT)
| | | | +------ Month of the Year (range: 0-11 or JAN-DEC)
| | | +-------- Day of the Month (range: 1-31)
| | +---------- Hour (range: 0-23)
| +------------ Minute (range: 0-59)
+-------------- Second (range: 0-59)

Note: The system assumes that the days and times reflect the UTC time zone and will be executed accordingly.

Any number of actions may be enabled to run on a schedule, and each may be configured to run on the same schedule or on different schedules. Each action may even be configured to run on multiple schedules. When configuring multiple schedules for the same action, separate each CRON expression with a new line.

Scheduling multiple actions to run at the same time may produce undesirable results if one action is dependent on another but its dependent doesn't finish before the next action is triggered (i.e. Optimize then Publish -- the appropriate schedule may not be published if Optimize is not given enough time to complete).

The following actions can be scheduled to run automatically:

KPI Snapshot: Use the KPI Settings slide to create KPI snapshots at the set intervals.

Advance the Clock: Use the Advance Clock Settings to advance the clock to "now" at the set intervals for all scenarios which are not isolated from clock advances. The clock will be advanced to the day and time that the CRON scheduled task is executed.

Compress the Schedule: Use the Compress Settings to compress the schedule according to the shared Compress Settings at the defined intervals.

JIT Compress: Use the Compress Settings to JIT compress the schedule according to the shared Compress Settings at the defined intervals.

Publish: Use the Publish Settings to publish the scenario data according to the configured Publish Options at the defined intervals.

Refresh Data: Use the Import Settings to refresh data from the configured data source at the defined intervals for all scenarios which are not isolated from imports.

Optimize Plan: Use the MPS/MRP Optimize Settings to run the MPS/MRP Optimize Plan function to regenerate jobs and a schedule according to the configured MPS/MRP Settings at the defined intervals.

Optimize Schedule: Use the Optimize Settings to run the Optimize Schedule function to schedule jobs according to the configured Optimize Settings at the defined intervals.

System

Jump to sub-section:

Data Options

Undo Options

User Options

Publish Options

Scheduling Options

Data Options

Track Actuals

Track Actuals deals with the preservation of activity blocks in the Gantt for finished activities. Typically, a finished activity will be removed from the Gantt, but with a value greater than 0 for the Track Actuals Maximum Age (and with the user setting to [x] Display Block Actuals enabled), finished activity blocks will remain on the Gantt until the clock is advanced beyond the specified time frame from the activity's finish date.

Track Actuals Maximum Age: The length of time (backwards) from the start of the schedule clock to an activity's finish date that Track Actual finished activity blocks will remain visible on the Gantt. 

Track Actuals Performance Thresholds: Visual indicators will be added to the finished activity block in the Gantt if its reported finish time was faster or slower than it was originally estimated to take (based on its cycle times and required quantity) by the defined percentage values.

Activities which were reportedly finished faster than originally anticipated by a percentage greater than or equal to the configured Fast threshold will display a light green highlighted segment in the finished activity block.

Activities which were reportedly finished slower than originally anticipated by a percentage greater than or equal to the configured Slow threshold will display a red highlighted segment in the finished activity block.

Prevent auto delete of tracked actuals: When enabled along with Track Actuals Maximum Age, finished jobs which are omitted from import will not be auto-deleted as long as the duration between the jobs' Reported Finish Date and the current schedule clock does not exceed the Track Actuals Maximum Age duration. This assumes that the Job Mappings option to Auto-delete omitted records is enabled in the Import Mappings.

Note:

In order to visualize the Block Actuals finished activity blocks in the Gantt, the user setting to [x] Display Block Actuals must be enabled.

Tracking Data

Quantity Rounding: Round all quantity values in the system to the selected precision (number of decimal places). Fine-tuning this setting can help with certain quantity rounding issues that arise when splitting jobs or operations and often when MRP is tasked with generating jobs with very specific quantities according to the job template configurations.

TimeSpan Rounding: Round all timespan values using the number of decimal places specified. Rounds the time in TICKS that an activity needs to schedule.

Fiscal Year End: This date is used to calculate the quarterly revenue KPI (This Qtr Revenue)

Annual Percentage Rate: A global APR setting for all warehouses in the data model to be used to calculate carrying costs of WIP and finished goods. This value is used if the individual warehouse(s) in the data model do not specify any APR in their warehouse settings.

Incoming Data

Prevent ERP Job changes within the Stable Span: When enabled, jobs which are scheduled in the Frozen Span or Plant Stable Span will not be altered or updated by a data Refresh even if those objects have been updated in the ERP/SQL data source.

Prevent ERP Job cancel or delete within the Stable Span: When enabled, a data Refresh from the ERP/SQL data source will not cancel or delete any jobs if they are scheduled in the Frozen Span or Plant Stable Span.

Prevent ERP changes on Started jobs: When enabled, no changes will be made to jobs which are scheduled in the Frozen Span or Plant Stable Span by a data Refresh even if those objects have been updated in the ERP/SQL data source.

Prevent ERP Cancel or Delete of Started jobs: When enabled, a data Refresh from the ERP/SQL data source will not cancel or delete any jobs with one or more operations whose status is any of Started, Setting Up, Running, Post-Processing, or Cleaning.

Allow ERP Production Status to override manually updated status: When enabled, jobs or operations whose production status (or reported time or quantities or similar) have been updated manually by a PlanetTogether user are allowed to be overridden under the specified conditions in the next Update values from ERP setting.

Update values from ERP:

Never: This option has no effect on the default behavior. It's as if Allow ERP Production Status to override manually updated status remains disabled.

If Values are Greater: If the values in the ERP/SQL data source are greater than the reported quantity or time values in PlanetTogether then they will be overridden with the ERP/SQL data source values.

Always: Regardless of whether the values in the ERP/SQL data source are greater than or less than the reported quantity or time values in PlanetTogether, the values that were manually entered in PlanetTogether will be overridden by the values imported from the ERP/SQL data source.

When capability does not exist: Define how to handle cases where an operation of a manufacturing order is imported from the ERP/SQL data source with a reference to a required capability which does not exist in the data model and/or which was not imported from the ERP/SQL data source.

Reject MO: All operations of the associated Manufacturing Order will be omitted from the data import.

Omit Operation: Only the operation which references the invalid capability requirement will be omitted from the Manufacturing Order.

Create Capability: The capability will be added to the data model and the Manufacturing Order will be imported. Note that the capability will not be assigned to any resource so there would still be additional configuration to do before the operation would be eligible to schedule on a resource.

Warn if Operation length is larger than: If the value is greater than 0 then a warning will be logged in the Message Logs if an operation is imported and its calculated schedule length/duration is greater than the defined value.

Publishing Data

Maximum number of Scenario Histories to store for each Scenario: This setting is used when recording scenario history. It is used to determine how many ScenarioHistory records to remove from the ScenarioHistoryManager to prevent the collection from getting too long.

Undo Options

Maximum seconds to perform Undo: The cumulative processing time of actions that trigger scenario data to accumulate for potential undos. Smaller values cause more frequent disk access but result in less time for an undo action. Larger values require less disk access but require more time to complete undo actions. 

Limit memory used for undo sets (in MB): The maximum number of MB used to store undo sets in memory. 

Checksum diagnostics: When enabled, connected client applications will check in with the server more frequently to ensure the data in the user's client application is not out of sync with the data stored on the server.

Clear Undo History: Purge all undo sets from the scenario. This action cannot be undone.

User Options

Require passwords to be changed periodically: When enabled, all users in the system will be prompted to change their passwords at specified intervals. Not recommended for SSO integrations.

Days between password changes: Define the number of days between prompts for users to change their password.

Maximum number of failed login attempts: Define the number of acceptable failed login attempts before a user account is locked. If set to "0" then the default value of 10 is enforced. If a user fails to enter valid credentials this number of times then their account will be locked until a user administrator unlocks it.

Enable password complexity rules: When enabled, password complexity rules are enforced according to the related settings.

Minimum password length: Define a minimum password length (number of characters).

Require at least 1 uppercase: When enabled, at least 1 uppercase letter is required in user passwords.

Require at least 1 lowercase: When enabled, at least 1 lowercase letter is required in user passwords.

Require at least 1 digit: When enabled, at least 1 digit (0-9) is required in user passwords.

Require at least 1 special character: When enabled, at least 1 special character (!@#$%^&*+=) is required in user passwords.

Auto logoff users: When enabled, users who have been inactive for the amount of time specified in the Auto Logoff Timeout setting will be logged off.

Auto logoff timeout: Define the number of minutes users must be inactive before being forced to log off. Inactive users will receive a message that they are being signed out due to inactivity and can decide to remain logged in when prompted.

The Timeout Period is reset when the user changes tabs, acts (Clock Advance, Import, Publish, Optimize, MRP, etc.), or another action that causes a popup window to open.

Publish Options

Publish Destinations

Publish to SQL Server: Publish to the SQL database defined in the workspace configuration on the PlanetTogether server.

Publish to a Custom Program: Publish using a custom integrated program or application.

A custom Microsoft .Net DLL can be called directly from PlanetTogether and passed to an in-memory dataset of the entire publish dataset. Please contact PlanetTogether Support for more information about configuring the application to use a custom program.

Publish to XML: Publish to an XML file on the PlanetTogether server (saved to C:\Users\Public\Documents\APS Export Files).

Publish all Activities for a Manufacturing Order if any are Published: This setting is used in conjunction with the Publish objects dated within the next setting from the Publish Options in the main toolbar dropdown. If not publishing the entire schedule, by enabling this option then if the publish is set to include one or more activities of a manufacturing order but also exclude one or more activities of the same MO since they are not scheduled within the defined time period, those otherwise excluded activities will be included in the published data.

Limits for High-Volume Data

Select which data objects should be published.

When Retain Published Schedules is enabled under the History section, the Keep History column becomes active and specific objects must be selected if their history is meant to be kept in the publish database. If the object is not selected under Keep History then all related published data will be purged during the next publish.

Run stored procedure after Publishing

When enabled, the defined stored procedure will execute after the successful completion of the publish event. The defined stored procedure is expected to reside in the Workspace's configured Import database.

When writing a stored procedure that gets used by the Publish process, 4 parameters are required to be defined with it:

UserDefinedParameter: This is a text parameter that can pass information, like parameter strings, to the stored procedure.

PublishDate: The date/time that will be stored in the PublishDate field in the Schedules table of the APS database. This can be used in the stored procedure to only update records that were just published, as opposed to including records from previous publishes (only necessary if storing history).

Message: This is a return message that is displayed in the Log Viewer window if non-null.

Undo: This can be set to 1 to cause an undo of the last action. This is typically only used for the Net Change Publish, thus enabling the stored procedure to validate the schedule change results and undo the change if necessary.

An example of these declarations in a stored procedure:

@UserDefinedParameter varchar(8000),
@PublishDate DateTime,
@Message varchar(8000) = '' OUTPUT,
@Undo bit = -1 OUTPUT

An example of a simple stored procedure called "PT_PutData":

ALTER PROCEDURE [dbo].[PT_PutData]

@UserDefinedParameter VARCHAR(8000),
@PublishDate DATETIME,
@Message VARCHAR(8000) = '' OUTPUT,
@Undo BIT = -1 OUTPUT

AS
BEGIN
-- SP logic goes here
END

An example of how to call the simple PT_PutData procedure from the Procedures tab of the Publish Options section with the text "EP_Test, PT_Publish" defined for the @UserDefinedParameter parameter:

PT_PutData 'ERP_Test, PT_Publish'

Run program after Publishing

Run a program after Publish: When enabled, the defined program file will execute after the successful completion of the publish event. A Select Program File button is available to help users locate and select a program from their network or PC. Note that the path defined here is relative to the user's machine who executes the Publish event, so the program file that needs executed after the publish event must reside on their machine or the path to the program must represent the full path to the program file on a shared network server. Command line parameters may optionally be entered to pass to the program when it's executed.

Publish dates using server's local time instead of UTC: When enabled, the dates reflected in the publish data will be represented in the server's local time zone rather than the default behavior of publishing dates according to the UTC time zone.

History

Retain Published Schedules: When enabled, certain data objects can be preserved in the publish SQL database for the specified amount of time in the related settings.

Delete activity scheduled to start beyond the next: Purge any activity from the publish database whose scheduled start date is this many days or more after the current date.

Delete all history older than: Purge any object from the publish database that is older than this amount of time from the current date.

Delete non-production scenario history older than: Purge any non-production scenario data from the publish database that is older than this amount of time.

Net-Change

Net-change publishing is an automated publish which will trigger after any change to the schedule.

Net-Change Publishing: When enabled, data will be published to the selected publish destinations each time a change is made to the schedule.

Run stored procedure after Net-Change Publish: When enabled, the defined stored procedure will execute after each net-change publish. Requires Net-Change Publishing to also be enabled. The defined stored procedure is expected to reside in the Workspace's configured Import database.

Security for Reports that connect to Databases

Specify the security type (Windows Integrated Security or Database Security) to use for any custom Reports which connect to a SQL Database.

If using Windows Integrated Security then the reports will use the credentials of the Windows user that is configured on the PlanetTogether server to run the workspace "System" service. For server administrators, more information is available here.

If using Database Security, enter the User Name and Password of the SQL user that the system should use to access to the database.

Disable Refresh During Publish

When enabled, the Refresh button will be disabled while a Publish is in process. This will prevent potential conflicts of data or API calls or stored procedures where the two operations call to the same external systems.

Publish Analytics

When enabled, the Publish button from the Publish dropdown from the main toolbar will publish to the Analytics database which is defined in the workspace configuration on the PlanetTogether server, in addition to any of the other selected publish destinations from the Data Published options section.

Note: This does NOT need to be enabled in order for the Publish Analytics button from the Publish dropdown to publish to the configured Analytics database.

Scheduling Options

Job Demand

Set sub-job Need Dates: Set or reset the Need Dates of sub-jobs during schedule optimization. This impacts all schedule optimization, not only MPS/MRP Optimize Plan. The Recalculate JIT on Schedule Change setting must also be enabled if this setting is set to anything besides Disabled.

Disabled: Sub-job Need Dates will not be altered by the Optimize Schedule operation, although the same setting can be defined in the MPS/MRP options in the Plan dropdown from the main toolbar for use with the Optimize Plan MPS/MRP function. This setting must be set to Disabled in System Settings in order for the Plan dropdown setting to work. Otherwise, the option defined in the System Settings will override the setting in the Plan dropdown.

To earlier of JIT and scheduled start date: The need date of the sub-job is set to the earlier of its JIT start date or its parent job's scheduled start date.

To JIT date: The need date of the sub-job is set to the JIT start date of its parent job.

To start date: The need date of the sub-job is set to the scheduled start date of its parent job. 

To bottlenecked Operation start date: The need date of the sub-job is set to the start date of whichever operation is causing a bottleneck.

To overlap supply sources: The need date of the sub-job is set to the end date of the parent job minus the amount of time required for the sub-job to make its first transfer of product to inventory.

Add prefix to MRP-generated jobs:

Set sub-job Priorities: When enabled, the Priority property of all sub-jobs will be forced to the lowest value (highest priority) of its parent job's Priority. 

Set sub-job Hot flags: When enabled, the Hot property of all sub-jobs will be updated to match that of its parent job's Hot setting. 

Plant Spans

Short-term Span: The duration from the start of the planning horizon to consider as the "Short-term Span". This span of time is referenced in a few areas of the software, such as the MPS/MRP Cutoff Duration setting, a Gantt zoom level option, and in various reports.

Planning Horizon: The duration from the current PlanetTogether clock date and time that certain constraints (materials, capacity, max delay, etc.) are enforced during scheduling. The Planning Horizon duration is visually represented in the Gantt, and jobs which are unable to schedule within the horizon due to constraints are flagged in the Jobs Board grid via the Past Planning Horizon property.

Lock Activities scheduled to start within the Frozen Zone: Any activity which is scheduled inside of the Department Frozen Zone will be locked to its currently scheduled resource. See: Locking and Anchoring.

Anchor Activities scheduled to start within the Frozen Zone: Any activity which is scheduled inside of the Department Frozen Zone will be anchored at its currently scheduled time. See: Locking and Anchoring.

Set Operation Commit Dates when Anchoring and Re-Anchoring: When enabled, an operation's Commit Dates will be updated when it is anchored or re-anchored at a point in time.

See also:

Plant Stability

Scheduling

Adjust MO Quantity: If enabled, the quantity of activity will be changed by dragging and dropping one side of an activity block.

Max Delay: If enabled, this feature will force an operation's successors to be scheduled within a certain amount of time as defined by the MaxDelayHrs column of the Alternate Path settings.

[ Deprecated; now default behavior ] Auto Select Alternate Paths: If enabled, Alternate Paths will automatically be selected. This option is useful when there are multiple methods of producing an item to let the system automatically select an alternate path when the needed date of the manufacturing order is approaching.

Calculate Optimize Scores: If enabled, the optimize score will be calculated and can be visualized in the Activities Board grid.

Note: Score calculatio</div>
        </section>
      
        <section class="article" id="article-188-user-management">
          <h3 class="article-title">User Management</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/user-permissions-management" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether provides a collaborative experience between multiple levels and departments within a business by supporting any number of users who might each have unique permissions according to their role.

A user administrator can create permission groups which each is assigned unique permissions to view and/or edit various data, then assign each user to a group to assume those permissions.

Jump to section:

User Management Grid

User Properties Tile

User Preferences Tile

Scenario Permissions Tile

User Permissions Management Tile

Plant Permissions Management Tile

Users Bulk Edit Tile

User Management Grid

The User Management grid offers quick toolbar actions to perform various actions, and also gives insights into each user configured in the Workspace.

Toolbar Actions

Open: Opens the User Properties tile where various user settings can be defined including (but not limited to) User and Plant Permission Group, User Name, and whether the user is Active or should be Deactivated. Select a grid row from the User Management tile grid to switch to edit other user's properties.

New: Creates a new user with default settings. 

Copy: Creates a new user copying the settings from the user currently selected in the grid.

Delete: Deletes the user selected in the grid. Note: Deleted users will be permanently removed from the system. Users can be marked as "inactive" in the User Properties dialog, preventing login but keeping the user information in the system.

Clear: Deletes all users in the list except for the administrator user. Note: There must always be at least one administrator. 

Sign Out: Users with administrator permissions can force other users with active connections to sign out by selecting one or more users from the grid and clicking the Sign Out button. Note: The selected users will not be able to cancel this action.

Note: It's possible to import User data from SQL. See: User Mappings

See Also:

Layouts, Metrics, and Targets

Grid Personalization

Object Bulk Edit Tiles

Grid Edit Mode

User Properties Tile

Modify various user settings and properties in this tile. Select a row from the User Management grid to populate the User Properties tile with their settings, then edit as necessary.

First Name: The user's first name

Last Name: The user's last name

User Access Status: An indication whether or not the user has permission to manage other users

Password: An encrypted password input. Passwords can be changed by simply typing in a new password here and saving the change.

Require Password Reset at next login: A flag to prompt the user to change the password the next time they login to the Workspace/Instance

Active: A flag to indicate whether the user is active or not. Inactive users are not able to login.

Web App User: A flag to indicate if the user is eligible to use the Shop Views application.

Compression Type: The compression type can assist with scenario loading times when initially logging into the software if dealing with larger scenario file sizes and slower network speeds. Note: The default is Fast compression. For most connections, this setting should be left at Fast for optimal performance. However, users on slow network connections may see improved login speed and reduced action delay when using Normal or High settings. 

None: The scenario will not be compressed at all when transmitting to the client.

Normal: Standard scenario compression is used.

Fast: Less compression is used, which will take less time to compress but may make loading times longer if the scenario is larger. 

High: More compression is used, which may take a few seconds longer to load but will reduce the overall loading times.

In some cases, High compression has been found to be unreliable. When retrieving the scenario data during login, high compression could fail and cause the client to disconnect from the server and fail to log in. It's recommended to use Normal compression instead of High in the cases where users are unable to connect.

User Permission Group: Select which user permission group the user is associated with.

Plant Permission Group: Select which plant permission group the user is associated with.

Server Connection Count: Count of the selected user's active connections to the Workspace/Instance.

User Name: The user name that the individual uses to login.

External Id: A unique identifier of the user.

Description: An optional text field where any descriptive notes can be added.

Notes: An optional text field where any additional notes can be added.

User Defined Fields: Custom user fields. These serve no functional purpose by default for user objects

User Preferences

User Preferences are user-specific settings that users without general permissions to manage all users can update for themselves as needed. A user administrator can also view and set these permissions as needed from the User Preferences tile in the Users board. Select a row from the User Management grid to populate the User Preferences tile with their settings, then edit as necessary.

General

First Name: The user's first name

Last Name: The user's last name

User Permission Group: The permission group name that is currently assigned to the user

Reset Password: Click the button to display a popup dialog to allow the user to change their password.

Display Language: The user's preferred language to view the Client application

Time Zone: The user's preferred time zone to view dates and times in the Client application. Note: This does not need to be set to the same time zone that the user lives/works. It may make sense to set the time zone to that of the location of the Plant for which the schedule is being created.

Publish on Exit Reminder: Opt whether or not to be prompted to Publish changes when exiting the application, or choose to automatically Publish changes when exiting.

AskUser: The user will be prompted to publish the schedule if any schedule changes have been made since the last publish.

Disabled: The user will not be prompted to publish and the schedule will not be published.

PublishOnExit: The schedule will be published automatically if any schedule changes have been made since the last publish.

Exit Dialog Timeout: When the user is prompted to Confirm or Cancel exiting the application, the popup will remain visible to them for this defined duration. After this duration, the application will automatically close.

Photo Sensitivity: When enabled, graphics which usually flash or that may make photosensitive individuals uncomfortable are suppressed and replaced with other means to draw their attention.

Use Daylight Savings Adjustment: When enabled, all dates in the system are adjusted to accommodate daylight savings start and end which may vary depending on the selected time zone. This setting is best used when the scheduler is trying to match time zones with a plant that is in another time zone. The setting will ensure that the scheduler's shifts don't change differently than the plant's time zone. For most other time zone changes, it requires shifting capacity intervals by an hour.

Show advanced user settings: Certain settings are considered more advanced as care should be taken before exposing them to all users.

Restore to Defaults buttons for various System and User settings

Advanced sorting controls of Gantt segments

Synchronize Activity Grid layouts: When enabled, the Secondary Activity Scheduling tile layouts will be in sync with the Primary Activity Scheduling tile layouts. See: Activities Board

Auto-reload Grid while in edit mode: When enabled, all board grids will automatically refresh when a schedule or data change is made by the current or other logged-in user, even while the current user is editing grid data in grid edit mode. Disabling this option can prevent disruptions while using grid edit mode, though does not always guarantee that all grid edits will be saved if the data that is edited was modified by some other user or means.

User Prompts

Show confirmation for undo or redo actions: Opt whether or not to be prompted to confirm when performing an Undo or Redo action.

Auto-save Workspace Profile settings: Opt whether or not to automatically save changes to User settings and configurations.

Show confirmation when deleting objects: (recommended) Opt whether or not to be prompted to confirm when deleting various objects.

Clock Advance

Auto Report Progress: Opt whether or not all clock advances issued by the user should automatically progress jobs that were in progress or previously scheduled to start before the clock date after the clock advance.

Auto Finish: Opt whether or not all clock advances issued by the user should automatically finish jobs that were in progress or previously scheduled to finish before the clock date after the clock advance.

Display the full date: Opt whether or not to display the full date and time in the Main Toolbar when the clock's date is the same as the current date. If disabled then only the clock time will display (not the date) if the clock date is the same as the current date.

Optimize

Use shared optimize settings: (recommended) When enabled, Optimize Schedule and Optimize Plan (MRP) settings are defined in the System Settings rather than User Settings and are shared among all users of the Workspace/Instance. When disabled, the user is presented with an option to select from any number of previously stored preset optimize settings configurations (see below).

Use shared compress settings: (recommended) When enabled, Compress settings are defined in the System Settings rather than User Settings and are shared among all users of the Workspace/Instance. When disabled, the user is presented with an option to select from any number of previously stored preset compress settings configurations (see below).

Optimize and Compress Preset Settings Configurations

When either Use shared optimize settings or Use shared compress settings options are toggled off, a dropdown selection appears to allow the user to select an Optimize or Compress Settings Preset Configuration. Each user may create any number of preset configurations and may use the User Preferences dialog in the User menu from the Main Toolbar any time to switch between them as needed.

These settings presets are meant to act as experimental configurations so that users may test various Optimize and/or Compress settings in order to fine-tune the behavior of these functions and how they impact the schedule. Once desirable settings are discovered, it's recommended to update the shared optimize or compress settings to match the preferred user-specific settings so that all schedulers in a multi-scheduler environment are using the same settings during optimize and compress.

New: Click the green sign to create a new configuration preset configured with the default settings.

Rename: Click the Rename button to change the name of the currently selected preset configuration.

Copy: Click the Copy button to create a new configuration preset configured with the same settings as the currently selected configuration's.

Delete: When more that one preset configuration exist, a red will appear in the User Preferences dialog next to the preset configuration name. Click this icon to delete the selected configuration.

Once a configuration is selected, any changes made to the Optimize and/or Compress settings in User Settings will automatically save to the selected preset configuration.

Move

Prepend Setup On Move: When enabled, whenever activity blocks found to the left of other blocks are moved, the system will add the setup time before the current start of the activity block to prevent it from being completed later. 

Always Show Move Cursor: When enabled, the multi-move cursor will be displayed during drag/drop moves in the Gantt rather than a shadow of the block that is selected to be moved. 

Session

Scenario Preferences: Choose which scenarios get loaded when the application launches. 

Load Last Session: All scenarios which were loaded in the last login session will be reloaded on startup.

Load Production Scenario: Only the current Production scenario will be loaded on startup.

Load Last Active Scenario: Only the last Active scenario will be loaded on startup.

Load All Scenarios: All scenarios will be loaded on startup.

💡Tip

Choose one of Load Production Scenario or Load Last Active Scenario for fastest application launch performance.

KPI

Number of KPI tiles to display: Choose how many custom KPI tiles per board to display (applicable to all boards where KPI tiles are available).

Scenario Permissions Tile

The Scenario Permissions tile allows for user administrators to view and manage permissions for all scenarios which exist in the Workspace. If a user belongs to a User Permissions Group which has the permission to manage all scenarios, then they will be allowed to view and edit all scenario permissions from this tile. Other users who have access to the Users board but do not have permission to manage all scenarios will be able to view scenario permissions but will not be able to edit them.

Permissions are edited per user or per user group via the dropdown selections from the Permissions column.

User Permissions Management

Permissions groups define various permissions settings associated with groups of users. An administrator can create as many groups as needed and any number of users can be assigned to any group. One of the groups can be selected as the Default group where all newly added users will be assigned if those users are added manually or if they are imported without an assigned user group.

Each user's assigned group is managed from the User Properties tile.

Plant Permissions Management

A separate Tile allows administrators to configure specific permission sets per plant for multi-plant scenarios. Similar to user groups, users can be assigned or associated with a Plant Permissions group so that those users in the group will all have the same permissions to view and/or schedule in the specified plant.

Each user's assigned group is managed from the User Properties tile.

Users Bulk Edit Tile

Use the bulk edit tile to make changes to one or more properties for one or more users. Select one or more rows from the User Management grid, then choose properties and values that should be applied to each selected user. Finally, press the Save button to apply the changes.

For more information, see: Object Bulk Edit Tiles</div>
        </section>
      
        <section class="article" id="article-340-user-settings">
          <h3 class="article-title">User Settings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/user-settings" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Several user settings are maintained to allow users to customize their experience with the Client application interface. This article details all of the settings each user can define for themselves.

Access User Settings from the User menu dropdown in the top right of the main toolbar.

Jump to Section:

Gantt

Layout

Scheduling

Gantt

Gantt settings allow users to customize the objects in their Gantt board. Customize the appearance of activity blocks, Tooltip hover text, simplify the Gantt by removing certain objects or features, configure manual drag/drop move behaviors, and create custom Plant Resource View configurations.

Jump to section:

Block Settings

Segments

Move Settings

Simplify Gantt Settings

Tooltip Settings

Block Links Settings

Plant View Settings

Scheduling Hints

Block Settings: Note that all colors can be customized from this settings page by clicking on the color preview squares and selecting a preferred option.

Block Actuals: When enabled, a visual indicator will be added to the Gantt blocks of any Activities in progress (started, running) or Finished (will remain on the Gantt) based on the user's defined color preferences for each Performance level (Fast, Normal, or Slow) and Status (Finished or Partially Finished).

Click the "Label" buttons to customize the text that displays in the segment block. See Activity Blocks: Segments & Labels for more information.

Block Actuals & Track Actuals

In order to see the completed jobs on the Gantt, Track Actuals also needs to be set to a time grater than 0 hours. See System Settings for more information.

Block Display: 

Labels to use in the Gantt: Opt whether to use a single Gantt block label or to display custom labels per each of the visible Gantt Segments.

Highlight Un-reviewed Jobs: When enabled, jobs which are not flagged as having been "Reviewed" will be highlighted in the Gantt. Users can customize the Label and Tooltip settings here as well for Unreviewed jobs.

Text Direction: Choose whether to view the text in Gantt segments horizontally, vertically, or dynamic based on block sizes and what will fit in the provided space.

Wrap lines: Allow text wrapping inside of Gantt block segment labels.

Padding: Adjust the amount of space between the Gantt block segment text and the block border.

Use solid colors instead of dithered colors: Enabling this will help Gantt block label colors to look smoother in older 256 color display devices.

Segments: Enable or disable visibility of each segment, customize the label text of each segment (if using Individual Segment Labels), and customize the colors of each of the various statuses. See Activity Blocks: Segments & Labels for more information. 

Commitment Segment: Visualize the job's Commitment level as defined by the Commitment property value.

Material Status Segment: Visualize the statuses of the sources of required materials. At least one item type must be selected from the multi-select box in order for the segment to appear.

Buffers Segment: Visualize penetration into Drum, Shipping, and Stock buffers.

Priority Segment: Visualize job priority values as defined by the Priority property value.

Priority Ranges: Define Low, Medium and High range values based on job Priority values in the data model. Low range will begin at 0 and end at the first chosen value. Medium range will begin +1 after the low range and end at the second chosen value. All successive values are considered to be in the High range. Any value beyond the end of the defined high range will be treated as the highest value within the high range.

Color Blending: Define a min and max color value for each priority range. The resulting segment color will be a blended color value based on the priority value within the range.

Status Segment: Visualize the activity Status as defined by the Production Status property of the Activity.

Progress Segment: Visualize completion progress of the activity.

Process Segment: Visualize the amount of time spent in each of the various process steps of the activity (Setup, Run, Post-Processing, etc.).

Max Delay Segment: Visualize Max Delay violations.

Ends Early: The operation is scheduled to end too early; the gap between it and its successor is larger than the Max Delay setting allowance.

Starts Late: The operation is scheduled to start too late; the gap between it and its predecessor is larger than the Max Delay setting allowance.

Both: It both ends early and starts late.

Timing Segment: Visualize the delivery timing of the completion of the activity based on its Need Date. Use this segment to also visualize bottlenecks caused by Material shortages, Capacity unavailability, or MO Release timing.

Attribute Segment: Visualize colors from colors associated with custom operation Attributes.

Job Color: Visualize the color of the associated job. 

Product Color: Visualize the product color of the associated manufacturing order.

Move Settings: Various options related to manual activity drag/drop scheduling and Expedite.

Move Settings:

Anchor After Move: When enabled, the moved activity(ies) will automatically be anchored at the point in time where it is dropped.

Lock After Move: When enabled, the moved activity(ies) will automatically be locked to the resource in which they are dropped.

Exact Move: When enabled, drag/drop moves will start as close to the dropped date and time as constraints will allow. If another operation is scheduled at that point in time on the same resource(s), then the previously scheduled operation will be forced to move to a later date and time. When disabled, operations which are scheduled at the dropped point in time will remain where they are scheduled and the dropped operation will be scheduled immediately after the currently scheduled operation (this may still push any operation(s) scheduled after it to a later date and time).

Expedite Successors: When enabled, drag/drop moving an activity to schedule at an earlier point in time will automatically expedite all successor activity(ies) of the moved activity(ies).

Show Move Validation: When enabled, invalid manual drag/drop moves will present the user with the Move Manager dialog to give them visibility into when and where the selected operation(s) can be scheduled.

Show Move Warnings: When enabled, invalid manual drag/drop moves will present the user with the Move Manager dialog to give them visibility into when and where the selected operation(s) can be scheduled.

Compress Predecessors: When enabled, drag/drop moves which result in an operation being dragged to a point in time before its predecessor results in the predecessor operation(s) also being moved earlier to accommodate the drop time of the activity.

Predecessors Do Not Move: Predecessor Activities don't move which causes the moving Activity to be constrained by the End Date of the latest Predecessor.

Predecessors Compress: Predecessors will "Compress" meaning they can move back as far as possible without changing Operation sequence on the Resource they're scheduled on. The moving Activity will be constrained by the End Date of the latest Predecessor after the Compress.

Predecessors Move: Predecessor will be able to move and change the sequence on the Resource they are scheduled on. If the move date intersects a scheduled block, the Predecessor will move to the End Date of the Scheduled Block, which may cause the moving Activity to not be able to move to the desired Move Date.

Expedite Settings:

Anchor After Expedite: When enabled, the moved activity(ies) will automatically be anchored at the point in time where it is expedited.

Lock After Expedite: When enabled, the moved activity(ies) will automatically be locked to the resource in which they are expedited to.

Include Supplies: When enabled, the supplying job(s) of the expedited activity will also be expedited to fulfill the activity at the desired time. When not enabled, activities can only be expedited as far forward as their material constraints allow.

Simplify Gantt Settings: Use these settings to hide hours or days from the Gantt chart, hide capacity intervals or activities that start further into the future than are needed to see, and prevent various behaviors that are known to slow down the user interface while they are processing.

Time Hiding: Select hours of the day and/or days of the week to hide from view in the Gantt. This is useful if there are never activities scheduled during certain time windows and users don't want to have to view the gaps in the schedule in the Gantt.

Speed-Ups: Opt to hide capacity intervals and/or activities which start at or later than defined points in time in the future (where "now" is the PlanetTogether clock time, not necessarily the current date and time).

Capacity Intervals: Opt to prevent dragging and resizing of various types of capacity intervals to prevent unwanted changes to the intervals while trying to scroll and perform other unrelated actions in the Gantt.

Campaign Settings: Opt to alternate campaign colors by item group rather than the default behavior of just a single color used to represent all campaigns.

Daylight Savings Settings: Opt to show a shaded region on the Gantt that will highlight the 1 hour of daylight savings adjustment.

Tooltip Settings: When enabled, tooltip text will appear while hovering the mouse over activity blocks or capacity intervals in the Gantt. Use the "Label" editor dialog to customize the information presented in the tooltip. This is the same setting/toggle as can be accessed in the Gantt chart toolbar directly where it's identified by this icon: .

Label: Customize the tooltip text by clicking the "Label" button and using the Tooltip Script dialog to modify the visible text and data. 

Available Fields: Search or browse through the plethora of available object properties that can each represent some piece of data related to the Inventory, Job, MO, Operation, or Activity. Either double-click the desired property/field name, or drag and drop it from the Available Fields dialog over to the Label section.

Label: Enter text freely into the Label section, and/or use property identifiers to create a tooltip that suits users needs.

Include custom Attributes and User Defined Fields

Attributes and UDFs can be displayed in the Tooltip dialog. They can be found as standard fields in the Label editor dialog window. If the attribute or UDF was imported or created in the current user session, it may be necessary to restart the client application before the custom fields can be visualized in the UI.

In this example, the custom attribute is called "OperationAttribute01":

Preview: This section previews what the tooltip text will look like according to the label settings. At least one activity must be scheduled for the Preview to be populated with any activity data.

Keep Window Pinned: When enabled, the tooltip window will remain in a static location as the user hovers from one activity block to another. When disabled, the tooltip window follows the mouse and opens near the activity block that the user is currently hovering over.

Show Insights: Insights can offer additional information about the scheduled activity including timing details or other scheduling analysis information.

Fade Duration (ms): Define the amount of time the tooltip window takes to fade in or out.

Fade Delay (ms): Define the amount of time to delay fading out the tooltip window.

Show Delay (ms): Define the amount of time to delay the tooltip from appearing or updating when the mouse is moved to hover over an operation or capacity interval.

Block Links: Use these settings to enable or disable particular types of activity links and to increase or decrease the thickness of the line drawn on the Gantt chart which symbolizes activity links. These options are used in conjunction with the Gantt option to "Show Activity Links".

Plant View Settings: Custom Plant Views (or Gantt layouts) allow users to filter and sort the visible resources in the Gantt. Any user can create any number of Plant View layouts to suit their scheduling needs. Plant View layouts are saved as part of a user's Workspace Profile which can be shared with other users.

Create a New Plant View layout by clicking the green icon in the Plant View dropdown select field.

Use the Rename button to change the name of an existing layout.

Use the Copy button to copy the currently selected layout to a newly created one.

Use the Generate Plant Layouts button quickly generate or re-generate system-generated Plant and Department layouts.

Click the View in Gantt button to quickly open the Gantt board with the currently selected layout preselected in the Gantt.

Modify the selected layout by selecting checkboxes next to each of the Plants, Departments, and Resources that should be made visible.

When Auto Enable New Resources is enabled, any newly added resources to the data model will automatically be added to the custom layout as a visible resource in the Gantt.

Toggle on the Advanced Sorting option to sort the selected resources in a preferred order. Rearrange the order of the resources by simply dragging and dropping the order around in the Advanced Sorting window, or use the quick sort buttons Sort Alphabetically or Sort by Workcenter. 

Scheduling Hints: Toggle on/off which scheduling hints are visible in the Gantt when the Show Scheduling Hints setting is enabled from the Gantt toolbar. This can help to simplify the Gantt for end users.

Gantt Lines: Choose which Gantt Hint lines are visible when an activity block is selected.

Material Availability Line: The date and time when the latest required material is available.

Product Consumed Line: The date and time when the selected operation's product is consumed by another scheduled operation.

Drum Due Line: The date and time when the drum operation needs to be completed before it's considered late based on the Drum resource and drum-buffer-rope scheduling configuration.

DBR Release Line: The date and time when the operation is released to schedule based on the drum-buffer-rope scheduling configuration.

DBR Shipping Due Line: The date and time when the operation needs to be completed before it's considered late based on the defined DBR Shipping Buffer on the Manufacturing Order.

Activity JIT Start Line: The just-in-time start date of the selected activity.

Head Start Line: The earliest start date of the selected activity based on its JIT date minus head start/JIT slack.

Job Need Line: The date and time that the last operation of the job must be completed by to be considered on time.

Op Need Line: The date and time that the selected operation must be completed by to be considered on time.

Job Finish Line: The date and time that the last operation of the selected job is currently scheduled to finish.

Constraint Line: An indicator of the latest constraint of the selected operation which prevented it from scheduling any earlier.

Successor Line: The scheduled start date of the successor operation.

M.O. Need Line: The date and time that the last operation of the manufacturing order must be completed by to be considered on time.

Earliest Constraint Line:

Optimize Start Line: The date and time that optimization began when using the optimize setting to start optimizing at a specific time.

Start After Line: A max delay hint to indicate the date and time that the operation must start at or after in order to comply with max delay constraint settings.

Start Before Line: A max delay hint to indicate the date and time that the operation must start at or before in order to comply with max delay constraint settings.

Transfer Available Line:

Gantt Regions

Transfer Availability Region: A shaded region which spans the entire vertical height of the Gantt to show the transfer span between operations as configured in the alternate path. The region appears when the successor operation is selected.

Layout

Notification Settings: Opt whether or not to automatically hide certain categories/types of notifications after a specified period of inactivity.

Bar Options:

Hide automatically when no tiles are visible: Enable this option to hide the notification bar when no notification tiles are visible.

Open Automatically: Selecting this option allows the notification bar to automatically appear at the bottom of the screen whenever a notification slide is triggered. Applicable to notification slide types with the Pop up the notifications bar when a slide becomes active setting enabled.

Open with flyout button: Selecting this option prevents the notification bar from appearing when notification slides are queued and instead prompts the user to click a flyout button to open the notification bar if they so choose. Applicable to notification slide types with the Pop up the notifications bar when a slide becomes active setting enabled.

Never open: Selecting this option prevents the notification bar from ever appearing. Notifications are still logged in the Message Log which is accessible from the Settings dropdown menu of the Main Toolbar.

Seconds to close inactive tiles and info bubbles: Choose the number of seconds to display inactive slides in the notification bar before they automatically close. Note that slides will not close automatically unless the toggle switch is enabled to Hide automatically when inactive for the particular slide category/type.

Scheduling

Each of these settings impact a user's personal scheduling settings only. These personalized settings are used by users whose Optimize and/or Compress Preferences are configured with the shared Optimize settings disabled. 

When disabled, users are presented with a dropdown selection list of stored preset settings configurations. Choose a previously created settings configuration, or create a new one to work independently of previously defined settings. This can be helpful for experimenting with various optimization settings before committing to use one as the standard for production schedule optimization. For more information, see: User Preferences.

If a user's preferences have the shared settings options enabled then their compress and optimize settings can be configured in the System Settings area.

MPS/MRP Settings: Define MPS/MRP Optimize Plan settings to be used for Personal Optimize Settings. An alternative means to edit the same settings is to use the Plan dropdown from the Main Toolbar.

For information about each of the settings in this section, see: MPS/MRP Optimize Plan Settings

Any changes made to any of these settings will be stored in the user's currently selected Optimize Settings Preset Configuration.

Optimize Settings: Define Optimize Schedule settings to be used for Personal Optimize Settings. An alternative means to edit the same settings is to use the Schedule dropdown from the Main Toolbar.

For information about each of the settings in this section, see: Optimize Settings

Any changes made to any of these settings will be stored in the user's currently selected Optimize Settings Preset Configuration.

Set sub-job need dates: When the setting is defined here, the selected option will determine how sub-job need dates get reset by right-click and Actions tile options from the Jobs Board, Activities Board, and Gantt.

Use System Options: The Set Sub-Job Need Dates value set in the Scheduling Options section of the System Settings will dictate the behavior.

To earlier of JIT and scheduled start date: The need date of the sub-job is set to the earlier of its JIT start date or its parent job's scheduled start date.

To JIT date: The need date of the sub-job is set to the JIT start date of its parent job.

To start date: The need date of the sub-job is set to the scheduled start date of its parent job.

To bottlenecked Operation start date: The need date of the sub-job is set to the start date of whichever operation is causing a bottleneck.

To overlap supply sources: The need date of the sub-job is set to the end date of the parent job minus the amount of time required for the sub-job to make its first transfer of product to inventory.

Compress Settings: Define Compress settings to be used for Personal Compress Settings. An alternative means to edit the same settings is to use the Compress dropdown from the Main Toolbar.

For information about each of the settings in this section, see: Compress the Schedule.

Any changes made to any of these settings will be stored in the user's currently selected Compress Settings Preset Configuration.

See Also

User Preferences

System Settings

Gantt Board

Optimize Settings

MPS/MRP Optimize Plan Settings

Compress the Schedule</div>
        </section>
      
        <section class="article" id="article-321-workspace-profiles-dashboard">
          <h3 class="article-title">Workspace Profiles Dashboard</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/workspace-profiles-dashboard" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

A user's Workspace Profile defines how they see and interact with the customizable components of the Client application user interface. The following settings and objects may be stored in each Workspace Profile:

Layouts and Metrics Configurations

Plant View Gantt Layout Configurations

Board, Tile, and Grid Settings

Gantt Segments and Labels

Gantt User Settings

Board and Tile Layout Arrangements and Window Sizes

Users may create or import multiple Profiles and quickly switch between them from their local collection to perform various tasks where different data or information may be more relevant in one case or another. 

Users may also share (export) their Profiles so that other users may import them. Profiles can be exported to a shared collection that gets stored within the Workspace, or exported to a file that can be moved from one Workspace to another.

Note that sharing of Profiles is not the same as the real-time sharing of the schedule and scenario data -- users import a snapshot of a shared Profile at a point in time, at which point they can make changes to it as they see fit and it will only impact their view of the workspace; their changes will not be reflected in the shared Workspace Profile of the user who originally shared it or anyone who also imported it to their local collection.

Jump to section:

Local and Shared profile collections

Manage

Import

Export

Auto Save

Workspace Profile Templates

Navigate to the Workspace Profiles Dashboard via the User Menu from the Main Toolbar:

Local and Shared profile collections

Local

The local profile collection consists of profiles that the user has either created or imported into their Workspace. No user can see another user's local profile collection. In order to add a new profile to a user's local collection, they may use the Copy button to create a copy of an existing local or shared profile, or they may Activate or Import one from the shared collection or from a compatible .ptwst file.

Shared

The shared profile collection consists of profiles which have been exported to the shared collection by Workspace users. Any user who connects to the Workspace is able to see the same Shared collection. If a user chooses to Activate or Import a shared profile then it gets added to their local profile collection. A shared profile is never automatically saved or overwritten. The only way to update an existing shared profile is to Export an updated version of it which the user chooses to overwrite the existing shared profile of the same name.

Manage

From the Manage section of the Workspace Profiles Dashboard, users can create new local Workspace Profiles as copies of existing local or shared Profiles. They can also rename or delete local or shared Profiles if their user permissions allow.

Actions

Activate a Workspace Profile

To activate a Workspace Profile is to load it into the current user's Workspace. Do this by selecting either the Local or Shared radio option and select an available Profile from the associated dropdown. The Local Profiles are loaded from the user's local client machine, while Shared Profiles are loaded from the PlanetTogether server.

Once a Profile is selected, click the Activate button.

A profile can also be activated by choosing it from the dropdown selection of the Workspace Profiles Dashboard section of the User Menu in the Main Toolbar:

Create a New Workspace Profile

To create a Workspace Profile, select either the Local or Shared radio option and select an available Profile from the dropdown. The Local Profiles are loaded from the user's local client machine, while Shared Profiles are loaded from the PlanetTogether server.

Once a Profile is selected, click the Copy button.

When prompted, enter a name for the new Profile and click Accept and Close.

The newly created Workspace Profile will now appear in the dropdown list and can be activated. It's not automatically activated after being created, so users must activate it if they wish to use it.

Rename a Workspace Profile

Select either Local or Shared radio option and select the Workspace Profile from the dropdown list, then click the Rename button. Enter the new name when prompted and click Accept and Close.

Delete a Workspace Profile

Select either Local or Shared radio option and select the Workspace Profile from the dropdown list, then click the Delete button.

Import

Import a Workspace Profile from a file or from the Shared Collection that exists on the server from other users sharing their Profiles.

Step 1: Import Options

Select an appropriate radio option to Import from disk or Import from shared collection. If importing from disk, click the "..." ellipsis icon to browse the local system to find the appropriate .ptwst file. If importing from a shared collection simply select the desired Workspace Profile from the dropdown list of options. Click Next to continue.

Step 2: Save Options

Select the desired radio option here to either Create new, Overwrite existing, or Import to specific user.

Create new: Create a new "Local" Workspace Profile. Enter the desired Profile name in the provided input box.

Overwrite existing: Overwrite an existing "Local" Workspace Profile. Choose the existing local Profile from the dropdown of options.

Import to specific user: Choose this option to create a new "Local" Workspace Profile for one or more users. Select each user to import the Profile for from the available multi-select dialog. If the selected user(s) already has a Profile of the same name then their existing Profile will be overwritten with the imported one.

Click Next to continue.

Step 3: Select workspace profile settings to import

Click the Select All button to import all Workspace Profile settings, or pick and choose specific settings from the Profile to import.

Optionally, toggle on the Reset existing settings not imported option to reset all settings back to their default values if they are not imported as part of the profile configuration.

Click Import to complete the process.

Export

Export a Workspace Profile to a file or to the Shared Collection on the server for quick sharing with other users.

Step 1: Export Options

Select an appropriate radio option to Export to disk or Export to shared collection. Select the desired Workspace Profile from the dropdown list of options. Click Next to continue.

Step 2: Save Options

Depending on the chosen export option, different Save Options may be available.

Export to disk: Click the "..." ellipsis icon then select a folder path and provide a file name when prompted.

Export to shared collection: Select a radio option to Create new or Overwrite existing

Create new: Export the Workspace Profile as a new Profile to the shared collection. Enter the desired Profile name.

Overwrite existing: Overwrite an existing Workspace Profile in the shared collection on the server. Choose from the dropdown list of options which Profile to overwrite.

Click Next to proceed.

Step 3: Select workspace profile settings to export

Click the Select All button to export all Workspace Profile settings, or pick and choose specific settings from the Profile to export.

Click Export to complete the process.

Backup Profile

Enable automatic profile backups to periodically save changes to the active Workspace Profile.

Backup profile automatically: When enabled, the active user Workspace Profile will automatically save every 5 minutes. It's only stored in the user's local collection and will overwrite the profile of the same name if the Use custom suffix for auto-saved profile name is disabled.

Use custom suffix for auto-saved profile name: When enabled, users can define a suffix to use to append to the automatically saved Workspace Profile name so that they might be able to easily visualize that the Profile was saved automatically when selecting, exporting, or managing Profiles.

Be sure to Save (or choose to Revert if necessary) any changes made to the settings before navigating to another screen.

Workspace Profile Templates

The PlanetTogether team has curated some Workspace Profiles to help onboard new users so they don't have to start from scratch. Feel free to download and import these as needed:

Standard: A standard, well-rounded profile fit for most users as a good starting point.

Last updated: August 31, 2024 (version 12.2.0.25)

Note: This template won't include any Gantt view layouts. It will likely be in user's best interest to navigate to User Settings -> Plant View Settings and click the Generate Plant Layouts button to generate Plant and Department layouts according to their data model. 

Default: The default profile with all of the default settings and no custom layouts or metrics. Import this to reset everything to defaults. For most complete results to reset everything to default settings, toggle the Reset existing settings not imported option on the final step before clicking the Import button:

See Also

Layouts, Metrics, and Targets

Plant View Gantt Configurations

Grid Personalization

Gantt Labels and Segments</div>
        </section>
      <h2 id="cat-feedback-support" class="category-header">Feedback &amp; Support</h2>
        <section class="article" id="article-176-planettogether-support-holidays">
          <h3 class="article-title">PlanetTogether Support Holidays</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/planettogether-support-holidays" target="_blank">Source</a></p>
          <div class="article-content">PlanetTogether offers 24/5 support from Sunday 5pm Pacific to Friday 5pm Pacific time, excluding major US, Canada, and India holidays where coverage will be reduced or not available. 

Global Holiday Calendar

No coverage will be available on these dates:

New Year's Day
Thursday, January 1, 2026

Christmas Day
Thursday, December 25, 2025

United States Holiday Calendar

Coverage will be limited during standard North American business hours.

Martin Luther King Jr. Day
Monday, January 20, 2025

President's Day
Monday, February 17, 2025

Memorial Day
Monday, May 26, 2025

Juneteenth
Thursday, June 19, 2025

Independence Day
Friday, July 4, 2025

Labor Day
Monday, September 1, 2025

Columbus Day
Monday, October 13, 2025

Veteran's Day
Tuesday, November 11, 2025

Thanksgiving Day
Thursday, November 27, 2025

Day after Thanksgiving
Friday, November 28, 2025

Christmas Eve
Thursday, December 24, 2025

Canada Holiday Calendar

Coverage will be limited during standard North American business hours.

Family Day
Monday, February 17, 2025

Good Friday
Friday, April 18, 2025

Victoria Day
Monday, May 19, 2025

Saint Jean-Baptiste Day
Tuesday, June 24, 2025

Canada Day
Tuesday, July 1, 2025

British Columbia Day
Monday, August 4, 2025

Labour Day
Monday, September 1, 2025

National Day for Truth and Reconciliation
Tuesday, September 30, 2025

Thanksgiving Day
Monday, October 13, 2025

Remembrance Day
Tuesday, November 11, 2025

Boxing Day
Friday, December 26, 2025

India Holiday Calendar

Coverage will be limited during Central European Time standard business hours.

Makar Sankranti
Tuesday, January 14, 2025

Holi
Thursday, March 13, 2025

May Day
Thursday, May 1, 2025

Independence Day
Friday, August 15, 2025

Ganesh Chaturthi
Wednesday, August 27, 2025

Eid e Milad
Friday, September 5, 2025

Vijayadashmi
Thursday, October 2, 2025

Diwali
Monday, October 20, 2025

Guru Nanak Jayanthi
Wednesday, November 5, 2025</div>
        </section>
      <h2 id="cat-feedback-support-product-feedback" class="category-header">Feedback &amp; Support &gt; Product Feedback</h2>
        <section class="article" id="article-217-product-feedback">
          <h3 class="article-title">Product Feedback</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/product-feedback" target="_blank">Source</a></p>
          <div class="article-content">This form is meant for feedback directly for the PlanetTogether Product team. Response times to new inquiries is typically 1-2 business days.

For urgent matters, please contact the PlanetTogether Support team.

Contact the PlanetTogether Product Team</div>
        </section>
      <h2 id="cat-feedback-support-product-support" class="category-header">Feedback &amp; Support &gt; Product Support</h2>
        <section class="article" id="article-220-request-support">
          <h3 class="article-title">Request Support</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/request-support" target="_blank">Source</a></p>
          <div class="article-content">Contact Support</div>
        </section>
      <h2 id="cat-getting-started-for-network-administrators-it-prof" class="category-header">Getting Started &gt; For Network Administrators &amp; IT Professionals</h2>
        <section class="article" id="article-210-server-administration">
          <h3 class="article-title">Server Administration</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/server-administration-302" target="_blank">Source</a></p>
          <div class="article-content">Find Server Administration links here: Server Administration.</div>
        </section>
      <h2 id="cat-getting-started-for-schedulers-standard-users" class="category-header">Getting Started &gt; For Schedulers &amp; Standard Users</h2>
        <section class="article" id="article-263-client-sign-in-manager-application">
          <h3 class="article-title">Client Sign-In Manager Application</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/client-sign-in-application" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Client Sign-In Manager application is each user's gateway to the scheduling workspace environments that they are given access to. Each user must go through some (typically) one-time setup steps, then they may use the application to connect to or manage connections to the various workspaces that they interact with.

Note: This article covers the next steps after downloading and installing the client application.

Jump to section:

Getting Started

Add Workspaces

Connect to a Workspace

Options

Default Installation Location

Getting Started

Each time the sign-in application starts up the user is required to provide login credentials. These credentials will be used to evaluate and authenticate the user to determine which instance workspaces they have access to connect to. If this is a user's first time connecting, a server administrator may be able to provide guidance as to which login option is most appropriate for the particular workspace(s) they're trying to connect to.

SSO Login: This method uses Single Sign-On authentication. It must be enabled for the instance workspace by a server administrator (see: SSO Integration). Selecting it will display a popup dialog to enter company SSO login credentials. Once validated, the user may be directed to Connect to a Workspace if they've already mapped all available workspaces, or they may be directed to the Add Workspaces screen.

Workspace User Login: This method uses basic PlanetTogether user authentication based on user/password information that is stored in the instance workspace. The user will be directed to the Add Workspaces section to enter their login credentials. Use this option when connecting to a new instance workspace for the first time.

Add Workspaces

Connect to a server from the Add Workspaces tab and add Workspaces to the sign-in application as needed for quick connections in future sessions. After adding a workspace, it remains stored in the Client Sign-In Manager until it is manually removed.

If using Single Sign-On then the user will not be presented with the Username and Password fields.

For system administrators and for new instance workspaces with no configured users, the username "admin" with a blank password field is the default credential. 

Server: Enter or select from the dropdown the Server Name, domain host name, or IP address of the server that hosts the PlanetTogether Instance Workspace(s) that you're attempting to connect to. No protocol ("https://") or port number are necessary - just the host name. Use "localhost" to connect to a local instance workspace hosted on the same machine as the sign-in application.

The client connects to port 7981 when communicating with the server to validate login credentials and fetch a list of Workspaces that the user has access to.

Username: Enter a valid username.

Password: Enter a valid password.

Click the Sign-in button when ready to proceed.

If you're connecting to a server that uses an insecure self-signed SSL certificate, you may receive an SSL Certificate is invalid error message after providing your login credentials.

This is an indication that an SSL thumbprint needs to be configured in the Options section of the sign-in application before you'll be able to add and connect to the workspaces on the server.

Select one or more workspaces from the Select workspaces to add dialog and click the Add Workspaces button when ready to proceed. 

If the workspace that you wish to connect to is already added to your sign-in application, you may click the Skip button to proceed to the workspace list where an option to Connect is available.

Sign in to a Workspace

After signing in to the Sign-In application with valid credentials and adding any new workspaces (if applicable), the user is presented with the Workspaces tab. 

From this section, users can maintain the list of workspaces that they frequently connect to, as well as see helpful status and user activity information.

If the Connect button is green then the workspace is online and the user may click the button to connect to it.

When connecting to a Workspace, the client must fetch files from the server (the latest scenario file and any extension files). It does so over the same port that is defined on the PlanetTogether server to run the Workspace Instance, typically in the 4000-4100 range.

If the button is gray then the workspace is currently unavailable (it may be offline, or it may have been mapped with different user credentials than the ones used to login to the sign-in application and the current credentials are not valid for the particular workspace). The workspace status will refresh itself every 15 seconds. To force the list to refresh, navigate away from the Workspaces tab (try Options or Welcome) then navigate back to Workspaces.

If any users are currently connected to a workspace, a number of Connected Users statistic will appear.

Use the Remove button to remove the workspace from the stored list of workspaces in the Client Sign-In Manager.

Options

The Options section shows which version of the Client Sign-In Manager is in use and allows users to manage SSL thumbprints. There are two optional checkboxes as well:

Automatically Check for Updates

Enable this option to be informed when new versions of the Client Sign-In Manager are available for download.

Minimize to system tray after launching the client

Enable this option to automatically minimize the Client Sign-In Manager window to the Windows system tray (accessible via the "^" up arrow in the lower right corner of your primary monitor) after successfully signing in to a workspace.

Note too that when the Client Sign-In Manager window is minimized manually that it also minimizes the Windows system tray which effectively closes the window but keeps the user signed in the background.

Thumbprints

An SSL certificate thumbprint may or may not need to be configured within the Client Sign-In Manager. If the server that hosts the PlanetTogether instance workspace(s) is using a trusted SSL certificate (purchased and signed by a trusted third party), then this step is not required. Otherwise, the server must use a self-signed certificate in which case it is required to configure the thumbprint so that the Client Sign-In Manager can establish a successful SSL handshake with the server.

If needed, a server administrator may retrieve the certificate thumbprint from the "Server" section of the Instance Manager.

Copy and paste the alphanumeric code into the Thumbprints box of the Client Sign-In Manager. The entry will save automatically.

For users who connect to multiple servers, enter as many thumbprints as are needed; it is not limited to just one. Enter one at a time and click in the white space beneath the Thumbprints entries to save and expose the "new thumbprint" entry again to enter the next one.

It is possible to Copy or Delete an existing thumbprint by right-clicking the thumbprint entry and choosing the desired Copy or Delete action.

Default Installation Location on the Server

The Client Sign-In Manager is installed in the %AppData%\PlanetTogether\ Windows user folder by default. The only option to "uninstall" it is to delete the installation folder manually.

See Also

Troubleshoot: Client Sign-In Manager Application

Workspace Profiles

Layouts, Metrics, and Targets

User Management</div>
        </section>
      
        <section class="article" id="article-334-desktop-client-installation-guide">
          <h3 class="article-title">Desktop Client Installation Guide</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/desktop-client-installation-guide" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The PlanetTogether desktop client application allows users to connect to instance Workspaces which run on a PlanetTogether server.

Jump to section:

Installation Procedure

Client Sign-In Manager Application

Installation Procedure

Step 1: Install .NET

This is a legacy requirement. As of software release version 12.2.1.71, installation of .NET 6 is no longer required. .NET 6.0 is only required to connect to PlanetTogether instances running software version 12.2.1.61 or older. 

In software version 12.2.1.62 and newer, the PlanetTogether sign-in application and client application each launch with .NET 8 components packaged within them, so no .NET package needs to be installed on the user's workstation.

Skip this step if connecting to instances running software version 12.2.1.62 and newer.

If connecting to an older software instance, install the required .NET 6.0 Core Runtime Windows Hosting bundle from Microsoft:

.NET 6.0 Core Runtime Windows Hosting Bundle - Installer

Step 2: PlanetTogether Installer

If the above step was skipped and .NET 6.0 is not installed, download this version of the Version 12 Client installer which does not require a .NET installation:

Version 12 Client Installer without .NET validation

With .NET 6.0 Core Runtime Windows Hosting installed, download the PlanetTogether Version 12 Client Installer:

PlanetTogether Version 12 Client Installer

Once complete, run the downloaded PlanetTogetherClient12.exe installer to start the installation wizard. 

Step 3: Installation Wizard

If upgrading the application from an older version to the latest, be sure to close any running iteration of it or else the installer won't be able to complete. While a window may not be open, the application may still be open in the background so be sure to check the system tray in the lower right corner for the icon and close it if necessary.

Choose an installation path and click Install Client to proceed.

The application will proceed to download and install. Upon successful installation, a Launch PlanetTogether button will be presented.

Client Sign-In Manager Application

Once the client has launched successfully, use the Client Sign-In Manager Application guide to configure the client and connect to a PlanetTogether Workspace.</div>
        </section>
      
        <section class="article" id="article-191-keyboard-shortcuts">
          <h3 class="article-title">Keyboard Shortcuts</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/keyboard-shortcuts" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Keyboard shortcuts can be used to quickly select all grid rows or toggle certain features on and off or zoom to various levels in the Gantt. Use this guide as a reference to find helpful keyboard shortcuts.

Jump to section:

Grids

Gantt

Workspace Settings

Grids

These keyboard shortcuts are functional on nearly all grids that can be interacted with throughout the interface.

Description
Shortcut

Select all visible grid rows
Ctrl + A

Copy grid cell value
Ctrl + C

Scroll to the leftmost grid cell of the currently selected row
Home

Scroll to the rightmost grid cell of the currently selected row
End

Scroll to the leftmost and topmost grid cell
Ctrl + Home

Scroll to the rightmost and bottommost grid cell
Ctrl + End

Select an adjacent grid cell
Up arrow; Right arrow; Down arrow; Left arrow

Select right-adjacent grid cell
Tab; Right arrow

Scroll to the top visible grid row
Page up

Scroll to the bottom visible grid row
Page down

Gantt

These shortcuts are functional with the Gantt Board in focus.

Zoom and Scroll

Description
Shortcut

Scroll the Gantt to Now (the current date and time)
Ctrl + N

Scroll the Gantt to Today (today's date at 12:00 am)
Ctrl + T

Zoom in or out to show one full Week (7 days)
Ctrl + W

Zoom in or out to show two full Weeks (14 days)
Ctrl + Shift + T

Zoom in or out to show one full Month (31 days)
Ctrl + M

Zoom in or out to show one full Year (365 days)
Ctrl + Y

Zoom and Scroll to show the entire Frozen Span
Ctrl + F

Zoom and Scroll to show the entire Plant Stable Span
Ctrl + S

Zoom and Scroll to show the entire Planning Horizon
Ctrl + Shift + H

Zoom the Gantt to a specific area.
Ctrl + Lasso select (click and drag)

Options

Description
Shortcut

Enable/disable Highlighting
Ctrl + H

Enable/disable Activity Links
Ctrl + Shift + L

Schedule Adjustments

Description
Shortcut

Move to alternate path
Alt + Drag-Drop

Optimize the schedule from the clicked point to the end of the schedule.
O + Left click

Compress the schedule of everything before the clicked point.
C + Left click

Expedite Manufacturing Order to date time (where the block was dropped)
Shift + Drag-Drop

Expedite Manufacturing Order ASAP
Shift + E + Left click

Expedite Manufacturing Order preserving frozen span
Ctrl + E + Left click

Expedite Manufacturing Order preserving stable span
Ctrl + Shift + E + Left click

 Unschedule a Job.
U + Left click

Anchor/Un-Anchor the activity.
A + Left click

Lock/Unlock the operation.
L + Left click

Lock and Anchor of an activity.
R + Left click

Select multiple individual activity blocks. Dragging-and-dropping the selected blocks will Expedite the selected Jobs to the mouse location when dropped.
Ctrl + Left click

Move selected activity/activities to mouse cursor resource/time on Gantt.
Ctrl + Right click

Select a group of Activities.
Shift + Lasso select (click and drag)

Split Job starting from the clicked cycle.
S + Left click

Display the Split Job dialog.
Shift + S + Left click

Split Manufacturing Order starting from the clicked cycle.
Shift + Ctrl + S + Left click

Display the Split Manufacturing Order dialog.
Shift + Ctrl + Alt + S + Left click

Join the Job you clicked with the Job scheduled before it, resulting in a single Job. Or if there are two ManufacturingOrders from the same job next to each other, they are joined.
J + Left click

Capacity Interval Adjustments

Description
Shortcut

Adjust the start time of an interval or series to the nearest half hour.
Alt + Drag-drop

Toggle a capacity interval between online and offline.
T + Left click

Change one capacity interval occurrence and all of its predecessors from a series into individual occurrences.
I + Left click

Workspace Settings

These shortcuts can enable or disable certain settings of a user's Workspace.

Description
Shortcut

Enable/disable tabular navigation
Shift + Tab

See Also

Gantt Board

Main Toolbar</div>
        </section>
      
        <section class="article" id="article-255-main-toolbar">
          <h3 class="article-title">Main Toolbar</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/main-toolbar" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Main Toolbar is where users can trigger various actions or navigate to the various areas of the Client application to perform various activities and analyze the schedule data. It's the central hub used to navigate the user interface.

Jump to section:

Boards

Scenarios

Settings

Help

User Menu

Debug

Schedule

Plan

Compress

Publish

Undo & Redo

Clock

Refresh

Boards

Boards represent the various planning tools available to create, fine-tune, and analyze the schedule and all data in the model. Board windows can be repositioned, docked vertically or horizontally, unpinned to move freely between multiple monitors, or hidden to match the user's preferences and/or screen resolutions.

Opening a New Board

New boards can be opened by selecting from the Boards drop-down menu.

Closing a Board

With tabs enabled, boards can be closed by clicking on the "x" button found at the right corner of the board's tab. Without tabs enabled, selecting to open a new board effectively replaces the one being viewed (though previously opened boards remain open in the background).

Split-Screen Board Grouping

Dock boards side-by-side or top-to-bottom by creating separate board groups. Create a new group by clicking the blue square rightmost icon while hovering over any board title.

The new board will automatically appear in a 50/50 split view. Additional boards added using the grouping method will continue to divide them evenly on the screen. 

With tabular navigation enabled, users can click and drag the tabs around the screen to dock them at the top, right, bottom, left, or center.

Board Functions and Features

Select from the table below for more details about the functions and features of each board:

Activities
Buffer Management
Capacity Planning

Customers
Database Manager
Gantt

Import Mappings
Inventory Plan
Jobs 

KPIs
Materials
Metrics

Purchase Orders
Routing Templates
Sales Orders

Scenario Data
Sequence Planning

Scenarios

Each PlanetTogether Workspace may contain many Scenarios. Each user can be given permission to view (or not) and/or edit each scenario. The creator of a scenario has control over who they share the scenario with, and/or user groups may be given permission to manage all scenarios so that users who are assigned to the group may manage all scenarios regardless of share settings (see: User Management).

Each scenario represents a unique set of data. Each starts out as a copy of an existing scenario, but any changes made within the scenario to settings, data, the schedule, etc. are only reflected in the active scenario. This functionality gives users opportunities to test various configuration or data model changes without impacting a Production or similar schedule/model.

More information about the various settings and options related to Scenario Management can be found here: Scenario Management

Settings

The Settings menu offers quick access to the Message Log, User Management, and System Settings as well as some user-specific options to enable or disable tabular navigation and Quick Actions.

Message Log

The Message Log is a place where all errors and notifications are logged. The messages are categorized to simplify browsing through the various types of messages that get logged.

Use the Refresh All button to refresh all log messages on all tabs.

Use the Send All button to send all log files via email (requires additional server configuration in the Instance Manager).

Use the Clear All button to clear all log data from all tabs.

Use the Show Details toggle to view the stack trace or more detailed information about each error or message logged.

Use the Auto Clear Import Logs toggle to automatically purge all old data import errors from the Interface logs tab so that only import errors from the most recent data refresh are visible. Older logs will remain visible in the Interface from Server logs tab.

Each tab has its own Refresh, Send, Copy, and Clear navigation buttons to perform each of the various actions on the local tab's messages only.

Categorized logs:

User: Errors which are specific to the logged-in user

Interface: Errors or warnings related to data imported from SQL during the current user session.

System: Errors with the Workspace/Instance System service

External: Errors or warnings from external systems or programs that communicate with PlanetTogether

Fatal: Failed processes or software functions (if recurring, contact Support as it may indicate a software bug or instability)

Misc: Uncategorized errors and messages

Scheduling Warnings: Warning messages from the scheduling engine

Notifications: All user notifications from the current session

Interface from Server: Errors or warnings related to data imported from SQL by other users or from previous user sessions. These are populated from the server logs to help all users visualize data import errors from recent import attempts, even if the import was not performed while the user was logged in. Users cannot clear these logs from the desktop application interface; they must be cleared from the server logs, if desired.

Tabs

This is a user-specific setting to enable or disable tabular board navigation.

No tabs: No board tabs are visible. This is the best option for users who prefer to view a single board at a time and use the "Boards" dropdown menu to switch between boards.

Show tabs: All open boards will contain a tab at the top with a "x" available to close the board. Tabs can be reordered or even dragged around to create separate board groups docked side-by-side or top-to-bottom with other board groups.

Smart tabs: Tabs will appear at the top of all boards only when there are more than 1 board open in the local board group. If there is only 1 board open in the local board group then no tabs will be shown. This allows users to quickly navigate between a few different boards as needed and gives them the flexibility of closing all boards except for 1 in order to maximize the visible work space.

Quick Actions

This is a user-specific setting to enable or disable Quick Actions. 

On: When enabled, all of the actions that can be performed via the Main Toolbar become split into single-click buttons on the left and a dropdown arrow to access the settings for the button on the right.

Off: When disabled, each menu item in the main toolbar expands a dropdown of options when clicked where settings can be configured and the actual action can be performed by clicking a button.

Users

This menu option opens the User Management board where user administrators can add or remove users and adjust user permissions.

System Settings

This menu option opens the System Settings board where global settings can be configured for all scenarios and all users within the Workspace.

Help

The Help menu provides insights about the Workspace environment (license and memory usage), as well as quick access to helpful tools.

License Information

The license Information dialog offers details about the permissions of the license used and software packages loaded into the Workspace. Basic information is provided as well, including the license expiration date, the company name the license is issued to, a generic description of the license, and whether the System and Data license attribute states are "Active" or "Inactive".

Packages

The Packages section shows which packages are included in the license, which are available to purchase, and which are currently loaded into the Workspace.

License Options

The License Options section shows any applied restrictions to the number of plants or users that can be configured in the Workspace with the current license.

Memory Diagnostic

The Memory Diagnostic dialog displays the number of each type of data object and how much memory each type of data object is consuming on the server and each connected desktop client.

Knowledge Base

The Knowledge Base slide offers a quick link to this Version 12 Knowledge Base.

Knowledge Base Chatbot

The Knowledge Base Chatbot slide opens an embedded chatbot window which communicates with the same Version 12 Knowledge Base Chatbot that is offered in this Version 12 Knowledge Base.

Keyboard Shortcuts

The Keyboard Shortcuts slide offers a quick link to the Keyboard Shortcuts page offered in this knowledge base.

User Menu

User-specific settings allow each user to customize the way they view and interact with the Client interface.

User Settings

Several user settings are maintained to allow users to customize their experience with the Client application interface. For detailed information about each setting available in the User Settings dialog, see: User Settings

User Preferences

User Preferences are user-specific settings that users without general permissions to manage all users can update for themselves as needed. For details of each setting and its behavior, see: User Management: User Preferences

Workspace Profiles Dashboard

The Workspace Profiles Dashboard offers users the ability to import, export, or share Workspace Profiles. A user's Workspace Profile defines how they see and interact with the customizable components of the user interface of the Client application (consider: Layouts and Metrics; Plant View Gantt Configurations; Board, Tile, and Grid Settings; Gantt Label and Scheduling Settings; etc.).

To learn more about how to manage and share Workspace Profiles, see: Workspace Profiles Dashboard

Logout

Use this to gracefully exit the Client application. It's the same as clicking the "X" in the top right corner to close the client application window.

Debug

Visibility of the Debug menu and its contents may be limited depending on each user's permissions.

Debug Console

Typically used by the PlanetTogether Support team for playing back recorded actions, the Debug Console offers a simple command line interface to control playing back a set of recorded actions from the server. The instance must be started in Recording Client Delayed start-up mode, then the following commands can be executed in order to play back the recorded actions:

de: Begin debug recording playback mode. Enter this first before attempting either of the playback commands.

pbs: Play back a single recorded action. This option allows users to step through the recordings one at a time.

pb: Play back all recorded actions. This option will play all actions back without stopping until it has played back all of the actions.

A user permission can be toggled to grant or deny visibility of this button.

Download Scenario

Use the Download Scenario option to download the current data model in PlanetTogether's standard .dat scenario file format. The downloaded scenario can then be used as a backup/restore point, or used to load in another Instance / Workspace, or delivered to PlanetTogether Support to allow them to troubleshoot various issues.

When selected, the user will be prompted to select which of the available scenarios in the Workspace should be downloaded, and whether or not to Clear Undo Sets. By clearing undo sets and selecting specific scenarios, the file size of the resulting download can be greatly reduced (albeit there will be less data in the file compared to the current Workspace).

A user permission can be toggled to grant or deny visibility of this button.

Cancel Simulation

If a long-running simulation is in process and users don't want to wait for it to complete, they can click this button to cancel it. When a cancellation is initiated, the system will interrupt the simulation process immediately and will reload the data model from the start of the most recent undo set, then proceed to play back each of the actions performed leading up to the last simulation (schedule move or optimize). It will stop playing back the actions when it encounters the simulation action that was cancelled, effectively recreating the scenario data from just before the cancelled action.

A user permission can be toggled to grant or deny visibility of this button.

Schedule

Use the Schedule dropdown to modify Optimize settings and to execute a Schedule Optimization. Information about each setting and option can be found here: Optimize Settings

Plan

Use the Plan dropdown to modify MPS/MRP Planning settings and to execute a Plan Optimization. Information about each setting and option can be found here: MPS/MRP Optimize Plan Settings

Compress

Use the Compress dropdown to modify Compress and JIT Compress settings and to execute either of these actions. Information about each setting and additional details of the Compress and JIT Compress functionalities can be found here: Compress the Schedule

Publish

Use the Publish dropdown to Browse Publish Data, Publish to the standard Publish database, or Publish to the configured Analytics database.

Publish options and settings can be found in System Settings.

Database configurations are setup by a server administrator in the Instance Manager.

Undo & Redo

Users can Undo or Redo recent tasks. Certain User Permissions may dictate whether or not users are able to see and Undo other user's actions. The number of actions that are available to be undone can be configured by a system administrator in the System Settings dialog under the Undo Options area. All Undo data and history can also be purged by a system administrator in the same System Settings dialog.

To perform an Undo or Redo action, expand the dropdown next to the action icon and select which action to undo or redo. All dependent actions leading up to the user's selection will automatically be selected to be included in the Undo or Redo action. Finally, click the Undo or Redo button in the lower right corner of the dropdown to execute the selected action.

Undo/Redo Individual Actions

When enabled, individual user actions may be undone/redone without requiring that all actions since the selected individual action(s) also be undone/redone. The only types of actions that are currently supported are manual schedule moves (drag/drop, Activities Board Move Manager, Expedite, Compress, JIT Compress). If any other type of action is performed then all previous supported actions will no longer be eligbile to be undone/redone.

This feature was introduced as a means to support multiple schedulers making their own individual manual schedule adjustments so that they would be able to undo and redo their own manual move actions without impacting moves made by other schedulers.

Clock

<p</div>
        </section>
      
        <section class="article" id="article-229-modern-user-interface">
          <h3 class="article-title">Modern User Interface</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/modern-user-interface" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether Version 12 boasts a modern interface design that features dock-able boards, tiles, tabs, sidebars, status panels, and more. The UI is designed to maximize the functional and visible space planners and schedulers have to work with, and is made to look and feel like a web-based application.

Main Toolbar

A minified toolbar at the top of the application offers quick access to the most commonly used functions and tools. Users can convert the default dropdown options in the main toolbar to "Quick Action" buttons to perform many actions with a single click (Optimize the Schedule, Run MRP Planning, Advance the Clock, etc.).

For details of the functions of each toolbar option and action, see: Main Toolbar

Boards & Tiles

Dock-able "Boards" and "Tiles" are gateways to the plethora of data and planning configurations and settings that users may visit to analyze data, fine-tune the model, and visualize the schedule. Every Board and Tile is customizable to each user.

Boards

Boards are the top-level categories where various data elements are presented.

With tabular navigation enabled, multiple boards may be opened at the same time and can be docked or arranged in the user's workspace to their personal preferences.

Tiles

Tiles are the elements that actually present the data to the user. Within each Board are various Tiles listed in a menu of icons that runs vertically across the left side of the Board. Each tile can be opened to view and/or manipulate various data related to the Board that the user is viewing. 

Tiles can be docked or arranged in the user’s workspace to their personal preferences. Users are even able to "unpin" a Tile from a Board to allow them to drag the Tile to another monitor or location on the screen that does not require that the Board be open to view the Tile data.

Tile Settings

Click the gear icon at the bottom of the Tile menu of any board to access some global tile settings.

Open tiles undocked as movable windows: When enabled, any new tile that opens will behave as an undocked window that can be dragged to any position on the user's screen, including to other monitors or screens.

Toggle Inline Menu: 

When enabled, the tile menu can be expanded to include text or retracted to only show icons for each tile. When expanded, the tile menu does not overlay on top of the tiles behind it.

When this option is disabled, the tile menu can be expanded temporarily to read the text but will retract back to icons only once a tile is selected. When the menu is expanded it overlays on top of the tiles behind.

Close open tiles: This quickly closes all open tiles associated with the currently viewed board.

Scenarios

All scenarios within an instance can be viewed and maintained under a dropdown menu located at the top of the application interface. This dropdown allows users to copy existing scenarios to create new ones, activate existing scenarios to perform tests or create alternate schedules as needed, or modify scenario settings and share permissions. Each user will only see the scenarios which are shared with them in some capacity (read-only or editable).

For additional details about managing and sharing scenarios, see: Scenario Management

Themes

By default, the "Light" theme is enabled, and a "Dark" theme is made available. It's possible to create a custom theme and have it loaded into each user's Workspace as well.

Previews

Light

Dark

See Also

New Functions and Features</div>
        </section>
      <h2 id="cat-integrations" class="category-header">Integrations</h2>
        <section class="article" id="article-347-importing-data-overview">
          <h3 class="article-title">Importing Data: Overview</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/importing-data-overview" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

ERP systems contain most of the data needed to create a schedule in PlanetTogether, including:

Plants, Departments, and Resources

Resource Capabilities (sometimes called Operation Types)

Warehouses and Inventories

Jobs (including Manufacturing Orders, Operations, and Material requirements)

Some of this data is fairly static, such as plants and departments, while jobs tend to be added, closed, and changed daily. All of the above data can be entered manually into PlanetTogether. Still, it is generally preferred to import as much as possible so that most data maintenance is in one place. For some data elements, the objects in PlanetTogether contain fields that do not have an ERP equivalent. In these cases, the values can be left at their default values, calculated by the system, or manually entered in PlanetTogether after the object is created via the client application interface. If a property value is omitted from the import data, then manual changes to the omitted property made in the client application interface will be preserved with subsequent data refreshes.

The general data flow is from an ERP system to a SQL staging database, then into PlanetTogether. Once the schedule has been created within PlanetTogether, it can be published back to a separate SQL database where the schedule data can be moved or migrated to an ERP or other external system as needed.

Note: Some data is entered directly in PlanetTogether and cannot be sent via the interface. This data, however, is straightforward to enter. It includes:

Sequencing Plans

System Settings

Data Source Options

PlanetTogether depends on a SQL database as its source of incoming data. The import database can be organized in any custom fashion, then the Import Mapping Wizard can be used to map fields from a SQL table or view to a PlanetTogether property.

Each PlanetTogether instance workspace can be configured to connect to a single import database. This is configured in via the Instance Settings of the Instance Manager on the PlanetTogether server.

A standard import database structure is documented here: Standard Import Database.

Whether the PlanetTogether instance is hosted by PlanetTogether in our Azure Cloud, or hosted locally or on-premises, an instance data model can be maintained in Excel format which can be converted to SQL and imported into PlanetTogether. For more information, see: Microsoft Excel Integration.

Trigger a Data Import

Once the data source is defined and the import mappings are configured, users may import data as needed via the Refresh dropdown from the main toolbar of the client application.

A data refresh can also be triggered by the Integration API for PlanetTogether cloud hosted instances which are configured to use the API.

Data Types

String

PlanetTogether properties which accept strings of text are recommended to use the nvarchar type in SQL, especially if the data stored might use non-English (double-byte) characters.

Double

Accepts numerical values, including decimals/remainders. No thousands-separators should be used (commas for English numbers).

Decimal

Accepts numerical values, including decimals/remainders. Commas or other thousands-separators are allowed.

Boolean

PlanetTogether accepts TRUE/FALSE or 1/0 for Boolean values.

Integer (Int32)

Accept numerical values with no decimals/remainders.

Colors

Many properties in PlanetTogether allow users to define a color value (Jobs, Products, Attributes, etc.). Colors are identified by their hexadecimal code values. Color names like "White", "Blue", "Red", etc. are still supported, or colors may be imported as hexadecimal codes with transparency (e.g. '#FFFFFFFF' for White with no transparency, or '#FFDC143C' for Red with no transparency). The first two characters define the transparency (where "FF" is fully opaque), followed by 6 characters which define the hexadecimal color code.

Click here to download an Excel sheet that contains ~140 hexadecimal code mappings to color names.

See Also

Standard Import Database

Import Mappings Board

Microsoft Excel Integration

Integration API</div>
        </section>
      
        <section class="article" id="article-278-integrations-overview">
          <h3 class="article-title">Integrations: Overview</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/integrations-overview" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether can work as a standalone product, but is designed to work closely with a master data set like an Enterprise Resource Planning (ERP) or a Manufacturing Execution System (MES) system. With a master data integration, all company data is entered into the master data set, then only certain data which is required for scheduling is migrated to a SQL database before being imported into PlanetTogether. Once PlanetTogether produces an accurate schedule, it is typically published back to SQL where a procedure can execute to send the schedule data back to the master data system.

When interfacing with a master data external system like an ERP, it is important to create an efficient link between the two systems so to not overburden hardware resources. Typically, this is done by creating one or more SQL stored procedures which copy data from the relevant tables in the master data set database into a staging database. Further manipulation or "massaging" of the data can be done through the use of SQL views. This helps to ensure that the master data system is not being queried constantly by PlanetTogether, thus tying up large amounts of hardware resources. This allows for better performance overall when using PlanetTogether.

A local system integration can also be achieved for training and demonstration purposes using an Excel sheet as the master data set. A local SQL server can be configured to fetch the data from Excel and put it into a staging database where it can then be pulled in to PlanetTogether. Again, the use of one or more stored procedures and some configuration of the PlanetTogether instance can be used to fetch the data from the Excel sheet each time a user initiates the data refresh operation from the PlanetTogether client interface.

Jump to section:

ERP Integrations

Microsoft Excel Integration

Available Integrations

ERP Integrations

PlanetTogether can be integrated with most ERP systems, particularly any system with an open database or API or which can export data.

There are three common "levels" of integration. The first level is the simplest, with the least amount of data required. The other levels have added capabilities and constraints, and therefore require more data.

These are the common levels:

Scheduling with Capacity Constraints

The ERP generates Work Orders and Planned Orders

PlanetTogether imports this data for scheduling/optimization

PlanetTogether pushes schedule dates and resources back to the ERP

Data Imported from the ERP to PlanetTogether:

Plants

Work Centers

Machines

Work Order Headers

Work Order Operations

Planned Order Headers

Planned Order Operations

Data published from PlanetTogether to the ERP:

Work Order Header Scheduled Start Date, Scheduled End Date, and Firm Status (if Firming in PlanetTogether)

Work Order Detail Scheduled Start Date, Scheduled End Date, and Scheduled Machine

Planned Order Header Scheduled Start Date and Scheduled End Date

Planned Order Detail Scheduled Start Date, Scheduled End Date, and Scheduled Machine

Add Material Constraints

Everything included in Level 1

PlanetTogether pulls Inventory, Purchase Orders, and Bill-of-Material data

PlanetTogether coordinates Material Constraints and prevents activities from scheduling before constrained material is ready

Additional Data Imported from the ERP to PlanetTogether:

Warehouses

Items

Inventories

Purchase Order Headers, lines, and shipments

Work Order Material Requirements

Work Order Products

Planned Order Material Requirements

Planned Order Products

Transfer Order Headers

Transfer Order Details

Additional data published from PlanetTogether to the ERP

None

Add Production Planning

Everything included in Levels 1 and 2

Import Sales Orders, Forecasts and inventory replenishment controls

Run MPS/MRP to generate Planned Orders and Planned Purchases

Additional Data imported from the ERP to PlanetTogether:

Sales Orders

Forecasts

Replenishment Control parameters (safety stock, min/max, buffers, batching rules, etc.)

Item Routings

Item Bills of Material

Additional data published from PlanetTogether to the ERP

Planned Order Headers (to create Planned Orders in the ERP based on what was created by PlanetTogether MPS/MRP)

Microsoft Excel Integration

Data can be imported into PlanetTogether from a Microsoft Excel workbook. This is useful for importing custom data for a demo or when doing preliminary factory modeling.

The basic concept is that the data from Excel is pulled into a SQL database before being imported into PlanetTogether. The transfer of data from Excel to SQL is done via a stored procedure which can be configured to be executed at the time a user clicks the Refresh button in the client user interface so that the data that gets imported is always up to date with the latest changes made to the Excel workbook.

Detailed documentation of PlanetTogether's Excel integration offering can be found here: Microsoft Excel Integration

Available Integrations

PlanetTogether has developed connectors for the following master data sources:

Kinaxis Maestro (formerly RapidResponse)

AVEVA MES

Microsoft Excel

See Also

Deploy Integration Files to the Server

Microsoft Excel Integration

AVEVA MES Integration Overview</div>
        </section>
      <h2 id="cat-integrations-aveva-mes" class="category-header">Integrations &gt; Aveva MES</h2>
        <section class="article" id="article-261-aveva-mes-integration-data">
          <h3 class="article-title">AVEVA MES Integration Data</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/aveva-mes-integration-data" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Certain data properties and fields from AVEVA MES can be imported into PlanetTogether for scheduling. Some examples of data can be imported include:

Resource entities (Work Center Groups and Work Centers)

Machines, Warehouses, Items and Inventory

Bill of Material

Purchase and Production Orders

Primary and Alternate Routing Lines and Production Order Components

Recurring and Non-Recurring Capacity Intervals (manufacturing calendar)

PlanetTogether also allows you to publish schedules back to AVEVA MES:

Start and End dates at the task level

Process route or Line route changes

Scheduled Resource entity

Integration file package download:

AVEVA MES v3.zip

Supported software versions:

AVEVA MES 2023 or newer

PlanetTogether 12.1.4.17 or newer

Jump to section:

AVEVA MES Fields

PlanetTogether APS to AVEVA MES Data Mapping

AVEVA MES Fields

Work Orders (Header)

Property

AVEVA MES Table

Field

Work Order Number

wo

wo_id

Item Number

wo

item_id

Required Finish Quantity

wo

req_qty

Need Date

wo

req_finish_time_local

Work Orders (Detail)

Process Routing (primary)

Property

AVEVA MES Table

Field

Work Order Number

job

wo_id

Operation Sequence

job

oper_id (+ process_id)

Required Quantity

job

qty_reqd

Status

job / job_state

state_cd / state_desc

Process Routing (alternate)

Property

AVEVA MES Table

Field

Work Order Number

job

wo_id

Operation Sequence

oper_ent_link

oper_id (+ process_id)

Required Quantity

wo

req_qty

Line Routing (primary)

Property

AVEVA MES Table

Field

Work Order Number

job

wo_id

Operation Sequence

job

oper_id (+ target_sched_line_id)

Required Quantity

job

qty_reqd

Status

job / job_state

state_cd / state_desc

Line Routing (alternate)

Property

AVEVA MES Table

Field

Work Order Number

job

wo_id

Operation Sequence

line_ent_link

oper_id (+ line_id)

Required Quantity

wo

req_qty

Bills of Material

Property

AVEVA MES Table

Field

Work Order Number

wo

wo_id

Routing Step

job

oper_id

Item Number

job_bom

item_id

Resources

Property

AVEVA MES Table

Field

Resource ID

ent

ent_id

Resource Name

ent

ent_name

Capacity

ent_attr

attr_value

Capabilities

Property

AVEVA MES Table

Field

Capability ID

ent

ent_id

Resource ID

ent

ent_id

Purchase Orders

Property

AVEVA MES Table

Field

Purchase Order Number

po + po_line

po_id + po_line

Item Number

po_line

item_id

Warehouse

<none>

"-1"

Quantity Ordered

po_line

quantity

Expected Delivery Date

po_line

reqd_by_local

Capacity Intervals

Property

AVEVA MES Table

Field

Recurrance
shift_pattern

recurring

Name

shift

shift_desc

CapacityType

shift_pattern

additive

Days of Week

shift_schedule

monday, tuesday, ..., sunday

start time

shift_schedule

start_time

end time

shift_schedule

end_time

Publish Fields

Property

AVEVA MES Table

Field

Work Order

wo, job

wo_id

Route

wo

process_id, target_sched_line_id

Start Time

job

sched_start_time_local

End Time

job

sched_finish_time_local

Scheduled Resource

job

target_sched_ent_id

PlanetTogether APS < > AVEVA MES Data Mapping 

Resource Objects

Plants (MES entity attribute pt_location = Plant)

PlanetTogether Field (PT_Plants table) 

MES Field (ent, ent_attr, attr tables) 

PlantID

ent_id

PlantDesc

description (entity)

PlantName

ent_name

Departments (MES entity attribute pt_location = Department)

PlanetTogether Field (PT_Departments table) 

MES Field (ent, ent_attr, attr tables) 

DeptID

ent_id

DeptDesc

description (entity)

DeptName

ent_name

Capabilities 

PlanetTogether Field (PT_Capabilities_All table) 

MES Field (job table)

CapabilityID

oper_id

Resources

PlanetTogether Field (PT_Resources table) 

MES Field (ent, ent_attr, attr tables) 

DeptID

ent_id

ResourceID

ent_id

ResourceName

ent_name

PlantID

ent_id

CapacityType

attr_value (for pt_resource attribute)

ResourceDesc

description (entity)

Capability Assignments (match on MES target_sched_ent_id) 

PlanetTogether Field (PT_CapabilityAssignments_All table) 

MES Field (job table) 

CapabilityID

oper_id

DeptID

ent_id

PlantID

ent_id

ResourceID

target_sched_ent_id

Capacity Interval (recurrence = 'NotRecurring')

PlanetTogether Field (PT_Recurring_Capacity_Interval_Mapping table) 

<td style="width: 50.0728%; paddin</div>
        </section>
      
        <section class="article" id="article-173-aveva-mes-integration-overview">
          <h3 class="article-title">AVEVA MES Integration Overview</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/aveva-mes-integration-overview" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

AVEVA and PlanetTogether have partnered to provide a standard integration solution template between AVEVA MES and PlanetTogether's Advanced Planning and Scheduling (APS) systems.

This integration allows AVEVA MES to automatically provide PlanetTogether APS with all of the necessary information to create an optimal production schedule. The schedule results are then sent back to AVEVA MES to update the order information, providing the organization with an accurate, optimal, and forward-looking production schedule to work with.

Integration file package download:

AVEVA MES v3.zip

Supported software versions:

AVEVA MES 2023 or newer

PlanetTogether 12.1.4.17 or newer

Jump to section:

Refresh scheduling data

Update AVEVA MES production order information

Track the progress of orders

Provide structure for complementary data

Choosing Alternate paths

Additional information and known limitations

Refresh Scheduling Data

The integration allows users to update the APS data used by PlanetTogether by extracting data from AVEVA MES. Users can then use the latest data from MES to create optimized production schedules.

The data that is extracted from the AVEVA MES system is as follows. This synchronizes the MES execution model with the scheduling model at the resource or entities (name of the resource in AVEVA MES shown in parentheses).

Plants (MES entities)

Department (MES entities)

Resources (MES entities)

Warehouses (MES entities)

Production orders (MES work orders and jobs)

BOM (bill of material)

Route (process or lines)

The sequence of operations (process or line operation sequence)

Production rate

Alternate Paths (alternate BOMs and Routes)

Reported Activity (MES job quantities)

Reported Good Quantity (MES quantity produced)

Reported Scrap Quantity (MES quantity rejected)

Actual Start and Finish Times (MES actual start/finish time local)

Inventory (MES item inventory)

Items (MES items and attributes)

Purchase orders (MES POs and PO line items)

Attribute Setup Matrix (Manual Entry in PT using GAP tables)

Shifts information (Manual Entry in MES. Turned off in PT by default.)

All this information is updated when a refresh is initiated in PT so that the data is up to date.

Update AVEVA MES Production Order Information

Once the schedule has been optimized, the integration takes data from PlanetTogether and updates the AVEVA MES work order and jobs.

The following MES data is updated:

Scheduled start date

Scheduled resources

Line or Process route changes

Track Production Progress

As MES executes the orders, the APS system is kept synchronized. As a result, the status and progress of each order and related activities are updated, including:

The order's status and each operation (Ready, Running, Suspended, etc.)

The quantity produced so far

The quantity rejected so far

Actual Finish Time (local)

Actual Start Time (local)

Any update to the production rate (if it has changed)

The inventory counts based on MES execution:

Reduction from consuming

Addition while producing

Addition based on material reception and MES purchase order updates.

Provide Structure for Complementary Data

While AVEVA MES provides a great deal of data, some additional elements must be provided for either configuration or functionality. Below is the list of the main aspects:

Warehouse mapping to align the different needs of granularity (allow for mapping/aggregating MES and scheduling inventory locations)

List of MES item attributes to be used for setup data

SQL Server table structure for all related setup data (static or matrix)

SQL Server table for resource capacity information such as Downtime information coming from MES (not populated by the standard integration)

Choosing Alternate Paths

For AVEVA MES and PlanetTogether, Items can be produced on different routes. For MES, they are called Processes or Lines; for PlanetTogether, they are called Paths and Alternate Paths. The AVEVA MES integration allows you to manually move an order from one path to another using the PlanetTogether Alternate Path move (alt-drag-n-drop.) When making an alternate Path Move-in PlanetTogether, you will be prompted to select a different path; these paths are other possible alternative processes or lines that are valid for the MES. Once you publish the schedule, the MES work order will be updated to reflect any line or process changes.

Additional Information and Known Limitations

The AVEVA MES Integration template is based on standard MES configuration and out-of-the-box PlanetTogether APS functionality. However, some assumptions were made to keep the integration generic to accommodate the configuration flexibility inherent in AVEVA MES. This template is considered a starting point for projects. It is expected that modifications to this template will be required for each project since requirements could vary and become very project specific.

By default, the receipt of purchased material is stored in a "Receiving Inspection" warehouse, which only exists in PlanetTogether.

After a move to an alternate path, the schedule should be published. This will update AVEVA (MESDB) with the new Line or Process ID. PlanetTogether will see this as a change in route and automatically un-schedule the work after the next refresh. In order to place the work back where it was, you will need to optimize the schedule.

There are limitations to the routes allowed when the initial operation requires a helper resource. This is avoided with routes that start with a single-resource operation. Please consult your implementation specialist for more details.

For more details about the AVEVA MES-PlanetTogether integration, please contact your PlanetTogether representative, or PlanetTogether Support.

See Also

AVEVA MES Integration Data

AVEVA MES Integration Setup</div>
        </section>
      
        <section class="article" id="article-236-aveva-mes-integration-setup">
          <h3 class="article-title">AVEVA MES Integration Setup</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/aveva-mes-integration-setup" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Use this walkthrough to setup a new PlanetTogether instance integrated with AVEVA MES.

Integration file package download:

AVEVA MES v3.zip

Supported software versions:

AVEVA MES 2023 or newer

PlanetTogether 12.1.4.17 or newer

Jump to section:

Install PlanetTogether Server Software

Install the Integration Files

Create a PlanetTogether Instance

Configure SQL Databases

Configure the PlanetTogether Instance

AVEVA Configuration

PT_GapData_AvevaMES Database Customization

PlanetTogether Instance Workspace Publish Settings

Test the Configuration

Install PlanetTogether Server Software

Use the PlanetTogether Server Software Installation Guide to install PlanetTogether Version 12.1.4.17 or newer.

Install the Integration Files

Download the AVEVA MES v3 integration files and extract its contents into the IntegrationFiles folder of the PlanetTogether server software installation location, typically:

C:\ProgramData\PlanetTogether\IntegrationFiles

Create a PlanetTogether Instance

Follow documented steps to create a new instance running the installed PlanetTogether server software. If the first step was followed correctly, there should be an option to select the AVEVA-MES-v3 integration code when creating the instance:

Configure SQL Databases

Three databases must be created in SQL:

An Import database named PT_Import_AvevaMES

A Gap database named PT_GapData_AvevaMES

A Publish database named PT_Publish_AvevaMES

Create each database manually, then use the SQL scripts provided in the AVEVA MES v3 integration files package to populate the respective databases with the necessary tables and fields.

The PlanetTogether instance service will read and write to the database. The service will be created during the instance creation process. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

Configure the PlanetTogether Instance

From the Instance Manager, double-click on the instance to open the Instance Settings.

Import Database Settings

From the Data Import tab, click the Import Database Settings button to display the connection string dialog.

Enter the Server Name and the SQL Import Database Name PT_Import_AvevaMES and SQL user credentials, if using SQL user authentication, or select [x] Integrated Security to use a Windows user's credentials for communicating with the SQL database.

Integrated Security

When disabled, authentication to the specified SQL server and database is established via the User Name and Password fields of this database settings dialog which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the System service of the instance. By default, the Windows user is the standard Local System user which typically does not have access to SQL databases. Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

Click Save when satisfied with the connection string settings.

Next, enable the checkbox to Run SQL before import, then enter the following stored procedure execution statement in the input to the right of the SQL to run before import label: 

EXEC PTsp_GetData_AvevaMES @SourceDB = 'MESDB', @GapDB = 'PT_GapData_AvevaMES'

Publish Database Settings

From the Data Publish tab, click the Publish Database Settings button to display the connection string dialog.

Enter the Server Name and the SQL Import Database Name PT_Publish_AvevaMES and SQL user credentials, if using SQL user authentication, or select [x] Integrated Security to use a Windows user's credentials for communicating with the SQL database.

Click Save when satisfied with the connection string settings.

AVEVA Configuration

Details regarding AVEVA MES configuration will be provided by an AVEVA representative. The information will summarize:

Using attributes to identify the Plants to be included

Using attributes to identify the Departments within each Plant

Using attributes to identify both the Resources present in a Department for a Plant, and also the Resource's capacity type (Single-Tasking, Multi-Tasking, Infinite)

Attributes to identify Warehouses

Item Attributes used for display and sequence dependent setup calculations

PT_GapData_AvevaMES Database Customization

The PT_GapData_AvevaMES database can be used to supplement the data coming from AVEVA MES. Work with your integration specialist to configure the following:

Attribute usage: This allows you to determine how the attributes will be used. For display purposes only, or for optimizing sequence dependent setup.

Capacity Intervals: This allows you to import a maintenance schedule over the existing manufacturing calendar in PlanetTogether.

Warehouse Aggregation: This allows multiple warehouses to be treated as a single storage location.

PlanetTogether Instance Workspace Publish Settings

Publish settings need to be configured in the PlanetTogether instance workspace so that the Publish action pushes the data to SQL and calls the appropriate stored procedure to push the data from SQL back to AVEVA.

From System Settings ➡️ Publish Options, toggle on the Publish to SQL Server and the Publish all activities for a manufacturing order if any are published options:

Include the following data objects, at minimum:

Warehouses, Inventory, Demand

Jobs

Manufacturing Orders

Operations

Activities

Activity Blocks

Activity Blocks Intervals

In the Procedures section, enable the option to Run stored procedure after Publishing and Publish dates using server's local time instead of UTC (if it's an option; this is the default behavior in software versions 12.2.0.10 and newer so the option is removed).

Add the following string to the box below Stored Procedure to Run after Publish (in import database):

PTsp_Publish_AvevaMES "MESDB, PT_Publish_AvevaMES, [Default Background User]"

Test the Configuration

Use the Refresh dropdown menu in the top right corner of the PlanetTogether interface and click the Refresh Active Scenario button to perform a data import.

Use the Publish dropdown menu from the main toolbar and click the Publish button to publish the data out of PlanetTogether.

See Also

AVEVA MES Integration Overview

AVEVA MES Integration Data

Server Installation Guide

Instance Manager

System Settings

Main Toolbar</div>
        </section>
      <h2 id="cat-integrations-microsoft-excel" class="category-header">Integrations &gt; Microsoft Excel</h2>
        <section class="article" id="article-232-full-excel-integration-package">
          <h3 class="article-title">Full Excel Integration Package</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/full-excel-integration-package" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The PlanetTogether team offers full data model Excel integrations for each major software release which can be used for local installations, on-premises installations, or PlanetTogether Cloud environments whose import database are connected to the Excel importer offered in the PlanetTogether web application. These integration files mimic a 1:1 mapping with each respective software version's import mappings structure. This allows for any data point to easily be mapped and imported into the data model without the necessity of modifying stored procedures in SQL or import mappings in PlanetTogether.

Jump to section:

Package File Downloads

Local Installation and Usage

Data Entry

Connect to an Instance Workspace

Package File Downloads

For PlanetTogether Cloud-hosted environments, only the Excel workbook and import mappings files are needed. The appropriate import mappings file must be submitted to PlanetTogether Support in a request to deploy to a specific environment. 

For local or on-premises installations, download the full integration package and follow the installation steps to proceed with installation and local environment setup.

Software Version
Excel Workbook
Import Mappings
Full Integration Package

12.1.4.x
PT_Import_Excel.xlsx
APSInterfaceSettings.xml
Excel_Full_12.1.4.zip

12.2.0.x
PT_Import_Excel.xlsx
APSInterfaceSettings.xml
Excel_Full_12.2.0.zip

12.2.1.x
PT_Import_Excel.xlsx
APSInterfaceSettings.xml
Excel_Full_12.2.1.zip

12.3.0.x
PT_Import_Excel.xlsx
APSInterfaceSettings.xml
Excel_Full_12.3.0.zip

Local Installation and Usage

Prerequisites

Before proceeding to configure an Excel integration, PlanetTogether server software must be installed, which also requires installation of .NET 8.0 and SQL Server or SQL Express. Use the Server Software Installation Guide to setup a PlanetTogether server.

Access to Microsoft Excel is also required, or another application which allows editing of XLSX files.

The SQL server must be configured to support OLEDB connections. See the Microsoft Excel Integration Overview page for steps to configure SQL server.

1. Download the File Package

First, be sure to download the Full Excel Integration file package. The integration files include:

APSInterfaceSettings.xml: The Import Mappings configuration.

PT_Import_Excel.xlsx: The Excel workbook template where data is maintained. It contains one sheet per each of the import mappings pages in PlanetTogether.

Get_Excel_Data.sql: Use this SQL script to create the stored procedure which transfers data from the Excel sheet into the import database.

PT_Publish_Excel.sql: Optionally, use this SQL script to create a standard publish database. This is only necessary if the schedule data in PlanetTogether will be published to SQL.

Integration.json: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

PtDbDataSet.xsd: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

To install the integration so that it may be used during software instance creation, download and extract the folder of files into the IntegrationFiles folder of the PlanetTogether software installation location, typically:

C:\ProgramData\PlanetTogether\IntegrationFiles

 When manually extracted correctly, each of the files listed above will reside in their own contained folder in the IntegrationFiles folder. For example:

C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\APSInterfaceSettings.xml
C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\Integration.json
C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\Get_Excel_Data.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\PT_Import_Excel.xlsx
C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\PT_Publish_Excel.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\Excel\PtDbDataSet.xsd

2. Create an Instance

Use the Instance Manager to create a new instance. For the quickest setup, select the appropriate Excel Integration Code from the dropdown list. If none are available, see the Integration Files section of this article to review the installation procedure. Choose to start from a New Scenario. Opt to not start the instance service yet since there is some configuration required before the instance and integration are functional.

3. Import Database

Create a new empty database named PT_Import_Excel which will act as the data source and import database. Once the database is created, open the Get_Excel_Data.sql file which was included in the Excel integration file download and execute it from a database management software application (e.g. Microsoft SQL Server Management Studio) to create the Get_Excel_Data stored procedure in the import database.

Get_Excel_Data

The Get_Excel_Data stored procedure is configured to fetch all data from each sheet of the workbook and insert it into a database table that matches the name of the sheet.

SET @trans_start = GETDATE()
SET @Sheet = 'User'
SET @SheetRename = @prefix + @Sheet
SET @Table = 'dbo.'+@SheetRename
IF EXISTS (Select 1 From INFORMATION_SCHEMA.TABLES where TABLE_NAME = @SheetRename) EXEC('Drop Table ' +@Table)
EXEC('select * into '+@Table+' FROM OPENROWSET(''Microsoft.ACE.OLEDB.16.0'', ''Excel 12.0;Database='+@FilePath+''', ['+@Sheet+'$]) WHERE [ExternalId] IS NOT NULL ')
SET @row_count = @@ROWCOUNT
SET @trans_end = GETDATE()
INSERT INTO _log_get_excel_data SELECT @import_date, @FilePath, @Sheet, @SheetRename, @trans_type, @trans_start, @trans_end, @row_count

Each property in row 1 of each sheet is dynamically created and added to the corresponding database table, even if it has no data value in the Excel sheet.

The import process will read and write to the database and may create and/or drop tables. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

In order to read the Excel file from disk, it may be necessary to use a sysadmin user. This is set in the Server Roles tab of the user properties.

Other more secure SQL connection configurations are available. Seek assistance from a representative of your IT department to ensure compliance with local policies in regards to SQL database authentication and permissions.

5. Publish Database

This step is optional. If the finished schedule data does not need published from PlanetTogether to a SQL database, skip this step.

Create a new empty database named PT_Publish_Excel. Once created, open the PT_Publish_Excel.sql from the downloaded integration files in a database management software application (e.g. Microsoft SQL Server Management Studio) and execute it to populate the database with two standard PlanetTogether publish stored procedures and one SystemData table. 

The publish database can be given any name, just be sure to use a global find/replace in the PT_Publish_Excel.sql document to replace all iterations of the text "PT_Publish_Excel" with the desired name.

The publish process will read and write to the database and may create and/or drop tables and fields. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

6. Instance Configuration

Import Database Connection

From the Instance Manager, double-click the Excel integration instance, or click it once to select it and click the Edit button from the actions toolbar. From the Import Data tab, click the Import Database Settings button to display the database settings dialog. Configure the appropriate server name (SQL server name where the Excel import database is hosted) and the database name (typically PT_Import_Excel) and choose either Integrated Security or SQL user authentication.

Once configured, click Save to proceed.

Integrated Security

When disabled, authentication to the specified SQL server and database is established via the User Name and Password fields of this database settings dialog which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the System service of the instance. By default, the Windows user is the standard Local System user which typically does not have access to SQL databases. Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

Run SQL Before Import

Back at the Import Data tab of the instance settings dialog, select the box to Run SQL before import. In the text area to the right of this checkbox, enter a stored procedure EXEC execution command to execute the stored procedure to move the data from Excel into SQL. Note that the file path may vary depending on where the Excel sheet master data resides on the PlanetTogether server.

EXEC Get_Excel_Data @FilePath = 'C:\ProgramData\PlanetTogether\Excel 12.2.1.48\IntegrationFiles\Excel_Full_12.2.1\PT_Import_Excel.xlsx'

Publish Database Connection

The same process described above can be repeated from the Data Publish tab of the instance settings dialog. Enter the server and authentication logic again, along with the database name.

Save and close all changes.

Data Entry

The PT_Import_Excel.xlsx workbook from the downloaded integration files will act as the master data set. When the Excel integration option is selected during the new instance creation step, the integration files template is copied into the instance folder. It's recommended to use this copy of the file for the specific instance that its data will be imported into so that the original file remains intact as a template for copying into new instances as needed. The instance folder of files is located in the PlanetTogether software installation location. The Excel workbook can be found in the INSTANCE_FOLDER\IntegrationFiles\Excel_Full_12.2.1 folder.

Example

C:\ProgramData\PlanetTogether\Excel 12.2.1.48\IntegrationFiles\Excel_Full_12.2.1\PT_Import_Excel.xlsx

The Excel workbook contains one sheet per mappings page from the Import Mappings Board of the PlanetTogether client application. Navigate the sheets using the tabs across the bottom of the Excel interface. Right-click the < > left/right arrows in the bottom left corner to display a list of all sheets for quickly navigating to one that is far away from the one currently in focus.

Each mappings sheet is pre-populated with every possible property that can be mapped and imported into PlanetTogether. Required properties are listed first (leftmost) and their column headers are colored with red text.

Each property's value is required to be a certain data type (String, Integer, Decimal, Double, or Boolean) and some properties are restricted to only accepting specific values. For properties which only accept specific values, data validation is added to the respective column of the Excel sheet to allow users to select an allowed value from a dropdown list. Each property of each object mapping is documented in the Object Import Mappings section of this knowledge base to be used as a reference, as needed.

Data Validation

Data validation can be modified or disabled per column by clicking the column letter to select it, then navigating to Data ➡️ Data Validation and modifying the settings as needed.

For more information, see Microsoft documentation: Apply data validation to cells

Otherwise, each cell can be typed into freely and each row represents a new data object that will be imported into the PlanetTogether workspace.

Keyboard Shortcuts

We are by no means Microsoft Excel experts, but here are some helpful keyboard shortcuts to help to navigate the large workbook:

Command
Description

Alt + ⬇️
Expand a dropdown list from the currently selected cell.

Ctrl + Home
Focus on the top leftmost cell of the currently active sheet.

Ctrl + Page Down
Navigate to the next right-adjacent sheet.

Ctrl + Page Up
Navigate back to the left-adjacent sheet.

F6
Focus the cursor on the sheet tabular navigation. From here, use Right / Left keyboard arrows to navigate through the sheets. Press Enter to bring the selected sheet into focus.

Connect to the Instance Workspace

Start the instance service from the Instance Manager if it's not running.

Use the Client Sign-In Manager Application to sign in to the newly configured Excel instance workspace.

Once logged in, expand the Refresh dropdown menu and click the Refresh Active Scenario or Refresh All Scenarios button in order to initiate the data import procedure. The data from the Excel template will populate in PlanetTogether. 

See Also

Microsoft Excel Integration

Server Installation Guide

Instance Manager

Client Sign-In Manager Application</div>
        </section>
      
        <section class="article" id="article-307-microsoft-excel-integration">
          <h3 class="article-title">Microsoft Excel Integration</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/microsoft-excel-integration" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Data can be imported into PlanetTogether from a Microsoft Excel workbook. This is useful for importing custom data for a demo or when doing preliminary or simplified factory modeling.

The basic concept is that the data from Excel is pulled into a SQL database before being imported into PlanetTogether. The transfer of data from Excel to SQL is done via a stored procedure. In a local or on-premises installation, the software instance can be configured to execute the stored procedure at the time a user clicks the Refresh button in the client user interface so that the data that gets imported is always up to date with the latest changes made to the Excel workbook. For PlanetTogether cloud-hosted environments, updates made to the Excel sheet must be uploaded via the PlanetTogether web application interface before the data changes can be imported into the instance workspace.

Sample Excel Workbook Data Models

PlanetTogether offers two sample Excel workbook strategies: a simple workbook which consolidates a lot of interdependent data objects and mappings into a much smaller number of sheets, or a full integration workbook which offers a 1-to-1 sheet and field mappings which contains a sheet per each of the mappings pages in PlanetTogether, and each sheet offers all data fields that can possibly be imported.

For more information on each sample model, see:

Simple Excel Integration Package

Full Excel Integration Package

Configure SQL Server to connect to Excel

For local and on-premises installations, the following steps are required to query Excel from SQL:

Install 64-bit Microsoft.ACE.OLEDB.16.0 driver: https://www.microsoft.com/en-us/download/details.aspx?id=54920

Configure ACE OLE and Database Properties by executing these commands against the "master" database in Microsoft SQL Server Studio Manager

USE [master]
GO

EXEC sp_MSset_oledb_prop N'Microsoft.ACE.OLEDB.16.0', N'AllowInProcess', 1
GO
EXEC sp_MSset_oledb_prop N'Microsoft.ACE.OLEDB.16.0', N'DynamicParameters', 1
GO

EXEC sp_configure 'show advanced options', 1; 
RECONFIGURE;
GO 
EXEC sp_configure 'Ad Hoc Distributed Queries', 1; 
RECONFIGURE; 
GO

Restart the SQL Server Windows Service 

Some servers require that the SQL Server Windows Service Log On user is configured to logon as the Local System account, as shown here:

See Also

SureStart Integration Methodology

Full Excel Integration Package

Simple Excel Integration Package

Standard Import Database

Standard Publish Database</div>
        </section>
      
        <section class="article" id="article-335-simple-excel-integration-package">
          <h3 class="article-title">Simple Excel Integration Package</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/simple-excel-integration-package" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The PlanetTogether team has created a simplified Excel integration which can be used for local installations, on-premises installations, or PlanetTogether Cloud environments whose import database are connected to the Excel importer offered in the PlanetTogether web application.

Jump to section:

Package File Downloads

Features Available in the Excel Template

Navigating the Excel Template

Customizing the Excel Template

Local Installation and Usage

Package File Downloads

For PlanetTogether Cloud-hosted environments, only the Excel workbook and import mappings files are needed. The appropriate import mappings file must be submitted to PlanetTogether Support in a request to deploy to a specific environment. 

For local or on-premises installations, download the full integration package and follow the installation steps to proceed with installation and local environment setup.

Software Versions
Excel Workbook
Import Mappings
Full Integration Package

12.2.0.x

12.2.1.x

PT_Import_Excel.xlsx
APSInterfaceSettings.xml
Excel_Simple_12.2.0.zip

Features Available in the Excel Template

This data model is meant for quick and simple Excel integrations. It can be expanded to include other data points, but may require significant alterations to the Excel workbook, the import mappings, and for local installations the SQL stored procedure. For complex integrations, it's recommended to use the full Excel integration which offers all PlanetTogether mapping table and fields to be imported.

The following features are available with the standard SureStart integration:

Feature
Notes

Plant
Only single-plant models are supported

Departments
Any number of departments

Resources
Any number of resources and assigned capabilities

Capacity Intervals
Any number of recurring or non-recurring capacity intervals

Warehouses
Any number of warehouses

Inventories
Any number of items and inventories

Jobs
Any number of jobs; each are limited to one manufacturing order; each may have any number of paths/routes which may each have any number of operations

Stock Material Requirements (BOM)
Any number of required materials per operation may be configured as scheduling constraints or not

Products
Any number of products per operation may produce inventory to any warehouse

Sales Orders
Any number of single- or multi-line sales orders

Purchase Orders
Any number of purchase orders

Navigating the Excel Template

The Excel workbook contains many sheets which allows users to define various data objects and fields which make up the scheduling data model.

Guide

This sheet offers an overview of the features included as well as a style guide defining what the various cell and column formatting indicates throughout the document.

Plant

Define the Plant object.

Department_Resources_Capability

Define Resource objects and assign them to a Department. Assign each resource one or more Capabilities.

Shifts

Define Capacity Interval objects.

Shifts_Resources

Assign capacity intervals which were defined in the Shifts sheet to resources which were defined in the Department_Resources_Capability sheet.

Items_Inventory

Define Item and Warehouse objects. Map warehouse objects to plants, and map item objects to warehouses.

Routings

Define Job objects and their dependencies: required quantity, need date, operations, paths, and operation sequence.

BOM_Input

Define the stock material requirements per each operation which was defined in the Routings sheet. 

BOM_Output

Define the product(s) produced by each operation which was defined in the Routings sheet.

SalesOrders

Define Sales Order objects.

PurchaseOrders

Define Purchase Order objects.

Customizing the Excel Template

The Excel template can be modified and customized as needed in order to add or remove properties from the scope of the integration.

Some fields in the Excel sheet are configured with data limitations or dependencies. For example, in the Shifts_Resources sheet, column A uses data validation in SQL to ensure that the value mapped to the ResourceId property matches that of an existing ResourceId from the Department_Resources_Capability sheet.

These validations can optionally be removed from the Data -> Data Validation section of the Excel workbook, but note that it may make the data in the workbook a bit more challenging to accurately update or manipulate.

Web Application Considerations

If using the PlanetTogether Web Application interface to upload the Excel data, any number of Excel workbook sheets can be added, and any number of columns can be added to any of the sheets. Each Excel sheet becomes a unique table in the import database, and each column with some value in the first cell becomes a field in the database. The data type is determined automatically by SQL based on the first value in the Excel sheet. If no values are imported, it assumes a string data type.

After fields and/or sheets are added and the updated Excel workbook uploaded to the Web Application, the user is expected to navigate to the Import Mappings Board and map the new tables and fields to PlanetTogether data objects and properties.

Local Installation Considerations

If running an on-premises installation, adding fields to existing Excel sheets is simple - those fields will automatically be added to the existing tables so that they can be mapped from the Import Mappings Board. Adding new sheets to the workbook though becomes a bit more challenging as the Get_Excel_Data stored procedure will need to be modified to ensure that the new sheet gets converted to a SQL database table.

Local Installation and Usage

Prerequisite

Before proceeding to configure an Excel integration, PlanetTogether server software must be installed, which also requires installation of .NET 6.0 and SQL Server or SQL Express. Use the Server Software Installation Guide to setup a PlanetTogether server.

Access to Microsoft Excel is also required, or another application which allows editing of XLSX files.

ACE OLE DB driver offered by Microsoft must also be installed and configured correctly. See the Microsoft Excel Integration page for more information.

1. Download the File Package

First, be sure to download the Simple Excel Integration file package. The integration files include:

APSInterfaceSettings.xml: The Import Mappings configuration.

PT_Import_Excel.xlsx: The Excel workbook template where data is maintained.

Get_Excel_Data.sql: Use this SQL script to create the stored procedure which transfers data from the Excel sheet into the import database.

PT_Publish_Excel.sql: Optionally, use this SQL script to create a standard publish database. This is only necessary if the schedule data in PlanetTogether will be published to SQL.

Integration.json: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

PtDbDataSet.xsd: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

To install the integration so that it may be used during software instance creation, download and extract the folder of files into the IntegrationFiles folder of the PlanetTogether software installation location, typically:

C:\ProgramData\PlanetTogether\IntegrationFiles

When manually extracted correctly, each of the files listed above will reside in their own contained folder in the IntegrationFiles folder. For example:

C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\APSInterfaceSettings.xml
C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\Get_Excel_Data.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\Integration.json
C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\PT_Import_Excel.xlsx
C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\PT_Publish_Excel.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\SureStart\PtDbDataSet.xsd

2. Create an Instance

Use the Instance Manager to create a new instance. For the quickest setup, select the appropriate Excel_Simple Integration Code from the dropdown list. If none are available, see the Integration Files section of this article to review the installation procedure. It is also recommended to select the New Scenario option from the Scenario File dropdown. Opt to not start the instance service yet since there is some configuration required before the instance and integration are functional.

3. Import Database

It's recommended to create a new empty database named PT_Import_Excel which will act as the data source and import database. Once the database is created, open the Get_Excel_Data.sql file which was included in the Excel integration file download and execute it from a database management software application (e.g. Microsoft SQL Server Management Studio) to create the Get_Excel_Data stored procedure in the import database.

Get_Excel_Data

The Get_Excel_Data stored procedure is configured to fetch all data from each sheet of the workbook and insert it into a database table that matches the name of the sheet prefixed with the text "data_". 

Declare @prefix AS nvarchar(100) = 'data_'

...

SET @trans_start = GETDATE()
SET @Sheet = 'Plant'
SET @SheetRename = @prefix + 'Plant'
SET @Table = 'dbo.'+@SheetRename
IF EXISTS (Select 1 From INFORMATION_SCHEMA.TABLES where TABLE_NAME = @SheetRename) EXEC('Drop Table ' +@Table)
EXEC('select * into '+@Table+' FROM OPENROWSET(''Microsoft.ACE.OLEDB.16.0'', ''Excel 12.0;Database='+@FilePath+''', ['+@Sheet+'$]) WHERE [PlantId] IS NOT NULL ');
SET @row_count = @@ROWCOUNT
SET @trans_end = GETDATE()
INSERT INTO _log_get_excel_data SELECT @import_date, @FilePath, @Sheet, @SheetRename, @trans_type, @trans_start, @trans_end, @row_count

Each property in row 1 of each sheet is dynamically created and added to the corresponding database table, even if it has no data value in the Excel sheet.

The import process will read and write to the database and may create and/or drop tables. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

In order to read the Excel file from disk, it may be necessary to use a sysadmin user. This is set in the Server Roles tab of the user properties.

Other more secure SQL connection configurations are available. Seek assistance from a representative of your IT department to ensure compliance with local policies in regards to SQL database authentication and permissions.

4. Publish Database

This step is optional. If the finished schedule data does not need published from PlanetTogether to a SQL database, skip this step.

Create a new empty database named PT_Publish_Excel. Once created, open the PT_Publish_Excel.sql from the downloaded integration files in a database management software application (e.g. Microsoft SQL Server Management Studio) and execute it to populate the database with two standard PlanetTogether publish stored procedures and one SystemData table. 

The publish database can be given any name, just be sure to use a global find/replace in the PT_Publish_Excel.sql document to replace all iterations of the text "PT_Publish_Excel" with the desired name.

The publish process will read and write to the database and may create and/or drop tables and fields. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

5. Instance Configuration

Import Database Connection

From the Instance Manager, double-click the Excel integration instance, or click it once to select it and click the Edit button from the actions toolbar. From the Import Data tab, click the Import Database Settings button to display the database settings dialog. Configure the appropriate server name (SQL server name where the Excel import database is hosted) and the database name (typically PT_Import_SureStart) and choose either Integrated Security or SQL user authentication.

Once configured, click Save to proceed.

Integrated Security

When disabled, authentication to the specified SQL server and database is established via the User Name and Password fields of this database settings dialog which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the System service of the instance. By default, the Windows user is the standard Local System user which typically does not have access to SQL databases. Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

Run SQL Before Import

Back at the Import Data tab of the instance settings dialog, select the box to Run SQL before import. In the text area to the right of this checkbox, enter a stored procedure EXEC execution command to execute the stored procedure to move the data from Excel into SQL. Note that the file path may vary depending on where the Excel sheet master data resides on the PlanetTogether server.

EXEC Get_Excel_Data @FilePath = 'C:\ProgramData\PlanetTogether\Excel_Simple 12.2.0.27\IntegrationFiles\Excel\PT_Import_Excel.xlsx'

Publish Database Connection

The same process described above can be repeated from the Data Publish tab of the instance settings dialog. Enter the server and authentication logic again, along with the database name.

Save and close all changes.

See Also

Microsoft Excel Integration

SureStart Integration Methodology

Full Excel Integration Package

Standard Import Database

Standard Publish Database</div>
        </section>
      
        <section class="article" id="article-322-surestart-integration-methodology">
          <h3 class="article-title">SureStart Integration Methodology</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/surestart-integration-overview" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

SureStart is a rapid implementation methodology for PlanetTogether that enables companies to utilize the core capabilities of PlanetTogether with minimal data requirements, in as little as 30 days. This agile methodology deploys tools that help users streamline scheduling, manage resource utilization, and provide real-time insights for effective decision-making. This is accomplished by loading core scheduling data via Excel spreadsheets and by relying initially on simple automated scheduling and manual schedule and data refinement rather than extensive automation.

Sample Excel Workbook Data Models

PlanetTogether offers two sample Excel workbook strategies: a simple workbook which consolidates a lot of interdependent data objects and mappings into a much smaller number of sheets, or a full integration workbook which offers a 1-to-1 sheet and field mappings which contains a sheet per each of the mappings pages in PlanetTogether, and each sheet offers all data fields that can possibly be imported.

For more information on each sample model, see:

Simple Excel Integration Package

Full Excel Integration Package

Custom Excel Workbook Data Models

It may be desirable to create a custom formatted Excel workbook which organizes the data in a way that makes sense to the business. This could be useful if the data required for planning can be exported in a specific Excel format from an existing ERP or other master data source. In these cases, the custom workbook can be used to reduce the amount of manipulation required to get it to conform to one of the sample workbooks offered by PlanetTogether.

Minimum Required Data 

There are required properties and data dependencies in PlanetTogether which must be accounted for in order for their associated data objects to be valid and their associated features to function properly. These data can be imported, or any data which is not imported can be created and maintained from the desktop application interface directly.

When importing the data, use the Standard Import Database article as a guide to realize which data are required per each mappings table.

Resources: Resources in PlanetTogether represent the machines, laborers, workstations, tools, or other equipment which perform the work required on the factory floor. Each are assigned one or more Capabilities which determines the type of work that the resource is allowed to perform. Resources must be assigned to a Department, and each Department must be assigned to a Plant. These data can easily be created in the PlanetTogether interface via the Scenario Data Board and the Capacity Planning Board. Data tables to consider when mapping:

Plant Mappings

Department Mappings

Resource Mappings

Capability Mappings

Capability Assignment Mappings

Resource Capacity: Capacity Intervals define whether a resource is Online or Offline where an Online resource is capable of performing work, while an Offline is not. They may recur, or they may be configured as a one-time capacity setting or shift. No work can be scheduled if no online capacity interval is assigned to the resource. These data can be created in the PlanetTogether interface via the Scenario Data Board. Data tables to consider when mapping:

Capacity Interval Mappings

Recurring Capacity Interval Mappings

Capacity Interval Resource Mappings

Inventories: Inventories indicate which items are stored in which warehouses. Each warehouse must also be assigned to one or more plants which they are capable of supplying with their inventories. These data can be created in the PlanetTogether interface via the Scenario Data Board. Data tables to consider when mapping:

Item Mappings

Warehouse Mappings

Plant Warehouse Mappings

Inventory Mappings

Jobs: Jobs represent top-level objects that generate requests for the shop to produce one or more items or products by a specific time. A job can specify one manufacturing order for a product or can be divided into multiple manufacturing orders. Each manufacturing order must specify at least one operation. An operation is considered one production or processing step of the order and is the actual work that gets scheduled on resources. Each operation must be assigned at least one resource requirement and capability requirement which determine the type of work that is needed and the type of resources that is needed to complete the work. Optionally, a bill of materials (BOM) can be required of an operation, and an operation can be configured to produce one or more items to be stored in inventory. These data can be created in the PlanetTogether interface via the Jobs Board, or job templates can be created in the Routing Templates Board which can then be copied to create actual jobs that can be scheduled. Data tables to consider when mapping:

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Resource Requirement Mappings

Required Capability Mappings

Material Mappings

Product Mappings

Workbook Formatting Considerations

When importing data from an Excel workbook via the PlanetTogether Web Application, take note of the following behavior of the import process and adjust the workbook format as needed:

Each sheet within the workbook becomes a SQL table. The table is named the same as the sheet.

Each column with text in the first row is added to the table as a field. The field is named the same as the text used in the first row.

The sheets and column headers can be named anything. Each field in Excel and SQL will be mapped to a corresponding PlanetTogether property where its name will be transformed as needed in order to confirm to PlanetTogether's standard property naming convention.

There is no need to define a data type for each column. The import process assumes each row accepts a string (nvarchar) since the PlanetTogether desktop application is capable of validating the data and converting it to the appropriate format needed for the property in the software.

Import Mappings

Once the data is imported successfully into the SQL import database, a user must configure the mapping of data from the Excel/database fields to PlanetTogether properties. This effort is achieved from the Import Mappings Board in the desktop application.

See Also

Microsoft Excel Integration

Simple Excel Integration Package

Full Excel Integration Package

Standard Import Database

Standard Publish Database</div>
        </section>
      <h2 id="cat-integrations-standard-planettogether-integration" class="category-header">Integrations &gt; Standard PlanetTogether Integration</h2>
        <section class="article" id="article-215-standard-import-database">
          <h3 class="article-title">Standard Import Database</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/standard-import-database" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether instance workspaces typically connect to a SQL database where data can be imported from. The import database is typically a staging database which acts as a link between a master data source like an ERP or MES system and the PlanetTogether scheduling application. This enables organizations to use one system to enter and manage all data (ERP, MES, etc.) so that the same data doesn't have to be re-entered into PlanetTogether for scheduling.

A standard import database consists of one table per object which can possibly be mapped into PlanetTogether, where each table consists of all fields which can possibly be imported per each object. PlanetTogether categorizes data into three buckets: Resource Objects, Inventory Objects, and Job Objects.

For some data elements, the definitions in PlanetTogether contain fields that do not have an ERP equivalent. In these cases, the values may be left at their default values (NULL values imported), calculated in the interface, or manually entered in PlanetTogether after the object is created via the interface. If a value is omitted in the import mappings, then manual changes made from the PlanetTogether user interface will be preserved when data is refreshed from the SQL source.

Jump to section:

Standard Database Creation Script

Resource Objects

Inventory Objects

Job Objects

Integration Approaches

Standard Database Creation Script

Use the provided .sql script to create the tables and fields of a standard import database.

PT_Import.sql

APSInterfaceSettings.xml

All field types are nvarchar(255) except for UserField fields which can often contain very long strings of text. These are designated nvarchar(MAX) to allow for strings longer than 255 characters. Using nvarchar allows for any text to be entered into any of the fields in the database. The data is validated though once it's imported into a PlanetTogether instance workspace. If the data does not conform to the expected data type per each imported field, then it won't be properly converted to the correct data type and will not be allowed to be imported. In these instances, the user who attempts to import the incompatible data will receive related errors from the Interface logs of the PlanetTogether user interface. The expected data types are denoted in the Import Mappings Board interface, and are also documented in each of the individual Import Mappings pages in this knowledge base.

Resource Objects

Resource Objects deal primarily with the physical setup of the manufacturing facility and will therefore consist of how machines and capital are organized into a tiered structure. Resource Objects are meant to reflect the manufacturer's capacity to do work and the type of work that can be done.

Required Resource Object Mappings

Plants

A Plant is meant to represent an entire facility or location where production occurs. It is usually synonymous with a single physical factory. However, in PlanetTogether, a Plant consists of any number of Departments that contain any number of Resources used to produce goods. PlanetTogether is a multi-plant capable system so there may be more than one Plant associated with the data model (software license permitting). Plants also play a role in inventory locations as Warehouses (see inventory objects) are associated with Plants.

Table Name: Plants

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the PLANT

String

✓

Name

PLANT Name

String

✓

StableSpanHrs

The plant stable span hours. For more information, see: Plant Stability.

Double

✗

All Plant Field Mappings 

Departments

Departments are a means to help to organize the grouping of Resources in whatever manner makes the most sense for an organization. A resource must be associated with exactly one department. PlanetTogether uses departments for display usability as users can filter the resources they see based on department. Their only impact on scheduling is the ability to set a frozen zone unique to each Department. Typically, Departments in PlanetTogether correspond to ERP work centers. 

Example: CNC1, CNC2, and CNC3 machines are all a part of the department CNC whereas labor resources ED, RYAN, and KELLY are all a part of the department LABOR.

Table Name: Departments

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the DEPARTMENT

String

✓

Name

DEPARTMENT Name

String

✓

PlantExternalId

ExternalId of the PLANT that the DEPARTMENT belongs to

String

✓

DepartmentFrozenSpanHrs

The Frozen Span Hours for the department. For more information, see: Plant Stability.

Double

✗

All Department Field Mappings 

Resources

Resources in PlanetTogether represent the machines, laborers, workstations, tools, or other equipment which perform the work required on the factory floor.

Table Name: Resources

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the RESOURCE

String

✓

Name

RESOURCE Name

String

✓

PlantExternalId

ExternalId of the PLANT that the RESOURCE belongs to

String

✓

DepartmentExternalId

ExternalId of the DEPARTMENT that the RESOURCE belongs to

String

✓

NoDefaultRecurringCapacityInterval

Prevents automatically assigning a default capacity interval to the RESOURCE, and prevents JOBs from scheduling on a newly-imported RESOURCE.

Boolean

✗

HeadStartHrs

Specifies the number of hours that a job or operation can be released to schedule on the resource ahead of its calculated Just In Time (JIT) date.

Double

✗

All Resource Field Mappings 

Capabilities

A capability defines the type of work or skill that a resource can do. Each resource can have multiple capabilities, and capabilities can be linked to multiple resources. In addition, each operation's resource requirement indicates the required capabilities that a resource must have to be considered eligible to operate. Therefore, for an activity to schedule on a resource, the operation must reference the number of resources required and those resources' capabilities. 

For example, a CNC machine may be able to DRILL, CUT, and MILL. Therefore these tasks (DRILL, CUT, and MILL) are considered capabilities. In the Job Objects section we will discuss Required Capabilities which links the capability requirement of the operation to the list of capabilities in PlanetTogether and in-turn the capable resource.

Most ERP systems do not have an exact equivalent to the Capability. A common approach therefore is to use the Item or Work Center as the Capability. Using Item as Capability would mean that each Resource is given a list of Items it can create (or Item/Operation for multi-step processes). Using Work Center as Capability would mean that each Resource in the Work Center can do equivalent work. While this is not always accurate, it may be a good starting point, with manual rescheduling to assign specific machines being used as needed. Note that in addition to using a Capability, a Default Resource can be specified for an operation to assign a particular Resource to do the work, rather than choosing from any Resource with the Capability. This is useful when certain Resources are preferred or required over others for a particular production operation.

Table Name: Capabilities

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the CAPABILITY

String

✓

Name

CAPABILITY Name

String

✓

All Capability Field Mappings 

Resource Capabilities

The resource capabilities table assigns each capability to one or more resource(s). Only Resources that are linked to the needed Capability(ies) of an operation may be assigned the work during scheduling.

Table Name: ResourceCapabilities

Recommended Fields:

Field Name

Field Description

Data Type

Required

CapabilityExternalId

ExternalId of the CAPABILITY

String

✓

PlantExternalId

ExternalId of the associated PLANT

String

✓

DepartmentExternalId

ExternalId of the associated DEPARTMENT

String

✓

ResourceExternalId

ExternalId of the associated RESOURCE

String

✓

All Capability Assignment Field Mappings 

Recommended Resource Object Mappings

Resource Capacity Intervals

Resource Capacity Interval objects define the intervals of time where resources are available (or not) to work on jobs, including the type of work and how much work can be scheduled at each interval. Capacity Intervals define whether a resource is Online or Offline, and they may recur, or they may be configured as a one-time capacity setting or shift. Capacity Intervals can be thought of as shift intervals to determine when a resource is available. Each Capacity Interval may be assigned to any number of Resources.

Table Name: CapacityIntervals

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the associated non-recurring CAPACITY INTERVAL

String

✓

Name

The Name of the non-recurring CAPACITY INTERVAL

String

✓

StartDateTime

The date and time that the non-recurring CAPACITY INTERVAL starts

Datetime

✓

EndDateTime

The date and time that the non-recurring CAPACITY INTERVAL ends

Datetime

✓

IntervalPreset

A preset CAPACITY INTERVAL type. 

Accepted values:

Online

Offline

Overtime

PotentialOvertime

Cleanout

Holiday

Maintenance

String

✗

All Capacity Interval Field Mappings 

Table Name: RecurringCapacityIntervals

Recommended Fields:

Field Name

Field Description

Data Type

Required

ExternalId

Unique identifier of the associated recurring CAPACITY INTERVAL

String

✓

Name

The Name of the recurring CAPACITY INTERVAL

String

✓

StartDateTime

The date and time that the recurring CAPACITY INTERVAL starts

Datetime

✓

EndDateTime

The date and time that the recurring CAPACITY INTERVAL ends

Datetime

✓

Recurrence

The frequency in which the interval should recur. 

Accepted values:

NotRecurring

Daily

Weekly

MonthlyByDayNumber

YearlyByMonthDay

String

✓

RecurrenceEndType

Determines when to end the recurrences. 

Accepted values:

NoEndDate

AfterMaxNbrRecurrences

AfterRecurrenceEndDateTime

String

✓

IntervalPreset

A preset CAPACITY INTERVAL type. 

Accepted values:

Online

Offline

Overtime

PotentialOvertime

Cleanout

Holiday

Maintenance

String

✗

Sunday

Boolean to control whether the interval is scheduled on Sundays during the recurrence period

Boolean

✗

Monday

Boolean to control whether the interval is scheduled on Mondays during the recurrence period

Boolean

✗

Tuesday

Boolean to control whether the interval is scheduled on Tuesdays during the recurrence period

Boolean

✗

Wednesday

Boolean to control whether the interval is scheduled on Wednesdays during the recurrence period

Boolean

✗

Thursday

Boolean to control whether the interval is scheduled on Thursdays during the recurrence period

Boolean

✗

Friday

Boolean to control whether the interval is scheduled on Fridays during the recurrence period

Boolean

✗

Saturday</div>
        </section>
      
        <section class="article" id="article-276-standard-integration-api">
          <h3 class="article-title">Standard Integration API</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/integration-api" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

A standard integration API is available for external applications to push and pull data from instances of PlanetTogether which are hosted in the PlanetTogether cloud environment. These REST API endpoints are offered with the intention to allow Value Added Reseller and Technology partner organizations to be able to create their own standard integration between PlanetTogether and a master data source like an ERP or MES system.

Collaboration with the PlanetTogether Cloud Operations Support team is required in order to gain access to use the API.

Collaboration with the PlanetTogether Product team is recommended to oversee efforts to create and maintain standard integrations between PlanetTogether and a master data source.

In general, instances hosted in the PlanetTogether cloud environment share a single database for import and publish data, so these API endpoints can be used to manipulate either import or publish data. Import database tables are prefixed with [import]. while publish database tables are prefixed with [publish].

API Endpoints

Jump to section:

CreateTable

ImportDataToTable

DeleteTableData

DeleteAllTableData

GetRecordsFromTable

UpdateTableData

TriggerImport

CreateTable

This endpoint will create a table in the database. The body of the request contains the column name and column data type.

Supported data types:

int

varchar

bool

float

long

datetime

string

double

decimal

HTTP Request

Method: POST

URL: https://api.planettogether.com/<ENV>/api/import/CreateTable/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of ImportDB table name (e.g. [import].[inventory])

Ocp-Apim-Subscription-Key: Azure API management key

Sample Request body

[
 {
 "ExternalId": "string",
 "Name": "string",
 "Description": "string",
 "Notes": "string"
 }
]

API Response

"Success" or Error message

ImportDataToTable

This endpoint will insert data into a table in the database. The body of the request contains the column name and its value.

HTTP Request

Method: POST

URL: https://api.planettogether.com/<ENV>/api/import/ImportDataToTable/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of ImportDB table name (e.g. [import].[inventory]). The table must already exist in the database.

Ocp-Apim-Subscription-Key: Azure API management key

Sample Request body

[
 {
 "ExternalId": "Plant01",
 "Name": "Plant01",
 "Description": "Description of the Plant",
 "Notes": "Notes about the Plant"
 }
]

API Response

"Success" or Error message

DeleteTableData

This endpoint will delete rows of data from a table in the database which match all of the fields and values provided in the request body.

HTTP Request

Method: DELETE

URL: https://api.planettogether.com/<ENV>/api/import/DeleteTableData/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of ImportDB table name (e.g. [import].[inventory])

Ocp-Apim-Subscription-Key: Azure API management key

Sample Request body

[
 {
 "ExternalId": "Plant01"
 }
]

API Response

"Success" or Error message

DeleteAllTableData

This endpoint will delete all rows of data from a table in the database.

HTTP Request

Method: DELETE

URL: https://api.planettogether.com/<ENV>/api/import/DeleteAllTableData/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of ImportDB table name (e.g. [import].[inventory])

Ocp-Apim-Subscription-Key: Azure API management key

Sample Request body

[]

API Response

"Success" or Error message

GetRecordsFromTable V2

This endpoint will retrieve records from a table from the database, and also return the total number of records in the table.

Past version documentation:

Version 1

HTTP Request

Method: GET

URL: https://api.planettogether.com/<ENV>/api/import/GetRecordsFromTable/v2

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of Import or Publish database table name (e.g. [publish].[Jobs])

Ocp-Apim-Subscription-Key: Azure API management key

QueryString: SQL query to filter the results (note that the WHERE clause is implied)

E.g. JobName like 'WO%'

Limit: The number of records to return. By default, 1,000 records are returned.

Offset: Number of records to skip.

OrderBy: Define the sort order logic that should be used when querying the table. This overrides the default value of "1".

The query sent to the database follows this pattern/syntax:

SELECT * FROM {tableName} WHERE {queryString} ORDER BY 1 OFFSET {offset} ROWS FETCH NEXT {limit} ROWS ONLY

Note that since the query already contains an ORDER BY clause, attempting to use an ORDER BY clause in the QueryString header will result in a syntax error.

Sample Request body

[]

API Response

Record count and details of each record from the specified database table.

UpdateTableData

This endpoint will update records in the specified database table.

HTTP Request

Method: PUT

URL: https://api.planettogether.com/<ENV>/api/import/UpdateTableData/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

TableName: Name of ImportDB table name (e.g. [import].[inventory])

Ocp-Apim-Subscription-Key: Azure API management key

QueryString: E.g. InventoryId='1933'

Sample Request body

[
 {
 "Description": "Updated description text for the Plant",
 "Notes": "Updated notes for the Plant"
 }
]

API Response

"Success" or Error response

TriggerImport

This endpoint will trigger a data import/refresh into the specified scenario in the specified instance.

HTTP Request

Method: POST

URL: https://api.planettogether.com/<ENV>/api/import/TriggerImport/v1

Where <ENV> is one of the following:

dev

qa

prod

Header requirement

CompanyId: Company Id provided by PlanetTogether

CompanyAPIKey: Security key provided by PlanetTogether

InstanceName: Unique instance name in PlanetTogether solution landscape

Ocp-Apim-Subscription-Key: Azure API management key

ScenarioName: Name of the scenario to import the data into

Sample Request body

[]

API Response

"Success" or Error response

See Also

Standard Import Database

Standard Publish Database</div>
        </section>
      
        <section class="article" id="article-308-standard-publish-database">
          <h3 class="article-title">Standard Publish Database</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/standard-publish-database" target="_blank">Source</a></p>
          <div class="article-content">Old Article Versions

This article is updated to reflect the latest software functionality. For older software versions, download and refer to the appropriate document version:

Software Version
Download Link

12.2.1.x
StandardPublishDatabase_12.2.1.pdf

Key Concept

When integrating PlanetTogether with external systems, a SQL database is used to publish or export the schedule from PlanetTogether before the schedule data gets transmitted to an ERP, MES, or other external integration destination.

PlanetTogether desktop application users have options to export the schedule data to a primary Publish database, or to an Analytics database. The exported SQL schema and data are identical between the two destinations. A common practice for many organizations is to configure the primary Publish database to retain only a single schedule while the Analytics database might be configured to allow for publishing many schedules so that reports can be used to see trends over time. Publishing to Analytics is entirely optional.

Publish and Analytics Database Creation

The Publish and Analytics SQL databases only needs to contain one table and two stored procedures to be compatible with PlanetTogether's Publish functionality. When a user first initiates a publish of the schedule from the instance workspace, all tables and fields will be created if they do not exist.

Standard Database Creation Script

Download this SQL script and execute its queries to create and/or alter a standard database called "PT_Publish":

PT_Publish.sql

It's recommended to first create an empty database with the desired settings:

Then execute the provided SQL queries to populate the database with the SystemData table and the two stored procedures.

Alternatively, the provided .sql script can create the table too if the top section is uncommented. This may require altering the file paths defined in the FILENAME parameter to point to the appropriate installation location of SQL Server.

Standard Publish Database Schema

Schema Files per Software Version

Software Version
Schema File

12.1.3.x
StandardPublishDBSchema_12.1.3.15.sql

12.1.4.x
StandardPublishDBSchema_12.1.4.24.sql

12.2.0.x
StandardPublishDBSchema_12.2.0.27.sql

12.2.1.x
StandardPublishDBSchema_12.2.1.58.sql

12.2.1.x
StandardPublishDBSchema_12.2.1.129.sql

12.3.0.x
StandardPublishDBSchema_12.3.0.90.sql

Table: [SystemData]

Field Name
Data Type
Nullable

Version
nvarchar
Yes

ValidateDB
bit
Yes

PrepareData
bit
Yes

ClearCustomTables
bit
Yes

Procedure: [ClearAllHistoryData]

The procedure doesn't need to do anything, it just needs to exist. In a standard publish database, this procedure uses TRUNCATE TABLE to purge all data from all standard publish tables. This procedure is called when a user or action triggers an instance workspace to publish a schedule if the [ ] Retain Published Schedules publish option is disabled.

When configuring an Analytics database, this procedure can be configured to do nothing, or it can be configured to only purge data which is older than some number of days, weeks, etc.

Procedure: [ClearOldHistoryData]

The procedure doesn't need to do anything, it just needs to exist. In a standard publish database, this procedure is called when a user or action triggers an instance workspace to publish a schedule if the [x] Retain Published Schedules publish option is ensabled. The procedure uses the application settings Delete activity scheduled to start beyond the next, Delete all history older than, and Delete non-production scenario history older than to define what data gets purged from the publish database tables based on how old it is (when it was previously published). This allows for many published schedules to be preserved in the publish database so that scheduling trends may be tracked over time.

When configuring an Analytics database, this procedure can be configured to do nothing, or it can be configured to only purge data which is older than some number of days, weeks, etc.

Database Schema

Table: [dbo].[Plants]

Field Name
Data Type
Nullable
Primary key

PublishDate
datetime
No
Yes

InstanceId
nvarchar(38)
No
Yes

PlantId
bigint
No
Yes

Name
nvarchar(max)
Yes

Description
nvarchar(max)
Yes

Notes
nvarchar(max)
Yes

BottleneckThreshold
float
Yes

HeavyLoadThreshold
float
Yes

ExternalId
nvarchar(max)
Yes

DepartmentCount
int
Yes

StableDays
float
Yes

DailyOperatingExpense
float
Yes

InvestedCapital
float
Yes

AnnualPercentageRate
float
Yes

Table: [dbo].[Departments]

Field Name
Data Type
Nullable
Primary key

PublishDate
datetime
No
Yes

InstanceId
nvarchar(38)
No
Yes

PlantId
bigint
No
Yes

DepartmentId
bigint
No
Yes

Name
nvarchar(max)
Yes

Description
nvarchar(max)
Yes

Notes
nvarchar(max)
Yes

ExternalId
nvarchar(max)
Yes

PlantName
nvarchar(max)
Yes

ResourceCount
int
Yes

DepartmentFrozenSpanDays
float
Yes

Table: [dbo].[Resources]

Field Name
Data Type
Nullable
Primary key

PublishDate
datetime
No
Yes

InstanceId
nvarchar(38)
No
Yes

PlantId
bigint
No
Yes

DepartmentId
bigint
No
Yes

ResourceId
bigint
No
Yes

Name
nvarchar(max)
Yes

Description
nvarchar(max)
Yes

Notes
nvarchar(max)
Yes

Bottleneck
bit
Yes

BufferHours
float
Yes

CapacityType
nvarchar(max)
Yes

Drum
bit
Yes

OvertimeHourlyCost
float
Yes

StandardHourlyCost
float
Yes

ExperimentalDispatcherOne
bigint
Yes

ExperimentalDispatcherTwo
bigint
Yes

ExperimentalDispatcherThree
bigint
Yes

ExperimentalDispatcherFour
bigint
Yes

NormalDispatcher
bigint
Yes

Workcenter
nvarchar(max)
Yes

CanOffload
bit
Yes

CanPreemptMaterials</</div>
        </section>
      <h2 id="cat-object-import-mappings-inventory-objects-mappings" class="category-header">Object Import Mappings &gt; Inventory Objects Mappings</h2>
        <section class="article" id="article-350-forecast-mappings">
          <h3 class="article-title">Forecast Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/forecast-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Forecasts

*ExternalId | String

A unique identifier of the Forecast. Must be unique per Item.

*ForecastVersion | String

The version of the forecast. The PlanetTogether software currently only supports one common version assigned to all imported forecasts, so while this can be assigned any string value, only forecasts which share a common ForecastVersion will appear in the Forecast Manager tile. If uncertain what to set for this value, just set it to "1".

*ItemExternalId | String

The External identifier of the Item for which the Forecast is generated.

*Name | String

Unique, changeable, text identifier of the Forecast.

*WarehouseExternalId | String

The Warehouse in which the Item is stored.

CustomerExternalId | String

The External ID of the Customer that the Forecast is associated with.

Description | String

Text for describing the Forecast.

Notes | String

Comments or special considerations about this Forecast.

Planner | String

The scheduler who will manage the Forecast.

Priority | Int32

Usually used to specify a combination of importance and urgency. The Balanced Composite Rule can use this. Lower numbers are more urgent/important.

SalesOffice | String

Specifies the sales office or other physical location that created the demand. This does not affect the Warehouse that satisfies the Forecast. It is for reference only.

SalesPerson | String

The sales employee who is responsible for this Forecast demand.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

Forecast Shipments

*ForecastExternalId | String

The External identifier of the Forecast is to be shipped.

*RequiredQty | Decimal

The Required Quantity of Items for the Forecast.

*RequiredDate | DateTime

The Required Date for the Shipment.

*WarehouseExternalId | String

The External identifier of the Warehouse associated with the Forecast.

See Also

Inventory Plan Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-292-inventory-mappings">
          <h3 class="article-title">Inventory Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/inventory-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ItemExternalId | String

The External identifier of the Item whose stock (inventory) is being stored.

*WarehouseExternalId | String

The External identifier of the Warehouse where the Item is being stored.

AutoGenerateForecasts | Boolean

If True, PlanetTogether automatically generates forecasts for this inventory item when its sales orders are updated.

ForecastInterval | String

This specifies the amount of time between each auto-generated forecast.

Quarter

Month

Week

Day

NumberOfIntervalsToForecast | Int32

This defines how many forecasts should be auto-generated.

BufferStock | Decimal

This is used in setting Warning Levels.

DbrReceivingBufferDays | Double

The Receiving Buffer Days of the Inventory for the Purchase to Stock.

DbrShippingBufferDays | Double

The Shipping Buffer of the Item’s Inventory.

ForecastConsumption | String

Forecast consumption is used as part of MRP. This specifies how MRP should consume forecasts before the MRP logic is executed. Accepted values:

Backward: Will search for forecasts with the same or earlier period.

Forward: Will search for forecasts with the same or later period.

BackwardThenForward: Starts as a backward strategy but switches to forward when no more backward forecasts are available, and sales orders are not fully consumed yet.

Spread: Finds the forecasts before and after the sales order then calculates the ratio between the sales order and forecast. The ratio amounts consume forecasts.

ForecastConsumptionWindowDays | Double

The number of days within the forecast consumption window.

LeadTimeDays | Double

The amount of time it takes between when the Item is ordered and delivered for this Warehouse.

MaterialAllocation | String

This field specifies how material will be allocated according to the production or procurement date of the material source. Accepted values:

NotSet: No allocation rules are set. Default behavior is to allocate oldest material sources first.

UseNewestFirst: The material requirement will source material from the most recently produced or procured material source.

UseOldestFirst: The material requirement will source material from the earliest/oldest produced or procured material source.

MaxInventory | Decimal

Specifies the maximum quantity of items that can be stored in inventory. Used to set alerts when Inventory Levels are predicted to be above this value.

MrpExcessQuantityAllocation | String

Controls which parent jobs are adjusted to accept the increased allocation when MRP-generated jobs produce excess. Accepted values:

None: Leave extra material as WIP in the warehouse or on the tank. This is the default.

LastParentJob: Allocate the remainder to the last consuming job (by Need Date).

AllParentJobsEqually: Divide the excess quantity equally among the parent jobs.

AllParentJobsProportionally: Divide the excess quantity proportionally to the parent job quantities.

MrpProcessing | String

This specifies whether MRP should generate Purchase Orders or Jobs to supply the Item. Accepted values:

Ignore: MRP Optimize Plan will not generate jobs or purchase orders.

GenerateJobs: MRP Optimize Plan will use the assigned TemplateJobExternalId routing template generate jobs to satisfy demands if MRP is configured to generate jobs.

GeneratePurchaseOrders: MRP Optimize Plan will generate purchase orders to satisfy demands if MRP is configured to generate purchase orders.

See also: MPS/MRP Planning.

OnHandQty | Decimal

Removed from software versions 12.3.0 and newer.

This value reflects the amount of inventory that is available to work with in this Warehouse. If the associated Item uses Lot Control then on-hand inventory must be imported as one or more Lots. See also:

Lot Controlled Planning

Lots Mappings

PlannerExternalId | String

The External identifier of the Planner is responsible for monitoring and managing this Item's stock level at this Warehouse.

PreventSharedBatchOverflow | Boolean

This prevents partial batching (meaning more than one batch is needed) with other demands. This can be used to better control batch creation and prevent issues with lot pegging if partial quantity is pegged.

PurchaseOrderSupplyStorageAreaExternalId | String

The ExternalId of the Storage Area that should be used by MRP when it generates purchase orders to satisfy demands. Required when MrpProcessing is set to GeneratePurchaseOrders.

SafetyStock | Decimal

The target level of this Item to have on hand at this Warehouse is to provide the desired service level to customers. Falling below the safety stock will trigger a warning on the Inventory Plan to alert that additional material is required.

SafetyStockJobPriority | Int32

Sets the Priority value of the MRP-generated Job replenishing the safety stock. This is used for optimization. Lower priority numbers are usually favored over higher numbers.

SafetyStockWarningLevel | Decimal

If a job's classification is "Safety Stock", then ignore the lateness if the current inventory is greater than the warning level.

If the Job's classification is "Safety Stock" and the Job has Products associated with it, then this value will be set to true only if the Job is later than the Safety Stock Warning Level of the Product's Inventory.

StorageCapacity | Decimal

A Scheduling Extension can use it to limit scheduling based upon the availability of storage space.

TemplateJobExternalId | String

The External identifier of the Job/Routing Template used by MRP to generate Jobs for this item.

See Also

Item Mappings

Inventory Plan Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-303-item-mappings">
          <h3 class="article-title">Item Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/item-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Item.

BatchSize | Decimal

The size of the Batch that can be produced or purchased. Jobs and Purchase Orders must be in integer multiples of this value.

BatchWindowHrs | Double

When batching demand to create Jobs or Purchase Orders, the batch should not reach out further than this value to reach the MaxOrderQty.

Cost | Decimal

The cost of the item. This value is used to calculate the value of inventory, reporting, and financial optimization.

DefaultLeadTimeDays | Double

Specifies the time it takes between when the items are ordered to when they are received. This is used by Material Requirements when there is no Inventory Record for the Item at any available warehouse.

Description | String

A text description of the Item.

ItemGroup | String

It can be used for visually grouping Items into categories.

ItemType | String

The type of item that is produced, stocked, or consumed. Mostly for informational purposes.

Tool type items are the only type with any sort of functional implication. They exhibit unique behavior when reporting progress against an operation which either consumes or produces the item. No partial consumption or production is reported to inventory.

Tool type items are also excluded from consideration when using the Update sub-job need date feature.

Accepted values:

FinishedGood

Intermediate

RawMaterial

Resource

SubAssembly

ByProduct

CoProduct

Tool

JobAutoSplitQty | Decimal

The quantity to be split off of the job. Jobs are auto-split if the item's JobAutoSplitQty is greater than the job's first manufacturing order's required quantity.

LotUsability | String

Removed from software versions 12.3.0 and newer.

Specifies how the lot can be used. See also: Lot Controlled Planning. Accepted values:

Uncontrolled: Lot controlled planning is disabled. This is the default value if no other value is imported.

ShelfLife: The item is lot controlled. Its lots are limited to be consumed within a certain time frame. Lot expiration is determined by the lot production date plus the value of the ShelfLifeHrs item property, or the expiration date can be imported and assigned to imported lots via Lots Mappings. Expired lots cannot be consumed and their inventory is removed at the time of expiration.

Controlled: The item is lot controlled. Lot codes can be used to peg batches of material to consuming jobs/operations.

ShelfLifeNonConstraint: The item is lot controlled. Its lots are limited to be consumed within a certain time frame, but expired lots remain in inventory and can still be consumed by jobs/operations. Layouts and Metrics can be enabled to visualized expired lot consumption so that a material planner may act to correct material allocations manually in order to reduce the amount of expired material.

MinOrderQty | Decimal

Each Job or Purchase Order for this item must be at least this quantity. Used in conjunction with BatchSize to calculate the minimum number of batches required.

MaxOrderQty | Decimal

Each Job and Purchase Order for this item must be no more than this quantity. Used in conjunction with BatchSize to calculate the maximum number of batches allowed.

MinOrderQtyRoundupLimit | Decimal

This value is added to the MinOrderQty when generating purchases to stocks when the quantity short is greater than this value.

Name | String

The name of the Item. Unique, changeable, text identifier.

Notes | String

Comments or special considerations about this Item.

PlanInventory | Boolean

Whether the item should be included in the Inventory Plan.

RollupAttributesToParent | Boolean

Whether the operation attributes are "rolled-up" into the job recursively as needed.

ShelfLifeHrs | Double

The amount of time that each lot of the Item will remain in inventory before expiring and being removed if it has not been depleted/consumed.

ShelfLifeWarningHrs | Double

Warning threshold time to be configured per item. The time desired to receive a warning when a material is consumed close to its expiry.

Source | String

Where the Item originates from. This value may dictate certain functional behavior. Accepted values:

Purchased: The item is always purchased from a supplier.

Manufactured: The item is manufactured in the factory.

PurchasedOrManufactured: The item may be purchased from a supplier, or manufactured in the factory.

Items whose source is either Manufactured or PurchasedOrManufactured may have Product Rules created and associated with them.

TransferQty | Double

As this product is produced, it is transferred to Inventory in quantities of this size when the operation product's InventoryAvailabilityTiming property is set to BasedOnTransferQty.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Inventory Plan Board

Import Mappings Board

Warehouse Mappings

Plant Warehouse Mappings

Inventory Mappings</div>
        </section>
      
        <section class="article" id="article-327-item-storage-lots-mappings">
          <h3 class="article-title">Item Storage Lots Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/item-storage-lots-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ItemExternalId | String

The ExternalId of the Item to be stored.

*StorageAreaExternalId | String

The ExternalId of the storage area where the item will be stored.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the associated storage area is located.

*LotExternalId | String

The ExternalId of the associated Lot that is stored in the storage area. The Lot object is imported via Lots Mappings.

*Qty | Decimal

The quantity of the lot that is stored in the storage area. It must be greater than 0.

See Also

Items, Inventories, Warehouses, & Storage Areas

Lots Mappings

Storage Area Mappings

Item Storage Mappings

Storage Areas Board</div>
        </section>
      
        <section class="article" id="article-235-item-storage-mappings">
          <h3 class="article-title">Item Storage Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/item-storage-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ItemExternalId | String

The External identifier of the Item.

*StorageAreaExternalId | String

The External identifier of the storage area.

*WarehouseExternalId | String

The External identifier of the Warehouse where the storage area is located.

DisposalQty | Decimal

Any quantity less than this that is stored in the storage area can be discarded in order to make room for other material.

DisposeImmediately | Boolean

Whether excess material under the DisposalQty will be discarded as soon as the quantity drops below the limit. If false, the material will only be discarded if it expires or it needs to be removed to store something else. If true, the material will be disposed as soon as it falls below the DisposalQty.

MaxQty | Decimal

The maximum quantity of the item that can be stored at any time in the storage area.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).</div>
        </section>
      
        <section class="article" id="article-341-lots-mappings">
          <h3 class="article-title">Lots Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/lots-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier for the Lot.

*ItemExternalId | String

The External identifier for the item.

*Qty | Decimal

Removed from software versions 12.3.0 and newer. Lot quantity is now imported via Item Storage Lots Mappings.

The Lot Quantity.

*WarehouseExternalId | String

The External identifier for the Warehouse storing the Lot.

Code | String

The Lot Code.

ExpirationDate | DateTime

The expiration date of the Lot.

LimitMatlSrcToEligibleLots | Boolean

Whether the material source should be constrained to the eligible lots. Note: If this is set to true, a Lot Code must also be set.

LotProductionDate | DateTime

Date of Lot Production

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Lot Controlled Planning

Item Mappings

Inventory Mappings

Storage Area Mappings

Item Storage Mappings

Item Storage Lots Mappings

Inventory Plan Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-241-plant-warehouse-mappings">
          <h3 class="article-title">Plant Warehouse Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/plant-warehouse-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*WarehouseExternalId | String

The external identifier of the Warehouse.

*PlantExternalId | String

The external identifier of the Plant to which this warehouse belongs.

See Also

Plant Mappings

Warehouse Mappings

Inventory Plan Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-310-purchases-to-stock-mappings">
          <h3 class="article-title">Purchases To Stock Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/purchases-to-stock-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier for the Purchase To Stock (Purchase Order). This value must be unique per each Purchase to Stock.

*ItemExternalId | String

The ExternalId of the item to be purchased.

*QtyOrdered | Decimal

The number of units of the item that have been ordered.

*StorageAreaExternalId | String

The ExternalId of the Storage Area where the order will be stored when received.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the order will be stored when received.

ActualReceiptDate | DateTime

The date and time at which the purchase order actually arrived at the warehouse. This can be used to track purchase order deliveries.

BuyerExternalId | String

The name of the individual who is responsible for this purchase. For informational purposes.

Closed | Boolean

If True, the Purchase to Stock is considered closed. Purchases to Stock are generally closed when all Required Quantities have been received.

Description | String

Additional text for describing the Purchase to Stock.

Firm | Boolean

This specifies that the Purchase to Stock is firm. Firm Purchases to Stock will not be deleted by MRP when MRP is used to generate Purchases to Stock/Purchase Orders.

LimitMatlSrcToEligibleLots | Boolean

Whether the material consumption should be constrained to eligible lots when this Purchase Order is consumed. If True, eligible lots are determined by the Lot Code pegging (LotCode of the Purchase Order must match that of the AllowedLotCode of the Material requirement).

UseLimitMatlSrcToEligibleLots | Boolean

Set to True to enforce the LimitMatlSrcToEligibleLots property logic.

LotCode | String

The Lot Code is to be applied to the items being received, if applicable.

Name | String

Unique, changeable, text identifier for the Purchase Order.

Notes | String

Comments or special considerations about the Purchase Order object.

OverrideStorageConstraint | Boolean

If True, this material will be allowed to store in excess of the storage area's max quantity when received. If false, any material that can't be stored will be discarded.

QtyReceived | Decimal

The number of items that have actually been received. This value may be different from the QtyOrdered.

RequireEmptyStorageArea | Boolean

If True, the destination storage area must be empty or else the received material will be discarded.

ScheduledReceiptDate | DateTime

The date and time at which the purchase order is scheduled to arrive at the warehouse.

TransferHrs | Double

The time it takes for the materials to be transferred into the warehouse after they are received. Material is not considered usable in production until this time has passed after the Scheduled Receipt Date.

UnloadHrs | Double

If scheduling Docks, this is used to specify the amount of time it will take to unload the items.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

VendorExternalId | String

The company that the Items or parts are ordered from. This ID must match that of an existing Customer object record.

See Also

Item Mappings

Warehouse Mappings

Plant Warehouse Mappings

Customer Mappings

Import Mappings Board

MPS/MRP Planning</div>
        </section>
      
        <section class="article" id="article-275-resource-storage-area-connector-in-mappings">
          <h3 class="article-title">Resource Storage Area Connector In Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-storage-area-connector-in-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*PlantExternalId | String

The ExternalId for the Plant in which the associated Resource is found.

*DepartmentExternalId | String

The ExternalId of the Department in which the associated Resource is in.

*ResourceExternalId | String

The ExternalId of the associated Resource which will be enabled to store material in the mapped storage area.

*StorageAreaConnectorExternalId | String

The ExternalId of the associated storage area connector.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the associated storage area is located.

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Mappings

Storage Area Connector Mappings

Resource Storage Area Connector Out Mappings</div>
        </section>
      
        <section class="article" id="article-252-resource-storage-area-connector-out-mappings">
          <h3 class="article-title">Resource Storage Area Connector Out Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-storage-area-connector-out-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*PlantExternalId | String

The ExternalId of the Plant in which the associated Resource is found.

*DepartmentExternalId | String

The ExternalId of the Department in which the associated Resource is in.

*ResourceExternalId | String

The ExternalId of the associated Resource which will be enabled to consume material from the mapped storage area.

*StorageAreaConnectorExternalId | String

The ExternalId of the associated storage area connector.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the associated storage area is located.

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Mappings

Storage Area Connector Mappings

Storage Area Connector Out Mappings</div>
        </section>
      
        <section class="article" id="article-324-sales-order-mappings">
          <h3 class="article-title">Sales Order Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/sales-order-mappings" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

Sales Orders

Sales Order Lines

Sales Order Line Distributions

Property Name | Data Type

Description & accepted values

* = Required

Sales Orders

Map data for each Sales Order object.

*ExternalId | String

The External identifier of the Sales Order.

*Name | String

The Sales Order name. Unique, changeable, text identifier for the Sales Order.

CancelAtExpirationDate | Boolean

If True, the Sales Order will be canceled at the Expiration Date defined.

Cancelled | Boolean

If True, the Job will not be scheduled.

CustomerExternalId | String

The unique External Id of the customer for which the Sales Order is created.

Description | String

Additional text to describe the Sales Order.

Estimate | Boolean

If True, then this is a quote (estimated order), not a firm order.

ExpirationDate | DateTime

If 'CancelAtExpirationDate' is True, then the Sales Order is marked as "Cancelled" when the PlanetTogether Clock passes this date.

Notes | String

Comments or special considerations about this Sales Order.

Planner | String

The user is responsible for planning this demand if planning by demand rather than by product or location.

Project | String

It can be used to track multiple demands tied to one project.

SalesAmount | Decimal

Specifies the sales amount for the sales order.

SalesOffice | String

Specifies the sales office or other physical location that created the demand. This does not affect the Warehouse that satisfies the order for reference only.

SalesPerson | String

The sales employee who is responsible for this demand.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

Sales Order Lines

Map data for each Line of each Sales Order object.

*ItemExternalId | String

The External identifier of the item associated with the Sales Order.

*LineNumber | String

The identifier for a line item within the sales order.

*SalesOrderExternalId | String

The External identifier for this Sales Order.

Description | String

Additional text to describe the Sales Order Line.

UnitPrice | Decimal

The sale price per unit. This can be used to maximize sales revenue.

Sales Order Line Distributions

Map data for each Distribution of each Line of each Sales Order object.

*LineNumber | String

The identifier for a line item within the sales order.

*QtyOrdered | Double

The total quantity for this Line Item Distribution is on order. This remains the same even if there is a partial shipment made.

*RequiredAvailableDate | DateTime

The material must be available in stock to reach the customer by the Promised Delivery Date.

*SalesOrderExternalId | String

The External identifier for this Sales Order.

MustSupplyFromWarehouseExternalId | String

Required if using MRP to generate jobs from the Sales Order. It can be used to force the Line to be supplied from the specified Warehouse. If not specified, then the material can come from any Warehouse (but is not compatible with MRP in a multi-warehouse data model).

UseMustSupplyFromWarehouseExternalId | Boolean
Required to be TRUE if using MRP to generate jobs from the Sales Order. When TRUE, this enforces the specified Warehouse in the MustSupplyFromWarehouseExternalId field to be the supplying Warehouse.

AllowedLotCodes | String

The Lot Codes that are allowed to supply the Sales Order.

AllowPartialAllocations | Boolean

This is currently a flag that specifies whether partial allocations of material can supply the Sales Order.

Closed | Boolean

If True, the Sales Order does not affect the plan.

Hold | Boolean

Whether the Sales Order was placed on Hold and work should not be done on it.

HoldReason | String

The reason why the Sales Order was put on Hold.

Id | Int64

The identifier of the Sales Order Line Distribution.

MaterialAllocation | String

This field specifies how material lots will be allocated. Allowed values:

NotSet: No Lot Allocation rules are set.

UseNewestFirst: Material requirements will pull from the latest (most recent) material source.

UseOldestFirst: Material requirements will pull from the earliest (oldest) material source.

MaterialSourcing | String

This field specifies whether to allow more than one material source to supply the Sales Order demand. Allowed values:

NotSet: No Material Sourcing rules are set. Any number of sources may be used.

Exclusive: The material source must be exclusive to a single source.

MaximumLatenessDays | Double

If using the StockShortageRule of "PushLater" and the demand has been pushed this number of days past the Required Available Date, the Sales Order is marked as a "Missed Sale."

MaxSourceQty | Decimal

If specified, only sources of supply with this much material or less will be eligible to fulfill the demand for material.

MinSourceQty | Decimal

If specified, only sources of supply with at least this much material will be eligible to fulfill the demand for material.

MinAllocationQty | Decimal

If AllowPartialAllocations is True, this is the minimum amount that must be allocated to the shipment

Priority | Int32

Indicates the importance of the shipment. Used during the allocation process to determine which requirements to allocate to first. Shipments with lower numbers are considered more important and receive allocation before shipments with higher numbers. Allocation is based upon the Allocation Rule specified during the time a Simulation is performed.

QtyShipped | Decimal

The number of items that have already been shipped.

SalesRegion | String

The geographic region for the shipment. For information only.

ShipToZone | String

Specifies the geographic area where the shipment is going for information only.

StockShortageRule | String

Specifies what should be done in stock planning when the shipment's full QtyOpenToShip cannot be satisfied. This can also be overridden during Optimize with a global rule.

See Also

Sales Orders Board

Import Mappings Board

MPS/MRP Planning</div>
        </section>
      
        <section class="article" id="article-192-storage-area-connector-in-mappings">
          <h3 class="article-title">Storage Area Connector In Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-area-connector-in-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*StorageAreaConnectorExternalId | String

The ExternalId of the associated storage area connector.

*StorageAreaExternalId | String

The ExternalId of the associated storage area.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the associated storage area is located.

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Mappings

Storage Area Connector Mappings

Resource Storage Area Connector In Mappings</div>
        </section>
      
        <section class="article" id="article-293-storage-area-connector-mappings">
          <h3 class="article-title">Storage Area Connector Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-area-connector-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The external identifier of the storage area connector. This value must be unique among all storage area connector objects.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the storage area is located.

CounterFlow | Boolean

A flag to indicate that material can flow in both directions at once. If false, the connector cannot be used simultaneously for filling and withdrawing from a storage area. If True, the connector can be used for both filling and withdrawing simultaneously.

CounterFlowLimit | Int32

Indicates the total limit of storage areas both storing and withdrawing simultaneously. If CounterFlow is True, and CounterFlowLimit is 3, the connector can be used to fill or withdraw from 3 storage areas at once.

Description | String

A text description of the storage area connector.

Name | String

The name of the storage area connector. Unique, changeable, text identifier.

Notes | String

Comments or special considerations about this storage area connector.

StorageInFlowLimit | Int32

Indicates how many storage areas the connector can fill at the same time.

StorageOutFlowLimit | Int32

Indicates how many storage areas the connector can withdraw material from at the same time.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Mappings

Storage Area Connector In Mappings

Resource Storage Area Connector In Mappings

Storage Area Connector Out Mappings

Resource Storage Area Connector Out Mappings</div>
        </section>
      
        <section class="article" id="article-312-storage-area-connector-out-mappings">
          <h3 class="article-title">Storage Area Connector Out Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-area-connector-out-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*StorageAreaConnectorExternalId | String

The ExternalId of the associated storage area connector.

*StorageAreaExternalId | String

The ExternalId of the associated storage area.

*WarehouseExternalId | String

The ExternalId of the Warehouse where the associated storage area is located.

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Mappings

Storage Area Connector Mappings

Resource Storage Area Connector Out Mappings</div>
        </section>
      
        <section class="article" id="article-309-storage-area-mappings">
          <h3 class="article-title">Storage Area Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/storage-area-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the storage area.

*WarehouseExternalId | String

The External identifier of the Warehouse where the storage area is located.

*Name | String

The name of the storage area. Unique, changeable, text identifier.

ConstrainCounterFlow | Boolean

A true/false boolean used to enforce (or not) the CounterFlowLimit property in order to constrain whether material can be stored and withdrawn from a Storage Area at the same time.

ConstrainInFlow | Boolean

A true/false boolean used to enforce (or not) the StorageInFlowLimit property in order to constrain how many sources can store material in a Storage Area simultaneously.

ConstrainOutFlow | Boolean

A true/false boolean used to enforce (or not) the StorageOutFlowLimit property in order to constrain how many sources can withdraw material from a Storage Area simultaneously.

CounterFlowLimit | Int32

The total limit of Simultaneous storage and withdrawal sources. If 0, only one direction can occur at a time.

Description | String

A text description of the storage area.

Notes | String

Comments or special considerations about this storage area.

SingleItemStorage | Boolean

Whether only a single item can be stored in the storage area at once. If true, material must be withdrawn or disposed before another item can be stored.

StorageInFlowLimit | Int32

Defines how many sources can store material in the Storage Area simultaneously. If 0, only on-hand sources can exist. Material will only be withdrawn.

StorageOutFlowLimit | Int32

Defines how many sources can withdraw material from the Storage Area simultaneously. If 0, Material in this Storage Area cannot be used.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Items, Inventories, Warehouses, & Storage Areas

Storage Areas Board

Storage Area Connectors

Item Storage Mappings

Storage Area Connector Mappings</div>
        </section>
      
        <section class="article" id="article-328-transfer-order-mappings">
          <h3 class="article-title">Transfer Order Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/transfer-order-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Transfer Orders

Use Transfer Orders to initiate transfers of inventory from one warehouse to another.

*ExternalId | String

The External identifier for the Transfer Order. Must be unique among all transfer orders.

*Name | String

Unique, changeable, text identifier for the Transfer Order.

*Closed | Boolean

If True, then the Transfer Order has no further effect on the Inventory Plan.

Description | String

Additional text for describing the Transfer Order.

Notes | String

Comments or special considerations about this Transfer Order.

Priority | Int32

Usually used to specify a combination of importance and urgency. The Balanced Composite Rule can use this. Lower numbers are more urgent/important.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

Transfer Order Distributions

*ExternalID | String

The External identifier for the Transfer Order Distribution. Must be unique per each Transfer Order.

*TransferOrderExternalId | String

The External identifier for the Transfer Order.

*FromWarehouseExternalId | String

The External identifier of the Warehouse that supplies the Items being transferred.

*ToWarehouseExternalId | String

The warehouse receiving the items being transferred.

*ItemExternalId | String

The External identifier of the Items being transferred.

*QtyOrdered | Double

The number of items that are to be transferred to another Warehouse.

*QtyShipped | Double

The number of items that have already been shipped to the receiving Warehouse (typically "0").

*QtyReceived | Double

The number of items that the receiving Warehouse has already received (typically "0").

*ScheduledShipDate | DateTime

The date and time at which the items are scheduled to leave the supplying Warehouse.

*ScheduledReceiveDate | DateTime

The date and time at which the items are scheduled to arrive at the receiving Warehouse.

*Closed | Boolean

If True, then the Transfer Order is considered Closed and has no further effect on the Inventory Plan.

AllowPartialAllocations | Boolean

If true, the transfer is allowed to source from multiple partial supplies.

FromStorageAreaExternalId | String

The ExternalId of the Storage Area that the material is going to be transferred from. If not assigned, the system can source the material from any Storage Area that has available material.

MaterialAllocation | String

This field specifies how material lots will be allocated. Accepted values:

NotSet: No Lot Allocation rules are set.

UseNewestFirst: Material requirements will pull from the latest (most recent) material source.

UseOldestFirst: Material requirements will pull from the earliest (oldest) material source.

MaterialSourcing | String

Define eligible sources of the material. Accepted values:

NotSet: No sourcing requirements are set.

Exclusive: Only one source may be used to satisfy the demand.

MinSourceQty | Double

If specified, only sources of supply with at least this much material will be eligible to fulfill the demand for material.

MaxSourceQty | Double

If specified, only sources of supply with this much material or less will be eligible to fulfill the demand for material.

OverrideStorageConstraint | Boolean

If true, this material will be allowed to store in excess of the storage area's max quantity when received. If false, any material that cannot be stored will be discarded.

PreferEmptyStorageArea | Boolean

If true, the material must be stored in an Empty Storage Area.

ToStorageAreaExternalId | String

The ExternalId of the Storage Area where the material is going to be transferred to. If not assigned, the system can place the material in any Storage Area available to store the material.

See Also

Item Mappings

Inventory Mappings

Warehouse Mappings

Warehouse Plant Mappings

Storage Area Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-170-warehouse-mappings">
          <h3 class="article-title">Warehouse Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/warehouse-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The identifier of the Warehouse for external system references. This value must be unique per each Warehouse.

AnnualPercentageRate | Decimal

APR for calculating carrying costs.

Description | String

Text for describing the Warehouse.

Name | String

The name of the Warehouse. Unique, changeable text identifier.

NbrOfDocks | Int32

Removed from software versions 12.3.0 and newer.

Each Warehouse can have a specified number of Docks. These Docks can be used to schedule receipt of Purchases To Stock as well as Shipments.

Notes | String

Comments or special considerations about this object.

StorageCapacity | Decimal

A Scheduling Extension can use it to limit scheduling based upon the availability of storage space.

TankWarehouse | Boolean

Removed from software versions 12.3.0 and newer.

Specifies whether this warehouse is a tank warehouse.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Inventory Plan Board

Import Mappings Board</div>
        </section>
      <h2 id="cat-object-import-mappings-job-objects-mappings" class="category-header">Object Import Mappings &gt; Job Objects Mappings</h2>
        <section class="article" id="article-214-alternate-path-node-mappings">
          <h3 class="article-title">Alternate Path &amp; Node Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/alternate-path-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Jump to section:

Alternate Paths

Alternate Path Nodes

Alternate Paths

*ExternalId | String

An External identifier for the Alternate Path. Must be unique per Path per Manufacturing Order.

*JobExternalId | String

The External identifier of the Job associated with the Alternate Path.

*MoExternalId | String

The External identifier of the Manufacturing Order is associated with the Alternate Path.

AutoBuildLinearPath | Boolean

Specifies whether PlanetTogether will automatically construct a simple linear Path based on the available Operations. If True, PlanetTogether will automatically build a simple linear path. If False, the user will have to define the Operation flow manually.

AutoUse | String

This specifies when PlanetTogether will choose an Alternate Path Node to use for the Operation flow automatically during optimization. Accepted values:

IfCurrent: The path is chosen only if it is marked as CurrentPath.

RegularRelease: The Path is released, as usual, based on the optimized settings, activity JIT start dates, etc.

ReleaseOffsetFromDefaultPathsLatestRelease: A timespan defining when the Path becomes eligible for automatic selection. The Alternate Path will not be used before the default path’s Release Date + AutoUseReleaseOffsetDays.

AutoUseReleaseOffsetDays | Double

The number of days when the Path becomes eligible for automatic selection. The Alternate Path will only be usable after the default path's Release Date + this number of days.

Name | String

The name used to identify the Alternate Path.

Preference | Int32

These values can be used in different ways by custom algorithms and serve as a visual indicator to the planner.

ValidityStartDate | DateTime

This date defines the earliest date and time that a path can be used.

ValidityEndDate | DateTime

This date defines the latest date and time that a path can be used. Note that this defines the latest start date of the path; the scheduled operations of the path may schedule to end after this date as long as the first operation starts no later than this date.

Alternate Path Nodes

*JobExternalId | String

The External identifier of the Job associated with the Path.

*MoExternalId | String

The External identifier of the Manufacturing Order associated with the Path.

*PathExternalId | String

The External identifier of the Path.

*PredecessorOperationExternalId | String

The External identifier of the Predecessor Operation associated with the Path.

AllowManualConnectorViolation | Boolean

If True, Operations can be moved to invalid resources based on the Predecessor Resource connectors defined. This can be used to allow a temporary violation that is flagged to give users more flexibility to reconcile and make exceptions manually.

AutoFinishPredecessor | String

Specifies when the Predecessor Operation's Status will be automatically changed to Finished. Accepted values:

NoAutoFinish: Users must manually change the status to Finished.

OnSuccessorSetupStart: The Predecessor Operation will be set to Finished when the Setup span of the Successor Operation starts.

OnSuccessorRunStart: The Predecessor Operation will be set to Finished when the Run span of the Successor Operation starts.

OnSuccessorPostProcessingStart: The Predecessor Operation will be set to Finished when the Post-Processing span of the Successor Operation starts.

OnSuccessorFinish: The Predecessor Operation will be set to Finished when its Successor Operation is complete.

IgnoreInvalidSuccessorOperationExternalIds | Boolean

If True, invalid Successor Operations will be ignored.

MaxDelayHrs | Double

The maximum hours that the successor Operation may be delayed before starting after its predecessor (this operation) finishes.

OverlapPercentComplete | Decimal

Specify the percentage of the Predecessor Operation that must be completed before the Successor Operation starts using PercentComplete Overlap Type.

OverlapSetups | Boolean

This is removed from software version 12.3.0 and newer. Overlapping setup can be achieved through other overlap configurations.

Specifies whether Successors can start setting up before the setup is complete on this Operation.

OverlapTransferHrs | Double

Specifies the number of hours that must pass after the start of the Predecessor Operation before the Successor Operation can start when using TransferSpan Overlap Type.

OverlapType | String

When using overlapping Operations, an Operation does not have to wait for its Predecessor to finish before it can begin. Accepted values:

NoOverlap: The entire Predecessor Operation must complete before the Successor Operation can begin.

TransferQty: The Successor Operation can begin once the first Operation has produced a specified quantity (specified in the OverlapTransferQty field in the Operation Mappings).

TransferSpan: Successor Operation can begin after the first Operation has been running for a specified time (specified in the OverlapTransferHrs field of the Alternate Path Node).

AtFirstTransfer: Successor Operation can start once a specified number of items is produced and transferred to inventory (specified in the TransferQty field in the Item mappings).

TransferSpanAfterSetup: Successor can begin after the OverlapTransferHrs plus any Setup time.

PercentComplete: Successor can begin after the predecessor operation has been completed to a percent specified in the OverlapPercentComplete field in the Alternate Node Mappings.

SuccessorOperationExternalId | String

The External identifier of the Successor Operation associated with the Path.

TransferDuringPredecessorOnlineTime | Boolean

Specifies that the TransferHrs should occur during the Predecessor Operation's Online capacity interval instead of calendar hours. For example, if an Operation completes at the end of a shift and has four hours of transfer time, the transfer time will not occur until the start of the next shift. If False, the transfer time will start immediately and could be completed before the next shift.

TransferHrs | Double

Specifies the number of hours it takes for the Items to be transferred from the Predecessor Operation to the Successor Operation. The successor cannot start until this time passes. Note: When used in combination with OverlapTransferSpan, the effect is additive.

TransferStart | String

The point of the predecessor operation where the transfer begins calculating from. Choose EndOfPostProcessing for a standard calculation. Accepted values:

StartOfOperation: At the start of this operation.

EndOfOperation: At the end of this operation.

EndOfPostProcessing: At the end of this operation's post-processing.

EndOfStorage: At the end of this operation's Tank Storage.

EndOfRun: At the end of all cycles/run of this operation.

EndOfSetup: At the end of this operation's setup.

TransferEnd | String

The point of the successor operation where the transfer calculation ends. Choose StartOfOperation for a standard calculation from the TransferStart. Accepted values:

StartOfOperation: At the start of the successor operation.

EndOfOperation: At the end of the successor operation.

EndOfPostProcessing: At the end of the successor operation's post-processing.

EndOfStorage: At the end of the successor operation's Tank Storage.

EndOfRun: At the end of all cycles/run of the successor operation.

EndOfSetup: At the end of the successor operation's setup.

UsageQtyPerCycle | Double

The Quantity of the Operation that is needed for each cycle of the Successor Operation. This is used for calculating when a Successor activity can start in an overlap situation.

See Also

Alternate Paths

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-337-customer-mappings">
          <h3 class="article-title">Customer Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/customer-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Customer Mappings

Map data for each Customer object.

*ExternalId | String

An External identifier for the Customer. Must be unique per Customer.

AbcCode | String

An optional code to assign to the Customer for reporting or grouping purposes. This is typically unique.

ColorCode | String

A hexadecimal color code to represent the Customer visually for reporting or grouping purposes.

CustomerType | String

Specifies the type of Customer. Accepted values:

Customer

Supplier

Vendor

Defaults to type "Customer" if none is defined.

Description | String

A text description of the Customer.

GroupCode | String

An optional code to assign to the Customer for reporting or grouping purposes. This is typically shared with other Customers that can be considered part of a group.

Name | String

A common name used to identify the Customer.

Notes | String

Comments or special considerations about this Customer.

Priority | Int32

A positive numerical value to represent the Customer's priority. This can be used for informational purposes, or used for prioritizing customer orders via the Customer Priority optimize factor in a sequencing plan. Lower values are given higher priority.

Region | String

An informational field which specifies a Region or location associated with the Customer.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs)

Customer Connections Mappings

Associate one or more Customers to each Job. Multiple CustomerExternalId's may be mapped to a single JobExternalId, but each association must be imported individually. Each CustomerExternalId-to-JobExternalId pairing must be unique.

*CustomerExternalId | String

The external identifier of the Customer object which is associated with the JobExternalId. Each customer may be defined once per Job.

*JobExternalId | String

The external identifier of the Job with which the CustomerExternalId is associated with. 

See Also

Import Mappings Board

Customers Board

Job Mappings

Jobs Board

Sales Orders Mappings

Sales Orders Board

Purchases to Stock Mappings

Purchase Orders Board</div>
        </section>
      
        <section class="article" id="article-319-internal-activity-mappings">
          <h3 class="article-title">Internal Activity Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/activity-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Activity. This value must be unique per Activity per Operation.

*JobExternalId | String

The External identifier of the Job associated with the Activity.

*MoExternalId | String

The External identifier of the Manufacturing Order associated with the Activity.

*OpExternalId | String

The External identifier of the Operation is associated with the Activity.

*RequiredFinishQty | Double

The total quantity that this Activity needs to produce.

ActualResourcesUsed | String

A comma-separated list of Resource ExternalId's which were used to complete the activity. This is useful for Track Actuals data which allows finished activities to remain visible in the Gantt and used for sequence-dependent Setup and Clean calculations on specific resources.

Anchor | Boolean

If True, optimizations will attempt to start the Activity as close as possible to the AnchorStartDate. 

AnchorStartDate | DateTime

The date and time at which the Activity is Anchored. (The 'Anchor' field must be set to 'True').

BatchAmount | Decimal

This field allows batching with a different value from batching based on the unit quantities produced (BatchSize set on the Item). For example, this can allow you to batch by volume, weight, size, etc.

CleanHrs | Double

Defines the time required for cleaning out each Resource that was used to run the operation.

CleanoutCost | Decimal

The cost of Production Cleanout. Used if Operation Cleanout is incurred.

CleanOutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule.

CleanTimeManualUpdateOnly | Boolean

Whether the CleanHrs field can be updated through import.

CleanTimeOverride | Boolean

When True, the CleanHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation CleanHrs.

Comments | String

Generic text to act as a section to include notes for schedulers or shop floor workers. For informational purposes.

Comments2 | String

Generic text to act as a section to include notes for schedulers or shop floor workers. For informational purposes.

CycleHrs | Double

The time required to perform one production cycle.

This is used with QtyPerCycle to determine the run the length of the activity. This value will take precedence over the same property which is set at the operation level if they differ.

CycleSpanManualUpdateOnly | Boolean

Whether the CycleHrs field can be updated through data import.

If True, then the CycleHrs field must be manually maintained by PT users rather than through data imports.

CycleSpanOverride | Boolean

When True, the CycleHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation CycleHrs.

NbrOfPeople | Double

If PeopleUsage is set to UseSpecifiedNbr, this is the maximum number of people allocated to the Activity. Fewer than this number will be allocated during time periods when the number of people available on the capacity interval assigned to the Primary Resource is less than this value. The setting is used with the Nbr Of People setting in the Resource’s Capacity Interval to determine how long the operation will take and/or how many Operations can be run simultaneously. The minimum of this number and the number available in the Capacity Interval are used. To allow multiple Operations to run simultaneously, the Resource’s Capacity Type must be set to Multi-Tasking, in which case the sum of NbrOfPeople across Operations running simultaneously must be less than or equal to the Capacity Interval's Nbr Of People.

If PeopleUsage is set to UseMultipleOfSpecifiedNbr, this is the numeric interval of the number of people used to perform the operation. The number of people that get assigned to the operation is dependent on the number of people available on the Primary Resource's capacity interval. PlanetTogether will attempt to use as many people as are available but will only increase the number of people used in increments of this value until there are not enough people available on the capacity interval to increase the value any more. For example, if an activity's NbrOfPeople is 4 and the resource's capcity interval has 11 people, then 8 people will be used to perform the activity.

Paused | Boolean

If True, the current Setup or Run process has been temporarily suspended. Pausing the activity does not necessarily mean that it will be re-schedulable. Schedulability will depend on the activity's Production Status and Hold Status. This is primarily a visual indicator that the activity is not currently being worked on.

PeopleUsage | String

The method in which available people are used to perform the Activity. Accepted values:

UseAllAvailable: All of the people available on the Resource's Capacity Interval are used by the Activity.

UseSpecifiedNbr: Only up to this number of the Resource's Capacity Interval's available people are allocated to the Activity.

This is not a scheduling constraint. If there are fewer than this number available and there are no other activities scheduled on the resource, all of the people in the capacity interval will be allocated to the Activity and the activity's cycle time will be lengthened by a factor of the missing number of people.

UseMultipleOfSpecifiedNbr: A multiple of NbrOfPeople will be used. For instance, if an activity's NbrOfPeople is 4 and the resource's capcity interval has 11 people . 8 people will be used to process the activity.

This is a scheduling constraint. If the capacity interval does not have at least the specified number of people available then the activity will be considered ineligible to schedule there.

PlanningScrapPercent | Decimal

The percent of produced parts that is expected to be scrapped. Used to calculate ExcpectedGoodQty and ExpectedScrapQty.

ProductionSetupCost | Decimal

The cost of Production Setup. Used if Operation Setup is incurred.

ScrapPercentManualUpdateOnly | Boolean

Whether the PlanningScrapPercent field can be modified through data import.

If True, then the PlanningScrapPercent field must be manually maintained by PT users rather than through data imports.

ScrapPercentOverride | Boolean

When True, the PlanningScrapPercent value of the Activity is used for scheduling. Otherwise, the activity uses the Operation PlanningScrapPercent.

PostProcessingHrs | Double

The number of hours of Post Processing required for the Activity.

This can be used to model cleanup or cool-down time, etc. The release of material produced by the operation is constrained by the Post Processing time. Whether a resource will be occupied during Post Processing depends on the Resource Requirement's UsageStart and UsageEnd settings. 

PostProcessManualUpdateOnly | Boolean

Whether the PostProcessingHrs field can be modified through data import.

If True, then the PostProcessingHrs field must be manually maintained by PT users rather than through data imports.

PostProcessOverride | Boolean

When True, the PostProcessingHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation PostProcessingHrs.

ProductionStatus | String

The current state of the Activity in production.

This field determines which portions of the Activity are scheduled. For example, if the Status is Running, then no Setup Span will be scheduled.

This value is set manually or imported, not set by PlanetTogether. If the status is SettingUp or Running, then the current resources will not be changed by an optimization unless the job is unscheduled manually or due to a routing change. Accepted values:

Waiting: The Activity is waiting for material, previous operations, or a release date before it will be ready to start.

Ready: The Activity can be worked on as soon as the necessary resources are available.

Started: Either time or quantity has been reported for the activity, and it is currently in a Waiting or Ready state.

SettingUp: The Activity is currently being set up on a resource. Once in Setup, the activity is scheduled near the front of the schedule and cannot be moved.

Running: The activity is currently being run on a resource. If in Run status, the activity is scheduled near the front of the schedule and cannot be moved.

PostProcessing: The activity is finished running but is now waiting for drying, cleanup, etc. If PostProcessing time is scheduled and Post Processing Uses Resource is true, then the activity is scheduled near the front of the schedule and cannot be moved. Otherwise, the activity is removed from the schedule.

Finished: The activity is completed in production and is ready for the successor operation or inventory. Once finished, it is no longer scheduled.

QtyPerCycle | Double

The quantity of product produced during each production cycle.

QtyPerCycleManualUpdateOnly | Boolean

Whether the QtyPerCycle field can be modified through data import.

If True, then the QtyPerCycle field must be manually maintained by PT users rather than through data imports.

QtyPerCycleOverride | Boolean

When True, the QtyPerCycle value of the Activity is used for scheduling. Otherwise, the activity uses the Operation QtyPerCycle.

ReportedCleanHrs | Double

The number of hours incurred during the "Clean" phase of the activity as reported by the shop floor.

ReportedCleanoutGrade | Int32

The Grade of the Clean phase of the activity as reported by the shop floor.

ReportedEndOfRunDate | DateTime

This property is renamed in 12.3.0 to ReportedEndOfProcessingDate

The reported date and time that the activity's run time ended.

This presumes that the activity is either finished or in the Post Processing phase (or Storage or Storage Post Processing if it ran on a Tank resource).

When the activity's state is changed to Finished or Post-Processing, this value is set to the Clock Date unless its value has already been reported.

ReportedEndOfPostProcessingDate | DateTime

The date on which the End Of Post Processing was reported for a finished activity.

ReportedEndOfProcessingDate | DateTime

The reported date and time that the activity's production cycles ended.

This presumes that the activity is either finished or in the Post Processing phase (or Storage or Storage Post Processing if it ran on a Tank resource).

When the activity's state is changed to Finished or Post-Processing, this value is set to the Clock Date unless its value has already been reported.

ReportedEndOfStorageDate | DateTime

The date on which the End Of Storage was reported for a finished activity.

ReportedFinishDate | DateTime

The reported date and time that the activity was finished.

ReportedGoodQty | Double

The reported quantity of finished items produced thus far by the activity.

ReportedPostProcessingHrs | Double

The reported amount of post processing time that has been completed thus far on the activity.

ReportedRunHrs | Double

The reported amount of run time that has been completed thus far on the activity.

ReportedScrapQty | Double

The reported amount of product that has been scrapped while performing the activity thus far.

ReportedSetupHrs | Double

The reported amount of setup time that has been completed thus far on the activity.

ReportedStartDate | DateTime

The reported date and time that the activity was started.

ReportedStartOfProcessingDate | DateTime

The reported date and time that processing began on the activity.

ReportedStorageHrs | Double

The reported amount of storage time that has been completed thus far on the activity.

SetupHrs | Double

The number of hours required for setting up the Resource to run the Activity.

SetupTimeManualUpdateOnly | Boolean

Whether the SetupHrs field can be updated through import. If True, then the SetupHrs field must be manually maintained by PT users rather than through data imports.

SetupTimeOverride | Boolean

When True, the SetupHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation SetupHrs.

StorageHrs | Double

The number of hours required for the Activity's Storage process.

StorageManualUpdateOnly | Boolean

Whether the StorageHrs field can be updated through import. If True, then the StorageHrs field must be manually maintained by PT users rather than through data imports.

StorageHrsOverride | Boolean

When True, the StorageHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation's StorageHrs.

TankPostProcessingHrs | Double

This field is removed from version 12.3.0. The TankPostProcessing process is replaced by a new Storage process and related fields.

The number of hours required for post-processing after all material is consumed or removed from a Tank resource before another operation is allowed to schedule on the resource.

TankPostProcessingHrsManualUpdateOnly | Boolean

This field is removed from version 12.3.0. The TankPostProcessing process is replaced by a new Storage process and related fields.

Whether the TankPostProcessingHrs field can be updated through data import.

If True, then the TankPostProcessingHrs field must be manually maintained by PT users rather than through data imports.

TankPostProcessingOverride | Boolean

This field is removed from version 12.3.0. The TankPostProcessing process is replaced by a new Storage process and related fields.

When True, the TankPostProcessingHrs value of the Activity is used for scheduling. Otherwise, the activity uses the Operation TankPostProcessingHrs.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-194-job-mappings">
          <h3 class="article-title">Job Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/job-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Job. Must be unique per each Job object.

*Name | String

Unique, changeable, text identifier for the Job.

AgentEmail | String

An extra property with no functional purpose. Use it to include any sort of additional information that maybe isn't appropriate to store elsewhere.

AlmostLateDays | Double

Jobs and Activities are considered AlmostLate if they end within this period from the Need Date.

Cancelled | Boolean

If True, the Job will not be scheduled.

CanSpanPlants | Boolean

If True, then the Operations can schedule in more than one Plant. Otherwise, all Operations must be scheduled in only one Plant. (Inherited from BaseOrder.)

Classification | String

It can be used to distinguish the purpose of the work request. Accepted values:

ProductionOrder: These jobs are created to produce items to supply demand.

Quote: This is used when estimating the finish dates and costs for items.

SafetyStock: This affects the Job Late Property based on the inventory safety stock warning level.

TransferOrder: These jobs are requests for items to be transferred from one warehouse to another.

Template: This job is used as a template.

BufferStockReplenishment: These jobs use the buffer penetration of the primary product's inventory instead of the drum or shipping buffer penetration.

SalesOrder: These are usually customer orders for finished products.

ColorCode | String

A Color that can be used to distinguish the Job from other Jobs in the Gantt. See: Supported color values (Excel)

Commitment | String

Indicates the likelihood that the work will be executed. This value can be updated internally and protected from external changes that attempt to set the value "backward" (such as from Firm to Planned). This allows the planner to advance the Commitment level internally and not have the change undone by an external system that has not been updated. Accepted Values:

Released

Firm

Planned

Estimate

CustomerEmail | String

The e-mail address(es) of the customer(s). For informational purposes only.

Description | String

Additional text for describing the Job. (Inherited from BaseObject.)

Destination | String

Indicates the geographical region or address where the products will be sent for information only.

DoNotDelete | Boolean

If True, then the Job will not be deleted by the system. This can be used to keep Jobs that will be used as templates for copying to new Jobs. This value can be set by the interface but cannot be updated. This is to preserve the manual changes made by the planner.

DoNotSchedule | Boolean

If True, then the Job will not be scheduled. This can be used to prevent quotes or other un-Firm Jobs from scheduling until a planner does. This value can be set by the interface but cannot be updated. This is to preserve the manual changes made by the planner.

Hold | Boolean

Whether the Job was placed On-Hold and work should not be done on it.

HoldReason | String

The reason the Job was placed On-Hold. Default accepted values (custom reasons can be accepted too if custom reasons are configured in System Settings):

1. Material Hold

2. Tooling Hold

3. Production Hold

4. Engineering Hold

5. Customer Hold

6. Quality Hold

7. Lack of Material

8. Design Change Pending

HoldUntilDate | DateTime

No Activities are scheduled before this date/time. This value is only set if the Job itself is placed On-Hold (Hold is set to 'True'), not if Operations or Activities only are placed On-Hold.

Hot | Boolean

This indicates that the Job is essential. The Balanced Composite Rule can use this.

HotReason | String

Specifies why the Job is set to Hot.

Importance | Int32

This indicates the value of the Job relative to other Jobs. For example, the Balanced Composite Rule can use this.

Invoiced | Boolean

Whether an invoice has been sent for the Job. For information only.

LatePenaltyCost | Decimal

Optional currency value that specifies the cost (either actual or estimated) per day of finishing late. For display only.

MarkForDeletion | Boolean

The Interface Customizer can use it to delete jobs that are batched together, etc.

MaxEarlyDeliveryDays | Double

The customer will accept the order this number of days before the Need Date. If Operations are scheduled with more than this amount of Slack, then they are considered Early. This does not impose a constraint on Optimizations or Moves as Jobs can still be scheduled earlier than this. If this value is zero, then E-mail Alerts are not sent to alert early Jobs since they cannot be accepted early.

NeedDateTime | DateTime

The date and time when the job should be finished to be considered on time.

Notes | String

Comments or special considerations about the Job. (Inherited from BaseObject.)

OldExternalId | String

It can be used to change the ExternalId of a Job once it has been imported. During import, if a Job with the specified ExternalId does not exist, then a Job with OldExternalId is searched for and updated if it exists. If this doesn’t exist either, a new Job is created with the ExternalId (not the OldExternalId).

OrderNumber | String

It can be used to specify the customer order number (the Sales Order(s) that the job is supplying). For display only.

Printed | Boolean

Whether the Job’s Traveler Report has been Printed.

Priority | Int32

Usually used to specify a combination of importance and urgency. The Balanced Composite Rule can use this. Lower numbers are more urgent/important.

Revenue | Decimal

The estimated amount paid for the parts produced by the Job.

Reviewed | Boolean

Tracks whether a planner has reviewed the Job. Only set during import for NEW Jobs and thereafter controlled internally.

Shipped | Int32

Whether the job has been shipped to the recipient. For information only.

ShippingCost | Decimal

The cost of shipping the parts produced by the Job.

Template | Boolean

This indicates that the Job is only used for copying to create new Jobs. Template Jobs are not scheduled.

Type | String

It can be used to specify a free-form type for grouping. For display only.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Jobs Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-298-manufacturing-order-mappings">
          <h3 class="article-title">Manufacturing Order Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/manufacturing-order-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Manufacturing Order.

*JobExternalId | String

The External identifier of the Job to which the Manufacturing Order belongs.

*Name | String

Changeable text identifier for the Manufacturing Order.

*RequiredQty | Decimal

The target quantity of Products to be made.

AlternatePathSelection | String

Controls how Alternate Paths are used. Accepts a AlternatePathID.

AutoJoinGroup | String

Manufacturing Orders with this same group are joined together during MRP when the "AutoJoinManufacturingOrders" option is set to 'True.

BatchDefinitionName | String

The Definition Name of the Batch.

BatchGroupName | String

The Group Name of the Batch.

CanSpanPlants | Boolean

If True, then Operations of the M.O. can schedule in more than one Plant. Otherwise, all Operations must be scheduled in only one Plant.

CopyRoutingFromTemplate | Boolean

If True, then any Path (Routing) information is ignored. The Path information for an existing Template Job is copied and used instead. The Product Name specifies which Product to copy the Path from. If there is more than one Template for the same product, the first one found by the system will be used. Note: Setting this to true on an existing Manufacturing Order will cause any current routing information to be lost and copied in from a Template when the Manufacturing Order is saved.

DBRShippingBufferOverrideDays | Double

This value is added to the Manufacturing Order's Need Date to set the Shipping Need Date. MOs should be completed before the Shipping Need Date to avoid Shipping Buffer Penetration.

DefaultPathExternalId | String

The initial Path to be used. A scheduler may still schedule the M.O. on a different Path.

Description | String

Additional text for describing the Manufacturing Order.

ExpectedFinishQty | Double

This is usually the same as the Required Qty, but production issues may result in more or fewer items than required. This is usually specified externally, but changing the quantities in the Job Dialog will update this value based on Operation Completion Quantities and whether "DeductScrapFromRequired" is set on the Resource Operation.

Family | String

For display only.

Hold | Boolean

Whether the Manufacturing Order was placed on Hold and work should not be done on it.

HoldReason | String

The reason the Manufacturing Order was placed On-Hold

HoldUntilDate | DateTime

The Date and Time specified when the MO was placed on Hold. All Operations have their HoldUntilDate set to this value as well. Note: This has no effect unless the 'Hold' field is set to 'True' for the MO.

IsReleased | Boolean

Whether a Planner has approved the Manufacturing Order to go into production, setting this to 'True' will set the Release Date to the current time.

LockedPlantExternalId | String

The External identifier of the Plant where all work must be scheduled.

LockToCurrentAlternatePath | Boolean

If True, the Manufacturing Order will be locked to the current Alternate Path.

MoNeedDate | Boolean

If True, then the Need Date of the Manufacturing Order can be updated manually in PT, via an import, when creating a CTP Job, or by an optimize (if the Set sub-Job Need Dates feature is on). If False, the Need Date of the MO will be set to the Job Need Date.

NeedDate | DateTime

The Date and Time when the Manufacturing Order should be finished to be considered On Time. The NeedDate is a calculated field that can be affected by the MoNeedDate checkbox defined above. It cannot be set unless the MoNeedDate is set to True.

Notes | String

Comments or special considerations about the Manufacturing Order.

PreserveRequiredQty | Boolean

If True, then the Required Qty can only be set manually, not via ERP imports. This value is automatically set to 'True' when a planner manually changes the Required Qty in PlanetTogether to preserve the change.

If true, TotalOutputQty on all products of all operations of the MO will not change when a new value is imported from the ERP/SQL.

ProductColor | String

It can be used to indicate the product being made visually.

ProductDescription | String

The description of the Product is made.

ProductName | String

The Name of the Product being made.

ReleaseDateTime | DateTime

No activities are scheduled before this date/time. This represents the date and time at which the activities can be Released to start.

ResizeForStorage | Boolean

If true, a single-operation Manufacturing Order can resize its Quantity to match the quantity that can fit in a Storage Area. 

SplitUpdateMode | String

Determines how the Manufacturing Order Splits will be updated. The following values are accepted:

UpdateSplitsIndividually: Hour and quantity reporting for the operation must specify the ExternalId of the MO to update, similar to when an MO has not been split.

ShareReportedValuesProportionallyDecimal: When hours or quantities are reported for the manufacturing order, they are allocated across all MOs and their activities in proportion to their Required Qty, allowing decimal values for quantities.

ShareReportedValuesProportionallyInteger: When hours or quantities are reported for the MO, they are allocated across all MOs and their activities in proportion to their Required Qty, rounded into integer values for quantities.

UOM | String

Unit of measure. For display only.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Job Mappings

Operation Mappings

Alternate Path Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-202-material-mappings">
          <h3 class="article-title">Material Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/material-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

** = Required for standard stock material requirements; not required for buy-direct material requirements (RequirementType is 'BuyDirect')

*ExternalId | String

The External identifier for the Material Requirement.

*JobExternalId | String

The External identifier of the Job associated with the Material Requirement.

*MoExternalId | String

The External identifier of the Manufacturing Order associated with the Material Requirement.

*OpExternalId | String

The External identifier of the Operation that is associated with the Material Requirement. This is the Operation consuming the item as Material.

**ItemExternalId | String

The External identifier of the Item to be used as a Material for the Operation. Required for standard stock material requirements; not required for buy-direct material requirements (RequirementType is 'BuyDirect').

**TotalRequiredQty | Double

The Quantity of Material to be consumed by the Operation for this requirement. If materials constrain the Operation, schedulability of the operation will be determined by availability of the material in inventory according to the material requirement's MaterialUsedTiming setting.

AllowedLotCodes | String

This is used to specify which Material Lots are allowed to supply the Material Requirement. The Lot Code(s) of the item or lot must match this value. Multiple lots can be added, separated by a comma (avoid spaces after comma-separated lot codes).

AllowExpiredSupply | Boolean

If true, the requirement will be allowed to use material sources that have expired (Shelf Life Hours of the item has passed since the Lot Production Date). This can be enabled to ensure operations don't get pushed past the planning horizon and to allow for visibility into expired sources being consumed by scheduled operations. Disable this to allow Storage Areas/Tanks to dispose automatically when material expires, and also improve scheduling performance.

AllowPartialSupply | Boolean

If true, MRP will consider any partial supply to satisfy the demand if there is not enough to satisfy the demand in full.

Available | Boolean

Used by buy-direct materials only, otherwise the availability is calculated for standard stock material requirements. If true, the scheduling logic will assume the material is available as early as the start of the scheduling clock.

ConstraintType | String

Indicates whether the Material Requirement should prevent its Operation from starting before the material arrives. Accepted values:

NonConstraint: The material requirement is not a scheduling constraint. Material availability has no impact on the operation's schedulability.

ConstrainedByEarlierOfLeadTimeOrAvailableDate:

If there is no Item associated with the MaterialRequirement (Buy-Direct only), the Operation can’t start until the earlier of the Material’s AvailableDate and Clock+LeadTimeSpan.

In the case where there is an Item associated with the MaterialRequirement. The AvailableDate is determined by Inventory levels, not the AvailableDate field within this class. So it’s the earlier of what can be supplied through inventory or the lead-time.

ConstrainedByAvailableDate:

If there is no Item associated with the Material Requirement (Buy-Direct only): Operation can't start until the AvailableDate defined within this Material Requirement.

In the case where there is an Item associated with the MaterialRequirement: The Operation is constrained to start until the Material is available in Inventory.

IgnoredConstrainedByEarlierOfLeadTimeOrAvailableDate: The material requirement is not constrained by default. A user may manually enable the constraint type according to the ConstrainedByEarlierOfLeadTimeOrAvailableDate setting by using the Actions tile or right-click action from the Gantt, Jobs board, or Activities board to Restore Constraints. Not compatible with buy-direct material requirements.

IgnoredConstrainedByAvailableDate: The material requirement is not constrained by default. A user may manually enable the constraint type according to the ConstrainedByAvailableDate setting by using the Actions tile or right-click action from the Gantt, Jobs board, or Activities board to Restore Constraints. Not compatible with buy-direct material requirements.

FixedQty | Boolean

If True, this specifies that the Required Quantity is a fixed number that does not scale up or down when the MO or Operation Required Quantity are adjusted higher or lower.

IssuedQty | Double

The quantity of material that has been issued to the Operation by physically removing the material from storage and delivering it to the floor for production.

LatestSourceDateTime | DateTime

When there are multiple sources supplying the material requirement, this date and time is meant to reflect the date that the latest of all material sources becomes available. It can be imported for Buy-Direct materials, otherwise is a calculated field.

LeadTimeHrs | Double

The minimum number of hours needed to procure the material. Applies to Buy-Direct Material requirements only (RequirementType is 'BuyDirect'). The value is visualized in the "LeadTimeDays" property of the Buy-Direct Materials grid of the Job Dialog.

If the Constraint Type is ConstrainedByEarlierOfLeadTimeOrAvailableDate, then the minimum of Available Date and Now + Lead Time is used as the constraint date. If the Constraint Type is ConstrainedByAvailableDate, then the Available Date is used instead, and Lead Time is only used if there is no supply at the end of the scheduling process.

MaterialAllocation | String

This field specifies how material will be allocated according to the production or procurement date of the material source. If set, this property will overwrite the property of the same name that may be set on the required Inventory record. Accepted values:

NotSet: No allocation rules are set. The material's allocation settings are defined at the Inventory level.

UseNewestFirst: The material requirement will source material from the most recently produced or procured material source.

UseOldestFirst: The material requirement will source material from the earliest/oldest produced or procured material source.

MaterialDescription | String

The Description of the Required Material. This is the item's description for stocked Items, and it can be set externally for Buy-Direct Material requirements.

MaterialName | String

The Name of the Required Material. This is the item's name for stocked Items, and it can be set externally for Buy-Direct Material requirements.

MaterialSourcing | String

NotSet:

Exclusive:

MaterialUsedTiming | String

This field defines when material is needed. The options are;

SetupStart: As soon as setup starts, all material is required to be available. If the operation does not incur setup, the materials are required at the start of the first production cycle.

ProductionStart: All material is required at the start of production (processing).

DuringSetup: Material is required evenly over the duration of the setup. The item's TransferQty will be used if set. If a Storage Area Connector is required, it will be used during the duration of setup.

ByProductionCycle: A portion of the material is required at each production cycle start. The quantity is the ratio of the material requirement TotalRequiredQty and the Operation RequiredFinishQty. Issued material will be omitted from the initial cycle's requirements. If a Storage Area Connector is required, it will be used during the duration of production.

LastProductionCycle: All material is required on the final operation cycle start.

FirstAndLastProductionCycle: Confirms that the first cycle has enough material and that all remaining material is available for when the last cycle starts. This can be used when the material overlap doesn't need to check every cycle, but the consuming operation is delayed by the first production cycle material and delayed by the full required material at the end of the operation.

PostProcessingStart: All material is required at the start of post-processing.

PostProcessingEnd: All material is required at the end of post-processing.

MaxEligibleWearAmount | Int32

Deprecated in software version 12.1.4 and newer. 

This specifies the maximum number of times that a material can be used.

MaxSourceQty | Decimal

MinAgeHrs | Double

Specify how old (in number of hours) the lot of a lot controlled material must be before it is considered eligible to satisfy the material requirement. The age of material is determined by the difference between the simulation clock and the lot's production time.

MinRemainingShelfLifeHrs | Double

This is the minimum number of hours that must be remaining on the Material's ShelfLife to be used as a Material. If the remaining ShelfLifeHrs are less than this amount, the Material cannot be used as it is considered expired.

MinSourceQty | Decimal

MultipleStorageAreaSupplyAllowed | Boolean

If True, the Materials required for the Operation can be supplied by multiple storage areas. If False, all required materials must be supplied from the same storage area.

MultipleWarehouseSupplyAllowed | Boolean

If True, the Materials required for the Operation can be supplied by multiple warehouses. If False, all required materials must be supplied from the same Warehouse.

PlannedScrapQty | Decimal

This is used to specify the Quantity of Scrap items that are expected to be consumed.

ProductRelease | String

RequireFirstTransferAtSetup | Boolean

Used by material requirements whose MaterialUsedTiming is either ByProductionCycle or FirstAndLastProductionCycle. If true, the first transfer of material is needed at the start of setup if the operation has a scheduled setup. If no setup is scheduled, the first transfer is required according to the first production cycle calculation. This is useful, for example, if part of setup is priming the resource with some starter material. Item TransferQty is used, otherwise a quantity of 1 is required.

RequirementType | String

This is used to specify whether the Material is being directly purchased or taken from inventory to supply the requirement. Accepted values:

FromStock: The Material is taken from Inventory. This is the default value if unset.

BuyDirect: The Material does not affect Inventory, and Inventory has no effect when this Material Requirement is satisfied.

Source | String

This is used to describe where the Material is coming from. ('Purchase Order XYZ, 'from stock,' etc.). This is set automatically for stocked items and can be set externally and imported for Buy-Direct materials.

StorageAreaExternalId | String

Defines which storage area the material will be pulled from.

TankStorageReleaseTiming | String

Deprecated in software version 12.3.0 and newer.

If the material is drawn from a Tank Resource, these values can indicate the timing of when the Tank is empty. Accepted values:

NotTank: Not expected to be drawn from a tank.

AtActivityStart: Release the Tank when the activity consuming the material starts.

AtEndOfActivitySetup: Release the Tank when the activity consuming the material has finished Setup.

AtEndOfProcessing: Release the Tank when the activity consuming the material has finished processing.

AtEndOfPostProcessing: Release the Tank when the activity consuming the material in the tanks has finished its post-processing.

TotalCost | Decimal

Used for buy-direct materials only. Used in KPIs and simulation rules to calculate WIP cost. Standard stock material requirement costs are calculated according to the item's Cost * Required Quantity.

UOM | String

The unit of measure of the Quantity fields. For information only.

UsabilityRequirement | Int32

Deprecated in software version 12.1.4 and newer.

UseOverlapActivities | Boolean

Deprecated in software version 12.3.0 and newer.

If True, the Material Requirement will be able to depend on Material from other Manufacturing Orders that are not yet Finished but whose material is projected to arrive in stock in time to satisfy the cycles of the Operation. Setting this may allow the operation and other operations to start earlier.

If False, then this Material Requirement may wait until the expected completion of Manufacturing Orders supplying the Material.

UseOverlapPurchases | Boolean

If True, the Material Requirement will depend on Material Purchase Orders that have not arrived yet, but whose material is projected to arrive in stock in time to satisfy the cycles of the Operation. Setting this may allow the operation and other operations to start earlier.

If False, then this Material Requirement may wait until the Expected Receipt Date of Purchase Orders supplying the Material.

WarehouseExternalId | String

The External identifier of the Warehouse that must supply this Material Requirement. If omitted, the Material Requirement can be satisfied by any Warehouse accessible by the Plant of the Primary Resource performing the work. For MRP and CTP functionality, the warehouse must be defined if there is more than one warehouse in the data model.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Item Mappings

Import Mappings Board

Inventory Plan Board

Materials Board</div>
        </section>
      
        <section class="article" id="article-246-operation-attribute-mappings">
          <h3 class="article-title">Operation Attribute Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/operation-attribute-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*AttributeExternalId | String

The unique external identifier of the Attribute.

*JobExternalId | String

The external identifier of the parent job.

*MoExternalId | String

The external identifier of the Manufacturing Order associated with the job.

*OpExternalId | String

The external identifier of the job operation to which the Attribute will be assigned.

Code | String

A string value assigned to the Attribute. This can be used by sequence-dependent Clean or Setup time configurations.

CodeManualUpdateOnly | Boolean

Whether the Code field can be updated through import.

ColorCode | Int32

A Color name or hexadecimal code that can be used to visually represent the Attribute in the Gantt. For example, if the Attribute represents paint colors, then the ColorCode can be the color of the paint. See: Supported color values (Excel).

ColorOverride | Boolean

If true, then the ColorCode property value defined here on the Operation Attribute mapping will override the ColorCode defined on the Attribute object.

ColorCodeManualUpdateOnly | Boolean

Whether the ColorCode field can be updated through import.

Cost | Decimal

The cost to perform the Setup or Clean triggered by this Attribute. This is only used if not using Lookup tables.

CostOverride | Boolean

If true, then the Cost property value defined here on the Operation Attribute mapping will override the DefaultCost defined on the Attribute object.

CostManualUpdateOnly | Boolean

Whether the Cost field can be updated through import.

DurationHrs | Double

The duration of the Setup or Clean triggered by this Attribute. This is only used if not using Lookup tables.

DurationOverride | Boolean

If true, then the DurationHrs property value defined here on the Operation Attribute mapping will override the DefaultDurationHrs defined on the Attribute object.

DurationHrsManualUpdateOnly | Boolean

Whether the DurationHrs field can be updated through import.

Number | Double

A numeric value assigned to the Attribute. This can be used by sequence-dependent Clean or Setup time configurations and constrain the Operation to Eligible resources.

NumberManualUpdateOnly | Boolean

Whether the Number field can be updated through import.

ShowInGantt | Boolean

Specifies whether to show this Attribute in the Gantt View when the 'Attribute(s)' segment is enabled on the labels.

ShowInGanttOverride | Boolean

If true, then the ShowInGantt property value defined here on the Operation Attribute mapping will override the ShowInGantt setting defined on the Attribute object.

ShowInGanttManualUpdateOnly | Boolean

Whether the ShowInGantt field can be updated through import.

See Also

Attribute Mappings

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-291-product-mappings">
          <h3 class="article-title">Product Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/product-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

An External identifier of the operation's Product entry. Must be unique per each Product per Operation.

*ItemExternalId | String

The External identifier of the item being produced.

*JobExternalId | String

The External identifier of the Job associated with this product.

*MoExternalId | String

The External identifier of the Manufacturing Order associated with this product.

*OpExternalId | String

The External identifier of the Operation associated with this product.

*WarehouseExternalId | String

The External identifier of the Warehouse where the produced Item(s) will be stored.

CompletedQty | Decimal

Define a quantity of work which has already been completed and added to inventory. When the operation completes, only the RemainingFinishQty amount (TotalOutputQty minus CompletedQty) is added to inventory.

FixedQty | Boolean

This specifies whether the TotalOutputQty is a fixed number. If True, the TotalOutputQty will not change if the RequiredQty of the Manufacturing Order is changed for any reason. This is not supported on the primary product (MO Product) of template jobs which are used to generate production orders via MRP and CTP. This is typically used to add Tool type items back to inventory.

InventoryAvailableTiming | String

When the inventory (Product) is created, controls are considered available in stock for use by a consuming Material Requirement. Accepted values:

AtOperationRunStart: All produced inventory is considered available at the scheduled start of the Operation’s Run time. This can be used when operations consuming the material should be allowed to schedule overlapping the operation producing the material. If Material Post-Processing Time is defined, the release time is delayed by that time span.

AtOperationRunEnd: All produced inventory is considered available at the end of the Operation's last run/cycle, plus any Resource Transfer time.

AtOperationResourcePostProcessingEnd: All produced inventory is considered available at the end of the Operation's post-processing step, plus any Resource Transfer time.

ByProductionCycle: If TransferQty is set, material will be moved to storage based on that quantity. Otherwise, it will be moved at the end of each cycle. See also: Manufacturing Order Production Overlap

This may cause scheduling performance to degrade, especially if Transfer Quantity is a very small value and the operation's TotalOutputQty is a large value. 

DuringPostProcessing: Material is transferred evenly over the full duration of PostProcessing. This will occupy a StorageConnector if one is used to store material. If Item TransferQty is set, the material will be moved to storage based on that quantity.

DuringStorage: Material is transferred evenly over the full duration of Storage. This will occupy a StorageConnector if one is used to store material. If Item TransferQty is set, the material will be moved to storage based on that quantity.

AtStorageEnd: Material is transferred immediately at the end of Storage.

Deprecated value in software versions 12.3.0 and newer:

BasedOnTransferQty: The material becomes available as it is produced in increments equal to its item's Transfer Quantity property value.

LimitMatlSrcToEligibleLots | Boolean

If True, the lot produced by the Product output can only be consumed by Stock Material Requirements which specify the Product's Lot Code in the AllowedLotCodes property. This is the default behavior if unset.

If False, the lot produced by the Product output can be consumed by any Stock Material Requirement.

UseLimitMatlSrcToEligibleLots | Boolean

This must be set to True when LimitMatlSrcToEligibleLots is set to False in order to override the default behavior.

LotCode | String

The Lot Code to be assigned to the items being produced.

MaterialPostProcessingHrs | Double

The amount of time after Processing that the Product must wait before another Operation can use it. For example, this can represent drying or cooling time. This time period does not consume capacity on Resources but is used to determine when the product is available.

RequireEmptyStorageArea| Boolean

Used to identify whether a tank/silo needs to be empty before material can be stored. If true, the Storage Area that will be storing this product must be empty or else it cannot be stored.

MaterialRequirement | String

Deprecated in software versions 12.3.0 and newer.

The Material Requirement associated with this product.

Predecessor | String

Deprecated in software versions 12.3.0 and newer.

The Predecessor Operation for this product.

SetWarehouseDuringMRP | Boolean

If True, then during MRP Warehouse is set to the Warehouse where the demand occurs, provided that the Item is stocked in the demand's warehouse.

StoreInTank | Boolean

Deprecated in software versions 12.3.0 and newer.

If True, and the Resource that the Product is processed on is defined as a Tank, then the material will be stored in the Tank Resource for no longer than the duration of the item's defined Shelf Life property.

StorageAreaExternalId | String

The Storage Area where the product will be stored.

TotalOutputQty | Decimal

The total amount of the specified Item to be made by the Operation.

UnitVolumeOverride | Decimal

Set a volume value directly on the operation to override the default calculated volume. Otherwise volume is defined by item.UnitVolume * Product.RequiredQty.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Item Mappings

Warehouse Mappings

Import Mappings Board

Inventory Plan Board</div>
        </section>
      
        <section class="article" id="article-233-required-capabilities-mappings">
          <h3 class="article-title">Required Capabilities Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/required-capabilities-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*CapabilityExternalId | String

The External identifier of the Capability to be assigned to the Resource Requirement for this Operation.

*JobExternalId | String

The External identifier of the Job to which the Manufacturing Order belongs.

*MoExternalId | String

The External identifier of the Manufacturing Order to which the Operation belongs.

*OpExternalId | String

The External identifier of the Operation is associated with the Resource Requirement and Required Capability.

*ResourceRequirementExternalId | String

The External identifier of the Resource Requirement to which the Required Capability is assigned.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Resource Requirement Mappings

Capability Mappings

Capability Assignment Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-190-resource-operation-mappings">
          <h3 class="article-title">Resource Operation Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-operation-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*CycleHrs | Double

The number of hours it takes for one cycle of the operation to complete. This is used with Qty Per Cycle to determine the length of the operation.

*ExternalId | String

The External identifier of the Operation. Must be unique per each Operation of a Manufacturing Order.

*JobExternalId | String

The External identifier of the job associated with the Operation.

*MoExternalId | String

The External identifier of the Manufacturing Order associated with the Operation.

*Name | String

Unique, changeable text identifier for the Operation.

*RequiredFinishQty | Double

The Quantity of good units that the Operation must produce.

AutoCreatedCapabilityExternalId | String

The External identifier of the capability associated with the Operation was automatically created.

AutoCreateRequirements | String

Whether requirements should be automatically created for this operation.

AutoFinish | Boolean

If True, the Operation will be Finished automatically when the Clock is advanced past its scheduled end date. See also: Automatic Activity Reporting and Finishing

AutoReportProgress | Boolean

If True, the Operation has its progress reported according to the schedule when the Clock is advanced past its scheduled start date. In addition, hours are automatically added to the fields for Reported Setup, Run, and Post-Processing based on the current Production Status of the activity.

For example, if the activity's Production Status is Running, when the Clock is advanced, the Reported Run Hours is incremented by the difference in hours between the old clock and new clock values. Note that for the activities to have their scheduled lengths adjusted due to this auto reporting of progress, the Time Base Reporting value on the Operation must also be True. To preserve the auto-computed values for Reported Setup, Run, and Post-Processing, updates from imports are ignored. However, manual updates of these fields from the user interface may be applied.

See also: Automatic Activity Reporting and Finishing

AutoSplit | Boolean

If the operation is scheduled after its JITStartDateTime, then it will be split evenly into N activities where N is the number of eligible Resources. The resulting split activities are scheduled independently of each other and may schedule on the same or different Resources. This also controls un-splitting. During optimizations, if an activity has been split unnecessarily, it will be unsplit. This applies both to automatically and manually split activities.

AutoSplitType | String

The type of AutoSplit that will be used when scheduling the operation. The default is None. Accepted values:

None: Auto-split is disabled.

Manual: Auto-split is disabled. Manual splitting is allowed.

PrimaryCapacityAvailability: Auto-split based on the capacity availability of the resource(s) chosen to schedule the primary resource requirement.

PredecessorMaterials: Auto-split a successor operation into the same number of activities as the predecessor was split when the predecessor feeds the successor material.

PredecessorQuantityRatio: Auto-split successor operations into an equal number of parts as its predecessor is split into.

ResourceQtyCapacity: Auto-split based on a resource's configured Maximum Quantity and/or Minimum Quantity values.

ResourceVolumeCapacity: Auto-split based on a resource's configured Maximum Volume and/or Minimum Volume values.

BatchCode | String

On Batch Resources, Operations with the same Batch Code are allowed to run in the same batch.

CampaignCode | String

A custom Campaign Code can be defined and used in conjunction with the Optimize Factor to prioritize scheduling operations of the same Campaign.

CanPause | Boolean

If True, then Activities of the Operation can be paused for offline capacity intervals (or gaps in online capacity). This allows the operation to start before an offline interval, span the duration of the offline interval with no progress made on the activity, then resume progress at the start of the next online interval.

If False, then Activities of the Operation won't be scheduled to start until there is sufficient time to complete them in one continuous online capacity interval.

CanResize | Boolean

If True, then Activities of the Operation can be resized via click/drag in the Gantt.

CanSubcontract | Boolean

This indicates to the planner that this Operation can be subcontracted if necessary. For display only.

CarryingCost | Decimal

This is the cost per unit, per day after this Operation is finished. This is for costs related to shrinkage, spoilage, raw materials, engineering changes, and customer changes that may cause materials to be scrapped. For KPI calculations.

CleanHrs | Double

Defines the time required for cleaning out each Resource that was used to run the operation.

CleanOutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule.

CleanTimeManualUpdateOnly | Boolean

Whether the CleanHrs field can be updated through import.

CleanoutCost | Decimal

The cost of Production Cleanout. Used if Operation Cleanout is incurred.

CommitEndDate | DateTime

The planned Operation End Date is to be used to measure schedule conformity.

CommitStartDate | DateTime

The planned Operation Start Date is to be used to measure schedule conformity.

CompatibilityCode | String

This is used to restrict Resources only to perform compatible work at simultaneous times. If specified, any scheduled Operation's CompatibilityCode must match the CompatibilityCode of the other operations scheduled on Resources with the same CompatibilityGroup.

Resources that are part of the same Compatibility Group can only run Operations concurrently if they have the same Compatibility Code. So, for example, if the same material input pipe feeds two machines, they can only run products that use that same material at any point in time.

The UseCompatibilityCode setting of the operation must also be set to True.

UseCompatibilityCode | Boolean

Whether to use the Operation's Compatibility Code when setting up Item/Resource Compatibility.

ConstraintType | String

Whether the Operation should prevent its successor(s) from starting before material from this Operation is finished. Accepted values:

NonConstraint

ConstrainedByLeadTime

ConfirmedConstraint

CycleSpanManualUpdateOnly | Boolean

Whether the CycleSpan field can be updated through data import.

Description | String

Text for describing the Operation.

IsRework | Boolean

This indicates that this work is being performed to fix a problem encountered in another operation. For display only.

JITStartDateBufferDays | Double

This is the timespan that is subtracted from the JITStartDate to allow additional JIT slack on an Operation basis.

MaterialsManualUpdateOnly | Boolean

Whether the Operation's Material Requirements can be updated through the data import. If True, the Material Requirements can only be updated manually in PlanetTogether.

MaxAutoSplitAmount | Double

This is a maximum quantity or volume amount for any resulting activity of a split.

MinAutoSplitQty | Double

This property is removed from software versions 12.2.0.1 and newer.

This is a minimum quantity for any resulting activity of a split.

MinAutoSplitAmount | Double

This is a minimum quantity or volume amount for any resulting activity of a split.

Notes | String

Comments or special considerations about this Operation.

Omitted | String

Omitted Operations are treated as if they take zero time. Accepted values:

NotOmitted: The Operation will be included as normal.

OmittedByUser: The Operation will be omitted per a user's preference/specification.

OmittedAutomatically: The Operation will be omitted automatically by the system due to bad data.

OnHold | Boolean

Whether the Operation should not be worked on for some reason until the Hold Until Date.

HoldReason | String

The Reason why the Operation has been put on Hold. Hold Reasons may be customized via System Settings, but these are the standard accepted values:

1. Material Hold
2. Tooling Hold
3. Production Hold
4. Engineering Hold
5. Customer Hold
6. Quality Hold
7. Lack of Material
8. Design Change Pending

HoldUntilDateTime | DateTime

If the Operation is on Hold, then activities for this Operation are scheduled to start after the Hold Until Date.

OperationSequence | Int64

The sequential order of the operation in relation to other operations of the same M.O. if not importing alternate path predecessor/successor mappings.

OutputName | String

The name of the Output Product produced by this Operation. This is useful when several predecessor operations producing the same type of material supply the same Successor Operation. The Successor will use this field to recognize quantities of identical materials available. If this field is not set, the Material will not be grouped with any other Predecessor Operations. Groups of material are used for things such as calculating the ExpectedFinishQuantity.

OverlapTransferQty | Double

The number of parts moved to the next Operation in each Transfer Batch. Smaller values can be used to shorten flow times by making Material available at Successor Operations more quickly.

NOTE: A quantity of "1" or similar small increment combined with a large total quantity produced by the operation (~100 or more) is known to impact scheduling performance and cause instance services to consume high amounts of RAM due to the number of calculations the simulation engine must perform in order to determine when the successor operation(s) can schedule.

PlannedScrapQty | Decimal

The quantity that is planned to be scrapped. This is a calculation of the RequiredQty x PlanningScrapPercent.

PlanningScrapPercent | Decimal

Percent of parts expected to be scrapped. Used to calculate ExpectedGoodQty and ExpectedScrapQty. Can be combined with DeductScrapFromRequired in order to have the system adjust the total production to equal RequiredQty plus PlannedScrapQty.

DeductScrapFromRequired | Boolean

Whether the ExpectedScrap should be deducted from the Required Finish Qty when determining the quantity to schedule. In some cases, more material is available, and additional products can be produced to make up for the scrap. In other cases, this is not possible, and the Operation will finish short.

PostProcessingHrs | Double

Specifies the number of hours that a resource may be occupied after Processing has been completed. This can be used to model cleanup time. The release of material is constrained by the Post Processing time, and no operations can schedule on the resource. Whether a resource will be occupied also depends on the Resource Requirement's UsageStart and UsageEnd settings.

PostProcessManualUpdateOnly | Boolean

Whether the PostProcessingHrs field can be updated through data import.

PreventSplitsFromIncurringSetup | Boolean

When True, split activities of this operation will not incur any Setup time.

PreventSplitsFromIncurringClean | Boolean

When True, split activities of this operation will not incur any Clean time.

ProductCode | String

The code to use for specific product rules that override the default product rule.

ProductionSetupCost | Decimal

The cost of Production Setup. Used if Operation Setup is incurred.

ProductsManualUpdateOnly | Boolean

Whether Operation’s Products can be updated through the data import.

QtyPerCycle | Double

The quantity of product produced during each production cycle.

QtyPerCycleManualUpdateOnly | Boolean

Whether the QtyPerCycle field can be updated through data import.

ResourceRequirementsManualUpdateOnly | Boolean

Whether Operation’s Resource Requirements can be updated through the data import.

ScrapPercentManualUpdateOnly | Boolean

Whether ScrapPercent field can be updated through data import.

SetupCode | String

This property is removed from software versions 12.3.0 and newer. The same behavior can be replicated using Attributes.

It can be used to calculate sequence-dependent setup and/or reduce the frequency of setups during optimizations. Operations that have different Setup Codes typically require some time to be spent during the changeover to set up the equipment for the next run. (Inherited from InternalOperation.)

SetupColor | String

A Color name or hexadecimal code that can be used to visually represent the Setup process of the operation in the Gantt. See: Supported color values (Excel).

SetupColorAlpha | Int32

The alpha color component is used to identify the type of setup on the Gantt visually.

SetupColorBlue | Int32

The blue color component is used to identify the type of setup on the Gantt visually.

SetupColorGreen | Int32

The green color component is used to identify the type of setup on the Gantt visually.

SetupColorRed | Int32

The red color component is used to identify the type of setup on the Gantt visually.

SetupHrs | Double

The time required for setting up each Resource that is used during the Operation's Setup time. See also: Resource SetupHrs. (Inherited from InternalOperation.)

SetupNumber | Double

The SetupNumber of the Operation this block belongs to. This is used by the Attribute Number Range Tables to determine the required amount of setup and can be used as an eligibility constraint.

SetupSplitType | String

Determines how Setup should be allocated when an Operation is split. Accepted values:

None: No override is required and the Setup is calculated normally.

FirstActivity: Only the first activity is scheduled with normal Setup and the rest have none.

SplitByQty: Each activity is scheduled with a proportional Setup duration according to the Activities split ratio.

SetupTimeManualUpdateOnly | Boolean

Whether the SetupHrs field can be updated through import.

SplitUpdateMode | String

Determines how the Operation Splits will be updated.

StorageHrs | Double

The time required for Operation Storage. This typically represents the amount of time it takes to transfer product to inventory from the resource where the operation runs.

StorageManualUpdateOnly | Boolean

Whether the StorageHrs field can be updated through import.

SuccessorProcessing | String

This is used to control whether Successor Operations should be scheduled on the same Resource as the current Operation. For example, 'KeepSuccessor' means that successor operations will try to schedule on the same resource as the predecessor, and 'KeepSuccessorNoInterrupt' will try to schedule it right after the predecessor operation. Use of this feature requires that the routing be linear within the predecessor and successor operation, that the operation only has 1 activity, and that the resource the predecessor ends up being scheduled on is eligible to perform the work required on the successor operation. Accepted values:

NoPreference

KeepSuccessor

KeepSuccessorNoInterrupt

KeepSuccessorsTimeLimitHrs | Double

The length of time that the SuccessorProcessing setting remains valid for. After this length of time has passed without the Successor Operation finding capacity on the Resource after its Predecessor, it may be scheduled on another Resource.

TankPostProcessingHrs | Double

The amount of time a Tank Resource is unavailable after all of the material has been removed.

TankPostProcessingManualUpdateOnly | Boolean

Whether the TankPostProcessingHrs field can be updated by import.

TimeBasedReporting | Boolean

Specifies whether the ReportedRunSpan is subtracted from the ScheduledRunSpan rather than calculating the ScheduledRunSpan based on the RemainingQty. (Inherited from InternalOperation.)

UOM | String

Indicates the meaning of one unit of this product. For display only.

UseExpectedFinishQty | Boolean

Whether the finish quantities of Predecessor Operations will influence the Expected Finish Qty of this Operation, in the event of multiple Predecessors, the most limiting one determines the Finish Qty.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

WholeNumberSplits | Boolean

Whether activities must be split into quantities with whole numbers, this is only possible if the original quantity is a whole number.

See Also

Job Mappings

Manufacturing Order Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-222-resource-requirement-mappings">
          <h3 class="article-title">Resource Requirement Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-requirement-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

An External identifier for the Resource Requirement. Must be unique per each Resource Requirement per Operation.

*JobExternalId | String

The External identifier of the Job associated with this Resource Requirement.

*MoExternalId | String

The External identifier for the Manufacturing Order associated with this Resource Requirement.

*OpExternalId | String

The External identifier of the Operation associated with the Resource Requirement.

AttentionPercent | Int32

The percent of the Resource's attention consumed by this Resource Requirement. For example, two Operations with Attention Percents of 60% and 40% could schedule to run simultaneously. A maximum of 100% summed across all simultaneous Operations is enforced. For this to have an effect, the Resource's Capacity Type must be set to Multi-Tasking, and the Activity's PeopleUsage must be set to Use All Available.

BlockFillImageFile | String

If the BlockFillType is set to Image, this image is used to fill the Gantt block (or the Resource Image is used if this is left blank). This can be used to differentiate the types of operations or resources. The values specified are the full name of the file, such as myfile.png. These image files are in the ResourceImages folder under the client executable (with the images displayed in the Resource grid).

BlockFillPattern | String

If the BlockFillType is set to Pattern, this pattern is used to fill the blocks in the Gantt. This can be used to differentiate the types of operations or resources.

BlockFillType | String

Specifies how the blocks in the Gantt should be filled. Accepted values:

Default

ImageAlignedCenter

ImageAlignedLeft

ImageAlignedRight

Pattern

CopyMaterialsToCapabilities | Boolean

If True, for each MaterialRequirement on the Operation, a RequiredCapability will be created and assigned to this ResourceRequirement. The Capability ExternalId will be the same as MaterialRequirement's ExternalId.

DefaultResourcePlantExternalId | String

The External identifier of the Plant in which the Resource used to complete the ResourceRequirement is found.

DefaultResourceDepartmentExternalId | String

The External identifier of the Department in which the Resource used to complete the ResourceRequirement is found.

DefaultResourceExternalId | String

The External identifier of the Resource used to complete the ResourceRequirement.

DefaultResourceJITLimitHrs | Double

This represents the duration from the release on the default resource for which the operation can schedule on non-default resources when UseDefaultResourceJITLimitHrs is set to True.

This provides flexibility during optimization to choose other Resources if the Default Resource cannot start the Activity on time. This minimizes the chances of it being late. A value of zero means the default resource is not a constraint, but otherwise, no effect. A value less than zero will allow the operation to schedule on non-default resources before the default resource.

UseDefaultResourceJITLimitHrs | Boolean

Whether to allow scheduling on non-default resources according to the DefaultResourceJITLimitHrs setting.

Description | String

Text that describes the purpose or the source of the Resource Requirement.

NumberOfResourcesRequired | Int32

If greater than 1, create this many duplicates of this ResourceRequirement.

PrimaryRequirement | Boolean

If True, the Resource Requirement is defined as being the Primary Resource Requirement. If any operation requires 2 or more resources, one must be designated the Primary requirement.

UsageStart | String

Defines when the Operation starts using the Resource. Must be less than or equal to the UsageEnd value. A Primary Resource Requirement must always start at Setup. Accepted values:

Setup: Start using from the start of the Operation Setup process. This is the required setting for all primary resource requirements.

Run: Start using from the start of the Operation Run (Cycle) process.

PostProcessing: Start using from the start of the Operation Post Processing process.

Clean: Start using from the start of the Operation Clean process.

Storage: Start using from the start of the Storage process.

Option removed from software version 12.3.0:

StoragePostProcessing: Start using from the start of the Storage Post-Processing process. StoragePostProcessing only occurs if the material is being stored in a tank.

StorageClean: Start using from the start of the Storage Clean process. StorageClean only occurs if the material is being stored in a tank.

UsageEnd | String

Defines when the Operation is finished using the Resource. Must be greater than or equal to the UsageStart value. A Primary Resource Requirement must always end at PostProcessing, Clean, or Storage. Accepted values:

Setup: Finish using at the end of the Operation Setup process. 

Run: Finish using at the end of the Operation Run (Cycle) process.

PostProcessing: Finish using at the end of the Operation Post Processing process.

Clean: Finish using at the end of the Operation Clean process.

Storage: Finish using at the end of the Storage process.

Option removed from software version 12.3.0:

StoragePostProcessing: Finish using at the end of the Storage Post-Processing process. StoragePostProcessing only occurs if the material is being stored in a tank.

StorageClean: Finish using at the end of the Storage Clean process. StorageClean only occurs if the material is being stored in a tank.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Required Capabilities Mappings

Import Mappings Board

Helper Resources</div>
        </section>
      
        <section class="article" id="article-257-successor-manufacturing-order-mappings">
          <h3 class="article-title">Successor Manufacturing Order Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/successor-manufacturing-order-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Successor Manufacturing Order. Must be unique per Manufacturing Order.

*JobExternalId | String

The External identifier of the Job associated with this Successor Manufacturing Order.

*MoExternalId | String

The External identifier of the Predecessor Manufacturing Order.

*SuccessorJobExternalId | String

The External identifier of the Job associated with the Successor Manufacturing Order.

*SuccessorManufacturingOrderExternalId | String

The External identifier of the Successor Manufacturing Order.

SuccessorOperationExternalId | String

The External identifier of the Successor Operation.

SuccessorPathExternalId | String

The External identifier of the Successor Path.

TransferHrs | Double

Specifies the number of hours it takes to transfer Items to supply the Successor Manufacturing Order after the Predecessor Operations are done. The Successor Manufacturing Order is constrained by the FinishDate of the Predecessor Manufacturing Order plus this number of hours.

UsageQtyPerCycle | Double

Specifies the quantity of the Predecessor Operation's Product that the Successor Operation consumes in each cycle of the Successor Operation.

See Also

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Alternate Path & Node Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-271-user-field-mappings">
          <h3 class="article-title">User Field Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/user-field-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

A unique identifier of the User Field.

*Name | String

The Name used to identify the User Field. This is the value displayed in grids, Gantt labels, and Tooltips.

*ObjectType | String

Specifies the type of PlanetTogether object that the related User Field belongs to. I.e: Plants, Resources, Jobs, Operations, etc. Accepted values:

Users

Plants

Departments

Resources

Cells

CapacityIntervals

ProductRules

ResourceConnectors

Items

Warehouses

SalesOrders

Forecasts

PurchasesToStock

TransferOrders

Jobs

ManufacturingOrders

ResourceOperations

Customers

*UDFType | String

Specifies the data type of the User Field. Accepted values:

String

Hyperlink

Integer

Double

Long

Decimal

Boolean

DateTime

TimeSpan

DefaultValue | String

Allows for a Default Value to be set for the associated User Field. This value is imported as a String value but parsed into the defined type during the import process.

Description | String

Additional text for describing the User Field.

DisplayInUI | Boolean

Specifies whether the User Field is displayed in grids and the Gantt. Default is True if omitted.

Notes | String

Additional notes related to the User Field.

Publish | Boolean

Specifies whether the User Field should be published to external systems. Default is True if omitted.

See Also

User Defined Fields</div>
        </section>
      <h2 id="cat-object-import-mappings-resource-objects-mappings" class="category-header">Object Import Mappings &gt; Resource Objects Mappings</h2>
        <section class="article" id="article-259-allowed-helper-resource-mappings">
          <h3 class="article-title">Allowed Helper Resource Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/allowed-helper-resource-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

AllowedHelperDepartmentExternalId | String

The ExternalId of the Department with which the Allowed Helper is associated.

AllowedHelperPlantExternalId | String

The ExternalId of the Plant with which the Allowed Helper is associated.

AllowedHelperResourceExternalId | String

The ExternalId of the Resource which is designated as an Allowed Helper to the Primary Resource.

ResourceDepartmentExternalId | String

The ExternalId of the Department with which the Resource to be granted an Allowed Helper is associated.

ResourceExternalId | String

The ExternalId of the Resource to be granted an Allowed Helper.

ResourcePlantExternalId | String

The ExternalId of the Plant with which the Resource to be granted an Allowed Helper is associated.

See Also

Allowed Helpers

Resource Mappings

Import Mappings Board

Capacity Planning Board</div>
        </section>
      
        <section class="article" id="article-320-attribute-code-table-mappings">
          <h3 class="article-title">Attribute Code Table Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/attribute-code-table-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Attribute Code Table

*TableName | String

Name of the Attribute Code Table.

Description | String

Description of the Attribute Code Table.

PreviousPrecedence | Boolean

This determines which wildcard match takes precedence when both non-exact match types are found. "The previous Precedence" means that the Code Table value that has the "Wildcard Code" in the "PreviousOpSetupCode" field will be used to calculate the setup.

Wildcard | String

This is a string or a character used to support pattern matching and is used to search within the "Table Values" data of the Code Table for occurrences within the "PreviousOpSetupCode" and "NextOpSetupCode" fields. 

Attribute Code Table Attribute Name

*TableName | String

Name of the Attribute Code Table.

*AttributeName | String

Name of the Attribute.

This property is removed from software versions 12.2.0.1 and newer.

*AttributeExternalId | String

The ExternalId of the Attribute. Must be unique to all Attribute ExternalId's per each Attribute Number Range Setup Table.

Attribute Code Table Attribute Code

*AttributeName | String

Name of the Attribute.

This property is removed from software versions 12.2.0.1 and newer.

*AttributeExternalId | String

The ExternalId of the Attribute. Must be unique to all Attribute ExternalId's per each Attribute Number Range Setup Table.

*TableName | String

Name of the Attribute Code Table.

*PreviousOpAttributeCode | String

The Attribute Code of the Previous Operation.

*NextOpAttributeCode | String

The Attribute Code of the Next Operation.

*SetupTime | Double

The time incurred for Setup.

This property is removed from software versions 12.2.0.1 and newer.

*DurationHours | Double

The time incurred for Setup or Clean when triggered by this table.

CleanoutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule.

Cost | Decimal

The cost incurred for Setup or Clean when triggered by this table.

SetupCost | Double

The cost incurred for Setup.

This property is removed from software versions 12.2.0.1 and newer.

Attribute Code Table Assigned Resources

*PlantExternalId | String

Identifier of the Plant to which the Resource is associated.

*DepartmentExternalId | String

Identifier of the Department to which the Resource is associated.

*ResourceExternalId | String

Identifier of the Resource that will be associated with the Attribute Code Table.

*TableName | String

Name of the Attribute Code Table.

See Also

Setup Time

Cleans

Import Mappings Board

Scenario Data Board</div>
        </section>
      
        <section class="article" id="article-270-attribute-mappings">
          <h3 class="article-title">Attribute Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/attribute-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

A unique identifier of the Attribute.

AttributeTrigger | String

Specifies when Setup or Cleans (and costs associated with each) will be triggered to schedule for the Attribute. The AttributeType property defines whether the attribute will be used for Setup or Cleans. Accepted values:

Always: This uses the DefaultDurationHours specified, no matter what.

CodeChanges: This uses the DefaultDurationHours whenever this attribute's Code changes from one scheduled operation to the next on the same resource.

NumberChanges: This uses the DefaultDurationHours whenever this attribute's Number changes from one scheduled operation to the next on the same resource.

NumberHigher: This uses the DefaultDurationHours when this attribute's Number increases from one scheduled operation to the next on the same resource.

NumberLower: This uses the DefaultDurationHours when this attribute's Number decreases from one scheduled operation to the next on the same resource.

LookupByCode: Uses an Attribute Code Table to determine the setup or clean duration. This overrides the DefaultDurationHours value.

LookupByRange: Used for Setup only. Uses an Attribute Range Table to determine setup duration. This overrides the DefaultDurationHours value.

Never: The attribute is not used for Clean or Setup time calculations.

Note

Setup calculations are dependent on the scheduled resource having its SetupIncluded property set to the value UseOperationAttributes.

Cleans calculations are dependent on the scheduled resource having its UseAttributeCleanouts property set to True.

For more information, see:

Setup Time

Cleans

AttributeType | String

Define whether the attribute is used for Cleans or Setups. Null values are accepted if used only for informational purposes. Accepted values:

Clean

Setup

CleanoutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower.

ColorCode | String

A Color that can be used to represent the value of the Attribute in the Gantt. The ColorCode property mapped via the Operation Attributes Mapping can be used to override the default value. See: Supported color values (Excel).

ConsecutiveSetup | Boolean

This is used to model operations where multiple Setup activities must be completed in a sequence and cannot be performed concurrently. If True, the total Setup time for the Operation is calculated as the sum of the maximum non-consecutive Setup time and the various consecutive Setup times.

DefaultCost | Decimal

The cost to perform the Clean or Setup incurred by this Attribute. This is only used if not using lookup tables. The Cost property mapped via the Operation Attributes Mapping can be used to override the default value.

DefaultDurationHrs | Double

The number of Clean or Setup hours incurred by this Attribute when triggered. This is only used if not using Lookup tables. The DurationHrs property mapped via the Operation Attributes Mapping can be used to override the default value.

Description | String

Additional text for describing the Attribute.

HideInGrids | Boolean

If True, the Attribute cannot be displayed in the Activity Scheduling grids. The default value/behavior is False if unset.

IncurResourceSetup | Boolean

If True, the Sequenced Setup will be incurred even if the UseSequencedSetup field on the Resource is set to false.

Name | String

The Name used to identify the Attribute.

ShowInGantt | Boolean

Specifies whether to show this Attribute in the Gantt View when the 'Attribute(s)' segment is enabled on the labels by default. This can be overridden by specific operations via Operation Attribute Mappings.

UseInSequencing | Boolean

Specifies whether to include this Attribute to be available to use in sequencing plan optimization factors.

See Also

Attributes

Operation Attribute Mappings

Job Mappings

Manufacturing Order Mappings

Resource Operation Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-239-attribute-range-table-mappings">
          <h3 class="article-title">Attribute Range Table Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/attribute-range-table-mappings" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

Attribute Range Table

Attribute Range Table Attribute Name

Attribute Range Table From-Range

Attribute Range Table To-Range

Attribute Range Table Resource

Property Name | Data Type

Description & accepted values

* = Required

Attribute Range Table

Establish the presence of each Attribute Number Range Setup Table.

Formerly labelled "Attribute Setup Table"

*Name | String

Unique, changeable, text identifier for the Attribute Number Range Setup Table.

*TableId | Int64

A unique identifier of the Attribute Number Range Setup Table. Must be unique among all imported Setup Tables.

Description | String

Additional text for describing the Attribute Number Range Setup Table.

Attribute Range Table Attribute Name

Define each of the Attributes which will be mapped to each Attribute Number Range Setup Table.

Formerly labelled "Attribute Setup Table Attribute Name"

*AttributeName | String

The Name of the Attribute. Must be unique to all Attribute Names per each Attribute Number Range Setup Table.

This property is removed from software versions 12.2.0.1 and newer.

*AttributeExternalId | String

The ExternalId of the Attribute. Must be unique to all Attribute ExternalId's per each Attribute Number Range Setup Table.

*TableId | Int64

The unique identifier of the Attribute Number Range Setup Table.

Description | String

Additional text for describing the Attribute.

EligibilityConstraint | Boolean

Defines whether the Attribute is a scheduling constraint. If True, operations will only be eligible to schedule on resources that can perform the work based on its attribute number value and the from/to range defined in this Attribute Number Range Setup Table.

Attribute Range Table From-Range

Each Attribute mapped to each Attribute Number Range Setup Table is required to have at least one defined From Range. The From Range is enough to establish resource eligibility constraints (no To Range is required).

Formerly labelled "Attribute Setup Table From-Range"

*AttributeName | String

The Name of the Attribute. Must match an Attribute Name that was mapped in the Attribute Setup Table Attribute Name mappings table.

This property is removed from software versions 12.2.0.1 and newer.

*AttributeExternalId | String

The ExternalId of the Attribute. Must be unique to all Attribute ExternalId's per each Attribute Number Range Setup Table.

*FromId | Int64

A unique identifier for the From Range. Must be unique per From Range per Attribute Name.

*FromRangeStart | Double

The starting value of the From Range.

*FromRangeEnd | Double

The ending value of the From Range.

*TableId | Int64

The unique identifier of the Attribute Number Range Setup Table.

Attribute Range Table To-Range

Define a To Range if using the Attribute Number Range Setup Table to calculate sequence-dependent setup times based on the From ➡️ To Range configurations. A To Range is not required to be defined.

Formerly labelled "Attribute Setup Table To-Range"

*AttributeName | String

The Name of the Attribute. Must match an Attribute Name that was mapped in the Attribute Setup Table Attribute Name mappings table.

This property is removed from software versions 12.2.0.1 and newer.

*AttributeExternalId | String

The ExternalId of the Attribute. Must be unique to all Attribute ExternalId's per each Attribute Number Range Setup Table.

*FromId | Int64

The unique identifier of the From Range associated with the To Range.

*TableId | Int64

The unique identifier of the Attribute Number Range Setup Table.

*ToRangeStart | Double

The starting value of the To Range.

*ToRangeEnd | Double

The ending value of the To Range.

SetupCost | Double

The incurred cost of Setup for this From/To Range.

SetupMinutes | Double

The incurred Setup minutes for this From/To Range.

Attribute Range Table Resource

Associate any number of Resources to use each configured Attribute Number Range Setup Table.

Formerly labelled "Attribute Setup Table Resource"

*PlantExternalId | String

The External ID of the Plant to which the Resource is associated.

*DepartmentExternalId | String

The External ID of the Department to which the Resource is associated.

*ResourceExternalId | String

The External ID of the Resource that will be associated with the Attribute Number Range Setup Table. This must be unique per each Attribute Number Range Setup Table (the same resource cannot be associated twice to the same Table).

*TableId | Int64

The unique identifier of the Attribute Number Range Setup Table.

See Also

Setup Time

Scenario Data Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-240-capability-assignment-mappings">
          <h3 class="article-title">Capability Assignment Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capability-assignment-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*CapabilityExternalId | String

The ExternalId of the Capability to be assigned to a Resource.

*DepartmentExternalId | String

The ExternalId of the Department to which the Resource belongs.

*PlantExternalId | String

The ExternalId of the Plant to which the Department belongs.

*ResourceExternalId | String

The ExternalId of the Resource to which the Capability will be Assigned.

See Also

Capability Mappings

Resource Mappings

Department Mappings

Plant Mappings

Import Mappings Board

Capacity Planning Board

Scenario Data Board</div>
        </section>
      
        <section class="article" id="article-221-capability-mappings">
          <h3 class="article-title">Capability Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capability-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Resource Capability. Must be unique per each Capability object.

*Name | String

Unique, changeable, text identifier for the Resource Capability.

Description | String

Text for describing the Capability.

Notes | String

Comments or special considerations about the Capability.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Capacity Planning Board

Scenario Data Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-224-capacity-interval-mappings">
          <h3 class="article-title">Capacity Interval Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capacity-interval-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The external identifier of the capacity interval. Must be unique among all capacity intervals, including recurring intervals.

*Name | String

A common name used to identify the capacity interval.

*StartDateTime | DateTime

The date and time when the capacity interval starts.

*EndDateTime | DateTime

The date and time when the capacity interval ends.

CanBeDeleted | Boolean

If True, the capacity interval is allowed to be deleted by users who have permission to maintain capacity intervals. When disabled, the capacity interval cannot be deleted by any user.

CanBeDraggedOrResized | Boolean

If True, the capacity interval is allowed to be dragged and resized in the Gantt by users who have permission to maintain capacity intervals, and who have the similar user settings enabled. When disabled, the capacity interval cannot be dragged and resized in the Gantt by any user.

CanStartActivity | Boolean

If True, then activities are allowed to start on this interval. Default value is True if no value is defined and no IntervalPreset is defined.

CapacityCode | String

A custom code to restrict scheduling resource requirements with different codes. Operation resource requirements must define the code in order for them to be considered eligible to run on this interval.

CleanOutSetups | Boolean

Deprecated in software versions 12.3.0 and newer. Replaced by ResetAttributeChangeovers.

If True, then this interval resets sequence-dependent setup and cleanout trigger values.

Color | String

A Color that can be used to distinguish the Job from other Jobs in the Gantt. Accepts HTML hexadecimal color codes, or HTML color name strings. See: Supported color values (Excel)

Description | String

A text description of the capacity interval.

IntervalPreset | String

Use a preset capacity interval configuration to assign standard settings to common capacity interval types. Once a preset is defined, each option and setting may be manually changed, if desired. Each preset assigns a value to each of: IntervalType, Color, Overtime, CanStartActivity, PreventOperationsFromSpanning, CleanOutSetups (aka Reset Attribute Changeovers), UseOnlyWhenLate, UsedForSetup, UsedForRun, UsedForPostProcessing, UsedForStoragePostProcessing, and UsedForClean. Accepted values:

Online

Offline

Maintenance

Overtime

PotentialOvertime

Holiday

Cleanout

Details of each preset configuration can be found on the Capacity Intervals page.

IntervalType | String

Determines how the event will affect capacity. Accepted values:

Online: The resource is available to perform some type of work.

Offline: The resource is not available to perform work.

Accepted values changed in software version 12.2.1.x. Older software versions accept the following values:

NormalOnline: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Standard Hourly Cost property.

Overtime: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Overtime Hourly Cost property.

PotentialOvertime: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Overtime Hourly Cost property. Behaves the same as Overtime by default in terms of scheduling but the behavior can be manipulated using a custom extension.

Offline: The resource is not available to perform work. If an offline interval is placed at the same time on the same resource as an online or overtime interval then the resource is considered offline. Operations can be configured to span offline intervals (work may begin on the operation before an offline interval then pauses for the offline interval before resuming at the next online interval).

Cleanout: The resource is not available to perform work. No operations are allowed to be scheduled to span over this type of interval. If a cleanout interval is placed at the same time on the same resource as an online, overtime, or offline interval then the resource is considered offline and the cleanout interval behavior is enforced. This type is often used for resource maintenance when no operations should be started before the interval and placed on hold for the duration of the interval before resuming work at the next available online interval.

NbrOfPeople | Double

The number of people available during the interval.

 The interval's total capacity hours is calculated as a multiple of this number by the duration of the interval. For example, if the interval duration is 8 hours and the NbrOfPeople is 2, then the interval equates to 16 hours of total capacity. 

If the Resource Type is set to Multi-tasking, this number will determine how many operations can run simultaneously during the interval. 

Not used if IntervalType is Offline or Cleanout.

Notes | String

Comments or special considerations about this Capacity Interval.

Overtime | Boolean

When True, cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. When false, cost calculations for performing work on the interval use the Standard Hourly Cost on the resource. Default is False if not imported and no IntervalPreset is defined.

PreventOperationsFromSpanning | Boolean

If True, then operations are allowed to span this interval (pause) without performing any work. Interval type must be Offline.

ResetAttributeChangeovers | Boolean

If True, then this interval resets sequence-dependent setup and cleanout trigger values incurred by attributes and attribute tables.

UsedForClean | Boolean

When True, the capacity interval can be used to perform Clean processes.

UsedForPostProcessing | Boolean

When True, the capacity interval can be used to perform Post-Processing processes.

UsedForRun | Boolean

When True, the capacity interval can be used to perform Cycle/Run processes.

UsedForSetup | Boolean

When True, the capacity interval can be used to perform Setup processes.

UsedForStoragePostProcessing | Boolean

When True, the capacity interval can be used to perform Storage Post-Processing processes.

UseOnlyWhenLate | Boolean

When True, activities will only schedule on the capacity interval if they are late (the schedule clock date time is later than the activity’s JIT start date).

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Resource Capacity

Recurring Capacity Interval Mappings

Capacity Interval Resource Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-283-capacity-interval-resource-mappings">
          <h3 class="article-title">Capacity Interval Resource Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/capacity-interval-resource-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*CapacityIntervalExternalId | String

The external identifier of the Capacity Interval.

*DepartmentExternalId | String

The external identifier of the Department to which the Resource belongs.

*PlantExternalId | String

The external identifier of the Plant to which the Resource belongs.

*ResourceExternalId | String

The external identifier of the Resource to be assigned the Capacity Interval.

See Also

Resource Capacity

Resource Mappings

Capacity Interval Mappings

Recurring Capacity Interval Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-287-cell-mappings">
          <h3 class="article-title">Cell Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/cell-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External identifier of the Cell. Must be unique per each Cell object.

Description | String

Additional text for describing the Cell.

Name | String

The name of the Cell. Unique, changeable, text identifier.

Notes | String

Comments or special considerations about this Cell object.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Scenario Data Board

Capacity Planning Board

Resource Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-314-cleanout-trigger-table-mappings">
          <h3 class="article-title">Cleanout Trigger Table Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/cleanout-trigger-table-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Jump to section:

Cleanout Trigger Tables

Cleanout Trigger Tables Assigned Resources

Operation Count Cleanout Trigger Tables

Production Unit Cleanout Trigger Tables

Time Cleanout Trigger Tables

Cleanout Trigger Tables

*TableName | String

An unique identifier for the Trigger Table.

Description | String

Additional text for describing the Trigger Table.

Cleanout Trigger Tables Assigned Resources

*DepartmentExternalId | String

The external identifier of the Department to which the Resource belongs.

*PlantExternalId | String

The external identifier of the Plant to which the Resource belongs.

*ResourceExternalId | String

The external identifier of the Resource to be assigned the Trigger Table.

*TableName | String

The name of the Trigger Table being assigned to the resource. Must match the TableName property mapped to a table from the Cleanout Trigger Tables mappings.

Operation Count Cleanout Trigger Tables

*DurationHours | Double

The number of Clean process hours incurred by this table when triggered. 

*TableName | String

The name of the associated Trigger Table. Must match the TableName property mapped to a table from the Cleanout Trigger Tables mappings.

*TriggerValue | Int32

The number of operations to run on the assigned resource before a cleanout is triggered.

CleanCost | Decimal

The cost to perform the Clean incurred by this table when triggered. 

CleanoutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower.

Production Unit Cleanout Trigger Tables

*DurationHours | Double

The number of Clean process hours incurred by this table when triggered. 

*ProductionUnit | String

Define which production unit type to use for tracking and triggering cleans at various intervals. Accepted values:

Cycles: In this case, the TriggerValue specifies the total number of operation cycles scheduled on a resource since the last cleanout was scheduled.

ProductUnits: In this case, the TriggerValue specifies the total output production units (product Total Output Quantity * UnitVolume) of primary products produced by operations scheduled on a resource since the last cleanout was scheduled.

Quantity: In this case, the TriggerValue specifies the total output quantity of primary products produced by operations scheduled on a resource since the last cleanout was scheduled.

*TableName | String

The name of the associated Trigger Table. Must match the TableName property mapped to a table from the Cleanout Trigger Tables mappings.

*TriggerValue | Decimal

The number of production units which must be produced on the assigned resource before a cleanout is triggered. Uses the ProductionUnit property to determine which unit type is tracked.

CleanCost | Decimal

The cost to perform the Clean incurred by this table when triggered. 

CleanoutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower.

Time Cleanout Trigger Tables

*DurationHours | Double

The number of Clean process hours incurred by this table when triggered. 

*TableName | String

The name of the associated Trigger Table. Must match the TableName property mapped to a table from the Cleanout Trigger Tables mappings.

*TriggerValueHours | Double

The number of hours of production or calendar time that must pass before a cleanout is triggered. Uses the UseProcessingTime and UsePostProcessingTime property values to determine whether to use production or calendar time.

CleanCost | Decimal

The cost to perform the Clean incurred by this table when triggered. 

CleanoutGrade | Int32

Define a Grade value to prioritize which Clean signal to schedule. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower.

TriggerAtEnd | Boolean

When True, the clean is scheduled at the end of the operation which triggers the clean. When False, the clean is scheduled at the end of the operation which is scheduled just prior to the operation which triggers the clean.

UsePostProcessingTime | Boolean

When True, operation post-processing time will be used to calculate when cleans needs to be scheduled according to the TriggerValueHours setting. This can be combined with UseProcessingTime.

UseProcessingTime | Boolean

When True, operation run/cycle time will be used to calculate when cleans needs to be scheduled according to the TriggerValueHours setting.

See Also

Cleans</div>
        </section>
      
        <section class="article" id="article-203-compatibility-code-table-mappings">
          <h3 class="article-title">Compatibility Code Table Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/compatibility-code-table-mappings" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

Compatibility Code Tables

Compatibility Code Tables Assigned Resources

Compatibility Code Table Codes

Property Name | Data Type

Description & accepted values

* = Required

Compatibility Code Tables

Establish the presence of each Compatibility Code Table.

*AllowedList | Boolean

When True, the table is used to list allowed or compatible codes which are allowed to schedule simultaneously. When False, the table is used to list disallowed or incompatible codes which are never allowed to schedule simultaneously.

*TableName | String

A unique identifier of the Compatibility Code Table. Must be unique among all imported Compatibility Code Tables.

Description | String

Additional text for describing the Compatibility Code Table.

Compatibility Code Tables Assigned Resources

Associate any number of Resources to use each configured Compatibility Code Table.

*PlantExternalId | String

The External ID of the Plant to which the assigned Resource is associated.

*DepartmentExternalId | String

The External ID of the Department to which the assigned Resource is associated.

*ResourceExternalId | String

The External ID of the Resource that will be associated with the Compatibility Code Table. This must be unique per each Compatibility Code Table (the same resource cannot be associated twice to the same Table).

*TableName | String

The unique identifier of the Compatibility Code Table. This must match the property of the same name imported from the Compatibility Code Tables mapping.

Compatibility Code Table Codes

Define each of the Codes which will be mapped to each Compatibility Code Table.

*CompatibilityCode | String

A Code associated with the Compatibility Code Table. Each code must be associated with the Table one entry at a time.

*TableName | String

The unique identifier of the Compatibility Code Table. This must match the property of the same name imported from the Compatibility Code Tables mapping.

See Also

Compatibility Codes

Resource Mappings</div>
        </section>
      
        <section class="article" id="article-209-department-mappings">
          <h3 class="article-title">Department Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/department-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

An External identifier for the Department. Must be unique per each Department per Plant.

*PlantExternalId | String

The External identifier of the Plant to which the Department belongs.

DepartmentFrozenSpanHrs | Double

The Frozen Span Hours for the department. If not defined, a default value of 8 hours will be assigned. For more information, see: Plant Stability.

Description | String

Text that describes the purpose or the source of the Department.

Name | String

Unique, changeable, text identifier for the Department.

Notes | String

Comments or special considerations about the Department.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

See Also

Import Mappings Board

Capacity Planning Board

Plant Stability</div>
        </section>
      
        <section class="article" id="article-301-plant-mappings">
          <h3 class="article-title">Plant Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/plant-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The external identifier of the Plant. Must be unique per each Plant object.

AnnualPercentageRate | Decimal

The annual percentage rate on current interest-bearing liabilities. This is used when calculating an operation's Carrying Cost.

BottleneckThreshold | Decimal

If more than this percentage of Activities on a Resource's schedule are Capacity Bottlenecked, the Resource is flagged as a bottleneck. All resources in the plant share the same threshold value.

DailyOperatingExpense | Decimal

Monetary costs of operating the plant for a day. Note that Resource hourly costs are also added to the KPIs' OE value, so they should either be included here or in the Resource Cost but not both.

Description | String

Text for describing the plant.

HeavyLoadThreshold | Decimal

If a Resource has more than this percentage of its capacity allocated in the short term, it is considered 'Heavy Loaded' and is flagged as such.

InvestedCapital | Decimal

Monetary value encapsulating all monies invested in the plant. (Total Assets — Non-Interest-Bearing Current Liabilities — Excess Cash)

Name | String

Unique, changeable, text identifier.

Notes | String

Comments or special considerations about the plant.

StableSpanHrs | Double

The plant stable span hours. For more information, see: Plant Stability.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Capacity Planning Board

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-223-product-rules-mappings">
          <h3 class="article-title">Product Rules Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/product-rules-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*DepartmentExternalId | String

The External identifier of the Department to which the Resource belongs.

*PlantExternalId | String

The External identifier of the Plant to which the Resource belongs.

*ProductItemExternalId | String

The External identifier of the Item to which the Rule will be applied.

*ResourceExternalId | String

The External identifier of Resource to which the Rule will be applied.

CleanoutCost | Double

The cost of Production Cleanout.

UseCleanoutCost | Boolean

If true, it overrides the operation's Clean Cost with the CleanoutCost defined in the Product Rule.

CleanHrs | Double

The number of hours required for the Clean process when the Item specified is produced on the specified Resource.

UseCleanHrs | Boolean

If true, it overrides the operation's Clean Hours with the CleanHrs defined in the Product Rule.

CleanoutUnitsRatio | Decimal

Overrides Units Produced when calculating resource cleanout.

UseCleanoutUnits | Boolean

If true, it overrides the operation's Units Produces with regards to calculating resource cleanout with the CleanoutUnitsRatio defined in the Product Rule.

CycleHrs | Double

The number of hours required for one production Cycle of the Item specified on the Resource.

UseCycleHrs | Boolean

If true, it overrides the operation's Cycle Hours with the CycleHrs defined in the Product Rule.

HeadStartHrs | Double

The number of hours that the operation can start before its JIT start date. Higher values will assign operations to this resource earlier than resources with lower headstart values.

UseHeadStartSpan | Boolean

If true, it overrides the operation's HeadStart span with the HeadStartHrs defined in the Product Rule.

MaterialPostProcessingHrs | Double

The number of hours required for Material Post-Processing for the specified Item and Resource.

UseMaterialPostProcessingSpan | Boolean

If true, overrides the operation's Material Post-Processing span with the MaterialPostProcessingHrs defined in the Product Rule.

MinQty | Decimal

The minimum quantity that must be produced of the specified Item when it's scheduled to be produced on the specified Resource.

UseMinQty | Boolean

If true, overrides the minimum quantity allowed to be produced on the Resource according to the MinQty defined in the Product Rule.

MaxQty | Decimal

The maximum quantity that must be produced of the specified Item when it's scheduled to be produced on the specified Resource.

UseMaxQty | Boolean

If true, overrides the maximum quantity allowed to be produced on the Resource according to the MaxQty defined in the Product Rule.

OperationName | String

This property is removed from software versions 12.2.0.1 and newer.

If specified, then the rule only applies to Operations with this Operation Name. Otherwise, the rule applies to all Operations of any Manufacturing Order making this Product.

OperationCode | String

This property is removed from software versions 12.3.0 and newer. It's replaced by ProductCode for consistency.

If specified, then the rule only applies to Operations which have this code value defined in the Operation Product Code. Otherwise, the rule applies to all Operations of any Manufacturing Order making this Product.

PlanningScrapPercent | Double

The Planning Scrap Percent for the specified Item and Resource.

UsePlanningScrapPercent | Boolean

If true, it overrides the operation's Planning Scrap Percent with the PlanningScrapPercent defined in the Product Rule.

PostProcessingHrs | Double

The number of hours required for Post-Processing for the Item and Resource specified.

UsePostProcessingHrs | Boolean

If true, it overrides the operation's Post-Processing span with the PostProcessingHrs defined in the Product Rule.

Priority | Int32

A numerical Priority value to assign to the resource. Used for resource prioritization sequencing.

UsePriority | Boolean

If true, it overrides the resource's assigned Priority value with the one defined in the Product Rule.

ProductCode | String

If specified, then the rule only applies to Operations which have this code value defined in the Operation Product Code. Otherwise, the rule applies to all Operations of any Manufacturing Order making this Product.

ProductionSetupCost | Decimal

The cost of operation setup when running the operation on the specified resource.

UseProductionSetupCost | Boolean

If true, it overrides Operation Production Setup cost with the one defined in the Product Rule.

QtyPerCycle | Double

Quantity per Cycle. The number of items produced per cycle on the specified Resource.

UseQtyPerCycle | Boolean

If true, it overrides the operation's Qty Per Cycle with the QtyPerCycle defined in the Product Rule.

SetupHrs | Double

The number of hours required for Setup for the specified Item and Resource.

UseSetupHrs | Boolean

If true, it overrides the operation's Setup Hours with the SetupHrs defined in the Product Rule.

StorageHrs | Double

The number of hours required for Storage for the specified Item and Resource.

UseStorageHrs | Boolean

If true, it overrides the operation's Storage Hours with the StorageHrs defined in the Product Rule.

TransferQty | Decimal

The Item Transfer Quantity when the specified Item is produced on the specified Resource.

UseTransferQty | Boolean

If true, it overrides the item's Transfer Quantity with the TransferQty defined in the Product Rule.

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

See Also

Product Rules

Resource Mappings

Item Mappings

Import Mappings Board

Scenario Data Board</div>
        </section>
      
        <section class="article" id="article-172-recurring-capacity-interval-mappings">
          <h3 class="article-title">Recurring Capacity Interval Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/recurring-capacity-interval-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The External Identifier of the recurring capacity interval. Must be unique among all capacity intervals, including non-recurring intervals.

*Name | String

A common name used to identify the capacity interval.

*StartDateTime | DateTime

The date and time when the capacity interval starts.

*EndDateTime | DateTime

The date and time when the capacity interval ends.

*Recurrence | String

The recurrence frequency type of the capacity interval. Accepted values:

NotRecurring: The interval does not recur.

Daily: The interval recurs once daily, every day of the week. The days of the week boolean properties are ignored (as if all are set to True).

Weekly: The interval recurs weekly on specific days of the week. Used in conjunction with the days of the week boolean properties (Sunday, Monday, etc.).

MonthlyByDayNumber: The interval recurs once per month on the same numerical day of the month. Used in conjunction with the MonthlyDayNumber property.

YearlyByMonthDay: The interval recurs once per year on the same date defined in the StartDateTime property.

*RecurrenceEndType | String

Represents how the recurring capacity interval will end. Accepted values:

NoEndDate: The capacity interval recurs for the duration of the planning horizon.

AfterMaxNbrRecurrences: The capacity interval recurs a specific number of times, or until it reaches the end of the planning horizon, whichever occurs first. The maximum number of recurrences is defined in the MaxNbrRecurrences property.

AfterRecurrenceEndDateTime: The capacity interval recurs until a specific date and time, or until it reaches the end of the planning horizon, whichever occurs first. The end date is specified in the RecurrenceEndDateTime property.

CanBeDeleted | Boolean

If True, the capacity interval is allowed to be deleted by users who have permission to maintain capacity intervals. When disabled, the capacity interval cannot be deleted by any user.

CanBeDraggedOrResized | Boolean

If True, the capacity interval is allowed to be dragged and resized in the Gantt by users who have permission to maintain capacity intervals, and who have the similar user settings enabled. When disabled, the capacity interval cannot be dragged and resized in the Gantt by any user.

CanStartActivity | Boolean

If True, then activities are allowed to start on this interval. Default value is True if no value is defined and no IntervalPreset is defined.

CapacityCode | String

A custom code to restrict scheduling resource requirements with different codes. Operation resource requirements must define the code in order for them to be considered eligible to run on this interval.

CleanOutSetups | Boolean

Deprecated in software versions 12.3.0 and newer. Replaced by ResetAttributeChangeovers.

If True, then this interval resets sequence-dependent setup and cleanout trigger values. Default value is False if no value is defined and no IntervalPreset is defined.

Color | String

A Color that can be used to distinguish the Job from other Jobs in the Gantt. Accepts HTML hexadecimal color codes, or HTML color name strings. See: Supported color values (Excel)

Description | String

A text description of the capacity interval.

IntervalPreset | String

Use a preset capacity interval configuration to assign standard settings to common capacity interval types. Once a preset is defined, each option and setting may be manually changed, if desired. Each preset assigns a value to each of: IntervalType, Color, Overtime, CanStartActivity, PreventOperationsFromSpanning, CleanOutSetups (aka Reset Attribute Changeovers), UseOnlyWhenLate, UsedForSetup, UsedForRun, UsedForPostProcessing, UsedForStoragePostProcessing, and UsedForClean. Accepted values:

Online

Offline

Maintenance

Overtime

PotentialOvertime

Holiday

Cleanout

Details of each preset configuration can be found on the Capacity Intervals page.

IntervalType | String

Determines how the event will affect capacity. Accepted values:

Online: The resource is available to perform some type of work.

Offline: The resource is not available to perform work.

Accepted values changed in software version 12.2.1.x. Older software versions accept the following values:

NormalOnline: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Standard Hourly Cost property.

Overtime: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Overtime Hourly Cost property.

PotentialOvertime: The resource is available to perform work. Resource usage costs are calculated at the rate defined in the resource's Overtime Hourly Cost property. Behaves the same as Overtime by default in terms of scheduling but the behavior can be manipulated using a custom extension.

Offline: The resource is not available to perform work. If an offline interval is placed at the same time on the same resource as an online or overtime interval then the resource is considered offline. Operations can be configured to span offline intervals (work may begin on the operation before an offline interval then pauses for the offline interval before resuming at the next online interval).

Cleanout: The resource is not available to perform work. No operations are allowed to be scheduled to span over this type of interval. If a cleanout interval is placed at the same time on the same resource as an online, overtime, or offline interval then the resource is considered offline and the cleanout interval behavior is enforced. This type is often used for resource maintenance when no operations should be started before the interval and placed on hold for the duration of the interval before resuming work at the next available online interval.

Sunday | Boolean

Whether the capacity interval recurs each Sunday.

Monday | Boolean

Whether the capacity interval recurs each Monday.

Tuesday | Boolean

Whether the capacity interval recurs each Tuesday.

Wednesday | Boolean

Whether the capacity interval recurs each Wednesday.

Thursday | Boolean

Whether the capacity interval recurs each Thursday.

Friday | Boolean

Whether the capacity interval recurs each Friday.

Saturday | Boolean

Whether the capacity interval recurs each Saturday.

MaxNbrRecurrences | Int32

The maximum number of times the capacity interval may recur when the RecurrenceEndType is set to AfterMaxNbrRecurrences.

MonthlyDayNumber | Int32

Represents the day where the recurring capacity interval with a Recurrence set to MonthlyByDayNumber will recur.

NbrIntervalsToOverride | Int32

Specifies the number of intervals to override during the short-term capacity.

NbrOfPeople | Decimal

The number of people available during the interval.

The interval's total capacity hours is calculated as a multiple of this number by the duration of the interval. For example, if the interval duration is 8 hours and the NbrOfPeople is 2, then the interval equates to 16 hours of total capacity.

If the Resource Type is set to Multi-tasking, this number will determine how many operations can run simultaneously during the interval.

Not used if IntervalType is Offline.

NbrOfPeopleOverride | Decimal

Specifies the number of people to override during the short-term capacity.

Notes | String

Additional notes and comments.

Overtime | Boolean

When True, cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. When false, cost calculations for performing work on the interval use the Standard Hourly Cost on the resource. Default is False if not imported and no IntervalPreset is defined.

PreventOperationsFromSpanning | Boolean

If True, then operations are allowed to span this interval (pause) without performing any work. Interval type must be Offline.

RecurrenceEndDateTime | DateTime

The date and time when the recurrence of the capacity interval should end. Applies to whose RecurrenceEndType is after RecurrenceEndDateTime.

ResetAttributeChangeovers | Boolean

If True, then this interval resets sequence-dependent setup and cleanout trigger values incurred by attributes and attribute tables.

SkipFrequency | Int32

This will skip several intervals based on the Recurrence set. For example, if the SkipFrequency is set to 2 and the Recurrence is set to Weekly, the recurring capacity interval will skip two weeks before recurring.

UsedForClean | Boolean

When True, the capacity interval can be used to perform Clean processes.

UsedForPostProcessing | Boolean

When True, the capacity interval can be used to perform Post-Processing processes.

UsedForRun | Boolean

When True, the capacity interval can be used to perform Cycle/Run processes.

UsedForSetup | Boolean

When True, the capacity interval can be used to perform Setup processes.

UsedForStoragePostProcessing | Boolean

When True, the capacity interval can be used to perform Storage Post-Processing processes.

UseOnlyWhenLate | Boolean

When True, activities will only schedule on the capacity interval if they are late (the schedule clock date time is later than the activity’s JIT start date).

See Also

Resource Capacity

Capacity Interval Mappings

Capacity Interval Resource Mappings

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-256-resource-attribute-mappings">
          <h3 class="article-title">Resource Attribute Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-attribute-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*DepartmentExternalId | String

The external identifier of the Department in which the Resource is found.

*Name | String

Unique, changeable, text identifier of the Attribute.

*PlantExternalId | String

The external identifier of the Plant in which the Resource is found.

*ResourceExternalId | String

The external identifier of the Resource to be assigned the Attribute.

Code | String

The Attribute Code value. This can be used for sequence-dependent setup calculations, or optimization prioritization, or for informational purposes.

ColorCode | String

A Color name or hexadecimal code that can be used to visually represent the Attribute in the Gantt. See: Supported color values (Excel).

ConsecutiveSetup | Boolean

This is used to model operations where multiple Setup activities must be completed in a sequence and cannot be performed concurrently. If True, the setup time incurred by this Attribute will be added to any other setup time incurred on the operation (assuming attributes are configured to be considered when calculating Operation Setup time). See also: Setup Time.

Description | String

Text for describing the Attribute.

IncurSetupWhen | String

Specifies when to include a Setup time and cost for the Attribute. Accepted values:

Always: The Attribute's setup time and/or cost is always considered during simulation Setup calculations.

CodeChanges: Consider incurring setup when the Attribute Code value changes from the previously scheduled operation on the same Resource.

NumberChanges: Consider incurring setup when the Attribute Number value changes from the previously scheduled operation on the same Resource.

NumberHigher: Consider incurring setup when the Attribute Number value is higher compared to the previously scheduled operation on the same Resource.

NumberLower: Consider incurring setup when the Attribute Number value is lower compared to the previously scheduled operation on the same Resource.

LookupByCode: Consider incurring setup based on any applicable Attribute Code Table logic.

Never: Never incur setup based on this Attribute.

LookupByRange: Consider incurring setup based on any applicable Attribute Number Range Table logic.

See also: Setup Time.

ManualUpdateOnly | Boolean

Specifies whether this Attribute can be updated during data imports. This is usually set to 'True' once an Attribute has been modified manually to prevent an import from overriding those modifications.

Number | Decimal

The Attribute Number value. This can be used by Attribute Number Range Tables for sequence-dependent setup calculations and/or constrain the operation to eligible resources, or optimization prioritization, or for informational purposes.

SetupCost | Decimal

The cost to perform Setup incurred by this Attribute. This value is not considered if using Lookup tables.

SetupHrs | Decimal

The Setup hours incurred by this Attribute. This value is not considered if using Lookup tables.

ShowInGantt | Boolean

Specifies whether to show this Attribute in the Gantt View when the 'Attribute(s)' segment is enabled.

See Also

Resource Mappings

Department Mappings

Plant Mappings

Import Mappings Board

Setup Time</div>
        </section>
      
        <section class="article" id="article-213-resource-connector-mappings">
          <h3 class="article-title">Resource Connector Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-connector-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Jump to section:

Resource Connector Mappings

Resource Connection Mappings

Version 12.1.4 and Older Mappings

Resource Connector Mappings

*ExternalId | String

A unique identifier of the Resource Connector. This value must be unique per each Resource Connector.

*Name | String

A common name used to identify the Resource Connector.

Description | String

A text description of the Resource Connector.

LinkMaterials | Boolean

This property is deprecated in software version 12.3.0 and newer. Material connectors are now configured via Storage Area Connectors.

If True, then the Connector will be used to constrain Material supply based on linked Resources.

LinkSuccessors | Boolean

This property is deprecated in software version 12.3.0 and newer. All Resource Connectors are now used to link successor activities.

If True, then the Connector will be used to constrain successor activities based on linked Resources.

Notes | String

Comments or special considerations about this Resource Connector.

TransitHours | Double

The number of hours which need to pass between the end of a predecessor operation and its successor operation on a connected downstream resource.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

Resource Connection Mappings

*ConnectionDirection | String

This field determines the directional connection for a Resource Connector. Accepted values:

FromResource: Establishes the resource as the predecessor in the connection sequence.

ToResource: Establishes the resource as the successor in the connection sequence.

*PlantExternalId | String

Identifier of the Plant to which the Resource is associated.

*DepartmentExternalId | String

Identifier of the Department to which the Resource is associated.

*ResourceExternalId | String

Identifier of the Resource that will be associated with the Resource Connection.

*ResourceConnectorExternalId | String

Identifier of the Resource Connector.

Version 12.1.4 and Older Mappings

These mappings are deprecated in software versions 12.2.0.1 and newer.

DownstreamResourceDepartmentExternalId | String

The ExternalId of the Department to which the downstream Resource belongs.

DownstreamResourceExternalId | String

The ExternalId of the downstream Resource.

DownstreamResourcePlantExternalId | String

The ExternalId of the Plant to which the downstream Resource belongs.

FixedTransitHrs | Double

The number of hours which need to pass between the end of a predecessor operation and its successor operation on a connected downstream resource.

ResourceDepartmentExternalId | String

The ExternalId of the Department to which the primary connected Resource belongs.

ResourceExternalId | String

The ExternalId of the primary connected Resource.

ResourcePlantExternalId | String

The ExternalId of the Plant to which the primary connected Resource belongs.

See Also

Resource Connectors

Resource Mappings

Import Mappings Board

Tank Resources</div>
        </section>
      
        <section class="article" id="article-199-resource-mappings">
          <h3 class="article-title">Resource Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/resource-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The identifier of the Resource for external system references. This value must be unique per each Resource per each Department.

*Name | String

A common name used to identify the Resource.

*DepartmentExternalId | String

The External identifier for the Department in which the Resource is in.

*PlantExternalId | String

The External identifier for the Plant in which the Resource is found.

Active | Boolean

Specifies whether the resource is active (in use). If False then no operations will be allowed to schedule on the resource until it is active again.

ActivitySetupEfficiencyMultiplier | Decimal

This is used as a rate multiplier for activity setup values. It will be overridden if setup is used in a ProductRule. Multiplies the setup time to adjust for slower/faster setups. Larger numbers mean the resource is faster at performing setups. For example, specifying 3 means it can complete a setup process 3x faster than the time standards indicate.

AutoJoinHrs | Double

This is the number of hours from the PlanetTogether clock within which resources can be processed to auto-join.

AutoSplitHrs | Double

This is the number of hours from the PlanetTogether clock within which resources can be processed to auto-split.

BatchType | String

Specifies whether a percentage or a volume defines the batching. Accepted values:

None

Percent

Volume

BatchVolume | Decimal

Specifies the number of jobs that can be batched together on the resource. If an activity's Required Quantity is larger than this value, the job will fail to schedule.

BufferSpanHrs | Double

The hour span of the Buffer when using Drum-Buffer-Rope Release rules. Buffer spans are used to prevent starving this resource to keep its utilization high.

CapacityType | String

Specifies whether the resource may be capable of running multiple operations simultaneously. Accepted values:

SingleTasking: Only one operation may be performed at any point in time.

MultiTasking: A finite number of operations can be performed at the same time.

Infinite: Any number of activities can be performed at the same time (no constraint).

CellExternalId | String

The External Identifier of the Cell assigned to the Resource.

Cells represent a physical grouping of Resources in an autonomous production line. When one operation of a job which has multiple operations schedules on a resource in a designated Cell, all successor operations will attempt to schedule on Resources within the same Cell.

ChangeoverSetupEfficiencyMultiplier | Decimal

A rate multiplier for activity changeover values. This is applied to setups incurred by attribute logic. Values larger than 1 will run setup faster.

CompatibilityGroup | String

This property is removed from software versions 12.2.0.1 and newer.

A Compatibility Group string identifier.

Resources that are part of the same Compatibility Group can only run Operations concurrently if they have the same Compatibility Code. So, for example, if the same material input pipe feeds two machines, they can only run products that use that same material at any point in time.

ConsecutiveSetupTimes | Boolean

Whether Resource and Operation setups are done consecutively or in parallel.

True: the Total Setup is the sum of the Resource and Operation setups.

False: the Total Setup is the maximum of the two.

This setting has no effect if UseOperationSetupTime is set to False.

CurrentProductSetup | String

This property is removed from software versions 12.2.0.1 and newer.

The Product for which the Resource is currently or was most recently set up. This is used to calculate the Setup time for the first scheduled activity on the Resource.

CurrentSetupCode | String

This property is removed from software versions 12.2.0.1 and newer.

The Operation Setup Code for which the Resource is currently or was most recently set up. This is used to calculate the setup time for the first scheduled activity on the Resource.

CurrentSetupNumber | Decimal

This property is removed from software versions 12.2.0.1 and newer.

The Operation Setup Number for which the Resource is currently or was more recently set up. Optimization can use this to sequence operations with Setup Numbers that are near each other or are in an increasing/decreasing sequence.

CycleEfficiencyMultiplier | Decimal

In software versions 12.2.0.x and older, these worked in reverse so that values greater than 1 resulted in activities running slower while values less than 1 ran them faster.

Multiplies run time to adjust for slower/faster Resources. Values greater than "1" represent a resource running faster than usual, while values less than "1" represent a resource running slower than usual.

Description | String

A text description of the Resource.

DisallowDragAndDrops | Boolean

If True, then drag and drop of activities on the Resource are not allowed.

DiscontinueSameCellScheduling | Boolean

If True, then same-cell scheduling for predecessor operations is discontinued. But if this resource is part of a cell, then the behavior is as usual and this resource's cell will become the new cell that the optimizer attempts to schedule successor operations in.

Drum | Boolean

Whether to treat this Resource as a Drum when using the Drum-Buffer-Rope Release rule.

ExcludeFromGantts | Boolean

Whether the Resource should be excluded from Gantt charts. This is often set to True for inactive resources.

ExperimentalSequencingPlan | String

The name of the first experimental sequencing plan assigned to the resource.

ExperimentalSequencingPlanTwo | String

The name of the second experimental sequencing plan assigned to the resource.

ExperimentalSequencingPlanThree | String

The name of the third experimental sequencing plan assigned to the resource.

ExperimentalSequencingPlanFour | String

The name of the fourth experimental sequencing plan assigned to the resource.

GanttRowHeightFactor | Int32

Controls how tall the row is relative to other rows. Valid ranges are from 1 (shortest) to 10 (tallest). For example, a value of 5 will make that resource row 5 times taller than another on the Gantt whose value is 1.

HeadStartHrs | Double

Specifies the number of hours that a job or operation can be released to schedule on the resource ahead of its calculated Just In Time (JIT) date when using the release rule JIT with Resource Headstart in Optimize Settings.

When this value is reduced, it may help to prevent inventory buildup. Conversely, when the value is increased then operations may be released to schedule earlier which may create excess inventory. 

ImageFileName | String

Filename (with file extension but not a full path) of which image to use in the Gantt to represent this Resource. Accepted values are available in this downloadable .txt file: ImageFileNames.txt

IsTank | Boolean

Specifies whether the Resource is a Tank Resource.

LimitAutoJoinToSameShift | Boolean

This property is removed from software versions 12.2.0.1 and newer.

If True, then AutoJoining will be limited to operations and activities starting in the same shift.

ManualAssignmentOnly | Boolean

If True, then operations and activities can only be assigned to the Resource manually. Jobs will not be automatically scheduled on this resource.

MaxQty | Decimal

For the Resource to be considered eligible for an Activity, the Activity's Required Finish Quantity must be less than or equal to this amount.

MaxQtyPerCycle | Decimal

For the Resource to be considered eligible for an Activity, the Activity’s QtyPerCyle must be less than or equal to this amount.

This is often used for batch processes where a Resource can hold a certain volume, which cannot be exceeded.

MaxSameSetupHrs | Double

This property is removed from software versions 12.3.0 and newer.

When using Same Setup Code optimization factor, a setup code change is forced after this specified number of hours of setup time has been scheduled consecutively without a code change between operations.

This option can be used to force periodic rotation between groups of products (setup codes).

MaxVolume | Decimal

For the Resource to be considered eligible for an Activity, the Activity's Required Finish Quantity multiplied by the associated MO Product's assigned Unit Volume must be less than or equal to this amount.

MinNbrOfPeople | Decimal

The minimum number of people that are required for the resource.

MinQty | Decimal

For the Resource to be considered eligible for an Activity, the Activity's Required Finish Quantity must be at least this amount.

MinQtyPerCycle | Decimal

For the Resource to be considered eligible for an Activity, the Activity's Quantity Per Cycle must be at least this amount.

This is often used for batch processes where a Resource can hold a certain volume, and there is a desire to use smaller Resources for smaller orders to avoid wasting capacity.

MinVolume | Decimal

For the Resource to be considered eligible for an Activity, the Activity's Required Finish Quantity multiplied by the associated MO Product's assigned Unit Volume must be at least this amount.

NoDefaultRecurringCapacityInterval | Boolean

If True, the First Shift default capacity interval will not be automatically assigning to this Resource. This is to prevent jobs from scheduling on a newly-imported Resource.

NormalSequencingPlan | String

The name of the Normal (standard) sequencing plan used by this resource.

Notes | String

Comments or special considerations about this Resource.

NumberOfResources | Int32

This property is removed from software versions 12.2.0.1 and newer.

Used to speed up importing multiple identical Resources. Create a single resource record and specify the number of resources in this field and the system will create the additional resources and add "-1", "-2", etc., to the Resource Name and ExternalId.

OmitSetupOnFirstActivity | Boolean

If True, then the Setup Time on the first Activity scheduled on the Resource is always zero.

OmitSetupOnFirstActivityInShift | Boolean

If True, then the Setup Time on the first Activity scheduled on a Capacity Interval on the Resource is always zero.

OvertimeHourlyCost | Decimal

The hourly cost for running the resource during overtime capacity intervals.

Priority | Int32

A numerical priority value assigned to the resource. This can be used during optimization when the applied sequencing plan is configured to factor in the Resource Priority factor. This allows for specific ranking of resource priorities when two or more resources are capable of performing the same work and each are available to schedule an eligible activity at the same time.

ResourceCleanoutCost | Decimal

Specify cost of incurred Resource Cleanout Cost.

ResourceSetupCost | Decimal

Specify cost of incurred Resource Setup Cost.

ResourceType | String

The type of physical entity represented by the Resource. Used for custom reports and other display groupings. Accepted values:

Machine

Operator

Supervisor

Engineer

Inspector

Team

Labor

Equipment

Tool

Subcontractor

Cell

work area

WorkCenter

Bay

Transport

Container

Special

Technician

Fixture

Employee

Tank

Inbox

SameSetupHeadstartMultiplier | Decimal

This property is removed from software versions 12.2.0.1 and newer.

Used in the calculation of how far an operation can be scheduled before its JIT Start Date. Larger values result in activities with longer setups being allowed to start earlier to save a setup. During Optimizations, activities are not permitted to start earlier than JITstartDate-(SameSetupHeadstartMultiplier*currentSetupSpan+headStartSpan). It can be used to prevent excessive inventory buildup and aid in grouping same-setup code activities.

ScheduledRunSpanAlgorithm | String

Name of the script used to calculate ScheduledRunSpan in activities on this resource. If specified, this gives the absolute final value for ScheduledRunSpan. The result must be a non-negative double, or 1 will be substituted, and an error will be logged.

ScheduledSetupSpanAlgorithm | String

Name of the script used to calculate ScheduledSetupSpan in Activities on this resource. If specified, this gives the absolute final value for ScheduledSetupSpan. The result must be non-negative double, or zero will be substituted, and an error will be logged.

ScheduledTransferSpanAlgorithm | String

Name of the script used to calculate ScheduledTransferSpan in Activities on this resource. If specified, this gives the absolute final value for ScheduledTransferSpan. The result must be non-negative double, or zero will be substituted, and an error will be logged.

Sequential | Boolean

This property only applies to infinite resources. It ensures that every activity that gets scheduled finishes on or after the last scheduled block time. If the activity being scheduled would have been scheduled to complete before the last block that was scheduled, the scheduled finish time is adjusted so that the block is scheduled to finish at the same time as the last scheduled block.

This property was added to help model conveyors. First, model the minimum length of time an activity must stay on the conveyor (transfer time) using an Infinite sequential resource, then model the unloading of the conveyor as a finite resource. You may also need to place the two resources used to model the conveyor and predecessor resource in the same cell. Setup the unloading resource and operation so that the unload's length matches the load's length.

SetupEfficiencyMultiplier | Decimal

This property is removed from software version 12.2.1 and newer. It is replaced by ActivitySetupEfficiencyMultiplier.

Multiplies the setup time to adjust for slower/faster setups. Larger numbers mean the resource is slower at performing setups. For example, specifying 3 means it takes 3x longer to perform a setup than the standards indicate.

SetupHrs | Double

The number of hours which must be spent to set up this resource whenever the preceding operation did not use this resource.

SetupIncluded | String

This property is removed from software version 12.3.0 and newer. It's replaced by boolean fields UseResourceSetupTime, UseOperationSetupTime, and UseSequencedSetupTime

Indicates when to add setup time to an operation scheduled on this resource. Accepted values:

WhenProductChanges: Setup is incurred when the M.O. product of the operation's associated M.O. is different from the previously scheduled operation's M.O. product on the resource.

WhenSetupCodeChanges: Setup is incurred when the operation's Setup Code is different from the previously scheduled operation's Setup Code on the resource.

WhenEitherChanges: Setup is incurred when either the M.O. product or the Setup Code of the operation is different from that of the previously scheduled operation on the resource.

Always: Always incur setup according to all configured possible sources of Setup time.

Never: Setup time is never incurred on the resource by any operation.

WhenSetupNumberChanges: Setup is incurred when the operation's Setup Number is different from the previously scheduled operation's Setup Number on the resource.

WhenSetupNumberIncreases: Setup is incurred when the operation's Setup Number is higher/larger than the previously scheduled operation's Setup Number on the resource.

WhenSetupNumberDecreases: Setup is incurred when the operation's Setup Number is lower/smaller than the previously scheduled operation's Setup Number on the resource.

UseSetupCodeTable: Lookup operation Setup Code changes in an associated Setup Code Table to determine how much setup to incur based on Setup Code changes between scheduled operations.

UseOperationAttributes: Setup is incurred according to operation attribute settings.

See also: Setup Time

Stage | Int32

Used for multi-stage scheduling to allow scheduling of groups of resources stage by stage.

Staging comes with the following restrictions:

Jobs can only have one Manufacturing Order. This is because the job release event only occurs once in simulation

Each operation can only have one predecessor operation and one successor operation.

An operation can only have one resource requirement to help prevent requiring resources that have different stages

Resources with the same capabilities must have the same stage number. Otherwise, the operation would be eligible in multiple stages, only one of the stages would be selected, and the resources from the other stages would become ineligible. If any of these restrictions are violated, then the simulation might fail.

StandardCleanHours | Double

The number of hours which must be spent to clean this resource whenever the preceding operation did not use this resource.

StandardCleanoutGrade | Int32

The Cleanout Grade value to use for the resource StandardCleanHours. For more information, see: Cleans.

StandardHourlyCost | Decimal

The hourly cost for running the resource during non-overtime online capacity intervals.

TransferHrs | Double

The time it takes for the items produced to be transferred to the next resource or inventory. Successor operations cannot start before this time passes after finishing the operation. However, the resource is not consumed during this time.

UseAttributeCleanouts | Boolean

Whether to consider operation attributes when calculating and scheduling Cleans.

UseOperationCleanout | Boolean

Whether to consider the Clean Time of the Operation when calculating and scheduling Cleans.

UseOperationSetupTime | Boolean

If true, the specified Operation Setup (Operation.SetupHrs) of operations scheduled on the resource will be factored in when calculating the scheduled setup.

UseResourceSetupTime | Boolean

If true, the specified Resource Setup (Resource.SetupHrs) will be factored in when calculating the scheduled setup of each operation that schedules on the resource.

UseResourceCleanout | Boolean

If true, the specified Resource Cleanout (Resource.StandardCleanHours) of operations scheduled on the resource will be factored in when calculating the scheduled cleanout.

UseSequencedSetupTime | Boolean

If true, Operation Attributes of operations scheduled on the resource will be factored in when calculating the scheduled setup.

UserFields | String

An optional list of user-defined fields. For more information, see: User Defined Fields (UDFs).

Workcenter | String

The name of the work center in the ERP system (or Department Name if not set). For display only.

WorkcenterExternalId | String

The External identifier of the Work Center in the ERP system.

See Also

Capacity Planning Board

Import Mappings Board

Helper Resources

Allowed Helpers

Allowed Helper Resource Mappings

Setup Time

Cleans</div>
        </section>
      
        <section class="article" id="article-258-setup-code-table-mappings">
          <h3 class="article-title">Setup Code Table Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/setup-code-table-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

Setup Code Table

*TableName | String

Name of the Setup Code Table.

Description | String

Description of the Setup Code Table.

PreviousPrecedence | Boolean

This determines which wildcard match takes precedence when both non-exact match types are found. "The previous Precedence" means that the SetupCode Table value that has the "Wildcard Code" in the "PreviousOpSetupCode" field will be used to calculate the setup.

Wildcard | String

This is a string or a character used to support pattern matching and is used to search within the "Table Values" data of the SetupTable for occurrences within the "PreviousOpSetupCode" and "NextOpSetupCode" fields. 

Setup Code Table Setup Code

*TableName | String

Name of the Setup Code Table.

*PreviousOpSetupCode | String

The Setup Code of the Previous Operation.

*NextOpSetupCode | String

The Setup Code of the Next Operation.

*SetupHrs | Double

The time incurred for Setup, in hours.

*SetupCost | Double

The cost incurred for Setup.

Setup Code Table Assigned Resources

*PlantExternalId | String

Identifier of the Plant to which the Resource is associated.

*DepartmentExternalId | String

Identifier of the Department to which the Resource is associated.

*ResourceExternalId | String

Identifier of the Resource that will be associated with the Setup Code Table.

*TableName | String

Name of the Setup Code Table.

See Also

Setup Time

Import Mappings Board</div>
        </section>
      
        <section class="article" id="article-184-user-mappings">
          <h3 class="article-title">User Mappings</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/user-mappings" target="_blank">Source</a></p>
          <div class="article-content">Property Name | Data Type

Description & accepted values

* = Required

*ExternalId | String

The external identifier of the User. Must be unique per each User object.

*Login | String

The username of the user.

Active | Boolean

Whether the user is active or not. If FALSE, the user will not be able to log in.

Description | String

Additional text for describing the user.

DisplayLanguage | String

Specifies which language to use in the user interface for this user. Accepted values:

English_US

English_GB

Note that English_GB uses the same text as English_US but with en-GB date and number formats.

Chinese_PRC

Dutch

French

German

Italian

Japanese

Polish

Spanish

FirstName | String

The user's first name.

LastName | String

The user's last name.

Notes | String

Comments or special considerations about the user.

Password | String

The user's password.

PlantPermissionGroup | String

The Name of the Plant Permission Group to assign to the user.

RequirePasswordResetAtNextLogin | Boolean

If TRUE, the user will be prompted to reset their password at the next login.

TimeZone | String

By default, this field will be set to the configured time zone of the user's machine. However, a TimeZone value can be imported to forcefully set the user's time zone. Accepted values:

Dateline Standard Time

UTC-11

Samoa Standard Time

Hawaiian Standard Time

Alaskan Standard Time

Pacific Standard Time (Mexico)

Pacific Standard Time

US Mountain Standard Time

Mountain Standard Time (Mexico)

Mountain Standard Time

Central America Standard Time

Central Standard Time

Central Standard Time (Mexico)

Canada Central Standard Time

SA Pacific Standard Time

Eastern Standard Time

US Eastern Standard Time

Venezuela Standard Time

Paraguay Standard Time

Atlantic Standard Time

Central Brazilian Standard Time

SA Western Standard Time

Pacific SA Standard Time

Newfoundland Standard Time

E. South America Standard Time

Argentina Standard Time

SA Eastern Standard Time

Greenland Standard Time

Montevideo Standard Time

UTC-02

Mid-Atlantic Standard Time

Azores Standard Time

Cape Verde Standard Time

Morocco Standard Time

UTC

GMT Standard Time

Greenwich Standard Time

W. Europe Standard Time

Central Europe Standard Time

Romance Standard Time

Central European Standard Time

W. Central Africa Standard Time

Namibia Standard Time

Jordan Standard Time

GTB Standard Time

Middle East Standard Time

Egypt Standard Time

Syria Standard Time

South Africa Standard Time

FLE Standard Time

Israel Standard Time

E. Europe Standard Time

Arabic Standard Time

Arab Standard Time

Russian Standard Time

E. Africa Standard Time

Iran Standard Time

Arabian Standard Time

Azerbaijan Standard Time

Mauritius Standard Time

Georgian Standard Time

Caucasus Standard Time

Afghanistan Standard Time

Ekaterinburg Standard Time

Pakistan Standard Time

West Asia Standard Time

India Standard Time

Sri Lanka Standard Time

Nepal Standard Time

Central Asia Standard Time

Bangladesh Standard Time

N. Central Asia Standard Time

Myanmar Standard Time

SE Asia Standard Time

North Asia Standard Time

China Standard Time

North Asia East Standard Time

Singapore Standard Time

W. Australia Standard Time

Taipei Standard Time

Ulaanbaatar Standard Time

Tokyo Standard Time

Korea Standard Time

Yakutsk Standard Time

Cen. Australia Standard Time

AUS Central Standard Time

E. Australia Standard Time

AUS Eastern Standard Time

West Pacific Standard Time

Tasmania Standard Time

Vladivostok Standard Time

Central Pacific Standard Time

New Zealand Standard Time

UTC+12

Fiji Standard Time

Kamchatka Standard Time

Tonga Standard Time

UserFields | String

A list of user-defined fields. See: User Defined Fields (UDFs).

UserPermissionGroup | String

The Name of the User Permission Group to assign to the user.

See Also

User Management

Import Mappings Board</div>
        </section>
      <h2 id="cat-packages-extensions-custom-package-development" class="category-header">Packages &amp; Extensions &gt; Custom Package Development</h2>
        <section class="article" id="article-237-create-a-custom-software-package">
          <h3 class="article-title">Create a Custom Software Package</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/create-a-custom-software-package" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

A package is a software bundle that can be dynamically loaded into an instance of PlanetTogether to affect the behavior of the software. A package may include software views, interactions, fields, UI components, scheduling logic, and/or server processes.

Each package is its own C# project, and will implement three kinds of PlanetTogether structures: packages, modules, and elements.

Packages are the main object the system loads. There are many package interfaces, and each
represents a general kind of application functionality. Each package project implements one or more package interfaces.

Modules are used to configure the methods of creating Elements.

Elements are the content that get loaded into the program.

Creating a Package

Tip

Find a sample package offered in the PlanetTogether SDK.

Follow these steps to create a new Package Project:

Right-click the PackageProjects folder and select New Project 

Select Windows Forms Class Library (search box can be used to find this option) 

Select .NET 6.0 or .NET 8.0 as the target Framework 

.NET 6.0 should be chosen for PlanetTogether version 12.2.1.61 or lower

.NET 8.0 should be chosen for PlanetTogether version 12.2.1.62 or higher 

When choosing a name, be sure to end the name with Package, e.g., SdkPackage 

Also, set the directory to be the PackageProjects folder within the repository

Right-click on the created project and select Properties to change the output name and namespace 

The output name, which can be chosen under Assembly Name, must start with PT for the system to recognize it, e.g.: PT.SdkPackage 

Copy the value chosen for Assembly Name into the Default Namespace project property 

The Windows Form project template may comes with extra files that are not needed. Delete everything except for the dependencies and a class file. 

Rename the file to PackageInfo.cs. This is a standard file that all PT packages must have. 

Rename the class inside of PackageInfo.cs to match the package name 

Example: SdkPackage 

Add the following to the .csproj file of the C# project:

<Import Project="..\..\ProjectSharedTargets.props" /> 

The props file contains information regarding the various references/dependencies that all PT packages have 

Many of the .dll references can be removed from ProjectSharedTargets.props if the SDK developer deems them to be unnecessary for their package 

The .csproj file will likely have some properties that were auto-generated, but are also in the .props file. These duplicate references should be removed. 

Create a public constructor with no parameters 

Have the class implement IPackage or one of the interfaces that derive from IPackage. 

Create an AssemblyInfo.cs file for the package project

This file has information the system uses to determine whether or not a .dll is a package and whether or not said .dll should be loaded 

The following five fields are necessary to include in AssemblyInfo.cs: 

[assembly: AssemblyTitle("SdkPackage")] 

[assembly: PT.Common.Attributes.Assembly.AssemblyPackageId(4021)] 

[assembly: PT.Common.Attributes.Assembly.RequiresLicense(false)] 

[assembly: PT.Common.Attributes.Assembly.TargetPackageFrameworkVersion("12.2.0")] 

[assembly: PT.Common.Attributes.Assembly.PackageFrameworkVersion("12.2.0")] 

The five fields above should be adjusted to suit the package being created 

AssemblyTitle should match the name of the package being created 

AssemblyPackageId must be unique within the system. Non-SDK PlanetTogether Packages will not have any PackageIds above 4000. 

RequiresLicense should be false for SDK packages 

TargetPackageFrameWorkVersion and PackageFrameworkVersion should match the version of the PT software that is installed on the SDK developer's computer. Example: If the user has software version 12.2.1.21 installed, then these values should be 12.2.1.

Loading a Package

When the system starts, it will look for available packages in a folder on the server (default location is
{Instance's base directory}\System\Data\Packages). There should be a set of compiled .dll files located in this folder or its subfolders, and after the system determines that each .dll implements the necessary
package interfaces (described in the Creating a Package section), it will load the package into memory. If any of the Package content is used by the PlanetTogether Client application, the server will send the content over to the client upon startup.

For more information about loading and unloading packages, see: Software Package Management.

Note

The sample project also has a postbuild event that copies the .dll over to the folder specified in the .props file. This postbuild event can be copied into any package if desired. 

See Also

Software Package Management

PlanetTogether SDK: Getting Started</div>
        </section>
      
        <section class="article" id="article-313-planettogether-sdk-getting-started">
          <h3 class="article-title">PlanetTogether SDK: Getting Started</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/planettogether-sdk-getting-started" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

This guide is meant to assist software developers who are ambitious enough to create their own custom software packages that can be loaded into an instance of PlanetTogether in order to alter default functionality or add new functionality.

Note: 

An SDK license is required to use the SDK client. Please contact PlanetTogether Support to obtain an SDK license or to modify an existing license to allow for SDK development. Please provide your existing serial code if you already have a PlanetTogether license.

Jump to section:

Prerequisites

Configure the Solution

Prerequisites

Install Visual Studio 2022

Download and install Visual Studio from Microsoft: Visual Studio 2022. Use the Individual Components tab to select any .NET 6.0 components.

Install ASP.NET

Install version 6.0 or newer from Microsoft: APS.NET.

Install DevExpress Packages

Run DevExpress's Unified Component Installer to install various DevExpress packages.

Install PlanetTogether Server Software

Follow the Server Software Installation Guide to install software version 12.2.0.25 or newer.

Create a new Instance

Use the Instance Manager to create a new software instance, but ensure the service remains stopped (existing instances can be used, but this means operations done through SDK will effect the instance's scenario data).

Configure the Solution

Download the SDK: PlanetTogetherSDK_12.2.1.zip

Unzip the SDK zip file into a new folder location

Run Visual Studio with administrator permissions

Open the VS solution that is provided in the SDK zip (aps-sdk.sln)

Add the following to the PlanetTogetherClient debug properties:

The Debug Properties dialog can be accessed by clicking the downward triangle on the Start button near the top of the screen next to the startup project name PlanetTogetherClient.

\ServerManagerUri:https://localhost:7980 
\SystemServiceURI:https://localhost:{LocalInstancePort}
\InstanceName:{LocalInstanceName} 
\SoftwareVersion:{VersionNumber} 
\UserName:admin
\Password:
\EndQuickly:
\CreateInstanceOfServer:Internal 
\CertificateThumbprint:{CertificateThumbprint}
\InstanceDataConnectionString:"Server=localhost;Database={DBName};TrustServerCertificate=True;User ID={Username};Password={Password};"

Replace the following with values from the local environment:

{LocalInstancePort}: The System service port used by the SDK instance

{LocalInstanceName}: The Name of the SDK instance

{VersionNumber}: The PlanetTogether software version number used by the SDK instance

{CertificateThumbprint}: The certificate thumbprint of the local PlanetTogether server's SSL certificate (this can be found in the Server Manager Settings of the Instance Manager)

InstanceDataConnectionString: The parameters values in the connection string should be replaced with appropriate SQL server credentials to connect to the PlanetTogether server instance configuration database

An example of a well-formed set of arguments:

\ServerManagerUri:https://localhost:7980 \SystemServiceURI:https://localhost:4051 \InstanceName:SDK \SoftwareVersion:12.2.0.25 \UserName:admin \Password: \EndQuickly: \CreateInstanceOfServer:Internal \CertificateThumbprint:4A0E559FA28DA4428C696812FD624A42AB81C5E2 \InstanceDataConnectionString:"Server=localhost;Database=PTInstances;TrustServerCertificate=True;User ID=InstanceManagerUser;Password=P@$$w0rd;"

Next, locate the path to the Client.zip file of the PlanetTogether Client application and unzip it to a new folder location. The default installation location is:

C:\ProgramData\PlanetTogether\Software\{VersionNumber}\Client.zip

Replace {VersionNumber} with the SDK instance software version

From the Visual Studio project, open the ProjectSharedTargets.props file from the Misc folder. Paste the path to the unzipped/extracted Client application into the ClientDependenciesPath property.

Locate the path to the SDK instance's Packages folder and paste the path into the PackageProjectPath property in the same ProjectSharedTargets.props file. The default location of the instance Packages folder is:

C:\ProgramData\PlanetTogether\Software\{InstanceName} {SoftwareVersion}\System\Data\Packages\

Replace {InstanceName} and {SoftwareVersion} with the name and version of the SDK instance

Locate the PT.BrandingPackage.dll file from the BrandingPackage folder from the SDK instance Packages folder (found in the previous step). Copy this file into the folder of the ClientDependenciesPath property.

The solution should now build and start!

Important

Visual studio must be run with administrator permissions, or enough permissions to be able to start a service and use a port.

Important

The SDK instance service should always remain stopped while using the SDK method to connect to it.

See Also

Create a Custom Software Package

Software Package Management

Instance Manager</div>
        </section>
      <h2 id="cat-partner-resources-sales-enablement" class="category-header">Partner Resources &gt; Sales Enablement</h2>
        <section class="article" id="article-331-partners-resource-hub">
          <h3 class="article-title">Partners Resource Hub</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/partners-resource-hub" target="_blank">Source</a></p>
          <div class="article-content">Getting Started

Partner Onboarding Presentation

A brief history of PlanetTogether

Partner Webinar

PlanetTogether v12.3: Solution Updates & Demo Best Practices session!

{% video_player "embed_player" overrideable=False, type='hsvideo2', hide_playlist=True, viral_sharing=False, embed_button=False, autoplay=False, hidden_controls=False, loop=False, muted=False, full_width=False, width='688', height='387', player_id='198488810092', style='' %}

Demo

{% video_player "embed_player" overrideable=False, type='hsvideo2', hide_playlist=True, viral_sharing=False, embed_button=False, autoplay=False, hidden_controls=False, loop=False, muted=False, full_width=False, width='688', height='387', player_id='198477475920', style='' %}

General Resources

2026 Global List Prices

Knowledge Base

Cloud Data

Discovery EQPA

POC/Evaluation Agreement

Register a Lead

PlanetTogether Payments Options

Marketing and Sales

PlanetTogether Sales Deck

What is PlanetTogether

What is PlanetTogether - Spanish

Competitive Advantages brochure

PlanetTogether Use Cases: Industry Packages

PlanetTogether Feature Listing

FAQ - Frequently Asked Questions 

FAQ - Frequently Asked Questions (Video)

Just the Facts Brochure

Why ERP alone is not the answer

Requirements Gathering Tools

D365/Dynamics Brochure

Optimize Manufacturing Distribution

SAP ByD Brochure

SLA/EULA Clickwrap

SLA/EULA Signature

Keyword Planning - Global

How Advanced Planning and Scheduling Optimizes the CPG Supply Chain

Resilient Chemical Supply Chains3

Building a Resilient CPG Supply Chain with Advanced Planning and Scheduling (Video)

Pharmaceutical Industry

Pharmaceutical Supply Chains: Challenges and Solutions

Life Sciences Supply Chain with APS

Version 12 

V12 General (short version) Product Video: (Highlights key features)

V12 Features (long version)

V12 Web Application Reporting: Your Key to Smarter Decisions and Lower Risk

Version 12 Presentation Announcement

Version 12 Partners Anuncio Spanish

AI 

Bot Library

Case Studies 

Advanced production scheduling drove efficiency and growth for a leading flexible packaging manufacturer

How Digital Planning Elevated Genealogy Operations

Transforming Production Scheduling in the Medical Devices and Industrial Equipment Industry

Transforming Truck Equipment Production with Advanced Scheduling Solutions

A Digital Journey with Integrated Planning for Coffee Producers

Streamlining Production with AI Planning and Digital Supply Chain Solutions

How a Top Communications Network Manufacturer Grew with AI-Powered Planning and Scheduling

How a Whole Food Nutrient Solutions Leader Transformed Production with Advanced Planning

Production Scheduling in Brewing: Achieving 30% Faster Setups with Digital Optimization

Transforming Coffee Production: How Digital Solutions Enhanced Scheduling Efficiency by 50%

Graphic International Packaging's Success with AI Planning and Digital Transformation

Driving Innovation: How One Mobility Manufacturer Embraced Digital Solutions to Optimize Operations

SnakKing - Spanish Case Study

Graphic Packaging - Spanish Case Study

Industry Packages
(Chemical, CPG, Life Sciences and Mobility)

Complete Deck in here - All Industries 

To make your presentations impactful, we’ve tailored slide decks per industry—Chemicals, CPG, Mobility, and more. Use these decks to engage with clients, highlighting industry-specific benefits and solutions that resonate. Whether you’re presenting to leaders in Chemicals or the CPG sector, these slides are designed to showcase how PlanetTogether addresses unique challenges in each field. Review, customize, and use them as you see fit!

Social Media Channels

Youtube Channel

LinkedIn

Facebook

X (formerly Twitter)

Instagram

Newsletter

Web - Newsletter/Mailing list (Request)

Web - LinkedIn Newsletter</div>
        </section>
      
        <section class="article" id="article-186-sample-data-models">
          <h3 class="article-title">Sample Data Models</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/sample-data-models" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether has created and maintains sample data models which enable users to train or demo the software using industry-based models that each offer unique features and functionalities of the software. They can be used without the integration by simply loading the provided scenario file, or fully integrated into the software instance with the provided Excel sheet as the master data source.

Jump to section:

Excel Integration Overview

Sample Data Models

Excel Integration Overview

Each of the provided sample data models can be integrated using our Full Excel Integration Package integration strategy. Some preparation of the SQL environment and the instance is necessary in order to use the provided Excel sheets as the master data source. This is optional though -- each data model can be loaded into any software instance by simply loading the provided scenarios.dat file.

Sample Data Models

[ More information about each model coming soon... Each download includes a "readme.txt" with more information about the model and how to load it. ]

Click the links to download the data model .zip files according to the software version you'll be running them in. It is recommended to upgrade to the latest version though for any training or demos.

Versions 12.2.0 and 12.2.1
Version 12.3.0

Job Shop
Job Shop 12.3.0

Brewery
Brewery 12.3.0

Pharma Tablets
Pharma Tablets 12.3.0

Complex Reactor
Complex Reactor 12.3.0

Consumer Packaged Goods (CPG)
Consumer Packaged Goods (CPG) 12.3.0

Bakery
Bakery 12.3.0

Steel Mill
Steel Mill 12.3.0

See Also

Microsoft Excel Integration

Full Excel Integration Package

Load a Scenario File

Standard Import Database

Standard Publish Database

Server Software Installation Guide

Instance Manager</div>
        </section>
      
        <section class="article" id="article-332-version-12-availability-adoption">
          <h3 class="article-title">Version 12 Availability &amp; Adoption</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/version-12-availability" target="_blank">Source</a></p>
          <div class="article-content">Overview

PlanetTogether has made our new product, Version 12, available for new and existing customers. It is available for on-premises hosted solutions as well as PlanetTogether Cloud Hosted solutions. At initial launch, all features and functionalities will be available to both on-premises hosted and PT Cloud hosted environments, though some of our future development roadmap items may only be offered to PT Cloud hosted customers, so we are encouraging all early adopting customers to also allow us to host their instances.

Early Adopters: Considerations

Version 12 is becoming more stable with each release since the first customers began adopting it in November 2023. One year later, we have a handful of customers actively using it in their production environments and a dozen or so more in the implementation phase. We are confident in the stability of our General Availability releases and encourage customers to upgrade, especially if they are interested in any of the newly developed features and functionality.

While each General Availability software release is meticulously tested with various data models, users may still find ways to use the system and its features in ways that are not thoroughly tested so they may reveal instabilities that our testers did not uncover. Rest assured, however, that PlanetTogether developers are treating all customer-reported issues with utmost urgency in order to ensure the smoothest possible integration and implementation onboarding or adaptation. We strive to release fixes for reported issues within 1-2 weeks or less depending on their severity.

Existing Customer Upgrades: Considerations

While available for existing customers, please note that this is not just an upgrade of an existing Version 11 (or older) installation.

This product is priced only as a SaaS subscription which requires a new license agreement and represents a full migration from one product offering to another.

Any existing Version 11 license may continue to be used by the customer which purchased it until it expires. Perpetual Version 11 licenses will remain active/valid indefinitely.

Migration to the new platform may not always be simple and will require partner involvement throughout the process to train users on the new system, update the integration, reconfigure data points that don't copy over like Workspaces, Optimize Rules and Settings, User Permissions, User and System Settings, etc.

Ideally, this is an opportunity for integrators to charge for services/solutions involvement. We estimate it will take about 10-25% of the effort of an initial implementation project depending on the size and complexity of the data model and integrated software features.

For more detailed information about the migration process and effort, see: Upgrading from Version 11

Version 12 Licensing

This product is priced as a SaaS subscription which requires a new license agreement. All Version 12 project deals should flow through our partner as if it is a new sale with that partner detailing the solution to the customer.

To get started, request a POC license from PlanetTogether via our License Request Form. If interested, feel free to note in the form submission that you'd prefer that we host the POC instance in our cloud environment (or follow up with PlanetTogether Support after the license has been issued to request the same) and we'll work closely with you to configure the data model and integration as needed.

Each partner will be responsible for configuring the POC data model, providing product demonstrations, training, etc. through to the eventual closure of the new sale.

Our Support and Enablement teams are available to answer any questions our partners may have throughout the POC and sales cycle so you can have informed conversations with interested customers.

Once the sale is finalized, PlanetTogether Support and Enablement teams will also make themselves available to the customer for additional support and training, as needed (in addition to giving them access to LMS and Knowledge Base resources).

Pricing information is available in the 2026 Global List Prices asset.

See Also

New Functions & Features

Upgrading from Version 11

Limited Release Functional Limitations

Product Feature Roadmap

LMS Course: Version 12 Introduction</div>
        </section>
      <h2 id="cat-partner-resources-software-licensing" class="category-header">Partner Resources &gt; Software Licensing</h2>
        <section class="article" id="article-277-license-request-form">
          <h3 class="article-title">License Request Form</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/license-request-form" target="_blank">Source</a></p>
          <div class="article-content"></div>
        </section>
      <h2 id="cat-planettogether-employee-resources-software-license" class="category-header">PlanetTogether Employee Resources &gt; Software Licenses</h2>
        <section class="article" id="article-305-software-licensing-overview">
          <h3 class="article-title">Software Licensing Overview</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/software-licensing-overview" target="_blank">Source</a></p>
          <div class="article-content">This document is internal to PlanetTogether employees. Do not share its contents externally.

Key Concept

Software licenses allow users to run instances of PlanetTogether. Various license types may have unique capabilities and those will be covered here at a high level.

License Subscriptions

PlanetTogether offers two primary license models: subscription licenses and perpetual licenses. Each comes with distinct payment structures, access rights, and implications:

Feature
Subscription License
Perpetual License

Payment Structure
Recurring (monthly/annual) payments
One-time, upfront payment

Software Usage/Access
Only while subscription is active, otherwise software enters Read Only mode
Indefinite (unless terminated by other means)

Maintenance Updates & Support
Included for the duration of subscription
12 months from initial purchase; may optionally be renewed annually

Software Upgrades
Always entitled to upgrade to the latest version
Fixed version unless maintenance and support subscription is renewed

Maintenance & Support

Customers who have purchased a perpetual software license may optionally pay for Maintenance and Support. If they choose to subscribe to maintenance and support then they are entitled to the following:

Product support from our internal support teams

Software upgrades to the latest software version of their current product

For Version 11 customers and licenses, they may only upgrade to the latest Version 11 release

Software bug fixes from our development team

When maintenance and support expires, the software license will no longer allow the user to download newer software releases or run instances of the newer software release versions. Otherwise, the expiration of maintenance has no impact on a perpetual software license or if there are rare cases where a subscription license is renewed without maintenance and support -- the license will allow the software to work normally as long as it's running a software version that was released prior to the maintenance expiration date.

System ID Type

The System ID Type determines whether the software license can run services of a single instance at a time, or as many instances as the server/PC will allow.

License Service

The License Service type entitles the license to run services of a single instance at a time. It can be transferred between users and servers as needed with no engagement with PlanetTogether Support as long as it's only ever running a single instance. If more than one instance is running with a software license of this type, then the first instance that was started will work normally but subsequent instances will start in Read Only mode.

CPU ID

The CPU ID type entitles the license to run services of any number of instances simultaneously, but it is limited to functioning only on the server or PC with the assigned System ID. If the license is used on any server or PC whose System ID does not match that of the one configured on the license server, then the instances will start in Read Only mode.

Windows Product ID

The Windows Product ID type is a legacy type that is tied to a server or PC's Windows product ID. It works similarly to the CPU ID type. No new licenses should be issued with this type.</div>
        </section>
      <h2 id="cat-server-administration-installation-and-updates" class="category-header">Server Administration &gt; Installation and Updates</h2>
        <section class="article" id="article-316-deploy-integration-files-to-server">
          <h3 class="article-title">Deploy Integration Files to Server</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/deploy-integration-files-to-server" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Each PlanetTogether instance is required to load a set of integration files. During the server software installation process, the standard PlanetTogether integration files can be downloaded and usually those are fine to use as a starting point for any newly created instance. 

When creating a new instance which will use a particular master data source (ERP, MES, or Excel) for which PlanetTogether offers a standard integration as a starting point, those integration files can be downloaded and deployed to the IntegrationFiles folder of the server software installation location so that they may be selected during new instance creation.

Download Integration Files

Integration files are offered in the knowledge base documentation associated with PlanetTogether's available integrations.

Deploy Integration Files

To deploy the integration file package so that it may be used during software instance creation, extract the downloaded folder of files into the IntegrationFiles folder of the PlanetTogether software installation location, typically:

C:\ProgramData\PlanetTogether\IntegrationFiles

The integration files offered may vary from one integration data set to the next, but typically include:

APSInterfaceSettings.xml: The Import Mappings configuration.

PT_Import.sql: A SQL script which can be used to create the necessary tables and stored procedures for the import database.

PT_Publish.sql: A SQL script which can be used to create a standard publish database.

Integration.json: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

PtDbDataSet.xsd: The PlanetTogether Server Manager uses this file when creating and operating instances which use this integration. It is required to remain in the IntegrationFiles folder of the instance.

When manually extracted correctly, each of the files listed above will reside in their own contained folder in the IntegrationFiles folder. For example:

C:\ProgramData\PlanetTogether\IntegrationFiles\Integration_Name\APSInterfaceSettings.xml
C:\ProgramData\PlanetTogether\IntegrationFiles\Integration_Name\Integration.json
C:\ProgramData\PlanetTogether\IntegrationFiles\Integration_Name\PT_Import.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\Integration_Name\PT_Publish.sql
C:\ProgramData\PlanetTogether\IntegrationFiles\Integration_Name\PtDbDataSet.xsd

See Also

Integrations: Overview</div>
        </section>
      
        <section class="article" id="article-174-installer-downloads">
          <h3 class="article-title">Installer Downloads</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/installer-downloads" target="_blank">Source</a></p>
          <div class="article-content">Download
Details

Version 12 Server Installer

The full Version 12 PlanetTogether Server and Client applications. Use this link when configuring a new server or upgrading an existing one.

Requires Microsoft .NET 8.0.4 or newer Windows Hosting Bundle.

Version 12 Client Installer

The Version 12 PlanetTogether Desktop Client application. Use this link to install only the Desktop Client application which allows users to connect to PlanetTogether Workspaces to create schedules.

Requires Microsoft .NET 6.0.4 or newer Windows Hosting Bundle. Compatible with all Version 12 instance workspace software versions. 

Version 12 Client Installer without .NET validation

The Version 12 PlanetTogether Desktop Client application. 

For use with software instance workspaces running version 12.2.1.62 or newer which have .NET 8 bundled into them and thus do not require users to install .NET as a separate component.

See also:

Server Installation Guide

Desktop Client Installation Guide</div>
        </section>
      
        <section class="article" id="article-207-offline-software-installation-and-manual-deploymen">
          <h3 class="article-title">Offline Software Installation and Manual Deployment</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/offline-software-installation-and-manual-deployment" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Software versions may be installed or deployed offline without using an installer executable. The software packages may be obtained from PlanetTogether's PT Builds SharePoint site, or shared and downloaded by any other means. This guide will step through how to deploy software versions manually.

PlanetTogether Employee SharePoint: PT Builds

PT Builds

Offline Installation

If the software package includes a PlanetTogetherFull12.exe installer and a PTLocalInstallationFiles collection of software package files, then run the PlanetTogetherFull12.exe and opt to Install from local files when prompted rather than entering a license serial code.

Choose which software components you wish to install as if it were the standard web installer (see: Server Installation Guide).

Manual Deployment

If the software package does not contain an installer executable, then make sure that you have downloaded and installed the latest version of Server Manager and Instance Manager, then locate the software version .zip file from the downloaded package and extract its contents into a new folder named the same as the software version in the PlanetTogether server software installation folder. The standard/default installation location is:

C:\ProgramData\PlanetTogether\Software

If done correctly, the software version folder will reside in the PlanetTogether\Software folder in a new folder of its own and will contain 4 folders/files:

C:\ProgramData\PlanetTogether\Software\N1.N2.N3\

Packages

ProgramFiles

UpdateFiles

Client.zip

Once the software version folder is correctly deployed, the new software version will be select-able from the New Instance creation dialog from the Instance Manager.

Example

In this example, the 12.1.4.6.zip file from PT Builds contains 2 files and 1 folder:

PTLocalInstallationFiles

PlanetTogetherClient12.exe

PlanetTogetherFull12.exe

Inside of the PTLocalInstallationFiles\Software folder is a compressed file called 12.1.4.6.zip.

This .zip file contains the actual software components. Cut or copy the .zip file and paste it to the server software installation folder.

Once the .zip file is saved in the Software installation folder, extract its contents to a new folder named that of the software version (12.1.4.6 in this case).

If successful, software version 12.1.4.6 will now be an available option to select when creating a new instance.</div>
        </section>
      
        <section class="article" id="article-253-server-installation-guide">
          <h3 class="article-title">Server Installation Guide</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/server-installation-guide" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Follow this guide to install PlanetTogether Version 12 Server Manager software on a server or test machine. The article linked at the bottom of the page will direct you to the next step of the process to create an Instance.

Don't worry about any existing Version 11 Installation on the same server or test machine – Version 12 will install separately from it so that both versions can run simultaneously.

Jump to section:

Installation Procedure

Software Upgrade Procedure

Instance Manager

Installation Procedure

Step 1: .NET 8.0.x

PlanetTogether APS Version12 requires the .NET 8.0 Core Runtime Hosting Bundle framework package. Begin by downloading and installing it from Microsoft.

ASP.NET Core Runtime 8.0.20 Hosting Bundle

NOTE:

Some servers may require that you restart the server after installing .NET before it can be used by other applications.

Step 2: Configure a SQL Database

All PlanetTogether servers require a connection to a SQL database in order to store server and instance configurations. SQL Server or SQL EXPRESS may be installed on the same server as the PlanetTogether instance host, or any other SQL server may work as long as the PlanetTogether instance host server has access to it.

To install SQL Server, see: Microsoft SQL Server downloads

It's recommended to create a new empty database which will act as the PlanetTogether Instance Configuration database, though any existing database may also be used. The software will require 3 tables to exist in the database, but if they don't exist then it will create them during the installation process. The tables that get created are:

Configuration

InstanceSettings

ServerSettings

The PlanetTogether Server Manager service will read and write to the database. The service will be created during the server software installation process. It may be configured to use Windows authentication (Integrated Security) or SQL authentication. Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

SQL Authentication Mode

If using SQL user authentication rather than Windows Integrated Security, the SQL server must be configured to allow SQL authentication. This can be enabled from the Security tab of the server Properties dialog.

Access server properties from the right-click menu of the object explorer in SSMS:

From the Properties dialog, select Security from the left navigation and select the Server authentication option SQL Server and Windows Authentication mode.

In order to apply this setting change, the SQL Server Windows service must be restarted.

Step 3: PlanetTogether Installer

With the appropriate .NET framework packages installed and a SQL database is prepared, download the PlanetTogether Version 12 installer:

PlanetTogether Version 12 installer

Once complete, run the downloaded PlanetTogetherFull12.exe installer to start the installation wizard. 

NOTE:

If not all .NET packages were installed correctly, a popup may appear to prompt the user to download and install the appropriate .NET package(s). Click Yes to download the missing package(s) from Microsoft. Once installed, re-run the PlanetTogetherFull12.exe installer.

Step 3: Installation Wizard

Server Software Installation

Server software installation using the web installer requires access to the subdomains and the Licensing URLs below.

https://www.planettogether.com

https://download.planettogether.com

https://deployment.planettogether.com

https://ptwebhost.table.core.windows.net

Licensing

The installer and server application requires an active internet connection and access to:

https://licenseserver.planettogether.net:45455

https://licenseserver2.planettogether.net:45455

An active internet connection means continuous internet access while the instance is running. However, intermittent connection losses will not affect licensing if the server has connection issues; consult with a PlanetTogether support to determine any potential licensing problems.

Enter a valid PlanetTogether Version 12 license serial code

Select a software version to install. 

Choose an installation location, if desired (if installing for the first time), then proceed to Install Server Manager.

Choose an existing SSL certificate or generate a new one if necessary. Be sure to choose a certificate with the DNS association "PlanetTogether.local" or one that validates the Server Name where the software is being installed by using the Find Certificate button before you Accept and proceed.

Follow this documented process to generate a certificate if you need to create one.

Enter Instance Database Connection String information

Use the connection string builder in the Build tab of the interface to simplify the connection string configuration process. Alternatively, use the Custom tab to build the connection string manually.

Once the credentials are provided, use the Test button to confirm that the connection to the server and database can be established. If successful, proceed by clicking the Accept button.

Integrated Security

When disabled, authentication to the specified SQL server and database is established via the Username and Password fields of this database connection string builder which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the PlanetTogether Server Manager Windows service which may not exist yet. By default, the Windows user is the standard Local System user (NT AUTHORITY\SYSTEM) which typically does not have access to SQL databases. Unless the Local System NT AUTHORITY\SYSTEM user has been given database access and rights, the initial installation may not fully succeed. After the installation completes (which creates the PlanetTogether Server Manager service), Integrated Security logon credentials can be modified from the Windows Services application via Properties ➡️ Log On ➡️ This account. Once the integrated security user is configured in Windows Services, restart the service so that the newly configured user may populate the Instance Settings database with necessary configurations using the defined Windows user's credentials.

Click the Install Server Files button to include the software version files.

Select the desired integration from the dropdown (PlanetTogether is recommended unless installing for a specific supported ERP system) and click the Install Integration button.

Choose an installation location, if desired (if installing for the first time), then click the Install Client button to include the Client Sign-In Manager application (recommended).

The installation should validate as shown in the image below.

Choose the button to Review Terms and Conditions.

Scroll down to the bottom of the Terms and Conditions dialog. Select the checkbox stating that "I have read and agreed to the terms and conditions." Then choose the Close button.

Click the Install Software button.

The installation will then begin. 

Software Upgrade Procedure

Upgrading to new software versions is very similar to new installations, except certain steps may optionally be skipped. It's typically recommended, however, to download and re-install all components of the installation in order to ensure the Server Manager component is compatible with newer core software versions.

Be sure to review the latest Release Notes to get an idea of what to expect for the upgrade.

The installer should create a backup of the existing Server Manager installation so that the upgrade may be reverted if deemed necessary. It might be a good idea though to still create a manual backup of the Server Manager folder in case the installer fails. The Server Manager files are typically installed at this location:

%ProgramData%\PlanetTogether\Software\ServerManager

Download the latest PlanetTogether Version 12 installer:

PlanetTogether Version 12 installer

Once complete, run the downloaded PlanetTogetherFull12.exe installer to start the installation wizard. 

Installation Wizard

Enter a valid PlanetTogether Version 12 license serial code 

Select a software version to install. 

It's recommended to opt to Re-Install Server Manager when prompted to install the latest version.

Accept the detected existing SSL certificate and proceed.

Accept the detected Instance Database Connection String information and proceed. 

Click the Install Server Files button to include the core software version files.

Select the desired integration from the dropdown (PlanetTogether is recommended unless installing for a specific supported ERP system) and click the Install Integration button.

Choose an installation location for the client sign-in application, if desired (if installing for the first time), then click the Install Client button to include the Client Sign-In Manager application (recommended).

The installation should validate as shown in the image below.

Choose the button to Review Terms and Conditions.

Scroll down to the bottom of the Terms and Conditions dialog. Select the checkbox stating that "I have read and agreed to the terms and conditions." Then choose the Close button.

Click the Install Software button.

The installation will then begin. 

Instance Manager

Version 12 introduces a new web-based application Instance Manager. Once the server software installation completes, use the Instance Manager guide to create an Instance on the server to start setting up a data model.</div>
        </section>
      
        <section class="article" id="article-336-single-sign-on-sso-integration">
          <h3 class="article-title">Single Sign On (SSO) Integration</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/single-sign-on-sso-integration" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether Instances can be configured to allow users to log in with their Single Sign On (SSO) network credentials. Note that SSO is only available to organizations with a "Pro" PlanetTogether license key.

Jump to section:

Collaboration with PlanetTogether Support

Instance Manager Settings

User Management

Sign in to a Workspace

Collaboration with PlanetTogether Support

The PlanetTogether team will need to configure our 3rd party authorization platform (Auth0) to enable the server that hosts the PlanetTogether instance(s) to allowing SSO connections from the customer organization's email domain(s).

To initiate this process, email support@planettogether.com or complete this form to submit a request to the Support team to enable the organization's domains for SSO connections. The Support team will need to know the name of the organization's SSO identity provider and each domain which requires access. Depending on which provider is being used, different instructions/requirements may be sent to complete the process.

Instance Manager Settings

This section only pertains to local or on-premises installations. For PlanetTogether Cloud Hosted instances, the PlanetTogether cloud team will manage this step.

Once the authorization platform configuration is updated, PlanetTogether will deliver an SSL certificate for local server installations. A server administrator will need to make the following changes to the PlanetTogether instance settings via the Instance Manager:

From the Instance Manager, open the instance settings dialog for the instance you wish to enable SSO for. Navigate to the Client Connections tab and check the box to [x] Allow Single Sign-On. Click the Search icon and find and select the appropriate SSO certificate to use for SSO validation. Once configured, click Apply or Save & Close.

After saving the changes, the instance service must be restarted before users may login using SSO.

User Management

Once SSO is configured in the instance, some additional user administration is required before users may login using their SSO credentials. 

Create User Accounts

A user administrator of the Instance Workspace must sign in to the Workspace and create a user account for each SSO user. For each user, the User Name field must match the email address that the individual uses to sign in to their SSO account. If users are expected to use SSO exclusively, then a password can be entered into the Password field which is not meant to be shared with the user. When SSO successfully authenticates, this Password field is not considered; it's only considered when logging in as a local Workspace user, so it can be set to anything random and not shared. Be sure to also toggle OFF the setting Require password reset at next login or else the user will be prompted to set a password, even if they connect via SSO.

For more information about user creation and management, see: User Management.

System Settings

It is recommended to disable the user options in System Settings to Require passwords to be changed periodically so that SSO users won't be prompted to change their password. This feature is meant for non-SSO users.

Sign In to a Workspace

Once their user account is created in the Workspace, a user may launch the PlanetTogether Sign-In Manager application and choose the SSO Login option from the Welcome screen.

A popup dialog will appear for the user to login to their company's SSO account.

Upon successful SSO login, the user may connect to an existing mapped workspace if they've already connected to one before, or they may connect to a server and add new workspaces to their Sign-In application for future connections.

For more information, see: Client Sign-In Manager Application

See Also

Contact Support

Instance Manager

User Management

Client Sign-In Manager Application</div>
        </section>
      
        <section class="article" id="article-228-software-package-management">
          <h3 class="article-title">Software Package Management</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/software-package-management" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Each instance loads many software packages which determine what features and functionality are loaded into the instance workspace for end users. Each Package includes specific features and functionality which can be included or excluded by loading or choosing not to load the particular package.

Custom packages may be developed in order to add or alter UI features, or alter scheduling or other system behaviors. These custom packages can be added to instances to customize the workspace users' experience.

Alternatively, it may be desirable to remove packages if they were not purchased and licensed, or if schedulers and users simply don't use the features contained within the package and they want to reduce clutter in the UI and improve system performance.

Jump to section:

Add a Package

Remove a Package

Add a Package

A package can be added to an installed software build so that it gets installed automatically on all instances created in that particular software version on the server, or it can be added to a specific instance after it's been created.

In either case, a Package Folder must be created which contains a Version folder within it, then the compiled package .dll file contained within the version folder. All PlanetTogether compiled packages are required to start with the prefix "PT." in the file name. The Version folder name must only use numbers and decimals.

Example

MyCustomPackage ➡️ 1.0 ➡️ PT.MyCustomPackage.dll

Once the Package Folder is created, it can be copied to the installed software build location where it will be included in all instances created in the associated software version moving forward (but will not be included in any existing instance that was created before the package was added here):

[INSTALL_LOCATION]\Software\[VERSION]\Packages

Example: C:\ProgramData\PlanetTogether\Software\12.1.3.9\Packages

Or, it can be copied to a specific instance folder where it will only be included for that specific instance:

[INSTALL_LOCATION]\[INSTANCE_NAME] [SOFTWARE_VERSION]\System\Data\Packages

Example: C:\ProgramData\PlanetTogether\TestInstance 12.1.3.9\System\Data\Packages

If adding the package directly to an instance, then the instance service must be restarted before the package is loaded into the workspace for all users.

Remove a Package

Any number of packages may be removed from a specific instance so that the associated functions and features are removed for all users in that specific workspace, or packages can be removed from an installed software build so that any instance created on the server in that software version will not load the package(s).

To remove a package from the software installation folder, remove the entire associated package folder from the installation location:

[INSTALL_LOCATION]\Software\[VERSION]\Packages

Example: C:\ProgramData\PlanetTogether\Software\12.1.3.9\Packages

To remove a package from a specific instance, remove the entire associated package folder from the specific instance folder:

[INSTALL_LOCATION]\[INSTANCE_NAME] [SOFTWARE_VERSION]\System\Data\Packages

Example: C:\ProgramData\PlanetTogether\TestInstance 12.1.3.9\System\Data\Packages</div>
        </section>
      
        <section class="article" id="article-204-uninstall-planettogether">
          <h3 class="article-title">Uninstall PlanetTogether</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/uninstall-planettogether" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Use this as a guide to uninstall the PlanetTogether Server software and/or Client and Client Sign-In Manager applications.

Jump to section:

Uninstall PlanetTogether Server Software

Uninstall PlanetTogether Client Application

Troubleshoot: Manual Uninstallation

Uninstall PlanetTogether Server Software

PlanetTogether can be uninstalled from Windows using an uninstaller application. This will automatically uninstall the PlanetTogether Services and delete the PlanetTogether installation folder, including all instance folders and data.

Backup all data now before proceeding, if desired.

Follow these steps to ensure the cleanest and most seamless uninstallation procedure:

Stop services of all running instances

Open the Instance Manager and ensure that all instance services are stopped.

Run the uninstaller

From Windows Control Panel, navigate to the Uninstall a Program section, or from System Settings navigate to the Apps & features section. Search for PlanetTogether. Select the application from the search result and click Uninstall.

Optionally, the uninstaller.exe may also be found in the installation folder; typically:

C:\ProgramData\PlanetTogether\Software\ServerManager

The uninstaller will prompt the user to confirm y/n to proceed with the uninstallation. Type the letter y to confirm and press enter as prompted to proceed.

Once the uninstallation completes, all Windows Services associated with the Server Manager and all instances are removed. All server software files and all instance data files are also removed. Instance data which was stored in the server manager settings database are also purged from the database tables, though the database itself will remain intact.

Uninstall PlanetTogether Client Application

The client application isn't a formal Windows application that gets installed and embedded into the Windows registry, so removing it is quite simple. All it takes is to remove or delete the entire folder of files where it was installed.

The standard installation folder location is:

%AppData%\PlanetTogether

By simply deleting the PlanetTogether folder and all of its contents, the application is effectively uninstalled.

Troubleshoot: Manual Uninstallation

If the installation process fails for any reason, a user may need to uninstall each component manually. The process includes removing files and folders, as well as deleting associated Windows services.

Software files and folders

Open the Instance Manager and ensure that all instance services are stopped. Close all Windows applications which may be using files from the software installation location. 

In order to prevent additional Windows services deletion efforts later, it's recommended to use the Instance Manager interface to delete as many instances as possible. If one or more instances are returning errors or cannot be deleted though, then proceed with the manual deletion steps.

Open Windows Services and stop the service called PlanetTogether Server Manager if it's currently running.

Navigate to the installation location and delete the entire installation folder.

The standard installation location is:

C:\ProgramData\PlanetTogether

In this case, delete the entire PlanetTogether folder.

Windows Services

Windows Services can be uninstalled by running an elevated command prompt or PowerShell (run as administrator).

The command sc delete "Service Name" will remove the associated service. Collect a list of each Windows service that still exists and execute the sc delete command for each one individually. Each service's name will start with the text PlanetTogether.

Example

sc delete "PlanetTogether Server Manager"</div>
        </section>
      <h2 id="cat-server-administration-licensing" class="category-header">Server Administration &gt; Licensing</h2>
        <section class="article" id="article-266-manually-install-license-key-files">
          <h3 class="article-title">Manually Install License Key Files</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/manually-install-license-key-files" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

If a server running the PlanetTogether server software is unable to download License Key files from the PlanetTogether license server (https://licenseserver.planettogether.net:45455) then the files may be downloaded and installed manually.

Jump to section:

Download License Key Files

Install License Key Files

Download License Key Files

First, retrieve the appropriate license key files by navigating to https://licenses.planettogether.com/ and entering the 12-character license key into the form input. Press Continue when ready.

If the license key is valid, the next screen will contain a link to Download the license key files. Click it to download a .zip file containing the key files.

Install License Key Files

From the Instance Manager, stop the instance service if it's currently running.

Navigate to the license key folder of the instance. From the software installation location, the license key files are located in the INSTANCE_FOLDER\System\Data\Key directory.

Optionally, backup any existing files in the folder by selecting them all then right-clicking any of the selected files and choosing Send to ➡️ Compressed (zipped) folder

Finally, extract contents of zipped key files that were downloaded from the license server. If prompted, opt to overwrite all files of the same name.

The instance service can now be started from the Instance Manager.

Submit a Support Request

If you are still experiencing issues, you will need to submit a support request to PlanetTogether's support team. Please fill out all of the required fields, and be sure to include:

The license key(s) in question

Details of the problem, along with any recent changes to the server or data model

See Also

Instance Manager</div>
        </section>
      <h2 id="cat-server-administration-system-network-requirements" class="category-header">Server Administration &gt; System &amp; Network Requirements</h2>
        <section class="article" id="article-201-it-reference-guide">
          <h3 class="article-title">IT Reference Guide</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/it-reference-guide" target="_blank">Source</a></p>
          <div class="article-content">Table of Contents:

Hardware Selection

Minimum Server Requirements

Minimum User Workstation Requirements

On-Premises Server Management

Server Demands and Benchmarks

Performance with many users

Operating System Compatibility

Cloud Installation

Network Requirements

Server Software Installation

Licensing

Data Sources

Fail-over and Recovery

Load Balancing

Network Latency

Secure Connections

Service & Support

Overview

This guide will help IT personnel determine how their existing hardware and network infrastructure can be used or expanded to support PlanetTogether software. This guide will cover hardware requirements for a server and end user's computers, failover and recovery, and possible impact on users from limited networks. Content provided is for planning and informative purposes only. This guide does not contain step-by-step instructions for implementing or configuring PlanetTogether software features.

References to the phrase 'PlanetTogether' in this document refers to the Advanced Planning and Scheduling software provided by PlanetTogether Inc.

Note that this is not the PlanetTogether installation guide. Installation instructions can be found in the Getting Started section of this knowledge base.

Hardware Selection

The recommended hardware depends on if PlanetTogether will be running on a dedicated machine or sharing resources with other demanding applications. If running PlanetTogether on a dedicated machine, the Workstation recommendation is ideal. The server recommendation will provide better results if the engine runs other applications such as SQL Server, ERP software, or PlanetTogether clients (even on other isolated virtual machines). PlanetTogether may be run on virtual environments with no additional hardware requirements.

Tip:

CPU speed is the most impactful component on PlanetTogether performance. Therefore, faster CPU speeds will result in noticeable speed improvements.

Investment in faster desktop hardware for the client application will be more valuable in user-perceived performance. The only noticeable impact of having a server slower than the client will be when publishing the schedule, as the server will have to catch up before the publish is started. This is especially important in cloud server environments since cloud servers with high-speed processors can be expensive.

Minimum Server Requirements

The minimum recommendation is a CPU with a speed of 2.3 GHz. PlanetTogether must be running on an environment with at least four dedicated CPU cores. In addition, the server should have at least 10 GB of free disk space per instance for transactional data files.

Recommended Server Specifications

Server CPU: Latest Intel Xeon 3.8 GHz or faster

At least 4 cores should be dedicated to the PlanetTogether environment

At least 2 cores should be devoted to each instance of PlanetTogether running concurrently.

OR Workstation CPU: Latest Intel i7, i9, or AMD Ryzen. 4.0 GHz or faster

Workstations can help run PlanetTogether instances if performance is a top priority. Non-server CPUs often have faster speeds and better CPU cooling available. A high-end i9 can complete CPU-limited actions such as optimization at up to 5GHz, resulting in a significant performance gain over a higher core count server CPU.

Memory

Dedicated 32 GB if under 20,000 job operations across all active instances

Dedicated 64 GB if over 20,000 job operations or using End User method 2 (below)

Hard Drive

A Solid State Drive is recommended

Dedicated 50 GB of disk space if under 20,000 job operations across all active instances

Dedicated 100 GB of disk space if over 20,000 job operations across all active instances

Note: 

Actual memory requirements will depend on the data model and the number of instances running and other applications on the same server, such as SQL Server.

Minimum User Workstation Requirements

Minimum: 8 GB RAM, 2 Cores

Recommended: 16 GB RAM, 4 Cores

Scenarios with > 20k operations may require 32 GB RAM or more

Tip:

The client performs substantial calculations in processing a schedule optimization and will utilize parallel processing. Still, faster processors will always be better. More than four cores will allow the client to more quickly display additional data views at the same time but is not required. 

On-Premises Server Management

PlanetTogether Data Volume Performance

PlanetTogether's architecture is designed to provide the fastest possible responsiveness to users in data-intensive applications. All data is loaded into computer memory for processing that is much faster than disk-based operations that are common in traditional databases. The memory-resident data objects also have direct links to each other designed to allow for immediate access to needed information without relying on time-consuming lookups that are also common in many other traditional database systems. The software also utilizes multi-threading extensively. The result is that in most businesses, small or large, PlanetTogether will provide schedule optimizations and adjustments in minutes or even seconds, resulting in a system that is easier and more enjoyable to use.

The most important factors affecting performance are: (1) the number of operations in the schedule, (2) the features in use, and (3) the computer hardware.

Forwarding Proxy Configurations

The PlanetTogether host server must have an open internet connection to the PlanetTogether License Server or else instances won't be able to start properly and will run in Read Only mode. The PlanetTogether Server Manager supports WinHTTP proxy configurations. If the host server is required to forward outbound traffic from installed applications through a proxy server, then the PlanetTogether host server's WinHTTP proxy must be configured to route outbound traffic to the PlanetTogether License Server domains through the forwarding proxy. This can be achieved by executing this command (with the appropriate proxy host name or IP and port) from an elevated command prompt:

netsh winhttp set proxy proxy-server="<proxy>:<port>" bypass-list="licenseserver.planettogether.net;licenseserver2.planettogether.net"

Server Demands and Benchmarks

The hardware used to perform the following tests matched the Workstation Recommended Specifications above (both server and client components were installed on the Workstation).

This first table shows your estimated optimize times based on data volume with minimal constraints. The model contained 100 resources with random need dates and minimal restrictions. The only way to be sure of actual performance and memory requirements is to build a representative model of the particular factory with the required features and substantial data volumes running on the computers to be used. This article provides tips for performance tuning.

Example model data volumes from realistic models

The following diagram shows realistic models containing multiple constraints.

PlanetTogether End Users

There are three common ways to run the PlanetTogether client application. In each case, the client computer needs access to the PlanetTogether server on the standard installation TCP ports. No other internet access is required. Allowing user access to planettogether.com may be helpful for online help and support resources. End users typically run a PlanetTogether sign-in application that automatically retrieves the latest client updates. This allows for upgrades to PlanetTogether without additional configuration or updates to the end user's computer. The sign-in application is not required, and users may also run the complete client application to connect to PlanetTogether.

Users run PlanetTogether client on their computers

Each user's computer should meet the minimum hardware requirements for PlanetTogether and the memory recommendation for workstations

Users run PlanetTogether on the server machine

In this setup, the Server hardware selection is recommended

Each end-user should be using a separate windows user

Users run PlanetTogether in a virtual desktop environment.

Virtual desktops are supported; however, the client sign-in application stores information in the user's roaming AppData folders.

As an alternative, users can run the complete client application to log in. This full client does not require information stored in user profiles but must be installed and accessible for each user.

A note about ports:

PlanetTogether uses TCP connections to communicate between clients, the server, data sources, and configuration programs.

Port 7981 is the secure port to allow clients to connect to a PlanetTogether server. Ports 7980 is used on the PlanetTogether server only, and no access outside of the server is required to it. 

Each instance of PlanetTogether runs on a single port. By default, the ports start in the low 4000's range, though this can be configured in the Instance Settings. Each instance port will need to allow incoming and outgoing communication to connecting clients.

Performance with many users

User scheduling actions are processed synchronously. If one user's activity is being processed, other users' scheduling actions will be queued and processed in sequence. PlanetTogether clients will remain responsive while scheduling actions are being processed. Users may continue to view and analyze certain data, run reports, and queue additional actions while other users' actions are in process, but certain data may not be visible until all queued scheduling actions have completed (for example, job details dialogs, the Materials view, and inventory plots may not be visible since the scheduling actions have a direct impact on the data that gets presented).

Login speed may be impacted if many users attempt to log in to PlanetTogether simultaneously due to network bandwidth limitations. This is because each client will be retrieving the required application data from the server. If clients take too long to log in due to low bandwidth, consider staggering user logins or leave clients connected continuously to avoid the login process.

Operating System Compatibility

PlanetTogether server, clients, and associated programs run on the Microsoft .NET Framework (.NET 6.0 for older PT versions, and .NET 8.0 for software versions newer than 12.2.1.71). It is compatible with all Microsoft Windows operating systems that support this framework. However, a 64-bit operating system is recommended for better performance and future support.

Cloud Installation

Any virtual machine that meets the minimum hardware requirements and runs a compatible operating system is sufficient to handle PlanetTogether. The standard approach to installing PlanetTogether in the cloud is to use a Windows virtual machine on any cloud platform.

Note that there is significant variability in the performance of cloud virtual machines. However, as CPU performance is an essential factor for the speed of PlanetTogether, cloud machines with fast computing performance are recommended.

Network Requirements

PlanetTogether uses TCP connections to communicate between clients, the server, data sources, and configuration programs. The TCP ports used by PlanetTogether are configurable for each of these connections. Typical data volumes include: between 10 MB to 200 MB during startup of the client, 1 MB to 5 MB between the server and the import data source during queries of the data source, and minimal network during regular operation of a client.

Server Software Installation

Server software installation using our web installer requires access to the subdomains and the Licensing URLs below. An offline installer is also available if internet access is unavailable.

https://www.planettogether.com

https://download.planettogether.com

https://deployment.planettogether.com

https://ptwebhost.table.core.windows.net

Licensing

The server application requires an active internet connection and access to:

https://licenseserver.planettogether.net:45455

https://licenseserver2.planettogether.net:45455

An active internet connection means continuous internet access while the instance is running. However, intermittent connection losses will not affect licensing if the server has connection issues; consult with a PlanetTogether engineer to determine any potential licensing problems.

Data Sources

The primary data import and export source for PlanetTogether is Microsoft SQL Server. Version 2014 and newer are supported. A SQL Server installation is most likely required. Integrations to or from other data sources can be achieved through PlanetTogether integrations that use SQL Server as a staging database. Data can also be imported directly from Excel files. For Excel import, a data adapter that matches the Excel version is required.

PlanetTogether can also export to an XML formatted data file for custom export processes.

Integration services and methods vary; please consult with a PlanetTogether engineer to determine the ideal setup for your environment.

Fail-over and Recovery

To assist in server failure, a standby PlanetTogether instance can be prepared for fast recovery.

Backing Up PlanetTogether

PlanetTogether automatically provides transactional data backups. These files reside on the PlanetTogether server.

Transactional files should be backed up to a secondary location for recovery in case of a server failure.

Recovering PlanetTogether

A second PlanetTogether installation is required in case of a server failure. The second instance can be pre-installed with the same configuration as the primary instance. However, it cannot be active while the primary instance is active.

The latest transactional backup can be restored for recovery by taking the newest snapshot (scenario.dat file and/or transaction files) and applying it to the secondary instance. The secondary instance can then be started. Once started, the instance will become active automatically if the primary instance is offline.

Clients connect to the instance by a server connection string. The connection string must be pointed to the new instance, or clients must use a unique connection string to access the secondary instance.

Load Balancing

PlanetTogether does not support load balancing. Only a single server instance is running at once. PlanetTogether is a high-performance, memory-resident program capable of optimizing large amounts of data due to its in-memory objects. To allow for this capability, scheduling operations cannot be distributed among multiple services, and data is not stored in a shared database or store. In most situations, the high performance of PlanetTogether alleviates the need for load balancing to achieve fast performance. If your application has a high volume of scheduled operations (more than 25,000, for example), testing the application in a Proof-of-Concept configuration is recommended.

Network Latency

Most user actions are not affected by latency or slow connections. However, users may experience a slight delay between attempting to act and when the action begins under inferior connections. A slow connection will more heavily impact the following steps:

Client login: Slow connections may result in long login times for end-users. This action is the most heavily impacted. Depending on the connection limits, it may be preferred to stay logged in to the system.

Data refresh: Depending on the amount and frequency of data brought into the system, import actions may take longer for users on a slower connection.

Data export: This action is only affected by the server's network performance. Slow connections will result in longer publish durations.

Unstable connections where network connections may be disrupted have varying effects. The server must have, at a minimum, a few-minute connection each day to the internet for licensing communication. Client's whose connection with the server is disrupted will not be able to perform actions. If the client's connection is disrupted for a long duration (configurable but generally 1-3 minutes), it will be disconnected from the server and need to log into the system again when the network connection is restored.

Secure Connections

PlanetTogether uses SSL (TLS) for all of its connections. PlanetTogether does not handle the transfer or the storage of files, but everything that PlanetTogether transfers is done via TLS connections. All customers are partitioned, and data is segregated.

An SSL certificate is required during server software installation. To manage SSL connections and PlanetTogether's certificate, see the following setup instructions: Server Manager settings.

Enforce TLS 1.2

PlanetTogether server will use TLS 1.2 by default; however, if a Client is running an older version of windows, it may request to use an older version of TLS.

Older versions of TLS can be can restricted by altering the CHANNEL registry keys in windows. Here is a reference: https://docs.microsoft.com/en-us/windows-server/security/tls/tls-registry-settings#tls-dtls-and-ssl-protocol-version-settings

Go to the following section of the registry: HKLM SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols.

You may have to create the TLS 1.0 and TLS 1.1 subkeys. Create them if they don't exist.

Under each of those subkeys, create a Server subkey (if it doesn't already exist).

In each Server subkey, create a DWORD called "Enabled" and set it to 0. This will disable the specific protocols referenced.

HKLM SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols\TLS 1.0\Server Enabled DWORD 0

HKLM SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols\TLS 1.1\Server Enabled DWORD 0

A reboot may be required to take effect. Note that this will disable TLS 1.0 and 1.1 for all applications using CHANNEL on this server.

Service & Support

For ease of service and support during integration, implementation, and support/maintenance activities, VPN remote access to PlanetTogether application server and SQL Server is recommended. This typically is configured the following way:

Windows Remote Desktop access with Administrator privileges

Windows users must have administrator privileges on the server

SQL Server authentication login/user

read/write/owner access to PlanetTogether Staging Databases

Ability to execute stored procedures, update, select, drop, insert, etc.

Read access to linked servers and other data sources containing scheduling data.

See Also

System Performance

SSL Certificate Management

Server Software Installation Guide</div>
        </section>
      
        <section class="article" id="article-282-ssl-certificate-management">
          <h3 class="article-title">SSL Certificate Management</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/ssl-certificate-management" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Any server or test machine that hosts PlanetTogether instances is required to be configured with an SSL certificate for increased security. The most secure option is to procure and install a signed and trusted certificate from an internal or external certificate authority which matches the server name and/or network address that users will use to connect to the PlanetTogether instances. Alternatively, a self-signed certificate can be generated and used which will require each user to configure an SSL thumbprint in their sign-in application in order to establish an SSL handshake with the server before they will be able to connect.

Jump to section:

Generate a Self-Signed Certificate

Server Configuration

Client Connections

Generate a Self-Signed Certificate

Disclaimer:

This method is recommended for test machines only. It's advisable to purchase and install a valid SSL certificate from a trusted Certificate Authority in any production environment to ensure the highest security standards are maintained.

This manual process requires local administrator rights on the device where the certificate is being generated and installed. Generate the certificate by following these steps: 

Begin by opening the Windows PowerShell application as an administrator 

From the PowerShell command prompt, enter the following: 

New-SelfSignedCertificate -DnsName PlanetTogether.local -FriendlyName PlanetTogether -CertStoreLocation cert:\LocalMachine\My

This requires PowerShell v3.0 or higher. If the above command produces an error then try upgrading to the latest compatible version of PowerShell, then try again.

Upon successful execution of the command, the certificate information will be presented. For example:

The new certificate is now ready to be used with the PlanetTogether server configuration.

Server Configuration

During the server software installation, if the appropriate certificate information is not found and automatically populated in the installer at the Select Certificate screen then click the Find Certificate button. If necessary, choose the More choices link from the dialog and find the desired certificate. 

A prompt to install the certificate may appear. Proceed through the installation wizard, ensuring to opt to store the certificate for the Local Machine if prompted:

Let the installer Automatically select the certificate store based on the type of certificate if prompted:

Upon successful installation of the certificate, the information will be displayed in the PlanetTogether installer and software installation may resume.

If PlanetTogether is already installed, a server administrator may associate a certificate with the existing server manager installation. Navigate to the Server Settings page of the Instance Manager (https://localhost:7980/#/server-settings) and click the Choose Certificate button under the Certificate Settings section. Select the desired certificate from the list and click Accept.

After updating the certificate settings, be sure to Save the change from the Server Manager Settings.

For trusted certificates, the certificate name must match the Instances Host Name value from the Server Settings. This value can be edited as needed; it does not need to match the Server Name exactly. Be sure to Save the change from the Server Manager Settings page if any edits are made.

Manual Service Restart

Any changes made to the Server Manager Settings will require you to restart the PlanetTogether Server Manager Windows service before the changes are applied.

Client Connections

The value of the Instances Host Name must be the same value used in the Server field from the Sign-In Manager Application when users connect externally to instance workspaces hosted on the server.

When running the Sign-In Client Application on the server directly, the Server field may optionally be set to "localhost".

If using a trusted certificate then the SSL handshake should be established without any additional configuration.

If using a self-signed certificate then users will be required to enter the Certificate Thumbprint into their client application in order to establish an SSL handshake between the client and server. The thumbprint is exposed in the Server Manager settings screen in the Instance Manager and must be shared with each user so that they can paste it into the Options section of the Sign-In Manager Application.

See Also

Server Installation Guide

Instance Manager

Server Administration

Client Sign-In Manager Application</div>
        </section>
      
        <section class="article" id="article-195-system-performance">
          <h3 class="article-title">System Performance</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/system-performance" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

This article describes which factors contribute to software performance as well as some guidelines to configure the settings in a way to optimize performance for all users.

Jump to section:

Computer Hardware

System Settings

Computer Hardware

Please pay special attention to the processor speed and memory (RAM) requirements, as these tend to have the greatest impact on the performance of the software. In particular, be aware of the following:

Most CPUs now have on-die memory controllers; whether or not that memory controller is a dual channel or triple channel will affect the amount of RAM to get.

For example, a dual-channel controller will typically support 2-stick or 4-stick configurations (2x4, 2x8, 4x2, etc.).

A triple channel controller will typically be in 3-stick or 6-stick configurations (3x2, 3x4, etc.).

If you use more than 3GB of RAM, you will need a 64-bit operating system to take advantage of the memory.

Software Settings

The following features and data have a significant impact on performance:

A high volume of Jobs and Operations 

Custom software packages (extensions)

Overlap by Transfer Quantity (Job Production Overlap)

Max Delay

MRP Optimization

Scheduling on multi-tasking resources

Having many boards and tiles open which require continuous refreshing as the schedule changes

Gantt Labels that are calculation-intensive

The following are ways to improve performance:

Use shorter Optimize release limits

Use the Simplify Gantt Options

Shorten the Planning Horizon or MRP Cutoff Date

Hide columns in grids; or manual refresh of grids 

Reduce the number of undo-sets or the number of actions to store per undo set to slightly speed up the system and undo/redo at the cost of less history

Model single-tasking resources instead of multitasking resources 

In KPI visibility settings, KPIs can be set not to calculate. That will help reduce the processing.

Fewer scenario copies will reduce data Refresh time

Simplify the constraints used as much as possible

If many manual changes are needed, unschedule jobs outside the time period of focus during the manual changes and then add them back to the schedule when done.

Split off independent Resources/Job/Items into a separate Instance

Analyze your need for manual changes and try to automate them

Use computers with faster processors (and more memory and cores if memory is an issue)

See Also

IT Reference Guide

System Settings

User Settings

User Management

Software Package Management</div>
        </section>
      <h2 id="cat-server-administration-workspace-instance-managemen" class="category-header">Server Administration &gt; Workspace Instance Management</h2>
        <section class="article" id="article-226-audit-log">
          <h3 class="article-title">Audit Log</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/audit-log" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Each PlanetTogether instance workspace can be configured to log user activity and errors to an Audit Log database. This can be helpful to understand user actions, behaviors, and trends over time, or to analyze errors of the system that users may experience.

Database Configuration

A server administrator may create or designate an existing SQL database to act as the Audit Log destination for the PlanetTogether instance workspace(s) to log data to. One Audit Log database can be used for multiple instance workspaces, if desired. The data that gets logged is labeled to easily query and filter on specific instance workspaces and software versions, as needed.

No tables, views, or stored procedures need to be created. All that the PlanetTogether instance workspace needs is an existing SQL database destination and it will create tables and the appropriate schema within the configured database as needed. If one does not exist, create a new empty database with any configuration. When the instance workspace inserts records into the database tables, it will insert them into the following tables:

InstanceLogs: This table contains all error log entries from errors encountered by connected clients.

InstanceServiceLogs: This table contains entries of users signing in and out of the instance, and the instance service starting and stopping.

TransmissionLog: This table contains all user transmissions (actions) as they perform actions from their connected client machines.

Instance Workspace Configuration

A server administrator may enable audit logging from the Other tab of the Instance Settings dialog, as shown here:

Enter SQL database information via the Logs Database Settings dialog. 

Build

Server Name: Enter the computer name of the server that hosts the SQL data, or use "(local)" or "localhost" if the SQL data is hosted on the same server as the PlanetTogether instance.

If the SQL server uses SQL Express, then the Server Name will need "SQLEXPRESS" appended to the end. For example: "localhost\SQLEXPRESS"

Database Name: Enter the name of the database.

Integrated Security:

When disabled, authentication to the specified SQL server and database is established via the User Name and Password fields of this database settings dialog which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the System service of the instance. By default, the Windows user is the standard Local System user which typically does not have access to SQL databases. Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

Encrypt: Choose whether to encrypt the connection to the SQL server. This can usually be disabled, but some SQL server security settings may require it to be enabled.

User Name: With Integrated Security disabled, enter the user name of the SQL user with appropriate permissions to access the specified database on the server.

Password: With Integrated Security disabled, enter the password of the SQL user with appropriate permissions to access the specified database on the server.

Custom

Use Custom Connection String: Check this box to allow the instance to use the custom connection string input rather than the connection string builder.

Text input: Enter a custom connection string to use to establish a connection to the data source.

Test: Click the Test button to test the database configuration to ensure a connection can be established successfully. Note that this does not test that the user has all appropriate SQL permissions, only that the connection can be established to the database using the credentials provided.

Note that the Test button may not be active/available when using Integrated Security if the instance System service is not started since SQL authentication is established by the Windows service itself rather than a SQL user.

Audit Log Database Schema

Table: [dbo].[InstanceLogs]

Field Name
Data Type
Description

InstanceName
nvarchar(MAX)
Name of the instance workspace

SoftwareVersion
nvarchar(MAX)
Software version of the instance workspace

TypeName
nvarchar(MAX)
Log entry type

Message
nvarchar(MAX)
Log entry message

StackTrace
nvarchar(MAX)
Log entry stack trace

Source
nvarchar(MAX)
Source of the log entry

InnerExceptionMessage
nvarchar(MAX)
Log entry exception message (for exception type errors)

InnerExceptionStackTrace
nvarchar(MAX)
Log entry exception stack trace (for exception type errors)

LogType
nvarchar(MAX)
Log entry log type category

HeaderMessage
nvarchar(MAX)
Log entry header message

Timestamp
datetime
Log entry timestamp

Table: [dbo].[InstanceServiceLogs]

Field Name
Data Type
Description

InstanceName
nvarchar(MAX)
Name of the instance workspace

SoftwareVersion
nvarchar(MAX)
Software version of the instance workspace

Message
nvarchar(MAX)
Log entry message

EventType
nvarchar(MAX)
Log entry event type category

Reason
nvarchar(MAX)
Log entry reason description

TimeOfEvent
nvarchar(MAX)
Timestamp of the event occurrence

DurationSinceStart
nvarchar(MAX)
Duration since the start of the associated user session

Timestamp
datetime
Log entry timestamp

Table: [dbo].[InstanceServiceLogs]

Field Name
Data Type
Description

InstanceName
nvarchar(MAX)
Name of the instance workspace

InstanceVersion
nvarchar(MAX)
Software version of the instance workspace

ScenarioName
nvarchar(MAX)
Name of the instance workspace scenario where the transmission was sent from

Username
nvarchar(MAX)
Username of the user who triggered the transmission

Description
nvarchar(MAX)
Description of the transmission

ScenarioType
nvarchar(MAX)
Scenario type indicator (Production or not)

TransmissionType
nvarchar(MAX)
Transmission type indicator

Details
nvarchar(MAX)
Details of data modifications impacted by the transmission

Timestamp
datetime
Log entry timestamp

TransmissionNumber
bigint
Sequential transmission number reference

See Also

Instance Manager</div>
        </section>
      
        <section class="article" id="article-326-instance-manager">
          <h3 class="article-title">Instance Manager</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/instance-manager" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The Instance Manager is used to create and configure Instances of the PlanetTogether software application on a server or test machine. An "Instance" in this context is a single copy or iteration of the PlanetTogether software running on a physical or virtual server or computer.

Jump to section:

Accessing the Instance Manager

Dashboard

Instance Management

Instance Actions Menu

Create a New Instance

Copy an Instance

Upgrade an Instance

Instance Settings

Log Viewer

License Manager

Bulk Update Settings

Server Manager Settings

Accessing the Instance Manager

The instance manager can only be accessed from the same server or test machine where the PlanetTogether Server Manager application has been installed. It is accessed in any web browser at the following URL: https://localhost:7980

Users may be prompted that the connection is not private. Depending on the browser used to access the Instance Manager, a slightly different message may appear but it can safely be ignored.

In Chrome, click the Advanced button and choose the link to Proceed to localhost (unsafe). 

The Instance Manager will open. 

These warnings can be avoided in various browsers by enabling an advanced setting:

Chrome

Go to chrome://flags/#unsafely-treat-insecure-origin-as-secure and enable the option to Treat given (insecure) origins as secure origins and enter https://localhost as a domain to treat as secure.

Edge

Go to edge://flags/#unsafely-treat-insecure-origin-as-secure and enable the option to Treat given (insecure) origins as secure origins and enter https://localhost as a domain to treat as secure.

Dashboard

The Dashboard acts as the 'home' page of the Instance Manager. This can always be accessed by clicking the Home button on the left main navigation menu.

The dashboard pie charts show each started, stopped, and erroneous Production and Test instance for a quick overview of the number of active and inactive instances configured on the server. 

The lower half of the dashboard displays an overview of the number of users that are actively connected to each instance.

Instance Management

Access the Instances page where instances can be created, edited, and deleted by clicking the folder icon from the left navigation menu to be taken to https://localhost:7980/#/instances.

Instance Actions Menu

From the list of instances, click once on any instance to select it to reveal a menu of action buttons.

 Stop

Stop the instance service to effectively shut it down. Users will not be able to connect to the instance until it is started again. 

 Start

Start the instance service to allow users to connect to it. 

 Edit

Open the Instance Settings dialog box to configure various aspects of the instance.

 Logs

Open the Log Viewer dialog box to view warning and error messaged logged by the selected instance.

 Copy

Create a copy of the selected instance for the purpose of testing or upgrading to a new software version. See: Copy an Instance

 Upgrade

Upgrade the selected instance to a new software version. See: Upgrade an Instance

 Delete

Delete the selected instance. Once confirmed, the deletion cannot be undone nor can the data be retrieved if it was not backed up somewhere prior to the deletion. 

Create a New Instance

To create a new instance, navigate to the Instances page from the left navigation and click the New Instance button.

A dialog will pop up with configuration options.

Version: Select the desired version from the dropdown of installed versions

Instance Name: Name the Instance to identify it among others 

Integration Code: Select the desired integration from the dropdown of installed integrations (typically "PlanetTogether")

Scenario File: Select New Scenario to start from a blank scenario, or select Browse Disk to use the file picker to choose an existing .dat file to load into the instance

Environment Type: Choose whether the instance will represent a Production, Development, or QA environment. This is for informational purposes only and has no effect on the functionality of the instance.

Workspace Profiles: Select from available standard user Workspace Profiles to pre-load for all new users of the Instance

Serial Code: Enter a valid license serial code

Start Instance Service: Indicate whether or not to start the instance service immediately upon its creation

Once the options are defined, click the Create button. The new instance will be added to the grid list.

Copy an Instance

New instances can be created as copies of existing instances, typically for testing purposes where a server administrator might adjust some of the settings in the instance to see how a change might behave. 

To Copy an existing Instance, navigate to the Instances page and click once on any Instance from the grid to select it, then click the Copy button from the actions toolbar.

Note: It's advisable to Stop the instance service before proceeding to ensure all current data gets copied to the new instance.

A dialog similar to that of the New Instance dialog will appear to configure the new instance. One notable difference is that the Scenario to Load dropdown will now contain a Keep Scenario option which will effectively copy the latest scenario file from the existing instance. Otherwise everything is the same and can be configured independently of the original Instance as needed.

Instances which are created as copies of other instances in this manner will run on their own unique port so they can be run on the same server at the same time (license restrictions permitting).

Upgrade an Instance

New instances can be created by upgrading existing instances, typically used when upgrading a production instance to a more recent software version of PlanetTogether. In fact, the Upgrade option only works if a new software version has already been downloaded and installed, otherwise just use the Copy button for other testing and more flexibility in what can be configured with the newly created instance.

To Upgrade an existing Instance, navigate to the Instances page and click once on any Instance from the grid to select it, then click the Upgrade button from the actions toolbar.

Note: The instance service is required to be stopped before proceeding since the new instance will be created to use the same port as the existing instance that is being upgraded.

A simple Upgrade Instance dialog will appear to select the software version of the new instance. No other options or settings can be configured.

After selecting the software version, click the Upgrade button to proceed to create the new instance.

Instances which are upgraded in this manner will be configured to run on the same port as the instance that was selected to be upgraded so only one can possibly run at a time unless the port assignment is manually changed. If it was previously enabled, the instance setting to [ ] Automatically start service after server reboots will be disabled on the original instance which was upgraded, but will remain enabled on the newly created instance.

Instance Settings

There are many options and settings to configure for a PlanetTogether Instance. No changes are required from the default settings in order to run the instance and have users connect to it, though their ability to utilize all functions and features of the software will be limited without updating some of the options in the Instance Settings dialog. The most important settings are those connecting to the SQL data source to fetch data from an integrated ERP system, and to connect to a SQL Publish database where completed schedules can be published to so that they can be fetched by ERP systems and/or shared with shop floor workers.

Jump to Instance Settings section:

Data Import

Data Publish

Service Configuration

Client Connections

Diagnostics

Audit Log

Backup

Start-Up

Other

To modify the settings of an instance, navigate to the Instances page and double-click on any Instance row from the grid, or click once to select it and click the Edit button from the actions toolbar.

Data Import

Configure Import database connections to link the instance to a master data source.

Data Source

Enter SQL database information via the Import Database Settings dialog to act as the data source for the instance. This database connection is used during the Refresh process to pull data from a SQL database into PlanetTogether.

Program to run before import: An optional input to run a program or batch file from the server prior to each data Refresh/Import operation. This input accepts a fully qualified path to the .exe, .bat, or similar program executable file.

Program arguments: Optional arguments that can be passed to the program which gets run before each data Refresh/Import.

Run SQL before import: When enabled, a SQL command can be executed before each data Refresh/Import operation as defined in the next SQL to run before import input field.

SQL to run before import: A SQL statement that will be executed by the SQL server before each data Refresh/Import operation.

Note that if both a program and a SQL statement are configured to run prior to each data Refresh/Import then the program gets run first, followed by the SQL statement.

Import URLs

Pre-Import URL: The API URL to call prior to each data Refresh/Import.

Post-Import URL: The API URL to call after to each data Refresh/Import.

Data Publish

Configure the Publish database connection to link the instance to a publish destination. Optionally, configure an Analytics database as a secondary publish destination.

Data Export

Enter SQL database information via the Publish Database Settings dialog to act as the data publish destination for the instance. This database connection is used during the Publish to SQL process to push data from within PlanetTogether out to a SQL database.

Export URLs

Pre-Export URL: The API URL to call prior to each data Publish.

Post-Export URL: The API URL to call after to each data Publish.

Analytics Export

The data published to the standard Publish database is the same data that gets published to the Analytics database. Analytics may be published to more or less often depending on how organizations prefer to generate analytical reports from the data.

Enter SQL database information via the Analytics Database Settings dialog to act as the analytics publish destination for the instance. This database connection is used during the Publish Analytics operation where schedules and other data may be published to a separate database that is connected to external analytical tools for additional insights and analysis.

SQL Command to Run after Publish: A SQL statement that will be executed by the SQL server before after each publish to the analytics database.

Analytics URL:

Timeout seconds per table: Define the number of seconds that the Publish process may wait to complete before timing out and moving on to the next table.

Auto-Publish Every: Define a number of hours and/or minutes to automatically publish data to the analytics database. If both values are 0 zero then auto-publish will be disabled. If either value is greater than 0 zero then auto-publish will be enabled.

Database Settings Dialog

There are a handful of Database Settings dialogs throughout the Instance Settings window that are each used for various purposes, but each use the same configuration logic. A connection string builder form is offered for simple connection configurations, or a custom connection string entry is also offered.

Build

Server Name: Enter the computer name of the server that hosts the SQL data, or use "(local)" or "localhost" if the SQL data is hosted on the same server as the PlanetTogether instance.

If the SQL server uses SQL Express, then the Server Name will need "SQLEXPRESS" appended to the end. For example: "localhost\SQLEXPRESS"

Database Name: Enter the name of the database.

Integrated Security:

When disabled, authentication to the specified SQL server and database is established via the User Name and Password fields of this database settings dialog which accept a SQL user's login credentials.

When enabled, authentication to the specified SQL server and database is established via the Windows user credentials that are used to start and run the System service of the instance. By default, the Windows user is the standard Local System user which typically does not have access to SQL databases. Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

Whichever method is chosen, the user whose credentials are used will need to be able to read and write to the database, including the ability to create tables. At minimum, the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

Encrypt: Choose whether to encrypt the connection to the SQL server. This can usually be disabled, but some SQL server security settings may require it to be enabled.

User Name: With Integrated Security disabled, enter the user name of the SQL user with appropriate permissions to access the specified database on the server.

Password: With Integrated Security disabled, enter the password of the SQL user with appropriate permissions to access the specified database on the server.

Custom

Use Custom Connection String: Check this box to allow the instance to use the custom connection string input rather than the connection string builder.

Text input: Enter a custom connection string to use to establish a connection to the data source.

Test: Click the Test button to test the database configuration to ensure a connection can be established successfully. Note that this does not test that the user has all appropriate SQL permissions, only that the connection can be established to the database using the credentials provided.

Note that the Test button may not be active/available when using Integrated Security if the instance System service is not started since SQL authentication is established by the Windows service itself rather than a SQL user.

Service Configuration

This section allows adjustments to the instance "System" Windows service settings.

Server Port

System Service: The port on the server or test machine that is used to run the instance System service.

Logs Status: A flag icon indicator that shows whether or not there are any warning or error messages in the instance service log files. Hover over the icon to view the number of logged messages. A gray icon indicates no messages are logged, while yellow indicates one or more message is logged.

Service Status: A visual indicator of the service status (Active, Started, Stopped, Starting, Stopping).

Actions

Start/Stop: Start or Stop the instance service (Start will be available if the service is currently stopped, while Stop will be available if the service is currently running).

Logs: Open the Logs dialog to view warning and error messages in the instance service log files.

Start Service

Automatically Start Service after Server Reboots: When enabled, the System service of the instance will automatically start when the server or PC reboots, or when the PlanetTogether Server Manager service is started/restarted.

Start Service Timeout (in seconds): Define a number of seconds to wait before attempts to start the instance Service timeout. A value of 0 zero indicates that attempts will never timeout.

Serial Code: The license key serial code used to run the instance.

Environment Type: Choose whether the instance will represent a Production, Development, or QA environment. This is for informational purposes only and has no effect on the functionality of the instance.

System Service Logon As

Used for Integrated Security SQL authentication.

Username: The username of a Windows user to run the System service as. 

Password: The password of the Windows user to run the System service as.

Client Connections

Adjust how users are allowed to connect to the instance.

Credentials

Update Admin Credentials: The instance service must be running for this option to be active. Use this to reset any administrative user's password as a means to either quickly change the password for security reasons, or to gain access where maybe it has been lost.

Add App User: Web App users cannot login or access the Client application like a scheduler can. They can only be used to perform API calls to web-based integration applications. Server administrators may use this button to quickly add App users as needed without having to connect to the instance and create the user(s) from the client application directly.

Timeouts

Client Timeout (in seconds): The number of seconds to wait before users' attempts to connect to the instance time out.

Web API Timeout (in seconds): The number of seconds to wait for API connection requests to this instance to respond back with the requested data.

User Login

Allow Single Sign-On: When enabled, SSO can be used to connect to the instance. Requires a valid SSO certificate to be installed.

Single Sign-On Certificate: Displays the thumbprint of the SSL certificate used to validate SSO connection requests. Use the search icon to browse existing installed certificates and select an appropriate one for SSO validation.

For more information, see: Single Sign-On (SSO) Integration

Diagnostics

Enable additional logging to better track user activity and/or automatically submit errors and usage statistics to the PlanetTogether development team.

Diagnostics Service

Enable Diagnostics: When enab</div>
        </section>
      
        <section class="article" id="article-344-migrating-from-version-11">
          <h3 class="article-title">Migrating from Version 11</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/upgrade-from-version-11" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Generally speaking, all Version 11 data from versions 11.50.20 and newer with the exception of Extensions is compatible with Version 12. This includes scenario data as well as the integration mappings file (APSInterfaceSettings.xml) and import and publish databases. Use this guide to upgrade an instance from Version 11 to be used in Version 12.

Jump to section:

Server and Client .NET Upgrade Requirement

Scenario Compatibility Requirements

Integration Changes

Instance Services

Instance Start-Up Type

Folder Structure

File Names and File Types

Known Exceptions

Unavailable Features

.NET Upgrade Requirement

Version 12 requires an upgrade to .NET from version 4.8 to 6.0.4 (or newer) for both the Server Manager and the Client applications.

For more information, see:

Desktop Client Installation Guide

Server Installation Guide

Scenario Compatibility Requirements

Version 12 only supports scenarios that were created in version 11.52.28 or newer. When attempting to upgrade from an older version, the scenario must first be loaded in an instance running 11.52.28 or newer, then saved from Version 11. All Version 11 and older scenarios can be loaded in 11.52.28 or newer, and it’s just a matter of loading the data in the new version then stopping the instance services so that a new scenarios.dat file is written using the new version’s serialization logic.

Process steps to Serialize a Version 11 Scenario for Version 12

If necessary, use the Version 11 web installer to download and install a compatible version (11.52.28 or newer)

If necessary, create a new Version 11 instance running a compatible version

Locate a scenarios.dat file from the existing non-compatible version, then load it into the compatible Version 11 instance

Start and stop the instance services

The resulting scenarios.dat file that gets written to the INSTANCE_NAME\System\Data\Scenario folder is now compatible to use in a Version 12 instance. See the Instance Start-Up Type section below for additional considerations when loading a Version 12 instance from a scenarios.dat file.

Integration Changes

The Import Mappings configuration file APSInterfaceSettings.xml from the INSTANCE_NAME\IntegrationFiles\ folder of the Version 11 instance can act as a good starting point for the migration to Version 12. The instance folder structure between versions is the same, so the file location will be the same in both versions. Much of the property mappings have not changed, but some modifications may be required in order to allow data refreshes from SQL to function properly. These are each of the integration changes that may need accounted for:

Colors. In Version 11, colors were identified by their RGB values. In Version 12 they are identified by their hexadecimal code values. Color names like "White", "Blue", "Red", etc. are still supported, or colors may be imported as hexadecimal codes with transparency (e.g. '#FFFFFFFF' for White with no transparency, or '#FFDC143C' for Red with no transparency).

Click here to download an Excel sheet that contains ~140 hexadecimal code mappings to color names.

Customers. In Version 11, customers, venders, and suppliers were represented as strings of text associated with jobs, sales orders, CTPs, and purchase orders. In Version 12 we've introduced Customer Objects which can be imported from a SQL data source mapped via the Customer Mappings sections of the Import Mappings Board, and/or managed via the Customers Board. Customers, Vendors, and Suppliers are now associated with their object names and unique IDs.

Associate one or more Customers to each Job via the Customer Connections Mappings section of the Import Mappings Board, or manually choose customers to associate with jobs via the Job Details dialog.

Associate one Customer to each Sales Order via the Sales Order Mappings section of the Import Mappings Board, or manually define a customer from the Sales Order Details tile of the Sales Orders Board.

Associate one Vendor or Supplier via the VendorExternalId property of the Purchases to Stock Mappings section of the Import Mappings Board, or manually define a vendor from the Purchase Orders Board. 

Associate one Customer to each Forecast via the Forecast Mappings section of the Import Mappings Board, or manually define a customer from the Forecast Manager tile of the Inventory Plan Board.

Attributes. In Version 11 and early releases of Version 12, Attributes could be assigned to Resources and Operations. In the latest Version 12 release, Attributes are first imported as stand-alone objects in the data model, then those Attribute objects can be assigned to Operations. Resource Attributes have been deprecated (User Defined Fields can still be assigned to Resources).

Resource Capacity / Capacity Intervals. In the latest Version 12 release, capacity intervals have been redesigned to be more configurable and flexible so that they can be assigned specific types of work. Capacity Interval Presets can be assigned to quickly define the type of work that each interval can do, or each new option may be configured individually.

Resource Connectors. Resource connectors specify a flow relationship between two or more resources. A resource can have connections to one or more downstream resources which can enforce the following scheduling constraints:

Which resource(s) successor operations of the same manufacturing order can be scheduled

Which resource(s) may consume material from a producing tank resource

The number of simultaneous material allocation connections which can be made from a tank resource to consuming operations

Compatibility Codes. Compatibility Code Tables define lists of Operation Compatibility Codes which are either allowed or disallowed to schedule concurrently within a group of resources. Resources may be assigned one or more Compatibility Code Tables, and each table may be assigned to any number of resources.

Frozen Span / Stable Span. The Frozen Span system setting is removed in Version 12 in favor of mapping department-specific frozen spans for each department. The optional Plant Stable Span is still an option.

Setup Efficiency Multipliers. Setup time efficiency multipliers on resources is diverged into two settings: ActivitySetupEfficiencyMultiplier and ChangeoverSetupEfficiencyMultiplier.

Additions, removals, and updates to all imported and published fields can be reviewed in these standard integration change reports:

Import Mappings Comparison Report: 11.52 vs. 12.2.1

Publish Database Comparison Report: 11.52 vs. 12.2.1

Instance Services

Where all Version 11 instances used 5 services (Interface, Extra Services, Client Updater, Scheduling Agent, and System) Version 12 only uses 1 - a System service.

Where Version 11 instance services used ports in the 8000-8999 range, Version 12 instance services use ports in the 4000-4999 range.

Where Version 11 instance services started with the text APS (e.g. "APS Instance Name 11.50.20 Extra Services") Version 12 instance services begin with PlanetTogether.

Instance Start-Up Type

Version 11 would always default to start up by loading the scenarios.dat file in the "Scenario" folder. This file would only ever be updated with a new version when the instance services were stopped gracefully. This caused problems when a power outage or other unexpected server disruption caused the instance services to shut down without giving the system a chance to save the latest data in a new scenarios.dat file. This in turn would force a server administrator to intervene and manually restore the data from a Recordings folder backup.

Version 12 now starts up from the latest Recordings folder by default if a folder of files exists. If no folders of recordings exist then it loads from the Scenario folder. If neither exist then it loads a blank scenario. By loading from Recordings, if ever the instance service or server shut down unexpectedly, no manual intervention is necessary to restore the scenario data to its most current/recent state -- the system will automatically load from the latest recorded scenario file and play back any user actions which may have been performed since the last saved backup.

Considering the new default start-up mode for Version 12 loads data from Recordings, in order to load a Version 11 scenarios.dat file from the Scenario folder of the Version 12 instance, the contents of the Recordings folder will need to be removed if the instance was ever started from a blank or demo scenario.

A new feature of the Version 12 Instance Manager is that administrators may now choose to browse the local disk to pick a scenario file that should be used as a starting point when creating new instances.

Steps to manually load a scenarios.dat file:

Stop the instance service

Copy the scenarios.dat file to the Scenario folder of the Instance installation (typically %ProgramData%\PlanetTogether\INSTANCE_NAME\System\Data\Scenario)

Delete all folders of files inside of the Recordings folder of the instance (typically %ProgramData%\PlanetTogether\INSTANCE_NAME\System\Data\Recordings) 

Start the instance service

Alternatively, the instance can be configured to use the old start-up method by changing the start-up type to Scenario from the instance settings dialog.

Folder Structure

The folder structure of Version 12 instances is the same as Version 11 instances, though Version 12 does reduce the number of files and folders necessary since there are fewer instance services that need files stored.

Where Version 11 instances were stored on the hard drive under a PlanetTogether APS folder, Version 12 instances are stored on the hard drive in a folder named simply PlanetTogether.

File Names and File Types

All file names and types of files within each instance folder are the same in Version 12 as they were in Version 11.

Known Exceptions

Some data from Version 11 scenarios will not be available when you load the scenario file in Version 12. These will need to be reconfigured manually in Version 12 to ensure the same experience between versions. This data includes:

Instance settings

Workspaces (now considered "Workspace Profiles")

Layouts and Alerts

Gantt Labels and Tooltips

Optimization Rules (now considered "Optimize Factors" of "Sequencing Plans")

Permissions, settings, and options

User permissions

User settings

System options

System settings

User Optimize settings (including MPS/MRP Optimize and Compress settings)

Publish options

Operation attributes (see: Attributes)

Unavailable Features

Some Version 11 features are not made available in Version 12. Some may be added back later, while others are not planned to be included.

In-app reports: Reports which were developed using DevExpress Report Designer and offered in Version 11from the application interface are not currently supported. Those include: Job Travelers Report, Production by Product report, Changeover Schedule, and Late Job report. Many similar report tiles exist in Version 12, and with the Version 12 web application, any report can be designed using Microsoft's Power BI with the published schedule data as the data source.

Job Eligibility Dialog: Version 11 had an "Eligibility" dialog in the Jobs View which helped to visualize where a selected job was eligible to schedule. We plan to construct a more useful tool to help to visualize the same data and more in a future release of Version 12.

Sheets View: Version 11 offered a "Sheets" view to allow for very simple Plant, Department, Resource, Template, Item, and Job imports via a spreadsheet view built into the PlanetTogether Client application. Version 12 will soon allow for much more robust/complex imports from an Excel spreadsheet without a SQL component required. This is estimated to be released by the end of Q3 2023.

Shop Views: The Shop Views application that was available for Version 11 is not planned to be released for Version 12. A web-accessible schedule is planned to be developed which will first roll out with read-only capabilities but will eventually allow for shop floor progress reporting.

Visual Factory: Visual Factory mode cycled through various views and screens on a timer. This was handy to run on a shared monitor on the shop floor so that it would cycle through various views of the schedule for various departments. It was not a widely used feature, and we'll be offering a web application view of the schedule for PT Cloud hosted customers, so it was removed.

Scenario History: In V11, the "Scenario History" board listed user interactions over time. The same data can be tracked in SQL in V12 by configuring a Diagnostics Logs database in the Instance Manager.

Standard Gantt flags: Custom Gantt flags can still be created via extensions.

Schedule "Commit": An option to "Commit Schedule" was available in the Scenario dropdown of Version 11 which set a "CommitStart" and "CommitEnd" date on all scheduled activities. These dates could then be used to realize "Commit Drift" when schedule changes occurred that impacted the timing from the originally committed scheduled points in time. Eventually we want to reintroduce this feature along with some ways to visualize commit date drifting via Gantt highlighting and a schedule adherence report and/or KPI.

User Collaboration/Chat: Version 11 offered an in-app chat feature but this has since been removed as most organizations already use their own third party applications for company chat and communication.

Auto-Generate Forecasts: Version 11 supported integration with a 3rd party software called "R" in order to analyze sales orders in the data model and generate forecasts based on trends/patterns it found in the quantities required per item in the sales orders objects. This will not be supported in Version 12 since it requires the 3rd party integration, though auto-forecasting can be developed as a custom package/extension of the core product to suit a customer's specific needs.

Active Directory Authentication: Active Directory authentication has been removed. The only supported authentication methods are Single Sign On and PlanetTogether users (created and maintained manually in each instance).</div>
        </section>
      
        <section class="article" id="article-185-restore-a-scenario-from-a-recording-backup">
          <h3 class="article-title">Restore a Scenario from a Recording Backup</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/restore-instance-from-backup" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether instances are typically configured to save automatic backups of Scenario files in case of emergency. Backup frequency and other settings are configured in the Backup/Diagnostic Recordings section of the Instance Settings screen. Note that the instance Start-Up Mode ("Normal" or "Scenario") will also play a factor in how to restore the instance from a backup file.

Jump to section:

"Scenario" Start-up Type

"Normal" Start-up Type

Process Steps

The strategy to restore an instance back to a recorded point in time may differ depending on the System Start-up Type setting on the instance. If the Start-up Type is Scenario then it's as straightforward as copying an old scenario file from a folder of recordings and pasting it into the appropriate Scenario file to overwrite the existing one. If the Start-up Type is Normal though then recordings files and folders may need to be moved or deleted so that when the system starts up again it will start from an older point in time. It might be easier to temporarily set the Start-Up Type to Scenario during the backup procedure if it's currently set to Normal, then change it back to Normal once the scenario has been successfully restored.

For more information about the Start-Up Type, see: Instance Manager: Instance Settings - Start-Up

"Scenario" Start-Up Type

Stop the instance service in the Instance Manager (beware of any connected users): 

Locate a TIMESTAMP.scenarios.dat file from the instance Recordings folder on the server. The location can vary depending on which disk drive the software has been installed on, but can generally be found under C:\ProgramData\PlanetTogether\[Instance Name]\System\Data\Recordings

Locate the Recordings folder and select the desired file based on the Date modified and the date and time that the desired version may have been saved.

Copy the TIMESTAMP.scenarios.dat file from the Recordings folder and paste it into the Scenario folder (back two folders into Data and then into Scenario).

Rename (to back up) or delete the existing scenarios.dat file, then rename the copied TIMESTAMP.scenarios.dat file to be named scenarios.dat. 

Restart the instance service from the Instance Manager: 

"Normal" Start-Up Type

Stop the instance service in the Instance Manager (beware of any connected users): 

Locate a TIMESTAMP.scenarios.dat file from the instance Recordings folder on the server. The location can vary depending on which disk drive the software has been installed on, but can generally be found under C:\ProgramData\PlanetTogether\[Instance Name]\System\Data\Recordings

Locate the Recordings folder and select the desired file based on the Date modified and the date and time that the desired version may have been saved.

Move or delete all files from the folder which were created after the selected TIMESTAMP.scenarios.dat file so that it becomes the last/most recently created file in the folder.

Restart the instance service from the Instance Manager: 

See Also

Instance Manager

Server Administration</div>
        </section>
      <h2 id="cat-software-releases-roadmap-product-roadmap" class="category-header">Software Releases &amp; Roadmap &gt; Product Roadmap</h2>
        <section class="article" id="article-231-early-access-program">
          <h3 class="article-title">Early Access Program</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/early-access-program" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The PlanetTogether Early Access Program is designed for PlanetTogether customer and partners users interested in experiencing new features and software updates before they are released for general availability. To facilitate this, special Early Access versions of PlanetTogether will be made available to members of the program. Early Access versions will be updated periodically as significant changes are introduced.

Goals:

Provide a preview of new features so partners and users can become familiar with the software before the next official version is released.

Allow for initial feedback on changes.

Early Access Version

An Early Access version is a pre-release of the next version of PlanetTogether that may be in one of several stages of development. As such, it's not recommended for production environments without very careful testing and consideration.

Each version may have a specific purpose related to a new feature or change. Key changes will be identified in the email sent out to members when a new version is available for download. A complete list of changes is made available in the associated software version Release Notes page.

Requirements & Registration

To use the Early Access Version in a local environment, you must be a current PlanetTogether Customer or Partner with a PlanetTogether software license with the appropriate Early Access entitlement.

Any PlanetTogether cloud-hosted customer may request that any of their environments be upgraded to an Early Access version by requesting it from our Cloud Operations Support team.

If you'd like to opt in to receiving an Early Access Program software license and/or release communications, please submit the registration form:

Installation

The Early Access Version can be downloaded and installed from our standard web installer. When selecting the software version in the web installer, check the Include PreRelease Versions checkbox to be able to select from the standard or Early Access versions.

For detailed instructions on the installation process, see: Server Installation Guide.

Provide Feedback

Please submit general feedback, enhancement requests, or bugs via the Product Feedback form. This will go to the PlanetTogether Product team to debug and triage for development as needed.

Need Support?

If you encounter errors or need assistance installing or using an Early Access version, submit requests to PlanetTogether Support via email at support@planettogether.com or by completing the Contact Support webform.</div>
        </section>
      
        <section class="article" id="article-338-product-roadmap">
          <h3 class="article-title">Product Roadmap</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/product-feature-roadmap" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

The PlanetTogether development team tries to adhere to quarterly feature releases while bug fixing and maintenance is still supported on the most recent major feature release version. This article provides insights into the features and functionality currently being developed for the next major release, as well as a rough plan for the next release or two. Plans are subject to change, especially for releases further out than the next one upcoming. The quarterly timelines in this article suggest that each of the features of each version will be released at or near the end of each quarter.

If you'd like access to early release versions, consider signing up for our Early Access Program!

Disclaimer

This document, and any linked product roadmap materials, serve to provide a high-level overview of our anticipated product direction. These are purely informational and should not be incorporated into contracts. PlanetTogether makes no commitment to deliver specific features, code, or functionality based on these documents, and they should not be the sole basis of purchasing decisions. The development, release, and timing of product features or functionality are at PlanetTogether's discretion and subject to change. Please remember these documents reflect our current understanding of future development and are subject to change without notice.

Roadmap

Download the latest 6-quarter outlook (PDF).

See Also

Migrating from Version 11 to Version 12

Early Access Program

Release Notes</div>
        </section>
      
        <section class="article" id="article-351-software-release-announcements-opt-in-out">
          <h3 class="article-title">Software Release Announcements Opt-In/Out</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/software-release-announcements" target="_blank">Source</a></p>
          <div class="article-content">Enter your information and choose whether to Opt in or Opt out of receiving email announcements whenever a new Version 12 General Availability software release is made available.</div>
        </section>
      <h2 id="cat-software-releases-roadmap-release-notes" class="category-header">Software Releases &amp; Roadmap &gt; Release Notes</h2>
        <section class="article" id="article-295-release-notes-12-1-3">
          <h3 class="article-title">Release Notes: 12.1.3</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/release-notes-12.1.3" target="_blank">Source</a></p>
          <div class="article-content">Latest version: 12.1.3.15 | April 4, 2024

Jump to section:

New features & functionality

Improved functionality

Critical bug fixes

Integration changes

Deprecated functionality

General Availability Releases

Release Version
Release Date

12.1.3.5
January 10, 2024

12.1.3.12
February 26, 2024

12.1.3.14
March 14, 2024

12.1.3.15
April 4, 2024

NEW FEATURES & FUNCTIONALITY

Update the ProductRules table in the Publish DataSet | 12.1.3.15

The ProductRules table in the Publish data is updated so that the OperationName field is a primary key field. This enables multiple rules with the same Item and Resource pair with unique Operation Names to publish.

New Plant Tile In Scenario Data Board | 12.1.3.12

Plants and Plant Settings can be configured and maintained manually in a new Plants tile in the Scenario Data board.

New Department Tile In Scenario Data Board | 12.1.3.12

Departments and Department Settings can be configured and maintained manually in a new Departments tile in the Scenario Data board.

Material Allocation enforced by all Optimizations | 12.1.3.5

The MaterialAllocation property which can be set on an operation's Stock Material requirement or at the Inventory record level is now enforced by all Optimization logic. It was previously only used by MRP planning logic.

The MaterialAllocation property value defined at the Inventory level will be used by default, but the property of the same name can be set at the Stock Material Requirement level on an individual operation to override the Inventory level setting.

Material Allocation property values:

Use Oldest First: Materials will be allocated to consuming operations based on the material's earliest eligible produced source, starting with on-hand inventory.

Use Newest First: Materials will be allocated to consuming operations based on the material's newest/most recently produced or purchased eligible source. Existing on-hand inventory will be considered last if no job production or purchase order can supply the requirement.

Not Set: Defaults to the behavior of Use Oldest First.

User-Specific Optimize and Compress Settings Presets | 12.1.3.5

If a user chooses to not use shared optimize and/or compress settings in their user preferences, they will have the option to select from their Optimize or Compress settings preset configurations.

For more information, see: User Preferences.

Customers Board Tiles | 12.1.3.5

Added new Tiles to the Customers board to display charts for:

Sales Orders by Customer

Jobs by Customer 

Job Watch Gantt by Customer

A new Max Delay Gantt block segment is added | 12.1.3.5

A Max Delay Gantt block segment can be enabled along with an optional custom text label to help visualize when Max Delay is violated based on the position of the scheduled operation in relation to its successors or predecessors.

For more information, see: User Settings.

Add button to quickly regenerate system-generated Gantt Layout configurations | 12.1.3.5 

A new Generate Plant Layouts button is added to the Plant View Settings screen which generates or regenerates all Plant and Department Gantt layouts. Use it after adding new plants, departments, or resources.

Add sort buttons to Gantt Layout sorting controls | 12.1.3.5

Buttons to Sort Alphabetically or Sort by Workcenter are added to the Gantt layout configuration settings in the user's Plant View Settings for quick sorting of the selected resources.

Add grid layouts and grid search to all bound grids | 12.1.3.5

Added the PT Toolbar and the Grid Layout Module to all Bound Grids to allow users to create new layouts in all tile and dialog grids. Previously, these were only enabled in each board's main grid tile.

Update grids in Scenario Data to support multi-select actions | 12.1.3.5

Added multi-row deletion for Cells, Capacity Intervals, and Capabilities tiles in the Scenario Data board.

Implement Optimize Progress bar which can be controlled via the Progress Frequency setting | 12.1.3.5

Optimize progress percentage is shown on the progress bar and Progress Frequency setting alters the % precision accordingly.

Visualize move in Activity Move tile | 12.1.3.5

Added Move Result and Move Result Reason columns to activities grid on Activity Move tile.

Add current scenario name to Metric board slides in compare mode | 12.1.3.5

Added current scenario name to Metric slides in the Metrics Board when they compare two or more scenarios' data.

Add Conditional Formatting to Optimize Factors tile grid | 12.1.3.5

Enabled Conditional Formatting for bound grids such as the one used by the Optimize Factors tile.

Schedules Table Add: Instance ID, Instance Name, Instance Version | 12.1.3.5

The Schedules table of the Publish database now includes InstanceId, InstanceName, InstanceVersion fields.

InstanceId: A system-generated ID associated with the instance/workspace whose data was published.

InstanceName: The name of the instance/workspace whose data was published.

InstanceVersion: The software version of the instance/workspace whose data was published.

New Resource Properties | 12.1.3.5

Added Setup Code Table Name and Attribute Code Table Name columns to the Resources grid for visibility. 

Add permissions group visibility on the User Preferences dialog | 12.1.3.5

A user's current assigned permission group name is made visible in the User Preferences dialog.

Rename "AvailableDate" field in Materials Grid to "Latest Source Date" | 12.1.3.5

AvailableDateTime field on an operation's Material Requirement has been renamed to LatestSourceDateTime. The date represents the latest date and time of all material sources supplying the requirement.

The field can be imported for Buy-Direct materials. An integration change will be required for Import. 

Enhance Lot Eligibility to support Job Products LimitMatlSrcToEligibleLots | 12.1.3.5

Two new fields on an operation's Product allow the use of pegged lot remainder:

UseLimistMatlSrcToElibleLots should be enabled to override the default behavior 

LimitMatlSrcToEligibleLots can be set to false to change the default behavior of true. 

This will set the same named field on the Lot when produced by an activity. If false, when a pegged lot has been sourced for all pegged materials and demands, any remaining material will become available to non-pegged materials and demands. 

Add new Capacity Tools tile | 12.1.3.5

Moved the Capacity Tools from below the Gantt into a new Tile on the Gantt board.

Enable Gantt Printing / Exporting

The Resource Gantt and the Job Watch Gantt can now be printed using two new buttons from the Gantt toolbar.

Add back "Earliest Job Need Date" optimize factor | 12.1.3.5

Added Job Need Date sequencing factor.

Enhance MRP to handle demand pegging when the job is split | 12.1.3.5

MRP will now split the total demand for a created job among all of it's MOs. This will now more accurately calculate original demands for each MO.

IMPROVED

Automated Job Notes Should Reset After Optimizing | 12.1.3.15

Job Notes are no longer populated with the text "FailedToSchedule" if a job fails to schedule. This information is available in the Job Analysis as well as the Job Scheduled Status properties already.

General Performance and Stability Improvements | 12.1.3.12

A few performance-related issues were resolved related to loading data on initial sign-in; the client interface freezing when many boards and tiles were open at the same time; slow load times of certain boards in larger data models (Activities, Inventory Plan, Materials);

"Filter Gantt Selection" in Activities grids can be toggled independently | 12.1.3.12

The option to Filter Gantt Selection in the Activities board Activity Scheduling (Primary) and Activity Scheduling (Secondary) tiles can be toggled independently of one another.

Sort Activity Scheduling resource list in Resource Filter alphabetically | 12.1.3.12

Departments and Resources in the Resource Filter of the Activity Scheduling tile grids are now sorted alphabetically.

Metrics UI Performance update | 12.1.3.5

Resolved an issue where search for a metric layout control was not found causing issues when removing a metric to be still drawn and also caused a new metric control to be added on data change. Also, made further enhancement to minimize the number of instances a metric group's contents are refreshed on data change.

Investigate drag/drop performance | 12.1.3.5

Greatly improved UI performance when performing manual schedule move adjustments in the Gantt and Activity Scheduling grids.

Gantt Grid Enhancements & Simplification | 12.1.3.5

Inactive resource row has a distinctive background color on the Gantt

The Gantt grid is updated to have the following column changes:

New Plant name column

Removed Sort Column

Disabled Sorting on the Gantt Grid columns

Renamed ‘Message’ column to Eligibility

Renamed Resources column to Resource

Expose Plant Configuration resource sorting by default | 12.1.3.5

Advanced Sorting toggle is visible by default so that Resource sorting is displayed in Plant Configuration User Settings without needing to enable Show Advanced User Settings in a user's preferences.

Auto-add resources, only add the resource if the parent department/plant is enabled | 12.1.3.5

Gantt layouts with the 'Auto Add Resources' flag enabled will only add new resources if the parent department/plant is selected/enabled.

Hide "Advance All Scenarios" and "Refresh All Scenarios" from isolated scenarios | 12.1.3.5

Scenarios which are isolated from Clock Advance only have an option to Advance Active Scenario from the main toolbar. Scenarios which are isolated from Import only have an option to Refresh Active Scenario from the main toolbar.

Update User Mappings | 12.1.3.5

Administrator, InitialAccessLevel and InitialWorkspace have been removed from User Mappings. UserPermissionGroup and PlantPermissionGroup have been added as string Mappings to import a User Permission Group and/or a Plant Permission Group by name. 

Reduce white space in Activity Scheduling Resource Filter | 12.1.3.5

In order to save space, Plant node is removed from Resource Filter tree in Activity Scheduling tiles if there is only one Plant in the data model.

Bulk edit tile type-ahead search shows incomplete and evolving property name results | 12.1.3.5

Bulk edit tile type-ahead search accurately matches and displays all possible results.

Allow editing of "Image" property in Resources grid | 12.1.3.5

The Image property can be edited in Grid Edit mode from the Capacity Planning board's main Resources grid.

Format numerical grid property values with thousands separators | 12.1.3.5

All numeric properties in all grids are displayed with thousands separators every 3rd digit (commas in English, or decimals or spaces in other languages as appropriate).

CRITICAL BUG FIXES

Simple Sequencing Plans produce inaccurate Optimization results | 12.1.3.14

If a Sequencing Plan is used during optimization and its only weighted factors are "Constant" factors, then the system was previously defaulting to an incorrect scoring mechanism which resulted in inaccurate schedule optimization results. This is now fixed so that even simple Sequencing Plans use the correct scoring mechanism.

Daylight Savings Time causes many adverse side effects | 12.1.3.14

As daylight savings time rolled out across much of the world, it was discovered that the new Time Zone functionality in PlanetTogether was overly aggressively compensating for the time adjustment which resulted in manual scheduling moving jobs +1 hour; manual edits to jobs increasing the job need date by +1 hour; certain date time UI components displaying dates +1 hour later than the actual objects were configured with; etc. This build fixes all of the known issues that users encountered and reported related to daylight savings time.

Client became unresponsive when too many boards and tiles were opened | 12.1.3.12

Resolved an issue which was prompting the system to open thousands of error message dialogs in the user's session which would freeze the interface for several hours before becoming responsive again.

Poor performance when various boards are open (Inventory Plan, Materials, Activities) | 12.1.3.12

Fixed an issue with an object property updating incorrectly which negatively impacted performance. Created a new helper object to improve grid loading performance.

Job "Late" property boolean value is reversed | 12.1.3.12

Fixed an issue where the Job Late property was returning the value in reverse (Late=False if the job was actually scheduled to finish late).

Instance Unresponsive on User Logoff | 12.1.3.12

Fixed an issue where instance services may become unresponsive to Stop and Start signals occasionally after users logged off, so the services had to be forcibly killed from the Windows Task Manager.

INTEGRATION CHANGES

Import Mappings

Capacity Interval Resource Mappings: DeptExternalId is updated to DepartmentExternalId for consistency.

Job Mappings: The TravelerReport property is removed

User Mappings:

Administrator, InitialAccessLevel and InitialWorkspace are removed

UserPermissionGroup and PlantPermissionGroup are added as string properties

Cell Mappings: ConWipMoLimit and EnforceConWipMoLimit are removed.

Resource Mappings: Role property is removed.

Forecast Mappings: The Customer property is updated to CustomerExternalId. Its value is validated against the External ID of Customer objects that are imported or which exist in the data model.

Material Mappings: LatestSourceDateTime can be imported for Buy-Direct materials.

Product Mappings: Two new fields are added to allow the use of pegged lot remainder:

UseLimistMatlSrcToElibleLots should be enabled to override the default behavior 

LimitMatlSrcToEligibleLots can be set to false to change the default behavior of true.

Publish Data

InstanceId (varchar, primary key), InstanceName, and InstanceVersion are added to the published Schedules table.

InstanceId (varchar, primary key) is added to all publish database tables

DEPRECATIONS

Gantt Grid Functionality & Resource "Sort" Property | 12.1.3.5

The Gantt grid Sort column and sorting functionality on grid columns are removed. Resources can be custom-sorted via Gantt layout configurations in the user's Plant View Settings.

Plant, Department, and Resource Sort properties are removed from the UI and associated object import mappings.

Remove Cell and Capability Attributes | 12.1.3.5

Removed Attributes tab from the Edit Cell and Edit Capability popup dialogs since attributes are not supported on these objects. User Defined Fields are still supported.

Remove Analytics Board | 12.1.3.5

Analytics board is removed from the UI. A new web-accessible analytics view is coming soon to replace it.

Feedback & Support

We strive to make scheduling software that supports modelling of as many manufacturing processes as possible. We encourage all users to please send us your feedback if there is something we can do better -- a new feature; a bug fix; a UI enhancement; -- you name it and we'll do our best to accommodate.

To request assistance to upgrade an environment, please contact support and we'd be happy to help!</div>
        </section>
      
        <section class="article" id="article-177-release-notes-12-1-4">
          <h3 class="article-title">Release Notes: 12.1.4</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/release-notes-12.1.4" target="_blank">Source</a></p>
          <div class="article-content">Latest version: 12.1.4.24

Jump to section:

New features & functionality

Improved functionality

Server Manager updates

Critical bug fixes

Integration changes

Deprecated functionality

General Availability Releases

Release Version
Release Date

12.1.4.17
June 24, 2024

12.1.4.20
July 10, 2024

12.1.4.21
August 8, 2024

12.1.4.22
August 28, 2024

12.1.4.24
September 23, 2024

NEW FEATURES & FUNCTIONALITY

Enhanced Summary Metrics: Data summations, averages, minimums, and maximums | 12.1.4.17

New Metrics may now be configured to track quantity summations, averages, minimums, or maximums of any numerical property on any board grid which supports Metrics. Consider these possible use cases:

Track a sum quantity of production of a specific item

Track a sum quantity of Profit or Revenue from certain jobs (either from a particular customer, or during a particular time frame)

With visibility of these data in the Metrics board, they may be easily compared between scenarios to better track the impact of schedule and/or data changes.

For more information, see: Layouts, Metrics, and Targets.

Compress for a specific timeframe and resource(s) | 12.1.4.17

The Compress functionality is enhanced to allow users to define the specific time to start and end compressing the schedule, and to allow users to select which specific resources should be impacted by the Compress action.

For more information, see: Compress the Schedule.

Gantt Printing Options | 12.1.4.17

A new Print Gantt button is added to the Gantt toolbar.

The button opens a dialog with options to either print the Gantt on a connected printer, or export the Gantt to PDF format. The dialog gives users the option to select one custom Gantt layout to print, or offers a Print All button to print or export two or more select Gantt layouts (or all layouts, if desired).

For more information, see: Gantt Board: Toolbar.

Scenario Permissions tile added to Users Board | 12.1.4.17

A new Scenario Permissions tile is added to the Users Board to allow for administrators to view and manage all scenario permissions for all scenarios which exist in the Workspace in one place.

For more information, see: User Management.

Transfer Orders tile added to Inventory Plan Board | 12.1.4.17

A new Transfer Orders tile is added to the Inventory Plan board to allow users to manage Transfer Orders and give better visibility into Transfer Order details.

For more information, see: Inventory Plan Board.

Job Eligibility Properties added to Jobs Board Grid | 12.1.4.17

A new Eligibility property is added to the Jobs board grid. It offers insights into reasons why a job may not be eligible to schedule.

"Assigned Resources" button added to Capabilities tile | 12.1.4.17

A new Assigned Resources button is added to the Capabilities tile of the Scenario Data board to help with quickly assigning capabilities to resources. This is mostly used for demonstration and experimentation purposes, as this data is typically imported rather than manually maintained.

Include "Last Publish Date" in the User Interface | 12.1.4.17

The date and time of the last successful publish of the currently active scenario is made visible in the Publish dropdown.

Load Interface log errors from server when user logs in | 12.1.4.17

When users first login to the Workspace, their Message Log will now display "Interface" log errors that exist on the server via a new tab labelled Interface From Server. The Interface log documents data-related errors that occur during a data refresh. This enhancement can help give visibility into whether or not the last data refresh was entirely successful, regardless if the user was connected to the Workspace at the time of the last data refresh or not.

Each time the Message Log dialog is closed and re-opened, or when the Refresh All button is clicked, the data from the server is fetched again and displayed in the dialog.

By default, the Interface From Server data is sourced from the server's Interface.log file, located on the server here:

PlanetTogether\_INSTANCE_\System\Data\Alerts

If the instance is configured to write logs to the Audit Log database, then the Message Log dialog will fetch the Interface log data from the Audit Log database rather than the Interface.log file.

Insert Jobs Scheduling Feature | 12.1.4.17

A new function of the CoPilot feature is added to assist with inserting one or more jobs into the existing schedule without impacting the current order of scheduled jobs/operations. Any job which is not currently scheduled is eligible to be scheduled via one of the Insert Jobs functions. To use one of the functions, select one or more unscheduled jobs from the Jobs board grid, then right-click one of the selected rows or use the Job Actions tile and choose one of the Insert Jobs functions:

Insert Jobs Individually: Each of the selected jobs will be inserted into the existing schedule according to the configured System Settings.

Insert Jobs as a group: The system will attempt to insert all of the selected jobs into the existing schedule. If any one of them is unable to be scheduled, then all of them will fail to schedule.

In either case, the resulting schedule will be available in a new scenario copy. If the schedule result is desirable, the new scenario copy can be updated to become the new production scenario.

For more information, see: CoPilot Settings and Job Actions Tile.

Operation Transfer and Overlap Enhancement | 12.1.4.17

Transfer between operations can now be configured using different transfer start and end usages. For example, Transfer can be enforced between predecessor run end and the successor run start. This allows the successor operation to overlap some of the transfer based on the new usage settings TransferStart and TransferEnd.

This is compatible with Operation Overlap, so the successor can also overlap the predecessor while still enforcing the transfer span.

See also: 

Alternate Paths

Alternate Path & Node Mappings

Additional Experimental sequencing plan mappings | 12.1.4.17

Previously, each resource was allowed to be configured with one Normal and one Experimental sequencing plan to determine optimization scoring. This enhancement adds three additional Experimental settings so that each resource may now be mapped to one Normal and up to 4 Experimental sequencing plans.

The additional sequencing plan mappings may also be imported via Resource Mappings.

IMPROVED

Sign-in to server should respect max number of failed login attempts settings | 12.1.4.22

Previously, the Sign-in to server section of the sign-in application allowed unlimited login attempts. This enhancement counts each failed login attempt from the Sign-in to a server screen against each of the server's online instance's Maximum number of failed login attempts setting.

Client Application Performance Enhancements | 12.1.4.17

Various performance enhancements have been made to the client application:

The Import Mappings board has been reworked in order to improve the amount of internal memory required to view it.

The Metrics board has been reworked and now refreshes much faster as changes are made to the schedule.

Internal memory management has been improved when loading the Job Details dialog to ensure that making many manual edits to many jobs won't slow down the application.

Refactor Gantt Layouts | 12.1.4.17

Gantt layout configuration logic has been reworked to better support multiple scenarios in the same Workspace.

Automatic Actions: Improved scheduling flexibility | 12.1.4.17

Scheduling of Automatic Actions is improved to be much more customizable using CRON expressions. These can be made to be very specific to run actions on a more predictable and practical cadence. 

CRON expression syntax looks a bit odd to the untrained eye. It's recommended to use this CRON expression generator to assist with curating the Automatic Actions schedule:

CRON Expression Generator - Quartz

For more information, see: System Settings: Automatic Actions.

Move Job Watch to a new tile in the Gantt | 12.1.4.17

The Job Watch Gantt in the Gantt board is a bit more agile now as it has been decoupled from the Resources Gantt and converted to a separate tile. Add jobs to the Job Watch Gantt by right-clicking them in the Gantt and choosing Analysis ➡️ Watch Job on any scheduled activity block.

Preserve scroll location and row selections when grids refresh | 12.1.4.17

As multiple users interact in the same Workspace, one user may perform some action which causes other user's visible grids to refresh. This enhancement ensures that after the grid refreshes that the scroll location hasn't jumped around from where the user was previously viewing.

Prevent User From Deleting Last "Production" Scenario | 12.1.4.17

Users can no longer delete the last scenario from the workspace which is flagged as a "Production" scenario.

Make activity move selections visible in Activity Move tile | 12.1.4.17

Activities which are selected from the Activity Scheduling grid to be moved via the Activity Move tile are also selected and highlighted in the Activity Move tile for better visibility when the two grids may not be docked side by side.

Add Confirm button to Activity move | 12.1.4.17

A Confirm Resource and Time button is added to the Activity Move tile of the Activities board. The button displays a dialog which indicates whether the selected activities can be moved to the specified time or point in the schedule. This gives the user more confidence that the manual move will be successful, or provides them with a warning if one or more of the selected activities cannot be moved.

Resource Utilization Chart design update | 12.1.4.17

The Resource Utilization Chart in the Capacity Planning and Gantt boards is made a bit more flexible by separating the usage metric selection from additional categorization and chart grouping options.

Enable Product Rules to support User Defined Fields | 12.1.4.17

User Defined Fields (UDFs) can be imported for Product Rules. UDFs are made visible in the Product Rules tile grid of the Scenario Data board.

"Create Job" tile updates | 12.1.4.17

The Create Job tile is updated on both the Jobs board and the Routing Templates board. The tile text makes it more clear that the tile can be used to create copies of existing jobs, or create jobs from routing templates. A new button is also added to create new blank jobs or templates from scratch.

Add back removed KPIs | 12.1.4.17

Two KPIs which were previously removed from the KPIs board are added back:

Late Jobs

Total Setup Calendar Hours

Resize notifications to be larger and consistent | 12.1.4.17

Notification slides which appear across the bottom of the client interface are made a bit wider and formatted more consistently.

New settings to delay tooltip window refresh | 12.1.4.17

The Gantt tooltip window is enhanced by some new settings which allow users to customize how quickly the tooltip window refreshes as the user moves their mouse around the Gantt.

Remove extra space from the start of Gantt Label text | 12.1.4.17

Custom Gantt label text was previously starting each new line with a blank space. This extra space is now removed.

Scheduling enhancement to consider Cleanout intervals on Helper Resources | 12.1.4.17

Scheduling activities which require a helper resource is enhanced to consider cases when the helper resource has a Cleanout interval where the primary resource does not. Previously, the software was erroneously allowing operations to schedule on helper resources where there was a cleanout interval. Now the scheduling logic treats the cleanout interval appropriately and ensures that helper capacity is not available during the scheduled cleanout time.

Add back "POSSIBLE" supply activity links in Gantt | 12.1.4.17

When Gantt scheduling hints are enabled in the Gantt, a new "Possible" supply link may be drawn between two scheduled operations if an operation producing some material is scheduled to start later than a scheduled operation which has that material set as a non-constraining material requirement. The downstream supplying operation becomes a possible source of material for the earlier scheduled operation that otherwise has no known source of the required material.

This appears as a dark yellow/brown colored link with the arrow drawn to point from the downstream operation to the upstream one:

Activity progress AutoComplete enhancements | 12.1.4.17

Auto-reported activity progress via clock advance will now update production statuses and will accurately report setup time.

Auto-reported start date will now be the scheduled start before a clock advance instead of the clock date for better accuracy.

Auto-reported finish date will be set to the scheduled finish date from before the clock advance.

Add Gantt Background indicators for "Manual schedule resources" | 12.1.4.17

A blue bar will be drawn across the top of the Gantt row of any resource which is flagged to only allow for manual drag/drop scheduling.

User Permissions: Update, verify, enforce | 12.1.4.17

User permissions were revisited to ensure that each permission does what it is meant to do to grant or deny users access to various interfaces or actions.

Restore Desync handling | 12.1.4.17

Client desynchronization handling has been restored to help users restart the client application in the event that their local session has become desynchronized with the server.

Include more data points in Audit Log database | 12.1.4.17

Breaking Change

Servers and instances which utilize the Audit Log Database from an earlier software version will need to delete the InstanceLogs and InstanceServiceLogs tables for these changes to take effect. The tables will be re-created automatically with the updated schema when the instance starts up again.

The InstanceLogs and InstanceServiceLogs tables now accurately capture error data, and also provide an always-populated TIMESTAMP column to track the time of logging.

SERVER MANAGER UPDATES

Install PlanetTogether Server software on non-English systems | 12.1.4.17

The PlanetTogether Server software is now compatible to be installed on non-English servers/PCs.

Save/Load Instance Configuration Data from an Instance Database | 12.1.4.17

A database is now required for standard software installation and instance creation. Instance settings are to be stored in a SQL database rather than stored in the PlanetTogether_ServerSettings.json file on the server. For this release, the settings will be backed up to the JSON file on the server, but the Instance Manager and Server Manager will read and write to the configured database.

Instance configuration data may be stored in any SQL database. It's recommended to create a new database specifically for storing instance settings, but a dedicated database is not necessarily required. No database tables need to exist; the necessary tables will be created by the installer application during the installation process.

The software installer will now require the user to provide database connection information. If using Integrated Security, then the application will use the Windows User credentials that are configured to run the PlanetTogether Server Manager service to read from and write to the SQL database. If the service is configured to run using the default Local System user, then in SQL the NT AUTHORITY\SYSTEM user will need read/write access to the specified database. Otherwise, it might be more practical to configure a SQL user with read/write access to the database.

Enhanced "admin" user password reset dialog | 12.1.4.17

An Admin User dropdown selection is added to the Client Connections tab of the instance settings. This allows a server administrator to select which administrative user's password to reset. The list of users is populated with all user accounts in the current Workspace scenario who are part of an administrative group (one which allows for administrating users).

Changing Analytics Post-Publish command does not prompt the need for instance restart | 12.1.4.17

Modifying the SQL Command to RUN after Publish setting from the Analytics tab of the Instance Settings dialog will now prompt the user to restart the instance service to apply the change.

Log client/user errors on the server | 12.1.4.17

Errors which are experienced by client application users will now be logged on the PlanetTogether server. If Audit Logging is enabled in the instance settings, then the errors will be logged to the Audit Log database in the InstanceLogs table. If Audit Logging is disabled, then the errors will be logged in the instance folder on the server in the System\Data\Alerts folder.

CRITICAL BUG FIXES

System Out of Memory / Application Freezing | 12.1.4.17

Many users reported the client application would freeze and/or they would receive "Out of memory" errors. We were able to improve internal application memory allocation in a few areas of the code (Metrics, Import Mappings, and the Job Details dialog).

ScenarioType field in Publish data accurately reflects "Production" scenario types | 12.1.4.17

The ScenarioType field in the Schedules table of the publish database is updated to correctly identify scenarios with are flagged as Production scenarios in the instance workspace.

Unable to unlock a locked user account | 12.1.4.17

A user's account may now be unlocked after it gets locked due to too many failed login attempts.

Inventory adjustments are inaccurate for partially completed operations | 12.1.4.20

An issue was fixed so that activity production will now account for operation product completed quantity.

If an operation was partially completed and its product was imported with a CompletedQty value, it is expected that the total inventory output at the scheduled end of the operation would equal its total required quantity minus the completed quantity. This was not functioning correctly though and the entire original required quantity was being added to inventory instead. 

User permissions are not always enforced | 12.1.4.20

Two issues were fixed related to user permissions which were not being enforced:

Users without permission to advance the clock and/or refresh data were still able to advance the clock and/or refresh data

Users without permission to create scenarios were still able to create scenario copies

Resource utilization chart tile issues | 12.1.4.20

The Resource Utilization Chart tile in the Capacity Plan board and the Gantt board are fixed so that the user can switch between scheduled usage % and scheduled usage hours, and so that users may scroll forward and backward in time in the Gantt without altering the plotted data values.

Client application does not always shut down when closed | 12.1.4.21

A fix is released which addresses an issue where the client application Windows process would remain active in the background after being closed if the user had made one or more drag/drop moves during their active session. Over time, this could lead to too many sessions remaining open to a point where the user could experience "out of memory exception" errors.

INTEGRATION CHANGES

Import Mappings

Resource Mappings

Properties are added to support additional Experimental Sequencing Plan mappings:

ExperimentalSequencingPlanTwo | String

ExperimentalSequencingPlanThree | String

ExperimentalSequencingPlanFour | String

Each of these accepts values equal to the Names of existing Sequencing Plans in the Workspace, similar to the previously existing properties NormalSequencingPlan and ExperimentalSequencingPlan.

Additionally, properties are added which have no functional purpose yet but will be functional with a future release (12.2.x) once our Freeze Dryer solution is fully developed:

MinVolume | Decimal

MaxVolume | Decimal

Product Rules Mapping

New properties are added, but they don't serve a functional purpose yet. They will have functional implications in a future software version release (12.2.0.x) related to some new freeze dryer functionality that is currently under development.

MinVolume | Decimal

UseMinVolume | Boolean

MaxVolume | Decimal

UseMaxVolume | Boolean

Alternate Path Node Mappings

Two new properties are added to Alternate Path Node Mappings in order to support the new TransferStart and TransferEnd properties:

TransferStart | String: The point in time when the transfer from this operation to its successor should start.

TransferEnd | String: The point in time when the transfer from this operation to its successor should end. Choose StartOfOperation for a standard calculation from the TransferStart.

Accepted values for each of these fields:

StartOfOperation: At the start of the operation.

EndOfOperation: At the end of the operation.

EndOfPostProcess: At the end of the operation's post-processing.

EndOfStorage: At the end of the operation's Tank Storage.

EndOfRun: At the end of all cycles/run.

EndOfSetup: At the end of the operation's setup.

Publish Data

Inventories

Properties associated with auto-generating forecasts are removed:

AutoGenerateForecasts

ForecastInterval

NumberOfIntervalsToForecast

JobOperationAttributes

This table was found to be the one of a few without an InstanceId field. It has been added.

InstanceId | varchar(38)

JobPathNodes

Alternate path node properties are added to this table:

TransferStart | varchar(MAX)

TransferEnd | varchar(MAX)

JobResources

This table was found to be the one of a few without an InstanceId field. It has been added.

InstanceId | varchar(38)

ProductRules

The OperationName property is updated internally from having a character limit of 48 to a limit of 254.

ReportBlocks

The Duration property data type is updated from datetime to bigint.

Duration | bigint

Run this SQL query against the Publish database to drop then re-add the Duration property as a bigint data type:

ALTER TABLE ReportBlocks
DROP COLUMN Duration;

ALTER TABLE ReportBlocks
ADD Duration bigint;

Resources

One property is removed (it's been renamed):

ExperimentalDispatcher

Seven properties are added related to the work done to allow for more experimental sequencing plan mappings:

ExperimentalDispatcherOne | bigint

ExperimentalDispatcherTwo | bigint

ExperimentalDispatcherThree | bigint

ExperimentalDispatcherFour | bigint

ExperimentalOptimizeRuleTwo | varchar

ExperimentalOptimizeRuleThree | varchar

ExperimentalOptimizeRuleFour | varchar

ProductRules

In order to allow multiple Item-to-Resource rules where the Item and Resource are identical but the Operation Name is unique, the OperationName property is now designated as a Primary Key of the ProductRules table. In order for this change to propagate to an existing publish database, the entire ProductRules table should be dropped, then it will be recreated with the next Publish cycle. 

Schedules

Since Version 12 has two scenario types (Production and What-If), two properties are renamed and two others related to scenario types are removed.

Some code changes to the way that time zones are managed resulted in a renamed time zone property.

Removed:

LastLiveSchedulePublished

LastPublishedSchedulePublished

LastNetChangeLiveSchedulePublished

LastNetChangePublishedSchedulePublished

UtcOffsetHrs</l</div>
        </section>
      
        <section class="article" id="article-178-release-notes-12-2-0">
          <h3 class="article-title">Release Notes: 12.2.0</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/release-notes-12.2.0" target="_blank">Source</a></p>
          <div class="article-content">Latest version: 12.2.0.27

Jump to section:

New features & functionality

Improved functionality

Server Manager updates

Critical bug fixes

Integration changes

Deprecated functionality

General Availability Releases

Release Version
Release Date

12.2.0.27
October 7, 2024

NEW FEATURES & FUNCTIONALITY

Optimization Enhancement: Schedule Highest Scoring Resource First

An enhancement has been made to the standard optimization logic whereby all resources with capacity at any point in time during optimization will be considered eligible to schedule the next operation. All operations which are released to schedule on all resources with capacity will be scored per each of the available resources. The operation with the highest optimization score will be scheduled on whichever resource it scores highest on.

This behavior will help to improve resource selection during optimization. A practical example: If two or more resources are capable of scheduling the same operation at the same point in time, then the resource with the higher optimization score will be selected to schedule the operation. In previous software versions, the optimization engine would choose a specific resource and force something to schedule on that resource, even if there is only one eligible operation and if that eligible operation would score better and schedule better on another available resource.

For more information, see: Optimization.

New operation process: Clean

Operations may now be configured with a Clean process. Cleans are scheduled to run after operation post-processing and may be configured to be sequence-dependent, much like operation Setup.

Cleanout Triggers

Cleanouts can be triggered to schedule after a certain number of operations are scheduled on a resource, some number of Production Units are scheduled to be produced by a resource, or after a combined total run/cycle time of one or more operations scheduled on a resource, or after a certain duration of calendar time.

Cleanout Grade

Cleanout grade is a new field related to the new Clean process. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower. For example this can be modeled with a Minor cleanout of 0 and Major cleanout of 1.

For more information, see: Cleans.

Attributes redesign for more robust functionality

This is a breaking change. Operation Attributes are not backward compatible with previous versions. All attributes will need to be re-imported to accommodate the new structure.

Attributes have been redesigned to accommodate both dynamic operation Setup and dynamic operation Clean processes.

Attribute definitions are now imported in a new Attribute Mappings table as stand-alone objects

OperationAttributes must reference an Attribute definition when imported

Attribute definitions contain default durations, colors, and costs that can be overridden in each operation to support operation specific changeovers

Attributes have a new AttributeType field to indicate whether the changeover values are for setup or for clean

Resource Attributes are removed. Custom resource properties can be added as User Defined Fields (UDFs), and resource attributes will no longer be used for tracking sequence and setups. A new LastRunActivity mappings is created to import details of the last run activity on the resource. The attributes for that activity's operation will be used for sequence dependent setup and clean calculations.

For more information, see: Attributes.

Auto-Split Operations

Operations may be split into two or more activities automatically during optimization based on many configurable factors. Splitting operations allows the work to be spread across multiple resources in order to complete the work faster (as each split part may be run in parallel), or can be used to split the work across gaps in resource capacity. Splitting can also be used to break larger operations down into smaller parts so that each part may comply with maximum quantity or volume constraints across capable resources.

Auto-split can configured to split based on many factors:

Resource Quantity or Volume constraints

Capacity of the Primary resource when an operation requires one or more helpers

Predecessor material quantity and availability

For more information, see: Auto-Split Operations.

Resource Connectors redesign

This is a breaking change. Resource Connectors are not backward compatible with previous versions. All connections will need to be re-imported to accommodate the new structure.

Resource connectors specify a flow relationship between two or more resources. A resource can have connections to one or more downstream resources which can enforce the following scheduling constraints:

Which resource(s) successor operations of the same manufacturing order can be scheduled

Which resource(s) may consume material from a producing tank resource

The number of simultaneous material allocation connections which can be made from a tank resource to consuming operations

See: Resource Connectors.

Compatibility Codes redesign

This is a breaking change. Compatibility Code logic is not backward compatible with previous versions. All compatibility logic will need to be re-imported to accommodate the new structure.

Compatibility Code Tables define lists of Operation Compatibility Codes which are either allowed or disallowed to schedule simultaneously within a group of resources. Resources may be assigned one or more Compatibility Code Tables, and each table may be assigned to any number of resources.

This is an enhancement from previous software versions which only supported scheduling a single allowed code at a time.

See: Compatibility Codes.

New Product Rules functionality

Cleanout grades and durations can be configured per Product -to- Resource mapping via new Product Rules properties.

Min/Max Quantity and Volume can be configured per Product -to- Resource mapping

OperationName property is replaced with a new OperationCode property in order to support multiple iterations of the same Product+Resource+OperationName combination where the rules may need to be different. Each operation can be assigned an OperationCode to differentiate it from other operations of the same name producing the same product.

See: Product Rules.

Allow specific quantities to be allocated from specific lots

Lot controlled planning is enhanced to allow users to define specific quantities to be allocated from specific lots in the event that one operation needs to source the same material from multiple lots. This is achieved by configuring two or more material requirements for the same item on the operation, each with specific required quantities and allowed lot codes.

See: Lot Controlled Planning.

New Gantt Settings for Scheduling Hints

The following updates were made to the Gantt Scheduling Hints:

A toggle switch to show individual Gantt Lines was added to the new Scheduling hints settings category 

A toggle switch to show individual Gantt Region was added to the new Scheduling hints settings category 

Removed the 'Clear Activity Links' Option from the Gantt Viewer

Moved Activities Gantt to the Options dropdown on the Gantt Toolbar and renamed it "View As Daily Activities"

See: User Settings

New Sequencing Factors

New sequencing factors meant to help prioritize resources under certain conditions are added:

Closest Fit Quantity

Closest Fit Volume

Largest Quantity Fit

Largest Volume Fit

Least Waste Quantity Fit

Least Waste VolumeFit

Smallest Quantity Fit

Smallest Volume Fit

Others are added to help prioritize based on Clean cost, duration, and grade:

Clean Duration

Higher Cleanout Grade

Lower Cleanout Grade

Same Cleanout Grade

Clean Cost

Finally, a new factor Attribute Number is added to allow for prioritization based on a numerical value assigned to one or more attributes.

See: Sequence Planning Board.

New MRP options: MRP Start Type and Start Date

New MRP options are added so that users may define when MRP processing should begin to consider demand signals. See: MRP OptionsMPS/MRP Optimize Plan Settings.

Capacity Interval Configuration Options

Both recurring and non-recurring capacity intervals are given more configuration options. A new Holiday type is added, and new options allow users to customize the interval Color and opt to enable options to reset setup and clean calculations, and/or prevent operations from spanning the interval.

See: Resource Capacity.

New InventoryAvailableTiming for product: AtOperationRunEnd

A new Product InventoryAvailableTiming value AtOperationRunEnd allows for releasing product at the end of run for cases where resource post processing does not affect material availability.

MRP Source from Firm Orders

A new Source From Firm Orders MRP option allows sourcing from Firm and Released orders even if the material may not be available on time.

Add Gantt Background visibility for transfer span

Added a new module to draw a transfer span region when an operation is selected on the Gantt.

Expedite options are added to Activities and Jobs boards

Expedite options which were previously only available from the Gantt right-click menu are added to the Activities and Jobs board grid actions and right-click menus.

Do ASAP

Preserve the Frozen Span

Preserve the Stable Span

To specific date and time

IMPROVED

Gantt Layout Enhancements

Fixed sorting issue not reflecting in the Gantt

Fixed issue on Plant Gantt Layouts Settings control where user is prompted to save pending changes after they've just saved them

Removed the Advanced Sort Mode Toggle switch to ensure Resource List is always sortable

Disabled customization of system-generated Gantt layouts (selecting, sorting)

A default layout "All Plants" is generated at start-up if no such layout exist.

Users are prompted at start-up to regenerate Plant Layouts if invalid ones are detected. Criteria for prompting are:

If a plant layout exists with the plant not found in the current scenario

 If a department layout exists with the department not found in the current scenario

Job Flow Layouts are not serialized and are purged when:

A new layout is selected

Shutting down with a job flow layout set as the active layout

All layouts with the Auto-Enable new resources setting enabled will have newly added resources added to them.

Workspace Profile Auto-Save

Auto-save / backup of workspace profiles now saves to the user's computer. Users may choose where the backups are stored. If a backup has a more recent timestamp than the one that is loaded on startup, then it will automatically be loaded.

Desynchronization Logging

Additional logging is added to help diagnose server-to-client desynchronization errors.

Renamed "Attribute Setup Table" in mappings to "Attribute Range Table"

To avoid confusion, the "Attribute Setup Table" mappings pages are renamed to "Attribute Range Table" mappings in Import Mappings.

SERVER MANAGER UPDATES

Server Manager Version: 12.2.0.7

Nothing significant to note. Some minor bug fixes are released.

CRITICAL BUG FIXES

Limit the number of rows from audit log DB to message logs

The Interface from Server logs in Message Log is limited to 1,000 entries to prevent the dialog from taking several minutes to load when many thousands of entries exist in the interface log on the server.

User is allowed to toggle off [x] Production flag from all scenarios

Created a warning to appear if the user toggles off the production toggle for the last production scenario. This change is not allowed to save.

Users in a group which does not have Import Data permissions are allowed to import data

Fixed an issue with user permissions which allowed users without permission to import data to still have the option to import data.

Recurring Capacity Intervals created after Daylight savings start date are different than those created before

Recurring Capacity Intervals recurrences are calculated by using a StartDate that is closer to the clock date instead of using the import date to calculate, which can be far in the past, thus causing a daylight saving shift.

Editing MO Required Quantity from Activities grid does not scale other operation quantities

Editing a Manufacturing Order's Required Quantity from the Activities now properly triggers calculation of the related fields.

Activity Move tile goes into "Edit Mode" which prevents certain functionality from working

Activity Move Tile will now never enter edit mode.

INTEGRATION CHANGES

Import Mappings

Resource Mappings

Removed:

CompatibilityGroup

CurrentProductSetup

CurrentSetupCode

CurrentSetupNumber

Added:

StandardCleanHours

StandardCleanoutGrade

UseOperationCleanout

UseAttributeCleanouts

Resource Attribute Mappings

The entire mappings table is removed. User Defined Fields can be used in place of Resource Attributes.

Resource Connector Mappings

Resource Connectors have been redesigned. What was a single import mappings table is expanded to two to accommodate the new connector table structure.

Resource Connectors

Removed:

ResourcePlantExternalId

ResourceDepartmentExternalId

ResourceExternalId

DownstreamResourcePlantExternalId

DownstreamResourceDepartmentExternalId

DownstreamResourceExternalId

FixedTransitHrs

Added:

ExternalId

Name

Description

Notes

UserFields

TransitHours

LinkSuccessors

LinkMaterials

Resource Connections

 Added:

PlantExternalId

DepartmentExternalId

ResourceExternalId

ResourceConnectorExternalId

ConnectionDirection

Capacity Interval Mappings

Added:

Notes

Color

CleanOutSetups

PreventOperationsFromSpanning

Recurring Capacity Interval Mappings

Added:

Color

CleanOutSetups

PreventOperationsFromSpanning

Product Rules Mappings

Removed:

OperationName

Added:

OperationCode

CleanHrs

UseCleanHrs

MinQty

UseMinQty

MaxQty

UseMaxQty

CleanoutUnitsRatio

UseCleanoutUnits

Attribute Mappings

Attributes are now imported as objects before being associated with Operations or other objects. This is an entirely new mappings table:

ExternalId

Name

Description

ColorCode

DefaultCost

DefaultDurationHrs

AttributeTrigger

AttributeType

CleanoutGrade

ShowInGantt

HideInGrids

ConsecutiveSetup

UseInSequencing

Attribute Range Table Mappings (formerly "Attribute Setup Table Mappings")

Each of the mapping tables Attribute Range Table, Attribute Range Table Attribute Name, Attribute Range Table From-Range, and Attribute Range Table To-Range were updated to accommodate the change from AttributeName to AttributeExternalId.

Removed:

AttributeName

Added:

AttributeExternalId

Compatibility Code Table Mappings

Item Compatibility (old) is replaced by a more robust Compatibility Code concept whereby many codes can be listed as allowed or disallowed to be scheduled together across an assigned resource group. These are all new mappings tables:

Compatibility Code Tables

AllowedList

TableName

Description

Compatibility Code Table

CompatibilityCode

TableName

Compatibility Code Tables Assigned Resources

PlantExternalId

DepartmentExternalId

ResourceExternalId

TableName

Attribute Code Table Mappings

Each of the mapping tables Attribute Code Table, Attribute Code Table Attribute Name, and Attribute Code Table Attribute Code, were updated to accommodate the change from AttributeName to AttributeExternalId.

Removed:

AttributeName

Added:

AttributeExternalId

Additional changes to the Attribute Code Table Attribute Code mappings:

Removed:

SetupTime

SetupCost

Added:

DurationHours

Cost

CleanoutGrade

Lots Mappings

Removed:

WearAmount

Resource Operation Mappings

Removed:

MinAutoSplitQty

Added:

CleanHrs

CleanTimeManualUpdateOnly

CleanOutGrade

ProductCode

AutoSplitType

MinAutoSplitAmount

MaxAutoSplitAmount

SetupSplitType

Internal Activity Mappings

Added:

CleanHrs

CleanTimeManualUpdateOnly

CleanOutGrade

Product Mappings

Removed:

VolumeOverride

Added:

UnitVolumeOverride

Operation Attribute Mappings

Removed:

Name

Description

SetupHrs

SetupCost

IncurSetupWhen

ConsecutiveSetup

ShowInGantt

ManualUpdateOnly

HideInGrids

Added:

AttributeExternalId

CodeManualUpdateOnly

NumberManualUpdateOnly

DurationHrs

DurationOverride

DurationHrsManualUpdateOnly

Cost

CostOverride

CostManualUpdateOnly

ColorOverride

ColorCodeManualUpdateOnly

Cleanout Trigger Table Mappings

Cleanout Trigger Tables are all new to this version. These are all new mapping tables:

Cleanout Trigger Tables

TableName

Description

Operation Count Cleanout Trigger Table

TableName

DurationHours

CleanoutGrade

CleanCost

TriggerValue

Production Unit Cleanout Trigger Table

TableName

DurationHours

CleanoutGrade

CleanCost

TriggerValue

ProductionUnit

Time Cleanout Trigger Table

TableName

DurationHours

CleanoutGrade

CleanCost

TriggerValueHours

UseProcessingTime

UsePostProcessingTime

TriggerAtEnd

Cleanout Trigger Tables Assigned Resources

PlantExternalId

DepartmentExternalId

ResourceExternalId

TableName

Last Run Activities Mappings

This new table maps activities to a resource for tracking sequence dependent values. This will be set on the resource automatically as operations finish, but can be overridden with an imported value. The finished activity must exist in the system.

This table is already deprecated in the next software release.

It's recommended to not use this solution to track sequence-dependent setup and clean at the start of the schedule. Instead, enable Track Actuals and import any number of finished operations. The scheduled resource can be specified in the ActualResourceUsed property of the internal activity.

PlantExternalId

DepartmentExternalId

ResourceExternalId

JobExternalId

MoExternalId

OperationExternalId

ActivityExternalId

Publish Data

Breaking Change

A Primary Key change in the ProductRules table requires rebuilding the table, or at least dropping it. Once it's been dropped, the next successful Publish from the PlanetTogether desktop application will recreate the table with the new schema as long as the ValidateDB property of the [dbo].[SystemData] table in the publish database is set to True.

drop table [dbo].[ProductRules]

Database Schema File

Download the database schema file here: StandardPublishDBSchema_12.2.0.27.sql

Customers

Added:

ExternalId | [nvarchar](max)

Departments

Removed:

AttributesSummary

Inventories

Added:

PreventSharedBatchOverflow | [bit]

Items

Removed:

AttributesSummary

JobActivities

Added:

CleanHrs | [float]

CleanOutGrade | [int]

CleanManualUpdateOnly | [bit]

JobOperationAttributes

Removed:

Name

Description

ColorCodeColorName

ConsecutiveSetup

SetupHrs

SetupCost

IncurSetupWhen

ShowInGantt

ManualUpdateOnly

HideInGrids

Added:

AttributeExternalId | [nvarchar](max)

Cost | [float]

DurationHrs | [float]

ColorCode | [nvarchar](max)

JobOperations

Removed:

MinAutoSplitQty

Attributes

Added:

AutoSplitType | [nvarchar](max)

MinAutoSplitAmount | [float]

MaxAutoSplitAmount | [float]

SetupSplitType | [nvarchar](max)

Jobs

Removed:

AttributesSummary

Lots

Removed:

WearAmount

ManufacturingOrders

Removed:

AttributesSummary

Plants

Removed:

AttributesSummary

ProductRules

Updated data type:

OperationName from [nvarchar](254) to [nvarchar](max)

Added:

CleanHrs

UseCleanHrs

CleanoutUnitsRatio

UseCleanoutUnits

Primary Key Field Removed:

OperationName

PTAttributes

This is a newly added table.

PublishDate | [datetime]

InstanceId | [nvarchar](38)

Name | [nvarchar](max)

Description | [nvarchar](max)

ExternalId | [nvarchar](max)

ColorCode | [nvarchar](max)

ConsecutiveSetup | [bit]

DefaultCost | [float]

DefaultDurationHrs | [float]

AttributeTrigger | [nvarchar](max)

AttributeType | [nvarchar](max)

CleanoutGrade | [int]

ShowInGantt | [bit]

HideInGrids | [bit]

PurchasesToStock

Removed:

AttributesSummary

Resources

Removed:

CompatibilityGroup

CurrentProductSetup

CurrentSetupCode

CurrentSetupNumber

AttributesSummary

Added:

StandardCleanHours | [float]

StandardCleanoutGrade | [int]

UseOperationCleanout | [bit]

UseAttributeCleanouts | [bit]

OperationCountCleanoutTriggerTableName | [nvarchar](max)

ProductionUnitCleanoutTriggerTableName | [nvarchar](max)

TimeCleanoutTriggerTableName | [nvarchar](max)

TransferOrders

Removed:

AttributesSummary

Warehouses

Removed:

AttributesSummary

DEPRECATIONS

Sequence Factors Lowest and Highest Attribute Number are removed

The Highest Attribute Number and Lowest Attribute Number sequencing factors are replaced by a new Attribute Number factor. See: Sequence Planning Board.

Resource Attributes

Attributes are removed from Resource objects.</div>
        </section>
      
        <section class="article" id="article-325-release-notes-12-2-1">
          <h3 class="article-title">Release Notes: 12.2.1</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/release-notes-12.2.1" target="_blank">Source</a></p>
          <div class="article-content">Latest version: 12.2.1.138

Jump to section:

New features & functionality

Improved functionality

Server Manager updates

Critical bug fixes

Integration changes

Deprecated functionality

Maintenance Release Fixes

General Availability Releases

Release Version
Release Date

12.2.1.58
December 23, 2024

12.2.1.60
December 30, 2024

12.2.1.71
February 18, 2025

12.2.1.77
March 21, 2025

12.2.1.87
April 14, 2025

12.2.1.97
May 19, 2025

12.2.1.111
July 11, 2025

12.2.1.116
July 25, 2025

12.2.1.129
September 9, 2025

12.2.1.138
November 10, 2025

Major Feature Release: 12.2.1.58

NEW FEATURES & FUNCTIONALITY

Capacity Interval Enhancements

Alert

This is a breaking change. Imported capacity intervals are not backward compatible with previous versions. All imported capacity intervals will need to be re-imported to accommodate the new structure.

Capacity intervals are simplified in some ways, but also given more flexibility and options to define precisely what type of work can be performed on each.

Interval types are reduced to only 2:

Online

Offline

Each interval can be given a custom color of the user's choosing.

New boolean options are provided which determine various functionality of each interval:

Overtime: When enabled, the resource is available to perform work. Cost calculations for performing work on the interval use the Overtime Hourly Cost on the resource. When disabled, cost calculations for performing work on the interval use the Standard Hourly Cost on the resource.

Can Start Activity: When enabled, the interval can be used to start the first process of an activity (either Setup, if applicable, or Cycle).

Prevent Operations from Spanning: When enabled, the resource is not available to perform work, and no idle work is allowed to pause to span across this interval. This is typically a good option for resource maintenance or cleaning where schedulers don't want to start progress on an operation or activity, then pause for its offline maintenance, then pick back up the activity after the offline interval.

Reset Attributes Changeovers: When enabled, calculations which dictate sequence-dependent setups and cleans will be reset to 0.

Use Only when Late: When enabled, activities will only schedule on the capacity interval if they are late (the schedule clock date time is later than the activity’s JIT start date).

Used for Setup: When enabled, the capacity interval can be used to perform Setup processes.

Used for Run: When enabled, the capacity interval can be used to perform Cycle processes.

Used for Post Processing: When enabled, the capacity interval can be used to perform Post-Processing processes.

Used for Storage Post Processing: When enabled, the capacity interval can be used to perform Storage Post-Processing processes.

Used for Clean: When enabled, the capacity interval can be used to perform Clean processes.

Interval preset templates are made available to quickly preset an interval with recommended settings for various common interval types. Each preset can also be imported via a new IntervalPreset property:

Online

Online

CanStartActivity

UsedForSetup

UsedForRun

UsedForPostProcessing

UsedForStoragePostProcessing

UsedForClean

Overtime

Online

CanStartActivity

UsedForSetup

UsedForRun

UsedForPostProcessing

UsedForStoragePostProcessing

UsedForClean

Overtime

PotentialOvertime

Online

CanStartActivity

UsedForSetup

UsedForRun

UsedForPostProcessing

UsedForStoragePostProcessing

UsedForClean

Overtime

UseOnlyWhenLate

Cleanout

Online

UsedForClean

Holiday

Offline

PreventOperationsFromSpanning

Offline

Offline

Maintenance

Offline

PreventOperationsFromSpanning

ResetAttributeChangeovers

See also:

Resource Capacity

Scenario Data Board

Gantt Board

Capacity Interval Mappings

Recurring Capacity Interval Mappings

Scenario Management Enhancements

The following enhancements are made to Scenario Management:

Only one scenario may be designated a "Production" scenario. It cannot be deleted until replaced by another scenario (the workspace must have one Production scenario at all times).

A new Scenario Swap button is added which enables users to swap a non-production scenario with the current production scenario.

See also: Scenario Management

Resource Prioritization

Each resource may be given a Priority numerical value which can be considered during optimization when the associated optimize factor is scored so that if multiple resources are eligible to schedule an operation and each has available capacity, the Priority designation can force the scheduler to score the operation higher on the preferred resource.

Product rules can override the Resource Priority order depending on the Product that the job is producing.

See also: 

Resource Mappings

Sequence Planning Board

Product Rule Mappings

New Product Rule: Item Transfer Quantity Per Product / Resource

New product rules are created to override Item Transfer Quantity for a Product depending on which Resource it is made on.

See also:

Product Rules

Product Rule Mappings

New Gantt Segments: Job Color, Product Color

Two new Gantt segments are added: Job Color and Product Color.

Job Color: The segment is drawn with a background color equal to the defined Color property of the associated Job.

Product Color: The segment is drawn with a background color equal to the defined Product Color property of the associated Manufacturing Order.

See also: User Settings

New User Control: Cancel Simulation

A new option is available to users to cancel a long-running or stuck simulation process.

See also: Main Toolbar

New Message Log Control: Auto-Clear Import Logs

A new option is available in the Message Log Viewer to automatically purge old import (Interface) logs so that only the errors logged from the most recent data refresh are visible.

See also: Main Toolbar

Create a visible queue of waiting actions

When many manual schedule moves or similar actions are made in quick succession, each action may be added to a queue and processed in the order in which it was queued. The number of currently queued actions is made visible in a notification slide across the bottom of the screen.

Add a means for a user to change their password

A new Reset Password button is added to the User Preferences dialog to allow users to change their password.

See also: User Management

Activity Setup, Cycle, Quantity per Cycle, Post-Processing, and Clean can override Operation values

Activities are updated to allow for different time standards to be configured per Activity rather than inheriting them from the associated Operation. This is particularly helpful if splitting an operation into multiple activities might have an impact on time standards like Setup, Cycle, Clean, etc.

See also: 

Job Details Dialog

Internal Activity Mappings

New Gantt Hint Line: Product Consumed

A new Gantt hint is added which draws a vertical line where the selected operation's product is consumed by another scheduled operation.

See also: User Settings

New Optimize Factor: MO is Scheduled

A new optimize factor is added which prioritizes operations when one or more of its predecessors of the same MO are currently scheduled.

See also: Sequence Planning Board

Allow for Wildcard Characters in Attribute Code Tables

Wildcard characters which were previously only available to use in configuring Setup Code tables can now be used in Attribute Code tables.

See also: Scenario Data Board

[ 12.2.1.71 ] New Optimize Factor: Shelf Life

Added a new optimize factor prioritize operations if they consume materials which are close to expiring to help with scheduling shelf-life controlled lots to reduce waste.

[ 12.2.1.87 ] Add setting to disable Import while Publish is running

Adds a new setting and settings control to disable importing while a Publish is in progress.

[ 12.2.1.87 ] Show Connected Jobs flow

Added a new action element to the Gantt Right-click menu to show all related/ connected jobs flow of a selected job.

[ 12.2.1.87 ] Add way for users who can't publish to see last publish date in core product

The last publish date is presented in the top right corner for those users who do not have permission to see the Publish menu where the last publish date was previously displayed.

[ 12.2.1.87 ] Audit Logging: Add FromDepartmentName and ToDepartmentName fields to dbo.TransmissionLog Request

Added two new fields to the TransmissionLog Details column for Move Actions:

FromDepartmentName (string)

ToDepartmentName (string)

Instances from this version onward will begin provided this information for each moved logged.

[ 12.2.1.87 ] Add Grid Layout management to Inventory Details and KPIs board grids

Grid Layouts are now enabled for the Inventory Details Grid in the Inventory Plan board's Inventory Plot Report tile, as well as for the KPIs board grid.

[ 12.2.1.87 ] Expedite: Add way to Expedite Jobs without Predecessors and Supplies

A new Expedite option is added to the Gantt and Activities board Expedite Job and Supplies menus from the right-click actions menu. This option will only expedite the selected job without also expediting its supplying jobs.

[ 12.2.1.87 ] Grid is refreshing while editing when schedule changes occur

A User Preference is added to prevent grids from refreshing while in Edit Mode when other users are performing actions which typically trigger all grids to refresh.

[ 12.2.1.97 ] Offer a "Minimum optimize score" feature

A new Minimum Optimize Score feature is added which prevents scheduling an operation if its score does not meet or exceed a minimum value.

Added Global Min Score for Sequencing Plans. This score prevents Activities from scheduling on a Resource if its calculated Sequencing Factors score does not meet or exceed the configured Global Min Score value.

Added a column to the Sequence Plan Grid to display the Global Min Score

Added an editor to the Optimize Factor Settings Control to allow editing the Global Min Score (this interface will be improved with the next major 12.3.0 software release)

For more information, see: Sequence Planning Board.

[ 12.2.1.97 ] New optimize factor: Max Delay

A new optimize factor is added which scores operations according to how close they are from reaching or violating their predecessor's assigned Max Delay Hours. This is meant to be used without the Max Delay system setting enabled as a means to prioritize operations which are nearing or have exceeded their Max Delay Hours.

For more information, see: Sequence Planning Board.

[ 12.2.1.97 ] New optimize factor: MO time scheduled

A new optimize factor is added which scores operations according to how far away in time they are from the scheduled end date of their predecessor. This helps to keep operations of the same MO scheduled closer together.

For more information, see: Sequence Planning Board.

[ 12.2.1.97 ] New System Setting which allows breaking a resource's sequence on manual move of dependent predecessor operations

Added System Setting to Allow Change of Material Successor Sequence On Move. When enabled, the Material Successors related to the moving Activity are allowed to break the currently scheduled operation sequence on the resource they are scheduled on.

For more information, see: System Settings.

[ 12.2.1.97 ] New User Setting Move Options are added for Compress Predecessors behavior

Compress Predecessors Move Settings toggle setting has been replaced with a dropdown setting with the following options:

Predecessors Do Not Move: Predecessor Activities don't move which causes the moving Activity to be constrained by the End Date of the latest Predecessor.

Predecessors Compress: Predecessors will "Compress" meaning they can move back as far as possible without changing Operation sequence on the Resource they're scheduled on. The moving Activity will be constrained by the End Date of the latest Predecessor after the Compress.

Predecessors Move: Predecessor will be able to move and change the sequence on the Resource they are scheduled on. If the move date intersects a scheduled block, the Predecessor will move to the End Date of the Scheduled Block, which may cause the moving Activity to not be able to move to the desired Move Date.

For more information, see: User Settings.

[ 12.2.1.97 ] Set sub-job need dates enhancement: Account for production overlap

A new Set Sub-Job Need Dates option is added: Production Overlap. It calculates the sub-job need dates to be the start date of the parent job minus the amount of time required for the sub-job to make its first transfer of product to inventory.

For more information, see:

System Settings

MPS/MRP Optimize Plan Settings

IMPROVED

Inventory Plot: Consolidate rows when material supply comes from the same job and is distributed at the same time

Multiple grid rows are consolidated into one row when one operation consumes material from another single operation where the producing operation's product was added to inventory in batches from Item Transfer Quantity logic.

Inventory Management Tile: Allow for multi-row selections & deletions

Multiple grid rows can now be selected for deletion from the Inventory Management tile in the Scenario Data Board.

Last Refresh Timestamp is updated to be Scenario Specific

Each scenario may be refreshed at different times. The Last Refresh timestamp in the top right corner of the main toolbar will now reflect the date and time of the last refresh performed in the currently active scenario.

Limit the number of rows from the Audit Log to Message Logs

The number of data import errors logged on the server which get displayed in the Message Log dialog to end users from the Interface From Server tab are limited to only the last 1,000 records. This was done to improve performance of the message log.

Move Details are added to Audit Log Database Logging

Manual drag/drop moves will now have more details of each move recorded in the TransmissionLog table of the Audit Log database. Additional details include:

The Activity ID

The operation Name

The MO Name

The Job Name

The date and time the operation was previously scheduled

The date and time that the operation was moved to

The resource that the operation was previously scheduled on

The resource that the operation was moved to

Undo Details are added to Audit Log Database Logging

Undo actions will now have more details of each action which is undone logged in the TransmissionLog table of the Audit Log database. Additional details includes a description and a transmission number of each action which is undone.

Add Additional Fields to ChecksumValues for Desync Logging

Additional fields have been added to ChecksumValues to be logged during client desynchronizations.

Data Refresh Progress Bar Enhancement

The progress bar that is displayed in the Notifications slide during a data refresh is improved to show each specific step of the process and give users a rough idea of how far along it is and how close it is to completing.

Data validation is added to prevent recurring capacity intervals which run for longer than 24 hours

Recurring capacity intervals which run for longer than 24 hours can cause issues with intervals overlapping one another. New logic is added to prevent the creation of recurring intervals with a duration longer than 24 hours.

Non-recurring intervals are still allowed to run longer than 24 hours.

Reduce file size of downloaded scenarios

New options are presented to users who opt to download a copy of the scenarios.dat file. When initiated, the user will be prompted to select which of the available scenarios in the Workspace should be downloaded, and whether or not to Clear Undo Sets. By clearing undo sets and selecting specific scenarios, the file size of the resulting download can be greatly reduced.

See also: Main Toolbar

Prevent Moves in the Job Watch Gantt

Drag/drop moves could previously be performed in the Job Watch and Connected Jobs Gantts, even though the moves did not actually impact the schedule. Moves are now blocked in these Gantts to prevent confusion.

Update PlanetTogether Integration Files

Updates were made to the standard "PlanetTogether" integration files that get downloaded during the server installation process. The import database schema and a publish database script are updated according to the latest integration standards.

Enabled users to freely modify the Commitment property from Bulk Edit tiles

Previously, the Commitment property of a job could be progressed forward but not backward by a Bulk Edit tile modification. This change allows the Commitment to be set to any value at any time via the Bulk Edit tiles in Jobs and Activities boards.

Capacity Planning Charts Improvements

The Resource Utilization Chart and Scheduled Capacity Usage chart have been improved to show more accurate data.

SERVER MANAGER UPDATES

Server Manager Version: 12.2.0.17

Instance Settings Reorganization

A minor reorganization of Instance Settings is rolled out which more clearly defines Import and Publish database settings

See also: Instance Manager

CRITICAL BUG FIXES

Client process doesn't shut down

Fixed an issue where the client application Windows process would remain active after the application was closed.

Activity Move details are not always logged in Transmission Log database table

Fixed a bug where the Audit Log would not consistently log data when the system was busy or related data no longer existed at the time of logging.

Certain job quantity columns are rounding to nearest whole number

Non-editable numeric grid columns now have their precision set to 2 instead of 0 digits.

INTEGRATION CHANGES

Import Mappings

Resource Mappings

Removed:

SetupEfficiencyMultiplier

Added:

ActivitySetupEfficiencyMultiplier

ChangeoverSetupEfficiencyMultiplier

Priority

Capacity Interval Mappings

Added:

CanStartActivity

UsedForSetup

UsedForRun

UsedForPostProcessing

UsedForClean

UsedForStoragePostProcessing

Overtime

UseOnlyWhenLate

CapacityCode

IntervalPreset

Recurring Capacity Interval Mappings

Added:

CanStartActivity

UsedForSetup

UsedForRun

UsedForPostProcessing

UsedForClean

UsedForStoragePostProcessing

Overtime

UseOnlyWhenLate

CapacityCode

IntervalPreset

<a href="https://www.planettogether.com/knowledge-v12/product-rules-mappings" target="_blank" rel="</div>
        </section>
      
        <section class="article" id="article-169-release-notes-12-3-0">
          <h3 class="article-title">Release Notes: 12.3.0</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/release-notes-12.3.0" target="_blank">Source</a></p>
          <div class="article-content">Latest version: 12.3.0.97

Jump to section:

Migration Guide from 12.2 to 12.3

New features & functionality

Improved functionality

Server Manager updates

Critical bug fixes

Integration changes

Deprecated functionality

Maintenance Release Fixes

General Availability Releases

Release Version
Release Date

12.3.0.94
November 10, 2025

12.3.0.97
December 10, 2025

🔆 Release Highlights 🔆

✔️ Storage Areas are added to enhance tank scheduling capabilities

✔️ The desktop client application runs "lighter" as it requires less RAM by allowing users to load or unload what-if scenarios, and no longer storing Undo data in memory

✔️ New job-specific optimization options are available on one or more selected jobs, or for one or more selected resources

✔️ Alternate Paths can be assigned Validity Dates which allows path schedule eligibility dates to be explicitly defined 

✔️ New production overlap enhancements are added for more accurate and flexible scheduling of overlapping production

MIGRATION GUIDE FROM 12.2 TO 12.3

A curated guide has been created to assist in the upgrade process when upgrading from older Version 12 releases to 12.3.0:

Upgrading from 12.1.x or 12.2.x to 12.3.x

NEW FEATURES & FUNCTIONALITY

🔆 New Inventory Storage Solution: Storage Areas

⚠️ Alert

This introduces several breaking changes. All data models are required to be updated so that:

Each Warehouse is assigned at least one Storage Area via Storage Area Mappings

Each Inventory is assigned to at least one Storage Area via Item Storage Mappings

On-Hand Inventory Quantity is imported as a Lot (one Lot per inventory record) via Lots Mappings and Item Storage Lots Mappings

Purchase Orders
are required to specify which Storage Area the inventory will be stored in

If using MO Production Overlap, Job Operation Product and Material Requirement settings will need updated to use new properties and/or values.

Storage Areas are introduced as a new required data object. They represent an area within a Warehouse where material is stored. Each Warehouse must now have at least one assigned Storage Area. Storage Areas use Item Storage mappings to define properties for which items can be stored in each Storage Area and how they can be stored.

These are meant to replace Tank Resource objects and come packaged with many optional constraints that enable more accurate modeling of how storage tanks and silos are scheduled in PlanetTogether.

A high-level overview of the impact of the changes:

Storage Areas can constrain how material is stored in a warehouse. This can be general unconstrained floorspace, storage bins, tanks, silos, etc.

All scheduled and planned material must be stored in a Storage Area

A new Storage Areas board shows inventory levels per item per storage area over the course of the schedule. This is different than the inventory plan as it will not show Forecast demands or shortages which remain at the inventory (warehouse) level.

Storage Areas can constrain the flow of material by the number of simultaneous sources. Limits can be defined for simultaneous withdrawal, storage, and the combination of both.

Storage Areas can be constrained to store a single material at a time to model single-item storage bins or tanks

A new Item Storage object is added which extends inventory properties for each Storage Area. An item stored in a storage area is considered Item Storage. Similar to how Inventory contains properties for items within a specific warehouse, Item Storage contains properties for items stored in a specific Storage Area.

An item storage must exist for every item that can be stored in the storage area

An item storage may optionally define a maximum quantity of the item that can be stored in the storage area at any time

An item storage may optionally define a minimum limit to maintain material in the Storage Area. If the quantity ever goes below this quantity, the remainder will be disposed.

An item storage may optionally indicate whether the material will be disposed of immediately upon meeting the disposal requirement (time or quantity), or if the material should only be disposed if needed to make room for other storage.

Storage Area Connectors:

A new data object that links resources to storage areas. These act as constraints on when, how, and if the material can be transferred between resources and storage areas.

Replaces material-based resource connector functionality

Each connector has mappings for material flow from Resources In -> Storage Area In -> Storage Area Out -> Resources out

Each connector is a 'plan' of how material can be transferred between resources and storage areas. When storing material from an operation product, all available connectors in the Resources In mappings will be considered. Only one connector will be used to store the material. The 'best' connector will be determined by Product Storage rules. For example largest storage, closest fit, empty, not empty, etc.

If multiple resources can use a connector, it will be constrained by storage flow limits. StorageFlowIn and StorageFlowOut constrain how many storage areas can be used by the connector simultaneously.

CounterFlow limits whether the connector can be used to move material in and out of storage simultaneously, constrained by the CounterFlowLimit.

See: Storage Area Connectors.

Storage Area impact on the Inventory Plan Board

While a new Storage Areas Board has been added, some storage area details are made visible in the Inventory Plan Board as well. In particular, the Inventory Plot Report tile now includes the following details:

Storage Area: The storage area impacted by the adjustment.

Storage Area Level: The current total amount of inventory stored in the storage area.

Storage Area Available Level: The current amount of inventory stored in the storage area which is available to be used by consuming operations.

Storage Area impact on MRP

The impact of storage areas on MRP is minimal. The only new requirement to preserve old functionality is to define a Storage Area ExternalId at the inventory level via the PurchaseOrderSupplyStorageAreaExternalId property for any inventory that is configured to allow MRP to generate purchase orders to satisfy demands (MrpProcessing is set to GeneratePurchaseOrders).

Storage Area impact on Tanks:

⚠️ Warning

All previous notions and conceptions of Tanks modeled as Resources has been completely redesigned. Tanks are now modeled as Storage Areas and may be connected to Resources via Storage Area Connectors.

Storage tank functionality has been changed in the following ways:

Storage Post Processing stage and statuses have been removed. Clean now most aligns with this status/process.

Storage has been added as a standard production stage that comes after Post-Processing.

Product material availability can now be made available during Post Processing, During Storage, or at the end of storage.

Storage is meant to represent the time it takes to move material from the resource to a storage area, but it can be used and modeled as an extra production stage if needed, even if there is no material to move.

Most features that worked with Storage Post Processing have been updated to work with Storage. For example capacity interval used during storage post processing field.

Reported Storage can be imported similar to other Reported fields for the other production stages.

Storage Clean has been removed and Clean now always comes after Storage.

Product StoreInTank and other tank related fields have been removed

Where tanks previously disposed of its material only after being completely consumed/depleted by other operations, or after expiring, now Item Storage can be configured with a Disposal Quantity which defines a minimum threshold that allows the storage area to automatically dispose of the material if the level drops too low.

Review notes mentioned above and the newly documented Storage Areas functionality for more information about how to model tanks in this software release and beyond.

Storage Area impact on Lots and On-Hand Inventory:

All inventory is now stored and sourced from Lots. A single on-hand lot may be imported to keep modeling simpler. All scheduled production and POs will create new lots in the system.

Lot pegging with lot codes is unchanged and is still optional

Lot Quantity must be imported at the Item Storage level via Item Storage Lots Mappings which requires importing Lot objects via Lots Mappings. A single Lot can optionally be stored across multiple Storage Areas.

Storage Area impact on Operation Material Requirements:

MaterialUsedTiming - A new field is added to configure when the material is required: At start of setup, start of production, or based on production cycles. This replaces OverlapProduction fields.

StorageArea - A new optional field that may be specified to indicate material may only be sourced from a particular storage area within a warehouse. If unspecified, the material will be sourced from any available Storage Area.

MultipleStorageAreaSupplyAllowed - A new field similar to Allow Partial Supply and Multiple Warehouse Supply that specifies if the material can be sourced from multiple storage areas.

Storage Area impact on Operation Product:

StorageArea - A new optional field that may be specified to indicate the product must be stored in a specific storage area. If unspecified, the product will be stored in any available storage area.

RequireEmptyStorageArea - A new field that specifies whether the product must be stored in an empty storage area. This field works with the StorageArea field SingleItemStorage. If both are set to True, then a storage area must be emptied or disposed before the product can be stored in the storage area.

See also:

Storage Areas

Storage Area Connectors

Storage Areas Board

🔆 User Defined Fields have been Refactored

⚠️ Alert

This is a breaking change to integrations that use User Defined Fields. This is the first step in moving toward fully integrating custom fields into the integration and field mappings interface. 

In this version, the following changes will impact the integration and import of UDFs:

All UDFs must be defined as independent objects via User Field Mappings

For example, if a "UPC Code" UDF should be applied to both Jobs and Operations, there will need to be two definitions: one with the Job type and one with the ResourceOperation type. The External Id's need to be unique between them, but the Name can be the same.

When importing the user field on an associated object, only the field ExternalId and Value should be imported rather than name, value, data type, and display in UI boolean

field_externalid~value

User Field properties are now defined in a separate object called a UserFieldDefinition. Properties of each definition include: External Id, Name, UDF Type, Object Type, Default Value, and various flags. Having the User Fields defined in a central table will allow the integration to only import the External Id</div>
        </section>
      <h2 id="cat-software-releases-roadmap-software-installation" class="category-header">Software Releases &amp; Roadmap &gt; Software Installation</h2>
        <section class="article" id="article-225-software-installation-and-upgrades">
          <h3 class="article-title">Software Installation and Upgrades</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/software-installation-and-upgrades-302" target="_blank">Source</a></p>
          <div class="article-content">Navigate to the software installation pages here: Installer Downloads</div>
        </section>
      <h2 id="cat-software-releases-roadmap-upgrade-guides" class="category-header">Software Releases &amp; Roadmap &gt; Upgrade Guides</h2>
        <section class="article" id="article-197-upgrading-from-12-1-x-or-12-2-x-to-12-3-x">
          <h3 class="article-title">Upgrading from 12.1.x or 12.2.x to 12.3.x</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/upgrading-from-12.x-to-12.3.x" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

Software release version 12.3.0 introduces a significant new data structure in Storage Areas that impact all users and companies upgrading their data models from older Version 12 versions to 12.3.0 and newer. Use this guide to consider how your implementation and integration may be impacted by the changes.

Jump to section:

Import Database Updates

Storage Areas & Item Storage

Basic Storage Area and Item Storage

Tank Resources

On-Hand Inventory

Purchase Orders & MRP

Lot Controlled Planning & Shelf Life

Resource Setup

Capacity Intervals

Operations and Activities

Setup Codes

Tank Post Processing

Resource Requirements

Material Requirements

Products

Resource Connectors

Product Rules

User Defined Fields

Publish Database Updates

Import Database Updates

A best practice of any integration is to have the import database match 1:1 with PlanetTogether's import mappings tables. This isn't always practical and is not required and is a more involved process to organize the data into the latest table structure, but if your project has the time and flexibility to adopt the latest import database schema, use the provided schema and comparison files to fill in the gaps and/or update your existing import database:

Database Schema File

Download the database schema file here: 

Version
File Download

12.3.0.94
 StandardImportDBSchema_12.3.0.94.sql

Database Schema Comparison

Compare import database schemas between versions to clearly see what fields and tables have been added, removed, or updated:

Versions
File Download

12.2.1.129 vs. 12.3.0.94
 ImportDBSchemaCompare_12.2.1_vs_12.3.0.xlsx

Storage Areas & Item Storage

Storage Areas represent areas within a Warehouse where items can be stored. They are primarily introduced to improve PlanetTogether's tank modeling and scheduling solution since they can optionally be configured with constraints that are enforced during scheduling.

Even if Tank resources are not part of an existing data model, Storage Areas are required new objects. Every Warehouse in the data model must contain at least one Storage Area, and Items must be configured to be stored in at least one Storage Area.

Notably, none of the operation stock material or product data points need a storage area defined, so those objects do not need updated with storage area data.

Basic Storage Area and Item Storage

To upgrade with the minimum amount of effort, recycle existing Warehouse and Inventory data and map it to the new Storage Areas and Item Storage mappings.

✅ Example

My data model gets Warehouse data from the import table called "Warehouses".

It gets Inventory data from the import table called "Inventories".

I can map each Warehouse as a Storage Area by configuring Storage Area import mappings to fetch data from the Warehouses table and mapping appropriate fields.

I can then map Inventory records as Item Storage records to store all Warehouse inventories in the Storage Area.

Be sure to include Storage Areas and Item Storage in the Inventory Objects to Include section of the import mappings configuration:

Tank Resources

Tank resources complicate things a bit. In order to get the same behavior from old versions in the new version, each tank resource must be modeled as both a Resource and a Storage Area, and a Storage Area Connector should establish an in-flow connection between the two. Additionally, any items that get stored in the tank storage area must be mapped via Item Storage Mappings.

The path of least resistance here is to create a standard Table or View for each of Storage Areas, Item Storages, Storage Area Connectors, Storage Area Connector In, and Resource Storage Area Connector In data. The idea is to link a Resource to a Storage Area via a Storage Area Connector to allow that resource (and only that resource) to supply the Storage Area with material. This enables storage tracking and visibility from the Gantt and Storage Areas board. Each Storage Area should also be configured for Single Item Storage in order to emulate old storage tank behavior where only a single item was allowed to be stored in the tank at any given time.

✅Example

A brewery model with 16 Tank resources has them imported as both Resources and Storage Areas. Each of the Storage Areas reside in the same Warehouse, though this is not a requirement. Each Tank Storage Area is configured for Single Item Storage.

Create one Storage Area Connecter per Storage Area, then map StorageAreaConnectorIn and ResourceStorageConnectorIn logic to each connector where the Resource and Storage Areas share the same ExternalId's.

Finally, for each Item or Inventory that can be stored in each Tank, map an Item Storage association. Note that it may require mapping the same items to multiple Storage Areas if an item might be eligible to be stored in more than one tank.

Be sure to toggle on each of the appropriate Storage Area objects to import in the mapping wizard.

On-Hand Inventory

All inventory production, including on-hand inventory, are stored as Lots within Storage Areas. Lot codes are not required. With this in mind, in order to import on-hand inventory it must come into the system as a lot. This currently requires two separate sets of mappings:

Lots Mappings: Create the on-hand lot object here. If your model does not already utilize a Lots table, consider importing on-hand lots from the Inventories table where the OnHandQty field used to exist. In these cases, you might also consider filtering to only import lots when the OnHandQty is greater than 0 since it is not valid to import a lot with 0 quantity. A simple way to set the Lot ExternalId is to use the ItemExternalId.

Item Storage Lots Mappings: Assign each on-hand lot a quantity and a storage area here. Again, if Lots were not previously being imported then these Lot fields can be imported from the Inventories data where OnHandQty is greater than 0.

Purchase Orders & MRP

Purchase Orders (Purchases to Stock) now require a Storage Area ExternalId to be defined. If Purchase Orders are being imported, be sure to update the Purchases to Stock Mappings table with the Storage Area ExternalId data.

If your data model uses PlanetTogether's MRP functionality and specifically its option to Generate Purchase Orders to Satisfy Demand and Material Requirements, then each purchased Item will need a new property assigned from the Inventory Mappings: PurchaseOrderSupplyStorageAreaExternalId. Set its value to the appropriate Storage Area ExternalId where the generated Purchase Orders should be stored.

Lot Controlled Planning & Shelf Life

If any of your items or inventories were previously lot controlled, note that the LotUsability property has been removed. In this software version, all inventory is stored in Lots, so technically all inventories are now lot controlled. Lot codes and pegging is still optional.

The system now tracks shelf life of all items as well. If the ShelfLifeHrs property of the Item is greater than 0, then production of the item will expire after the number of shelf life hours has passed since the lot was produced.

In order to mimic the old LotUsability setting of ShelfLifeNonConstraint which allows expired material to be consumed, you must now set the AllowExpiredSupply property on the Operation Material Requirement to True. This will prevent those inventory lots from expiring and will give visibility into scheduled expired material consumption in the Materials board grid.

For more information, see: Lot Controlled Planning.

Resources Setup

Resource configurations have been modified to accommodate changes made to simplify how Operation Setup can be configured. The most notable change is the removal of the SetupIncluded property in favor now of boolean values:

UseResourceSetupTime: If true, the specified Resource Setup (Resource.SetupHrs) will be factored in when calculating the scheduled setup of each operation that schedules on the resource.

UseSequencedSetupTime: If true, Operation Attributes of operations scheduled on the resource will be factored in when calculating the scheduled setup.

Notably, the UseOperationSetupTime property still functions as it did before. If true, the specified Operation Setup (Operation.SetupHrs) of operations scheduled on the resource will be factored in when calculating the scheduled setup.

Be sure to set any of these to True if the resource needs to factor in these variables to schedule setup time on its scheduled operations.

Capacity Intervals

A small change is made to Capacity Intervals that may impact your implementation. The CleanOutSetups property is renamed to ResetAttributeChangeovers but serves the same purpose. If you were previously setting this to True on any of your recurring or non-recurring capacity intervals, be sure to set the new property name to True instead.

Operations and Activities

Setup Codes

Operation Setup has been slightly simplified/consolidated. The SetupCode property is removed (as are the accompanying Setup Code Tables) in favor of using Attributes to achieve sequence-dependent setup.

Tank Post Processing

With Tank Resources removed or refactored, the Operation TankPostProcessingHrs field and its associated Tank Post Processing production process are removed. Cleans most accurately represent what was Tank Post Processing, but for added flexibility a new Storage process has also been added.

Resource Requirements

Job operation Resource Requirements are updated to accommodate the removal of the Tank Post-Processing process noted above. Specifically, the UsageStart and UsageEnd properties no longer support the StoragePostProcessing or StorageClean options. To accommodate this, replace the StoragePostProcessing and StorageClean requirement usage start and end settings with either Clean or Storage depending on your strategy to adapt your tank modeling solution.

Material Requirements

If using MO Production Overlap, the former UseOverlapActivities property has been removed and a new MaterialUsedTiming property is added. These are the new options to model overlap using MaterialUsedTiming:

DuringSetup: Material is required evenly over the duration of the setup. The item's TransferQty will be used if set. If a Storage Area Connector is required, it will be used during the duration of setup.

ByProductionCycle: A portion of the material is required at each production cycle start. The quantity is the ratio of the material requirement TotalRequiredQty and the Operation RequiredFinishQty. Issued material will be omitted from the initial cycle's requirements. If a Storage Area Connector is required, it will be used during the duration of production.

LastProductionCycle: All material is required on the final operation cycle start.

FirstAndLastProductionCycle: Confirms that the first cycle has enough material and that all remaining material is available for when the last cycle starts. This can be used when the material overlap doesn't need to check every cycle, but the consuming operation is delayed by the first production cycle material and delayed by the full required material at the end of the operation.

The one that most closely mimics the old software behavior is the ByProductionCycle property, although you may get similar (often identical) scheduling results and improved optimize performance by using the new FirstAndLastProductionCycle option.

Products

Since tank resources are refactored, the StoreInTank property of the Operation Product has been removed. New StorageAreaExternalId and RequireEmptyStorageArea properties should be used to mimic former tank material production and storage using the new tank storage areas.

Resource Connectors

Resource Connectors are simplified to only support connections between predecessor and successor operations of the same manufacturing order and the resource(s) that the successor is eligible to schedule on. It can no longer be used to constrain which resources are eligible to consume material from other resources since that was a functionality of tank resources. In order to model material-linked connections, Storage Area Connectors must be used instead.

Similar to material-linked resource connectors, each Storage Area Connector represents a single pipe flow from a storage area to a consuming operation. If more than one operation are eligible to schedule to consume material from a storage area simultaneously, then two or more connectors are required (however many simultaneous connections are allowed).

To configure a material link between a storage area and a resource, first create or define the Storage Area Connector, then configure or map each of the Storage Area Connector Out and Resource Storage Area Connector Out settings where the Storage Area Connector Out defines which storage area(s) the material is stored in and the Resource Storage Area Connector Out defines the resource(s) which are eligible to consume material from the listed storage area(s).

⚠️ Note

Unlike previous connectors which reserve capacity across all resources for the duration of an operation's scheduled work, Storage Area Connectors are only considered in use while an operation is actively consuming material from it. With this in mind in regard to material-linked connectors, it's required to set the new MaterialUsedTiming field on the stock material requirement to some value that results in the material being consumed from the storage area for the duration of the running operation. For example, the setting to consume material ByProductionCycle will force the connector to be used for the duration of each production cycle of the operation so that no other operation can schedule at the same time to use the same connector.

✅ Example

My tank resource only has two connected pipes, so its contents may only be consumed by two operations simultaneously.

Here is the storage area connector configuration (each connection configured identically):

I have one production job which stores material in the tank resource.

I have three packaging jobs which each must source required material from the tank, and I have three packaging resources capable of packaging the material. Each of the job operations' stock material requirement are configured to consume material by production cycle (MaterialUsedTiming = ByProductionCycle).

When the work schedules, only two of the packaging jobs are allowed to run simultaneously. The third must wait for the pipe connection to be available before it is allowed to schedule to consume material from the tank resource, even though it has capacity to schedule earlier.

Product Rules

A small change to product rules was made to rename the OperationCode property to ProductCode so that it matches the Operation property of the same name. Be sure to update your mappings if you were previously using the OperationCode property.

User Defined Fields

Two major breaking changes are introduced in how User Defined Fields are modeled:

All UDFs must be defined as independent objects via User Field Mappings

For example, if a "UPC Code" UDF should be applied to both Jobs and Operations, there will need to be two definitions: one with the Job type and one with the ResourceOperation type. The External Id's need to be unique between them, but the Name can be the same.

When importing the user field on an associated object, only the field ExternalId and Value should be imported rather than name, value, data type, and display in UI boolean

field_externalid~value

Notably, User Fields are published as columns now using the User Field ExternalId instead of Name + UDF. If "U</div>
        </section>
      <h2 id="cat-software-releases-roadmap-version-12-introduction" class="category-header">Software Releases &amp; Roadmap &gt; Version 12 Introduction</h2>
        <section class="article" id="article-290-new-functions-features">
          <h3 class="article-title">New Functions &amp; Features</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/new-functions-features" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

Desktop Application Enhancements

Schedule Optimization Enhancements

Server Management Enhancements

Desktop Application Enhancements

Complete User Interface Redesign

Dock-able Boards with tiles; smart tabular navigation; sidebars navigation; status panels and more bring a sleek, modern look to the Client User Interface. For details and screenshots, see: Modern User Interface

User Permissions Management

Create permission groups and assign users to those groups for easier permissions management.

See also:

User Management

Grid Enhancements

More advanced filtering and sorting tools are now available, and grid columns and cells can have conditional formatting applied to them. Grids now load dynamically so there is never a need to manually refresh or reload a grid to see updated data.

See also:

Grid Personalization

Editable Grids

Most object properties are now editable directly in the main grids of each board that displays data object properties (Customers, Jobs, Inventory, Sales Orders, Purchase Orders, etc.). Simply toggle a new Edit Mode on and any editable fields which are visible in the currently selected layout will be available for editing. Non-editable fields will be grayed out. 

See also:

Grid Edit Mode

Metrics and Targets

Formerly called "grid alerts", defining Metrics allows users to quickly see if jobs, materials, or inventory items match filtering criteria to provide a quick analysis of schedule changes and their impact. Metrics can be created based on any grid property filter criteria defined. Each metric can optionally be given targets (goals) which allows for quick assessment of whether or not your targets are being met for each metric.

See also:

Layouts, Metrics, and Targets

Configurable Gantt Views

Create and save as many custom Gantt views as make sense for your users and your organization. Configurable Gantt views allow you to choose which resources get displayed in the Gantt and in which order, and quickly switch from one saved view to another.

See also:

Plant View Settings

Bulk Property Editors

Many boards have an object Bulk Edit tile which allows users to make changes to any editable property and apply the changes to one or more objects at the same time.

See also:

Object Bulk Edit Tiles

Predictive KPIs

Create your own KPIs to keep track of what matters most to you and your organization. You may now create up to 10 KPIs per Board (formerly "Views") for any number of factors based on your data within the planning horizon as presented in each of the Board grids.

See also:

Predictive KPI Tiles

Sales Orders: Late Analysis Properties in the Sales Orders Grid

Gather insights into how many Sales Orders are being delivered late with all new "Late" analysis properties offered in the Sales Orders grid.

See also:

Sales Orders Board

Capacity Planning Analytics

Tools and analytics to help plan capacity. Both Machine capacity and Worker schedules. Plan daily worker capacity, holidays, breaks, and planned maintenance. 

See also:

Capacity Planning Board

Scenario Management

Manage and share multiple scenarios with new scenario options and sharing permissions. Switching between scenarios is now faster, and there are more tools available for comparing scenarios within existing views to allow you to easily see differences in Metrics, Predictive KPIs, KPIs, and more.

Load and unload scenarios from memory to improve the desktop application performance.

See also:

Scenario Management

Workspace Profile Management

Managing and sharing user Workspace Profiles has been redesigned to allow full or partial Profile sharing (think: only import Metrics and Layouts from another user's Workspace Profile). Auto-save options are now available to save Workspace Profiles to user's local machines or to the server where they can be shared with others.

Server administrators will also be able to choose a standard default workspace for all users of an instance at the time the instance is created.

See also:

Workspace Profiles Dashboard

Notification Slides

Users are prompted with success and failure messages of their actions via Notification Slides which appear at the bottom of the screen. Settings can be configured to preserve or automatically hide these messages after a specified duration depending on their severity.

See also:

User Settings

Auto-save settings & configuration changes

Users can opt to auto-save their changes to most settings and configurations to help save time trying to find a Save button.

See also:

User Preferences

Sign-In Manager Application

The new Sign-In Manager application offers simple integration with various SSO providers and offers statistics and visual aids related to each of the instances that users frequently connect to.

See also:

Client Sign-In Manager Application

Configurable Time Zone Settings

Configure the time zone at the Instance and/or User level to ensure all schedulers around the globe are scheduling using the appropriate time zone.

See also:

User Preferences

Schedule Optimization Enhancements

Optimization Enhancement: Schedule Highest Scoring Resource First

An enhancement has been made to the standard optimization logic whereby all resources with capacity at any point in time during optimization will be considered eligible to schedule the next operation. All operations which are released to schedule on all resources with capacity will be scored per each of the available resources. The operation with the highest optimization score will be scheduled on whichever resource it scores highest on.

This behavior will help to improve resource selection during optimization. A practical example: If two or more resources are capable of scheduling the same operation at the same point in time, then the resource with the higher optimization score will be selected to schedule the operation. In previous software versions, the optimization engine would choose a specific resource and force something to schedule on that resource, even if there is only one eligible operation and if that eligible operation would score better and schedule better on another available resource.

See also:

Optimization

Optimization Rule Enhancements

Optimize rules/factors can be more easily weighted against each other with a new simple scoring system. New analytics offer insight into how the scores impact scheduling. Certain factors can be given negative weight to count against a score.

See also:

Sequence Planning Board

New Item Storage Options for Tank Modeling and Scheduling

Storage Areas are introduced as a new required data object. They represent an area within a Warehouse where material is stored. Each Warehouse must now have at least one assigned Storage Area. Storage Areas use Item Storage mappings to define properties for which items can be stored in each Storage Area and how they can be stored.

These are meant to replace Tank Resource objects and come packaged with many optional constraints that enable more accurate modeling of how storage tanks and silos are scheduled in PlanetTogether.

Storage Areas can constrain how material is stored in a warehouse. This can be general unconstrained floorspace, storage bins, tanks, silos, etc.

All scheduled and planned material must be stored in a Storage Area

A new Storage Areas board shows inventory levels per item per storage area over the course of the schedule. This is different than the inventory plan as it will not show Forecast demands or shortages which remain at the inventory (warehouse) level.

Storage Areas can constrain the flow of material by the number of simultaneous sources. Limits can be defined for simultaneous withdrawal, storage, and the combination of both.

Storage Areas can be constrained to store a single material at a time to model single-item storage bins or tanks

A new Item Storage object is added which extends inventory properties for each Storage Area. An item stored in a storage area is considered Item Storage. Similar to how Inventory contains properties for items within a specific warehouse, Item Storage contains properties for items stored in a specific Storage Area.

An item storage must exist for every item that can be stored in the storage area

An item storage may optionally define a maximum quantity of the item that can be stored in the storage area at any time

An item storage may optionally define a minimum limit to maintain material in the Storage Area. If the quantity ever goes below this quantity, the remainder will be disposed.

An item storage may optionally indicate whether the material will be disposed of immediately upon meeting the disposal requirement (time or quantity), or if the material should only be disposed if needed to make room for other storage.

See also:

Storage Areas

Storage Area Connectors

Storage Areas Board

New operation process: Clean

Operations may now be configured with a Clean process. Cleans are scheduled to run after operation post-processing and may be configured to be sequence-dependent, much like operation Setup.

Cleanout Triggers

Cleanouts can be triggered to schedule after a certain number of operations are scheduled on a resource, some number of Production Units are scheduled to be produced by a resource, or after a combined total run/cycle time of one or more operations scheduled on a resource, or after a certain duration of calendar time.

Cleanout Grade

Cleanout grade is a new field related to the new Clean process. When multiple cleans need to be scheduled simultaneously, the highest grade takes precedence. If two cleanouts of the same grade are scheduled together, the longest duration is used. When a cleanout occurs, it resets all cleanout triggers that are the Cleanout Grade or lower. For example this can be modeled with a Minor cleanout of 0 and Major cleanout of 1.

For more information, see: Cleans.

Attributes redesign for more robust functionality

Attributes have been redesigned to accommodate both dynamic operation Setup and dynamic operation Clean processes.

Attribute definitions are now imported in a new Attribute Mappings table as stand-alone objects

OperationAttributes must reference an Attribute definition when imported

Attribute definitions contain default durations, colors, and costs that can be overridden in each operation to support operation specific changeovers

Attributes have a new AttributeType field to indicate whether the changeover values are for setup or for clean

Resource Attributes are removed. Custom resource properties can be added as User Defined Fields (UDFs), and resource attributes will no longer be used for tracking sequence and setups. A new LastRunActivity mappings is created to import details of the last run activity on the resource. The attributes for that activity's operation will be used for sequence dependent setup and clean calculations.

For more information, see: Attributes.

Options to Optimize Selected Jobs or Resources

Actions tile and right-click menu options are added to the Jobs, Gantt, Capacity Planning, and Activities boards to:

Optimize Selected Jobs: Optimize only the selected jobs. All other scheduled jobs are locked and anchored and unscheduled jobs are flagged with Do Not Schedule temporarily while the selected jobs get optimized. After optimization, all previously unlocked and unanchored jobs are reverted to unlocked and unanchored again, and the Do Not Schedule flag is removed from previously unscheduled jobs.

Optimize Selected Jobs and Supplying Jobs: Optimize the selected jobs as well as the currently scheduled jobs which are supplying the selected jobs with one or more materials. All other scheduled jobs are locked and anchored and unscheduled jobs are flagged with Do Not Schedule temporarily while the selected jobs get optimized. After optimization, all previously unlocked and unanchored jobs are reverted to unlocked and unanchored again, and the Do Not Schedule flag is removed from previously unscheduled jobs.

Reschedule Resource: Optimize all jobs scheduled on the selected resource. To include multiple resources in the optimization, select multiple grid rows from the Capacity Planning tile and use the Actions tile or right-click menu from this board to optimize jobs scheduled on the selected resources. All other scheduled jobs are locked and anchored and unscheduled jobs are flagged with Do Not Schedule temporarily while the jobs on the selected resource(s) get optimized. After optimization, all previously unlocked and unanchored jobs are reverted to unlocked and unanchored again, and the Do Not Schedule flag is removed from previously unscheduled jobs.

Auto-Split Operations

Operations may be split into two or more activities automatically during optimization based on many configurable factors. Splitting operations allows the work to be spread across multiple resources in order to complete the work faster (as each split part may be run in parallel), or can be used to split the work across gaps in resource capacity. Splitting can also be used to break larger operations down into smaller parts so that each part may comply with maximum quantity or volume constraints across capable resources.

Auto-split can configured to split based on many factors:

Resource Quantity or Volume constraints

Capacity of the Primary resource when an operation requires one or more helpers

Predecessor material quantity and availability

For more information, see: Auto-Split Operations.

Compatibility Codes redesign

Compatibility Code Tables define lists of Operation Compatibility Codes which are either allowed or disallowed to schedule simultaneously within a group of resources. Resources may be assigned one or more Compatibility Code Tables, and each table may be assigned to any number of resources.

This is an enhancement from previous software versions which only supported scheduling a single allowed code at a time.

See: Compatibility Codes.

Alternate Path Validity Dates

New properties ValidityStartDate and ValidityEndDate are added to <a href="https://www.planettoge</div>
        </section>
      <h2 id="cat-troubleshooting" class="category-header">Troubleshooting</h2>
        <section class="article" id="article-208-delivering-files-to-planettogether-support">
          <h3 class="article-title">Delivering Files to PlanetTogether Support</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/deliver-files-to-support" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

PlanetTogether Support Agents may request files to be delivered in order to help them troubleshoot issues reported to them. All of the file deliverables mentioned in this guide require access to the files on the PlanetTogether server.

Note: PlanetTogether’s HighTail file upload portal is located here: https://spaces.hightail.com/uplink/planettogether

Jump to section:

Scenario file (scenarios.dat)

Recordings folder

Alerts folder

Instance Error Logs

Windows Event Viewer Logs

Customizations

Database backup

Scenario File (scenarios.dat)

Overview

In PlanetTogether, Scenarios contain all the data for the factory model, including plants, departments, resources, items, inventories, operations, and financial information. The Support team may request the scenario file if they are unable to replicate the reported issue in a simple data model.

Steps to deliver

From the Client Application

Users with appropriate user permissions may see an option from the client interface to download the latest scenario file. Login to the client and click the PlanetTogether logo in the top right corner to expand a dropdown, then choose the Download Scenario option.

Select a disk location to save the file and click Save.

Upload the resulting scenario file to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

From the Server

Navigate to the instance installation folder on the server. From the Instance Manager, edit the instance settings and view the "Backup" tab for a quick Copy Path option. Copy the path and paste it into a Windows File Explorer address bar.

From the instance System folder, navigate to Data ➡️ Recordings then into the Recordings folder that was most recently modified.

Locate the TIMESTAMP.scenarios.dat file with the most recent Date Modified date and right-click the file and choose Send to ➡️ Compressed (zip) folder (or if 7-Zip is installed, use 7-Zip ➡️ Add to TIMESTAMP.scenarios.7z for better compression).

Attach the resulting compressed file to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Recordings Folder

Overview

Recordings folders provide vital debugging information as to what may have contributed to a system issue by "Recording" each step that each user takes when interacting with the software. Those steps can then be replayed later to replicate or re-run the steps taken to produce the error or issue.

Recordings can also serve as backup scenario files. Follow the steps described in this document to restore the current scenario from one of the scenarios that are saved in a Recordings folder: Restore a Scenario from a Recording Backup.

Steps to deliver

1) Navigate to the instance installation folder on the server. From the Instance Manager, edit the instance settings and view the "Backup" tab for a quick Copy Path option. Copy the path and paste it into a Windows File Explorer address bar.

2) From the instance “System” folder, navigate to "Data" -> "Recordings"

3) Locate the Recordings folder with the appropriate date and timestamp around the time that the steps were taken in the software. Right-click the folder and choose "Send to" -> "Compressed (zipped) folder" (or if 7-Zip is installed, use "7-Zip" -> "Add to FOLDER_NAME.7z" for better compression).

4) Attach the resulting compressed file to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Alerts Folder

Overview

Alerts folders contain log files which log user activity and details of errors that users may encounter as they use the software. The message logs can help the PlanetTogether Support and/or Development team to quickly diagnose a problem that users may be experiencing.

Steps to deliver

1) Navigate to the instance installation folder on the server. From the Instance Manager, edit the instance settings and view the "Backup" tab for a quick Copy Path option. Copy the path and paste it into a Windows File Explorer address bar.

2) From the instance “System” folder, navigate to "Data" -> "Alerts"

3) Select all files from within the Alerts folder ("Ctrl+A" is a quick keyboard shortcut). Right-click on any of the highlighted files and choose "Send to" -> "Compressed (zipped) folder" 

4) Attach the resulting .zip file to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Instance Error Logs

Overview

The instance error logs contain error messages that get logged during instance management (starting and stopping services, editing settings, etc.). The error messages can help the PlanetTogether Support and/or Development team to quickly diagnose a problem that a server administrator may be experiencing.

Steps to deliver

1) Navigate to the Instance Manager

2) Click once to select the instance whose logs need analyzed, then click the LOGS action button

3) From the Logs dialog, click the Download Logs button and choose a place to save the resulting .zip archive

4) Attach the resulting .zip archive to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Windows Event Viewer logs

Overview

Windows Event Viewer logs provide insights from Windows as to why applications may crash or produce other critical errors or warning messages. These can be helpful in diagnosing PlanetTogether services or applications crashing unexpectedly. Follow the Steps to Deliver below to isolate, zip, and deliver the appropriate Windows Event Viewer log entries.

Steps to deliver

1) Open the Windows Event Viewer

The easiest way to find the Event Viewer is to use the Windows search function in the main toolbar. Search for "Event Viewer" and it should appear as the top result. Alternatively it may be found as a shortcut somewhere in your start menu. Otherwise it's found in the "system32" folder of the hard drive where Windows is installed on the server/PC.

2) Navigate the Event Viewer to find Warning and Error messages from around the time of the crash or failure

From the Event Viewer interface, expand the "Windows Logs" folder from the left menu and select "Application". You may choose to filter the results to only show Warning or Error messages using the "Filter Current Log..." dialog from the menu on the right side, but this is not necessary (only reduces the amount of scrolling). Scroll through the logs until you see entries from around the date and time of the incident in question and focus on any Warning or Error log entries.

If none are found in the "Application" logs, try the "System" logs from the "Windows Logs" dropdown in the left pane and repeat.

3) Select each relevant warning and/or error message and save to a file

Click to highlight each warning or error message that you suspect may be relevant to the error or incident in question. Press and hold Shift or Ctrl while you click in order to select multiple entries. Once all are selected, right-click on any of the selected items and choose the option to "Save Selected Events...". Choose the file location and name and click "Save" when prompted.

4) Attach the resulting .evtx file to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Custom Package Files

Overview

Custom package or "extension" files may be requested if they are suspected to be at fault for causing an issue on your system. The most common reason that a PlanetTogether Support agent might need your custom package file(s) is so that the PlanetTogether Development team can diagnose and fix any outdated or malfunctioning logic from within the custom coded file(s).

Steps to deliver

TBD...

N) Attach the resulting .zip file to an email to support@planettogether.com, or for larger files upload them directly to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether 

Database Backup Files

Overview

A PlanetTogether Support agent may request SQL database backup files from you if your issue seems to be related to your specific data, or if they think it might be easier diagnosed if they had access to your data. If you don't feel comfortable sharing the SQL backup for any reason, please try to be available for a Support agent to meet with you in a Zoom or similar screen-share meeting where we might be able to run various SQL queries and tests on your system directly with your supervision.

We may need either a backup of your Publish database or your Import database depending on the type of issue you're experiencing. In both cases we will also need your scenarios.dat file, and in the case that we need your Import database we will also need an additional file that contains the Import Mappings data. Continue reading for specific steps to deliver the requested files:

Steps to deliver

1) Create a full database backup from the Microsoft SQL Server Management Studio application in .bak format according to the steps provided by Microsoft in this document: https://docs.microsoft.com/en-us/sql/relational-databases/backup-restore/create-a-full-database-backup-sql-server

2) Follow steps above to locate and retrieve a copy of your scenarios.dat file.

3) If you're preparing to deliver your Import database to the PlanetTogether Support team then please also include the file named "APSInterfaceSettings.xml" from the same Instance folder as you found the scenarios.dat file:

PlanetTogether\INSTANCE_NAME\IntegrationFiles\APSInterfaceSettings.xml

4) Compress the db.bak, scenarios.dat, and APSInterfaceSettings.xml files into a single .zip file and upload it to the PlanetTogether HighTail portal which automatically gets submitted to the Support team: https://spaces.hightail.com/uplink/planettogether</div>
        </section>
      
        <section class="article" id="article-330-software-assembly-version-detector">
          <h3 class="article-title">Software Assembly Version Detector</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/software-assembly-version-detector" target="_blank">Source</a></p>
          <div class="article-content">Key Concept

In old software versions (12.2.1.x Neptune and older), if users open a scenarios.dat file in Notepad, the last line of text would indicate which software version the scenario file was written in. This is helpful for QA and Support to understand what software version issues are reported in.

This functionality is lost with all Hydrogen 12.3.0.x builds.

In response, the PlanetTogether development team has created a simple application that can read a file property that determines the software version that the file was created in.

Installation and Usage

Download the application .exe and store it anywhere on your local drive:

PTAssemblyVersionReader.exe (147 MB)

Just open/run the .exe executable whenever you need to scan a scenarios.dat file to determine which version it was run in. To use the application, drag and drop the scenarios.dat file into the white area at the top of the application interface and its meta data will appear in the gray area below.

Use the Reset button to clear the inputs and results from the application, if desired.</div>
        </section>
      <h2 id="cat-troubleshooting-common-issues" class="category-header">Troubleshooting &gt; Common Issues</h2>
        <section class="article" id="article-318-troubleshoot-client-sign-in-manager-application">
          <h3 class="article-title">Troubleshoot: Client Sign-In Manager Application</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/troubleshoot-client-sign-in-manager-application" target="_blank">Source</a></p>
          <div class="article-content">Case Study: Unable to Connect to a Server

If users are unable to establish a connection to the server then they won't be able to connect to the workspaces hosted there.

Causes & Troubleshooting

1. Incorrect server name or connection string

This issue may be accompanied by a simple error message:

Failed to connect to server.

From the Add Workspaces section of the Sign-In Manager, the server name or connection string should be entered without a protocol or port number. Simply "localhost" from the server itself or the server name by itself will suffice.

2. Invalid or expired SSL certificate

This issue may be accompanied by this error message:

Certificate is expired. If you are an IT administrator click here for more information.

In these cases, it's most likely the case the user has not properly configured the SSL thumbprint in the Client Sign-In Manager application. Navigate to the Options section of the Sign-In Manager and ensure a valid certificate thumbprint is entered.

It's also possible that the server doesn't have a valid SSL certificate installed and/or associated with the PlanetTogether software. A server administrator may access the "Server" section of the Instance Manager and select an appropriate certificate if one is already installed on the server that can be used.

If one is not yet available, one can be purchased from a trusted authority or an insecure self-signed certificate can be generated. See Generate a PlanetTogether Self-Signed Certificate for more information.

If a purchased certificate signed by a trusted authority is installed on the server then users that connect to it do not need to configure the SSL thumbprint in their Client Sign-In Manager application. Otherwise, if the certificate is not secure and was self-signed and/or self-generated then users will need to store the certificate thumbprint in their Client Sign-In Manager application before they can connect to it.

Case Study: Unable to login to a Workspace

If users try to change the login credentials from the Workspaces section of the Sign-In application then they may receive "Invalid Credentials" messages if the login credentials are not correct. If entered incorrectly too many times, the user account may get locked and a user administrator must unlock it.

Causes & Troubleshooting

1. Invalid login credentials

This issue will be accompanied by a simple error message:

ERROR 2454: Invalid login Credentials.

A user administrator may reset the user's password as needed from the Users section of the client interface (see: User Management). Alternatively, a server administrator may reset the user's credentials from the Instance Manager.

2. The user's account is locked

This issue will be accompanied by the following error message:

Unknown Error: 2459

 In this case, a user administrator must toggle the [x] Unlock Account option in the User Management section of the client interface. It might also be a good idea to reset the password from the same tile at the same time.</div>
        </section>
      
        <section class="article" id="article-349-troubleshoot-desktop-client-user-interface-display">
          <h3 class="article-title">Troubleshoot: Desktop Client User Interface Display</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/troubleshoot-desktop-client-user-interface-display" target="_blank">Source</a></p>
          <div class="article-content">Summary

Monitor display settings can cause layout issues in the PlanetTogether desktop client application.

Jump to section:

Monitor Scaling

Ease of Access Settings

Monitor Scaling

The monitor scaling factor of user's primary monitor is the greatest contributor to the display of the application. Unfortunately, due to the heavy integration with 3rd party developer DevExpress, the application only fully supports 100% scaled monitors. New monitors and especially 4K resolution monitors recommend and default to scaling around 150-250%, so users may have to reduce the scaling settings in order to view the application correctly.

From Windows Settings, navigate to System ➡️ Display. Select the primary monitor in the monitor selection section, then locate the Scale and layout setting. Ensure the setting is set to 100%, even if it is not the recommended scale setting. It may be necessary to repeat this step for each connected monitor.

Finally, restart the client application (logout and login again).

Ease of Access Display Settings

If the monitors are scaled to 100% but there are still display issues, other Ease of Use Windows display settings may be to blame.

From Windows Settings, navigate to Ease of Access ➡️ Display. Locate the Make text bigger setting and ensure that it's set to the smallest 100% value. Next, locate the Make everything bigger setting and ensure that this is also set to 100%, even if it is not the recommended setting.

Contact Support

If these steps have not helped to resolve the issue, or the issue that you are facing is not described here, please contact PlanetTogether Support to request assistance.</div>
        </section>
      
        <section class="article" id="article-218-troubleshoot-instance-manager">
          <h3 class="article-title">Troubleshoot: Instance Manager</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/troubleshoot-instance-manager" target="_blank">Source</a></p>
          <div class="article-content">Jump to case study:

Unable to connect to the Instance Manager

Unable to start an instance service

Case Study: Unable to Connect to the Instance Manager

A connection to the server cannot be established. This is often accompanied by a browser message similar to this one:

Causes & Troubleshooting

1. The PlanetTogether Server Manager service is not running

Navigate to Windows Services dialog and ensure the PlanetTogether Server Manager service status is Running.

If not, try to start it from the Services window. If it fails to start, check the Windows Event Viewer logs in Windows Logs ➡️ Application for related error messages to help troubleshoot further.

The most common reason why the PlanetTogether Server Manager service won't start or won't remain running is due to an invalid or incompatible SSL certificate selected during software installation. In order to remedy this in a test environment, it's easiest to generate a self-signed PlanetTogether certificate by running the following command from Windows PowerShell run as an administrator:

New-SelfSignedCertificate -DnsName PlanetTogether.local -FriendlyName PlanetTogether -CertStoreLocation cert:\LocalMachine\My

Once the certificate is successfully created, run the PlanetTogether Version 12 installer again, and be sure to click the Find Certificate button:

From the resulting dialog, choose More Choices and select the newly generated PlanetTogether certificate before accepting and proceeding to re-install all software components.

After re-installation completes, the PlanetTogether Server Manager service should be able to start and run.

Case Study: Unable to start an instance service

Instance services could fail to start for any number of reasons, and it's possible that no errors will be logged in the specific instance log folder. Typically, errors are likely to be logged in Windows Event Viewer with more details of why the service could not be started. Attempts to start the instance service from Windows Services directly will often produce the same result.

One common error is a timeout message. If an attempt to start an instance takes more than 30 seconds for the instance service to communicate back that it is at least still trying to start, an error message may popup in the instance manager:

The service did not respond to the start or control request in a timely fashion.

Another common error is that the "Port is already occupied". Each PlanetTogether instance occupies a single TCP port while its service is running. An instance service may fail to start if another instance or any other application on the server is using the same TCP port. An error message will appear in the top right corner when this issue is encountered when trying to start an instance:

It's also possible that the Server Manager version is not compatible to run an instance of the software version of the instance that is producing the error, or that the scenarios.dat file was created in a newer or older software version which is not compatible with the software version of the instance.

Causes & Troubleshooting

1. Another PlanetTogether instance is already running on the configured port

Check the System Service Port column in the Instances list and confirm that no other Started or Active instance is already running on the same port as the instance being started. 

If an instance is already running on the same port, either stop the instance service or edit the stopped instance to use a different port (one that is not already occupied by another instance).

2. The Instance Database Connection is not configured correctly

It has been observed (especially for new server installations) that the Instance Database configuration is not setup correctly which results in the Instance Manager and Server Manager not being able to properly communicate with the Instance services and as a result, the instance service(s) may be Running when observed from Windows Services, but Stopped when observed from the Instance Manager table of instances.

In these cases, it's advised to double-check the database connection settings and ensure that the defined SQL user or integrated security user has appropriate permissions to read and write to the database, including the ability to add or drop tables.

From the Instance Manager, navigate to the Server tab and click the button to Update Instance Database:

From the Instance Database Settings dialog, click Test to ensure the database connection is established successfully. If unsuccessful, update each setting or parameter until the Test returns a success message.

When the Test button succeeds, click Save and then Confirm if prompted to restart.

Scroll down to the bottom of the Server Settings page and click the Save button there as well.

Finally, open Windows Services and manually restart the PlanetTogether Server Manager service.

Upon successful restart, it should write out data to the instance database. The instance database consists of 3 tables:

Configuration

InstanceSettings

ServerSettings

Query each of these tables by selecting all rows from each. It's expected that the Configuration table has one row and only one cell of data (whose value is the current Server Manager version). The ServerSettings table should have one row of data which includes the server name, path to the server manager software installation location, SSL certificate thumbprint ID, and two SSO fields. Finally, the InstanceSettings should return one row of data per each instance that currently exists on the server. If any of these tables are missing data or if any of these tables do not exist, then it's likely that the SQL user or integrated security Windows User configured in the Instance Database Settings does not have proper read/write permissions. Per the Server Installation Guide, at minimum the user must have db_datareader, db_datawriter, and db_ddladmin permissions, though if deemed safe and appropriate, the db_owner designation works as well.

3. The SSL certificate was not installed correctly

If the server's SSL certificate was not installed correctly during the PlanetTogether server software installation process, it's possible that the certificate did not get bound properly to the PlanetTogether Server Manager port, so it can't read the instance service statuses. This would result in the instance service Running according to Windows Services, but Stopped according to the Instance Manager table of instances.

In these cases, it's recommended to force the Server Manager to apply or re-apply the SSL certificate configuration by following these steps:

Navigate to the Server section of the Instance Manager and scroll down and click the Choose Certificate button 

Even if there is only one option, select the radio option next to the appropriate certificate and click Accept 

Scroll down to the bottom of the Server Settings page and click Save to apply the certificate change 

Open Windows Services and manually restart the PlanetTogether Server Manager service

Once the service restart successfully, check the Instances page again to see if the instance statuses are accurately reflected in the grid.

4. Server Manager is configured to use Integrated Security, but the instance is not

When Server Manager is configured to use integrated security to communicate with the instance configuration database, each instance will also default to using integrated security for starting and stopping the service. In later 12.2.0.x releases, this is resolved by using the PlanetTogether Server Managers Windows service Logon As credentials for starting and stopping all instances, but in versions 12.1.4.x and early releases of 12.2.0.x each instance must also be configured to use a Windows user to run the instance service and the Windows user must have read/write access to the Instance Settings database.

Integrated security logon credentials can be modified in the Service Configuration section of the Instance Settings dialog, or from the Windows Services application via Properties ➡️ Log On ➡️ This account.

5. The instance version is not supported by the currently installed version of Server Manager

This is typically seen after server software upgrades when the user installing the updated software elects to Skip the installation/re-installation of Server Manager. It's always advisable to always upgrade Server Manager whenever installing a new version of the core software.

New versions of Server Manager are always backward compatible with old core software versions, so upgrading should not have any negative impact. As a quick step to rule out the possibility that the Server Manager version is incompatible, run the server software installer and choose to re-install Server Manager when prompted.

6. The scenarios.dat file was created in an incompatible software version

If attempting to start an instance from an existing scenarios.dat file, the scenario file must have been written in a compatible software version or else the instance service will fail to start. If the scenario file originated from a Version 11 instance, it must have been created in version 11.52.20 or newer. If the scenario file originated from a Version 12 instance, it must have been created in the same software version or an older software version than the version of the instance that it's trying to be loaded in to.

Contact Support

If these steps have not helped to resolve the issue, or the issue that you are facing is not described here, please contact PlanetTogether Support to request assistance.</div>
        </section>
      
        <section class="article" id="article-254-troubleshoot-instance-starting-in-read-only-mode">
          <h3 class="article-title">Troubleshoot: Instance Starting in Read-Only Mode</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/troubleshooting-read-only-mode" target="_blank">Source</a></p>
          <div class="article-content">Description

Certain license violations may cause an instance to load in read-only mode which will not allow the user to make any data or schedule modifications.

Note that most of these troubleshooting steps require a server administrator with access to the PlanetTogether server. For PlanetTogether Cloud hosted environments, please contact support for assistance.

A good place to start to diagnose these issues is the Logs dialog from the Instance Manager. Check for errors logged at the time the instance service was started to reveal clues of the underlying issue.

Jump to a Case Study:

License Cannot be Locked

Server is not automatically fetching new key files from PlanetTogether

Server Cannot Connect to PlanetTogether License Server

Multiple Running Instances Using the Same License Key

The License has Expired

Case Study: License Cannot be Locked

Overview

This is a fairly generic message which essentially means that the license is already in use.

*** Message *** 
License could not be locked.

A license key may only be used to run a single instance of PlanetTogether, so if other instances are running or try to start while another instance is running using the same license key, then this error may be logged.

There have been cases where there are no other running instances, but stopping the instance service doesn't properly unlock or release the license from the PlanetTogether License Service, so the license server thinks that the license is still in use when in reality it is not.

Troubleshooting

First and foremost, ensure that the license key is only in use by a single running instance. If the license key is used across multiple servers, be sure to stop all instance services from all servers, then proceed to only start the services of a single instance. For more tips in dealing with multiple instances, scroll down to the Multiple Running Instances Using the Same License Key section of this article.

If there are no other instances running, it's possible that the communication between the PlanetTogether host server and the PlanetTogether License Server was disrupted in some way. Often times, stopping all instance services for ~15 minutes will force the PlanetTogether License Server to release its lock on the license so that it may be used again.

Case Study: Server is not automatically fetching new key files from PlanetTogether

Overview

This case has no known cause and no errors are logged anywhere, but the fix is fairly simple. Instances that go into read only mode due to a supposed "expired license" even though the license is in fact not expired are prime candidates to try this quick fix to resolve the issue.

Typically a PlanetTogether server will fetch a new set of license key files from the PlanetTogether license server automatically at frequent intervals (at minimum each time the instance services are restarted). Occasionally the server either can't or simply doesn't try to fetch new files from the PlanetTogether server so it retains old files which contain outdated information (like an expiration date). In these cases, a forceful refresh may be necessary.

Troubleshooting

Force the server to fetch new license key files from the PlanetTogether license server by removing the existing key files from the current location, then start the instance services. When the services attempt to start the system will realize that no files are present and will fetch the latest files from the PlanetTogether license server.

Stop the instance service from the Instance Manager

Navigate to the license key folder for the instance

From the software installation location, the license key files are located in the INSTANCE_FOLDER\System\Data\Key directory 

Backup the files in the folder by selecting them all then right-clicking any of the selected files and choosing Send to ➡️ Compressed (zipped) folder 

Delete all of the files except for the newly created .zip backup

Start the instance services from the Instance Manager

The next time a user connects to the instance it should load normally if the license key files were downloaded properly (and the license isn't expired or in use elsewhere).

If the above process fails, try following the steps documented here to manually download and deploy a new set of license key files to the instance Key folder:

Manually Install License Key Files

Case Study: Server Cannot Connect to PlanetTogether License Server

Overview

If the server that hosts the PlanetTogether instance(s) is unable to reach the PlanetTogether license server to validate the license, then the instance will start in Read-Only Mode.

Troubleshooting

The server's connectivity to the PlanetTogether license server can be tested by navigating to the Licenses section of the Instance Manager:

If the Licenses table loads valid license data on this screen, then the connection can be established successfully and there are no firewall or proxy or other connectivity issues and this is not the reason that the instance is starting in read-only mode.

Otherwise, an IT administrator must check to make sure that the server is connected to the internet and that any firewall or anti-virus or proxy configuration is not blocking outgoing requests to either of these addresses and ports:

https://licenseserver.planettogether.net:45455

https://licenseserver2.planettogether.net:45455

For forwarding proxy configurations, note that the PlanetTogether Server Manager supports WinHTTP proxy configurations. If the host server is required to forward outbound traffic from installed applications through a proxy server, then the PlanetTogether host server's WinHTTP proxy must be configured to route outbound traffic to the PlanetTogether License Server domains through the forwarding proxy. This can be achieved by executing this command (with the appropriate proxy host name or IP and port) from an elevated command prompt:

netsh winhttp set proxy proxy-server="<proxy>:<port>" bypass-list="licenseserver.planettogether.net;licenseserver2.planettogether.net"

Manually Install a License Key

If it's expected that the server cannot and does not connect to the license server, then the license key files may be downloaded manually from the PlanetTogether License server, then extracted to the appropriate location on the server. This process is documented here: Manually Install a License Key

Note that there is a chance that the PlanetTogether license server goes down temporarily. If the local server is connected to the internet and no firewall or anti-virus rules are blocking connectivity to the addresses and ports mentioned above, please contact PlanetTogether Support to investigate any potential issues with the license server itself.

Case Study: Multiple Running Instances Using the Same License Key

Overview

Each PlanetTogether license is only allowed for single use, so if one license key is used to run the service of multiple instances then those which were not started first will start in read only mode. This may occur unexpectedly if a new instance was created using the same license key as a previous instance, or if multiple instances which share a license key are configured to [x] Automatically Start Services after Server Reboot in the Instance Settings and there was a recent server reboot, or perhaps during or after a migration to a new server if the old server was not properly updated to prevent the old instance from starting.

Troubleshooting

Stop all running instances across all servers which are using the license key, then start the service of only one instance. 

If multiple instances are needed to run simultaneously for testing or other purposes, additional licenses will be needed (one per instance). Contact the PlanetTogether Licensing team for assistance to provide additional test licenses. Note that there may be costs associated with the request which the Licensing team will be able to assess once the request is submitted. No requests will be fulfilled until all parties are in agreement on how best to proceed.

Case Study: The License has Expired

Overview

If the PlanetTogether license has expired then the instance will start in read-only mode.

Troubleshooting

Contact the PlanetTogether Licensing team for assistance in extending the expiration date of the license key.

Submit a Support Request

If the instance remains in read-only mode after following these troubleshooting steps, contact the PlanetTogether Support team for assistance. Please fill out all of the required fields, in addition to:

Details: Provide details of any changes which have been made to the model that could have caused the instance to go into read-only Mode. This can include changes made to the number of plants, resources, jobs, routings, items, etc.

Category: Select "License issue or Software is read-only."

File Upload: Please upload the latest scenario file.

See Delivering Files to PlanetTogether Support for step-by-step instructions.

See Also

Instance Manager

Manually Install License Key Files</div>
        </section>
      <h2 id="cat-troubleshooting-error-codes" class="category-header">Troubleshooting &gt; Error Codes</h2>
        <section class="article" id="article-352-error-codes">
          <h3 class="article-title">Error Codes</h3>
          <p class="source-url"><a href="https://www.planettogether.com/knowledge-v12/error-codes" target="_blank">Source</a></p>
          <div class="article-content">Jump to section:

2000-2050
2451-2500
2901-3000

2051-2100
2501-2550
3001-3999

2101-2150
2551-2600
4000-4050

2151-2200
2601-2650
4051-4100

2201-2250
2651-2700
4101-4150

2251-2300
2701-2750
4401-4450

2301-2350
2751-2800
7000-7050

2351-2400
2801-2850

2401-2450
2851-2900

Error Codes 2000 - 2050

Error Code
Description
Solution

0002
Error while updating the shop_ops DataSet for the CustomInterface.

2000
Multiple files are containing a PostSimulationCustomization in a specific folder. Only one can be specified.

2002
Failed to load PostSimulationCustomizer from a specific file.

2003
There is no Job in the Scenario with that specific External Id, so the status will not be updated in Shop Ops.

2004
There is no Manufacturing Order with that specific External Id, so Shop Ops will not update the status.

2005
There is no Operation with that specific External Id in for that Job and MO, so the status will not be updated in Shop Ops.

2006
The Operation is not an Internal Operation, so the status will not be updated in Shop Ops.

2007
The Activity with that specific External Id was not found in that Job, MO, and Op, so the status will not be updated in Shop Ops.

2008
Not set up to handle this type of block in status segments.

2009
Invalid Drag-Drop text. No valid DragDropType specified.

2010
Not set up to handle the linking of blocks from non-resource Operations.

2011
The Gantt has no Un-hidden hours!

2012
This should not happen because the top grid node should be visible.

2013
No Job was selected. Please select a Job for the Change Order. 

2014
The Options to specify a specific Planner are selected, but no Planner is chosen. Instead, please select a Planner or choose the option for Any Planner.

2015
Invalid BreakOff Qty of the product was specified for the MO.

2017
Invalid ValueOption specified.

2018
The 'From Resource' and 'To Resource' must be different Resources.
When setting up the resource connectors, you need to specify 2 different resources: 'From Resource' and one for the 'To Resource.' 

2019
The Select Column is not the right Type. It must be bool.

2020
Cannot use non-positive BucketDuration.

2021
Must have at least one row and one column.

2022
The specific Warehouse is not found on the Dock board but should be.

2023
It should not be set to null.

2024
Desynchronization occurred for the specific User on the Connection.

2025
The resource is not a Tank.

2026
This is not a recognized report file. Therefore, it must have a {0} suffix for Crystal Reports or a {1} suffix for Microsoft Reports.

2027
There is no longer a Job with this Id.

2028
There is no longer an Operation with this Id.

2029
There is no longer a Manufacturing Order with this Id.

2030
Expedite based on the Plant Stable Span can only be performed from the Gantt View.

2031
Only InternalOperations can be split.

2032
Only activities that have their primary resource requirement clock scheduled can be split.

2033
The PT Interface settings file could not be found, so a blank one was created.
If an Instance doesn't have an Interface Settings file loaded, PlanetTogether will start with a blank one. Any change required will need to be made through the import mappings. 

2034
Problem reading the PT Interface settings file. 
You can edit the file to fix its format or rename or delete it so that the Interface can create a blank file of the correct format. 

2035
At least one Job Alert must be stored for each Job to determine whether a new one needs to be sent.

2036
Data Validation Error: The UsedDuring field of the Primary Resource Requirement must be greater than or equal to the Helper Resource Requirements. 
The Primary Resource Requirement is used to calculate the length of different stages of production, so the primary resource requirement's UsedDuring must be greater than or equal to all the UsedDuring values of all the helper resources, so the length of different phases of an operation can be calculated correctly.

2037
A cycle appears to exist in this Path for the Manufacturing Order.

2038
This is not a valid old UDF Type Name.
Valid data types are String, Int, Long, Double, Decimal, DateTime, and Bool.

2039
The user field data value does not match the specified type.
When adding a UDF, the value must have the data type specified.

2040
The specified value is not the correct type. Instead, it must be one of the following: string, int, long, double, decimal, bool, or DateTime.
UDFs only accept the data type mentioned in error; please verify that the value matches one of them.

2041
Input string contains more than the maximum of two space-separated values.

2042
Input string contains one value that is not a time or day.
This means that the field requires DateTime data type values. First, check to see that all values have the correct format. 

2043
GanttRowHeightFactor must be between 1 and 10, inclusive.

2044
Must specify at least 1 for the Number of Resources. 

2045
Transmission error. {0} has been specified more than once.

2046
Invalid DbCommand object type.

2048
The Required Property in the table for the Transmission is null.

2049
InternalActivityUpdateT contains no ActivityStatusUpdate objects. It must contain at least one.

2050
Invalid value. NbrOfPeople must be greater than zero.
In the Job Dialog Operation | Status tab, the Nbr of People field must be greater than zero. 

Error Codes 2051 - 2100

Error Code
Description
Solution

2051
An Item's transfer quantity cannot be less than 0.
The Transfer Quantity value of the item must be equal to t or greater than 0.

2052
An item with ExternalId '{0}' has a non-positive BatchSize.
The Batch Size value of the item must be equal to or greater than 0.

2053
An item with ExternalId '{0}' has negative MinNbrBatches.
The Min Batch Size value of the item must be equal to or greater than 0.

2054
An item with ExternalId '{0}' has non-positive MaxNbrBatches.
The Max Batch Size value of the item must be equal to or greater than 0.

2055
An item with ExternalId '{0}' has a non-positive BatchWindow.
The Batch Window value of the item must be equal to or greater than zero.

2056
 MaxNbrBatches."}">Item with ExternalId '{0}' has MinNbrBatches > MaxNbrBatches.
The MinNbrBatches value cannot be greater than the MaxNbrBatches value. 

2057
An item with ExternalId '{0}' has a JobAutoSplitQty that's less than the MinOrderQty.

2058
You cannot add an operation more than once to an alternate path. Path {0} already contains Operation {1}.

2059
Operation {0} already contains a Material Requirement with ExternalId '{1}' and ItemExternalId '{2}'.

2060
Operation {0} already contains a Product with ExternalId '{1}'.
This error indicates that a product is being duplicated in the job.

2061
Operation {0} already has Operation {1} as its predecessor. It can't be added again.
When establishing predecessor and successor operations, the same operation cannot be added twice.

2062
Operation '{0}' Required Finish Quantity is {1}. It must be greater than z</div>
        </section>
      
  </main>
  
  <footer class="footer">
    <p>PlanetTogether Knowledge Base - Generated from HubSpot KB Import</p>
    <p>Total Articles: 184 | Categories: 45</p>
  </footer>
</body>
</html>